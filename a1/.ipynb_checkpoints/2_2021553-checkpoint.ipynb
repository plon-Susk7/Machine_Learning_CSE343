{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85fb8f4e-df3d-4d92-91c9-b9603a6d3399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8aef4f13-1e05-40c2-83cd-c6ab750f4d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "906f29cf-6bed-4da7-b095-d48eef43ee73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definding our x and y values respectively\n",
    "\n",
    "x = data.drop(['Outcome'],axis =1)\n",
    "y = data['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb1cc93a-b1e8-44ff-8c54-f302f68e81aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x:  (768, 8)\n",
      "Shape of y:  (768,)\n"
     ]
    }
   ],
   "source": [
    "#Converting to numpy array to feed into model\n",
    "\n",
    "x = x.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "print(\"Shape of x: \",x.shape)\n",
    "print(\"Shape of y: \",y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6c95767-6e2c-469a-ac0a-c9508e34f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperating data into training testing and validation set 70:20:10 (train:test:val)\n",
    "\n",
    "train = int(0.7*768)\n",
    "test = int(0.2*768)\n",
    "val = 768 - train - test \n",
    "\n",
    "train_x = x[0:train]\n",
    "train_y = y[0:train]\n",
    "\n",
    "test_x = x[train:test+train]\n",
    "test_y = y[train:test+train]\n",
    "\n",
    "val_x = x[train+test:]\n",
    "val_y = y[train+test:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1af05ad-261d-4931-8b3f-18552e1667bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "\n",
    "    def __init__(self, learning_rate, epochs):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.b = 0.01\n",
    "        self.epochs = epochs\n",
    "        self.w = np.ones(x.shape[1])\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return np.where(z >= 0, 1 / (1 + np.exp(-z)), np.exp(z) / (1 + np.exp(z)))\n",
    "\n",
    "    def forward_pass(self, x):\n",
    "        z = np.dot(x, self.w) + self.b\n",
    "        predictions = self.sigmoid(z)\n",
    "        return predictions\n",
    "\n",
    "    def binary_cross_entropy(self, pred):\n",
    "        loss = -(self.y * np.log(pred + 1e-9) + (1 - self.y) * np.log(1 - pred + 1e-9))\n",
    "        return np.mean(loss)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.n = x.shape[0]\n",
    "        self.loss = []\n",
    "        self.accuracy = []  # Array to store accuracy values\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            predictions = self.forward_pass(x)\n",
    "            dw = (1 / self.n) * np.dot(self.x.T, (predictions - self.y))\n",
    "            db = (1 / self.n) * np.sum(predictions - self.y)\n",
    "\n",
    "            self.w -= self.learning_rate * dw\n",
    "            self.b -= self.learning_rate * db\n",
    "\n",
    "            l = self.binary_cross_entropy(predictions)\n",
    "            self.loss.append(l)\n",
    "\n",
    "            accuracy = self.compute_accuracy(predictions, y)\n",
    "            self.accuracy.append(accuracy)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{self.epochs}, Loss: {l:.4f}, Accuracy: {accuracy:.4f}, Learning Rate: {self.learning_rate:.6f}\")\n",
    "\n",
    "    def compute_accuracy(self, predictions, y):\n",
    "        predicted_labels = np.where(predictions >= 0.5, 1, 0)\n",
    "        correct_predictions = np.sum(predicted_labels == y)\n",
    "        accuracy = correct_predictions / len(y)\n",
    "        return accuracy\n",
    "\n",
    "    def plot(self):\n",
    "        plt.subplot(2,1,1)\n",
    "        plt.plot(lr.loss)\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Loss vs. Iteration')\n",
    "        \n",
    "        \n",
    "        plt.subplot(2,1,2)\n",
    "        plt.plot(lr.accuracy)\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.title('Accuracy vs. Iteration')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def predict(self, data):\n",
    "        z = np.dot(data, self.w) + self.b\n",
    "        predictions = self.sigmoid(z)\n",
    "        return np.where(predictions >= 0.5, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc356ecf-8124-4cbc-b7f4-a4eaca94a416",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5705/2000293060.py:10: RuntimeWarning: overflow encountered in exp\n",
      "  return np.where(z >= 0, 1 / (1 + np.exp(-z)), np.exp(z) / (1 + np.exp(z)))\n",
      "/tmp/ipykernel_5705/2000293060.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.where(z >= 0, 1 / (1 + np.exp(-z)), np.exp(z) / (1 + np.exp(z)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 2/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 3/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 4/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 5/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 6/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 7/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 8/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 9/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 10/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 11/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 12/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 13/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 14/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 15/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 16/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 17/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 18/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 19/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 20/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 21/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 22/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 23/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 24/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 25/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 26/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 27/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 28/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 29/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 30/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 31/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 32/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 33/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 34/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 35/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 36/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 37/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 38/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 39/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 40/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 41/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 42/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 43/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 44/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 45/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 46/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 47/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 48/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 49/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 50/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 51/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 52/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 53/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 54/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 55/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 56/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 57/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 58/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 59/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 60/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 61/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 62/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 63/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 64/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 65/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 66/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 67/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 68/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 69/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 70/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 71/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 72/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 73/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 74/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 75/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 76/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 77/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 78/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 79/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 80/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 81/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 82/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 83/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 84/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 85/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 86/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 87/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 88/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 89/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 90/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 91/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 92/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 93/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 94/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 95/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 96/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 97/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 98/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 99/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 100/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 101/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 102/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 103/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 104/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 105/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 106/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 107/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 108/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 109/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 110/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 111/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 112/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 113/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 114/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 115/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 116/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 117/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 118/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 119/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 120/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 121/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 122/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 123/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 124/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 125/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 126/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 127/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 128/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 129/10000, Loss: 13.4295, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 130/10000, Loss: 13.4295, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 131/10000, Loss: 13.4294, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 132/10000, Loss: 13.4292, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 133/10000, Loss: 13.4290, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 134/10000, Loss: 13.4285, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 135/10000, Loss: 13.4276, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 136/10000, Loss: 13.4263, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 137/10000, Loss: 13.4244, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 138/10000, Loss: 13.4219, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 139/10000, Loss: 13.4186, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 140/10000, Loss: 13.4148, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 141/10000, Loss: 13.4106, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 142/10000, Loss: 13.4061, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 143/10000, Loss: 13.4013, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 144/10000, Loss: 13.3963, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 145/10000, Loss: 13.3909, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 146/10000, Loss: 13.3848, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 147/10000, Loss: 13.3782, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 148/10000, Loss: 13.3710, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 149/10000, Loss: 13.3635, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 150/10000, Loss: 13.3558, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 151/10000, Loss: 13.3480, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 152/10000, Loss: 13.3402, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 153/10000, Loss: 13.3324, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 154/10000, Loss: 13.3245, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 155/10000, Loss: 13.3166, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 156/10000, Loss: 13.3085, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 157/10000, Loss: 13.3003, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 158/10000, Loss: 13.2917, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 159/10000, Loss: 13.2825, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 160/10000, Loss: 13.2726, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 161/10000, Loss: 13.2623, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 162/10000, Loss: 13.2516, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 163/10000, Loss: 13.2408, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 164/10000, Loss: 13.2300, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 165/10000, Loss: 13.2194, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 166/10000, Loss: 13.2089, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 167/10000, Loss: 13.1987, Accuracy: 0.3538, Learning Rate: 0.000100\n",
      "Epoch 168/10000, Loss: 13.1884, Accuracy: 0.3538, Learning Rate: 0.000100\n",
      "Epoch 169/10000, Loss: 13.1780, Accuracy: 0.3557, Learning Rate: 0.000100\n",
      "Epoch 170/10000, Loss: 13.1676, Accuracy: 0.3575, Learning Rate: 0.000100\n",
      "Epoch 171/10000, Loss: 13.1577, Accuracy: 0.3575, Learning Rate: 0.000100\n",
      "Epoch 172/10000, Loss: 13.1479, Accuracy: 0.3594, Learning Rate: 0.000100\n",
      "Epoch 173/10000, Loss: 13.1370, Accuracy: 0.3631, Learning Rate: 0.000100\n",
      "Epoch 174/10000, Loss: 13.1239, Accuracy: 0.3631, Learning Rate: 0.000100\n",
      "Epoch 175/10000, Loss: 13.1075, Accuracy: 0.3631, Learning Rate: 0.000100\n",
      "Epoch 176/10000, Loss: 13.0873, Accuracy: 0.3631, Learning Rate: 0.000100\n",
      "Epoch 177/10000, Loss: 13.0626, Accuracy: 0.3613, Learning Rate: 0.000100\n",
      "Epoch 178/10000, Loss: 13.0332, Accuracy: 0.3613, Learning Rate: 0.000100\n",
      "Epoch 179/10000, Loss: 12.9988, Accuracy: 0.3594, Learning Rate: 0.000100\n",
      "Epoch 180/10000, Loss: 12.9581, Accuracy: 0.3594, Learning Rate: 0.000100\n",
      "Epoch 181/10000, Loss: 12.9102, Accuracy: 0.3594, Learning Rate: 0.000100\n",
      "Epoch 182/10000, Loss: 12.8560, Accuracy: 0.3594, Learning Rate: 0.000100\n",
      "Epoch 183/10000, Loss: 12.7971, Accuracy: 0.3594, Learning Rate: 0.000100\n",
      "Epoch 184/10000, Loss: 12.7349, Accuracy: 0.3594, Learning Rate: 0.000100\n",
      "Epoch 185/10000, Loss: 12.6707, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 186/10000, Loss: 12.6042, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 187/10000, Loss: 12.5342, Accuracy: 0.3501, Learning Rate: 0.000100\n",
      "Epoch 188/10000, Loss: 12.4600, Accuracy: 0.3482, Learning Rate: 0.000100\n",
      "Epoch 189/10000, Loss: 12.3789, Accuracy: 0.3464, Learning Rate: 0.000100\n",
      "Epoch 190/10000, Loss: 12.2880, Accuracy: 0.3464, Learning Rate: 0.000100\n",
      "Epoch 191/10000, Loss: 12.1870, Accuracy: 0.3482, Learning Rate: 0.000100\n",
      "Epoch 192/10000, Loss: 12.0790, Accuracy: 0.3482, Learning Rate: 0.000100\n",
      "Epoch 193/10000, Loss: 11.9688, Accuracy: 0.3445, Learning Rate: 0.000100\n",
      "Epoch 194/10000, Loss: 11.8588, Accuracy: 0.3464, Learning Rate: 0.000100\n",
      "Epoch 195/10000, Loss: 11.7468, Accuracy: 0.3464, Learning Rate: 0.000100\n",
      "Epoch 196/10000, Loss: 11.6303, Accuracy: 0.3557, Learning Rate: 0.000100\n",
      "Epoch 197/10000, Loss: 11.5083, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 198/10000, Loss: 11.3797, Accuracy: 0.3557, Learning Rate: 0.000100\n",
      "Epoch 199/10000, Loss: 11.2444, Accuracy: 0.3575, Learning Rate: 0.000100\n",
      "Epoch 200/10000, Loss: 11.1014, Accuracy: 0.3557, Learning Rate: 0.000100\n",
      "Epoch 201/10000, Loss: 10.9498, Accuracy: 0.3538, Learning Rate: 0.000100\n",
      "Epoch 202/10000, Loss: 10.7939, Accuracy: 0.3538, Learning Rate: 0.000100\n",
      "Epoch 203/10000, Loss: 10.6377, Accuracy: 0.3613, Learning Rate: 0.000100\n",
      "Epoch 204/10000, Loss: 10.4826, Accuracy: 0.3687, Learning Rate: 0.000100\n",
      "Epoch 205/10000, Loss: 10.3303, Accuracy: 0.3724, Learning Rate: 0.000100\n",
      "Epoch 206/10000, Loss: 10.1815, Accuracy: 0.3780, Learning Rate: 0.000100\n",
      "Epoch 207/10000, Loss: 10.0361, Accuracy: 0.3780, Learning Rate: 0.000100\n",
      "Epoch 208/10000, Loss: 9.8954, Accuracy: 0.3818, Learning Rate: 0.000100\n",
      "Epoch 209/10000, Loss: 9.7601, Accuracy: 0.3855, Learning Rate: 0.000100\n",
      "Epoch 210/10000, Loss: 9.6247, Accuracy: 0.3836, Learning Rate: 0.000100\n",
      "Epoch 211/10000, Loss: 9.4839, Accuracy: 0.3855, Learning Rate: 0.000100\n",
      "Epoch 212/10000, Loss: 9.3365, Accuracy: 0.3892, Learning Rate: 0.000100\n",
      "Epoch 213/10000, Loss: 9.1826, Accuracy: 0.3836, Learning Rate: 0.000100\n",
      "Epoch 214/10000, Loss: 9.0216, Accuracy: 0.3855, Learning Rate: 0.000100\n",
      "Epoch 215/10000, Loss: 8.8585, Accuracy: 0.3873, Learning Rate: 0.000100\n",
      "Epoch 216/10000, Loss: 8.6984, Accuracy: 0.3985, Learning Rate: 0.000100\n",
      "Epoch 217/10000, Loss: 8.5445, Accuracy: 0.4022, Learning Rate: 0.000100\n",
      "Epoch 218/10000, Loss: 8.3995, Accuracy: 0.4078, Learning Rate: 0.000100\n",
      "Epoch 219/10000, Loss: 8.2638, Accuracy: 0.4097, Learning Rate: 0.000100\n",
      "Epoch 220/10000, Loss: 8.1376, Accuracy: 0.4153, Learning Rate: 0.000100\n",
      "Epoch 221/10000, Loss: 8.0184, Accuracy: 0.4190, Learning Rate: 0.000100\n",
      "Epoch 222/10000, Loss: 7.9076, Accuracy: 0.4190, Learning Rate: 0.000100\n",
      "Epoch 223/10000, Loss: 7.8045, Accuracy: 0.4246, Learning Rate: 0.000100\n",
      "Epoch 224/10000, Loss: 7.7086, Accuracy: 0.4246, Learning Rate: 0.000100\n",
      "Epoch 225/10000, Loss: 7.6208, Accuracy: 0.4227, Learning Rate: 0.000100\n",
      "Epoch 226/10000, Loss: 7.5413, Accuracy: 0.4246, Learning Rate: 0.000100\n",
      "Epoch 227/10000, Loss: 7.4702, Accuracy: 0.4358, Learning Rate: 0.000100\n",
      "Epoch 228/10000, Loss: 7.4074, Accuracy: 0.4376, Learning Rate: 0.000100\n",
      "Epoch 229/10000, Loss: 7.3529, Accuracy: 0.4413, Learning Rate: 0.000100\n",
      "Epoch 230/10000, Loss: 7.3062, Accuracy: 0.4451, Learning Rate: 0.000100\n",
      "Epoch 231/10000, Loss: 7.2649, Accuracy: 0.4469, Learning Rate: 0.000100\n",
      "Epoch 232/10000, Loss: 7.2273, Accuracy: 0.4544, Learning Rate: 0.000100\n",
      "Epoch 233/10000, Loss: 7.1926, Accuracy: 0.4581, Learning Rate: 0.000100\n",
      "Epoch 234/10000, Loss: 7.1603, Accuracy: 0.4618, Learning Rate: 0.000100\n",
      "Epoch 235/10000, Loss: 7.1304, Accuracy: 0.4655, Learning Rate: 0.000100\n",
      "Epoch 236/10000, Loss: 7.1029, Accuracy: 0.4674, Learning Rate: 0.000100\n",
      "Epoch 237/10000, Loss: 7.0779, Accuracy: 0.4674, Learning Rate: 0.000100\n",
      "Epoch 238/10000, Loss: 7.0552, Accuracy: 0.4693, Learning Rate: 0.000100\n",
      "Epoch 239/10000, Loss: 7.0345, Accuracy: 0.4711, Learning Rate: 0.000100\n",
      "Epoch 240/10000, Loss: 7.0156, Accuracy: 0.4749, Learning Rate: 0.000100\n",
      "Epoch 241/10000, Loss: 6.9982, Accuracy: 0.4823, Learning Rate: 0.000100\n",
      "Epoch 242/10000, Loss: 6.9823, Accuracy: 0.4804, Learning Rate: 0.000100\n",
      "Epoch 243/10000, Loss: 6.9677, Accuracy: 0.4823, Learning Rate: 0.000100\n",
      "Epoch 244/10000, Loss: 6.9542, Accuracy: 0.4823, Learning Rate: 0.000100\n",
      "Epoch 245/10000, Loss: 6.9417, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 246/10000, Loss: 6.9300, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 247/10000, Loss: 6.9191, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 248/10000, Loss: 6.9088, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 249/10000, Loss: 6.8991, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 250/10000, Loss: 6.8899, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 251/10000, Loss: 6.8811, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 252/10000, Loss: 6.8728, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 253/10000, Loss: 6.8648, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 254/10000, Loss: 6.8571, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 255/10000, Loss: 6.8497, Accuracy: 0.4767, Learning Rate: 0.000100\n",
      "Epoch 256/10000, Loss: 6.8426, Accuracy: 0.4767, Learning Rate: 0.000100\n",
      "Epoch 257/10000, Loss: 6.8358, Accuracy: 0.4767, Learning Rate: 0.000100\n",
      "Epoch 258/10000, Loss: 6.8291, Accuracy: 0.4749, Learning Rate: 0.000100\n",
      "Epoch 259/10000, Loss: 6.8226, Accuracy: 0.4767, Learning Rate: 0.000100\n",
      "Epoch 260/10000, Loss: 6.8163, Accuracy: 0.4767, Learning Rate: 0.000100\n",
      "Epoch 261/10000, Loss: 6.8101, Accuracy: 0.4767, Learning Rate: 0.000100\n",
      "Epoch 262/10000, Loss: 6.8041, Accuracy: 0.4767, Learning Rate: 0.000100\n",
      "Epoch 263/10000, Loss: 6.7982, Accuracy: 0.4767, Learning Rate: 0.000100\n",
      "Epoch 264/10000, Loss: 6.7925, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 265/10000, Loss: 6.7868, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 266/10000, Loss: 6.7812, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 267/10000, Loss: 6.7758, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 268/10000, Loss: 6.7704, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 269/10000, Loss: 6.7650, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 270/10000, Loss: 6.7598, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 271/10000, Loss: 6.7546, Accuracy: 0.4804, Learning Rate: 0.000100\n",
      "Epoch 272/10000, Loss: 6.7495, Accuracy: 0.4804, Learning Rate: 0.000100\n",
      "Epoch 273/10000, Loss: 6.7444, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 274/10000, Loss: 6.7393, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 275/10000, Loss: 6.7344, Accuracy: 0.4823, Learning Rate: 0.000100\n",
      "Epoch 276/10000, Loss: 6.7294, Accuracy: 0.4823, Learning Rate: 0.000100\n",
      "Epoch 277/10000, Loss: 6.7245, Accuracy: 0.4823, Learning Rate: 0.000100\n",
      "Epoch 278/10000, Loss: 6.7196, Accuracy: 0.4823, Learning Rate: 0.000100\n",
      "Epoch 279/10000, Loss: 6.7148, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 280/10000, Loss: 6.7100, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 281/10000, Loss: 6.7052, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 282/10000, Loss: 6.7005, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 283/10000, Loss: 6.6957, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 284/10000, Loss: 6.6910, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 285/10000, Loss: 6.6863, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 286/10000, Loss: 6.6817, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 287/10000, Loss: 6.6770, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 288/10000, Loss: 6.6724, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 289/10000, Loss: 6.6678, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 290/10000, Loss: 6.6632, Accuracy: 0.4823, Learning Rate: 0.000100\n",
      "Epoch 291/10000, Loss: 6.6586, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 292/10000, Loss: 6.6540, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 293/10000, Loss: 6.6495, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 294/10000, Loss: 6.6449, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 295/10000, Loss: 6.6404, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 296/10000, Loss: 6.6359, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 297/10000, Loss: 6.6314, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 298/10000, Loss: 6.6269, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 299/10000, Loss: 6.6224, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 300/10000, Loss: 6.6179, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 301/10000, Loss: 6.6134, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 302/10000, Loss: 6.6089, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 303/10000, Loss: 6.6045, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 304/10000, Loss: 6.6000, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 305/10000, Loss: 6.5956, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 306/10000, Loss: 6.5911, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 307/10000, Loss: 6.5867, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 308/10000, Loss: 6.5822, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 309/10000, Loss: 6.5778, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 310/10000, Loss: 6.5734, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 311/10000, Loss: 6.5690, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 312/10000, Loss: 6.5646, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 313/10000, Loss: 6.5602, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 314/10000, Loss: 6.5558, Accuracy: 0.4879, Learning Rate: 0.000100\n",
      "Epoch 315/10000, Loss: 6.5514, Accuracy: 0.4879, Learning Rate: 0.000100\n",
      "Epoch 316/10000, Loss: 6.5470, Accuracy: 0.4879, Learning Rate: 0.000100\n",
      "Epoch 317/10000, Loss: 6.5426, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 318/10000, Loss: 6.5382, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 319/10000, Loss: 6.5338, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 320/10000, Loss: 6.5294, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 321/10000, Loss: 6.5250, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 322/10000, Loss: 6.5207, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 323/10000, Loss: 6.5163, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 324/10000, Loss: 6.5119, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 325/10000, Loss: 6.5076, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 326/10000, Loss: 6.5032, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 327/10000, Loss: 6.4988, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 328/10000, Loss: 6.4945, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 329/10000, Loss: 6.4901, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 330/10000, Loss: 6.4858, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 331/10000, Loss: 6.4814, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 332/10000, Loss: 6.4771, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 333/10000, Loss: 6.4728, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 334/10000, Loss: 6.4684, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 335/10000, Loss: 6.4641, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 336/10000, Loss: 6.4597, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 337/10000, Loss: 6.4554, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 338/10000, Loss: 6.4511, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 339/10000, Loss: 6.4467, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 340/10000, Loss: 6.4424, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 341/10000, Loss: 6.4381, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 342/10000, Loss: 6.4338, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 343/10000, Loss: 6.4294, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 344/10000, Loss: 6.4251, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 345/10000, Loss: 6.4208, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 346/10000, Loss: 6.4165, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 347/10000, Loss: 6.4122, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 348/10000, Loss: 6.4079, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 349/10000, Loss: 6.4035, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 350/10000, Loss: 6.3992, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 351/10000, Loss: 6.3949, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 352/10000, Loss: 6.3906, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 353/10000, Loss: 6.3863, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 354/10000, Loss: 6.3820, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 355/10000, Loss: 6.3777, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 356/10000, Loss: 6.3734, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 357/10000, Loss: 6.3691, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 358/10000, Loss: 6.3648, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 359/10000, Loss: 6.3605, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 360/10000, Loss: 6.3562, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 361/10000, Loss: 6.3519, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 362/10000, Loss: 6.3476, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 363/10000, Loss: 6.3433, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 364/10000, Loss: 6.3390, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 365/10000, Loss: 6.3347, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 366/10000, Loss: 6.3305, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 367/10000, Loss: 6.3262, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 368/10000, Loss: 6.3219, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 369/10000, Loss: 6.3176, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 370/10000, Loss: 6.3133, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 371/10000, Loss: 6.3090, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 372/10000, Loss: 6.3047, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 373/10000, Loss: 6.3004, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 374/10000, Loss: 6.2962, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 375/10000, Loss: 6.2919, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 376/10000, Loss: 6.2876, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 377/10000, Loss: 6.2833, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 378/10000, Loss: 6.2790, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 379/10000, Loss: 6.2747, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 380/10000, Loss: 6.2705, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 381/10000, Loss: 6.2662, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 382/10000, Loss: 6.2619, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 383/10000, Loss: 6.2576, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 384/10000, Loss: 6.2533, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 385/10000, Loss: 6.2490, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 386/10000, Loss: 6.2447, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 387/10000, Loss: 6.2405, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 388/10000, Loss: 6.2362, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 389/10000, Loss: 6.2319, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 390/10000, Loss: 6.2276, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 391/10000, Loss: 6.2233, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 392/10000, Loss: 6.2190, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 393/10000, Loss: 6.2147, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 394/10000, Loss: 6.2104, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 395/10000, Loss: 6.2061, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 396/10000, Loss: 6.2018, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 397/10000, Loss: 6.1975, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 398/10000, Loss: 6.1932, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 399/10000, Loss: 6.1889, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 400/10000, Loss: 6.1846, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 401/10000, Loss: 6.1803, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 402/10000, Loss: 6.1760, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 403/10000, Loss: 6.1717, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 404/10000, Loss: 6.1674, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 405/10000, Loss: 6.1631, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 406/10000, Loss: 6.1588, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 407/10000, Loss: 6.1545, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 408/10000, Loss: 6.1502, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 409/10000, Loss: 6.1458, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 410/10000, Loss: 6.1415, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 411/10000, Loss: 6.1372, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 412/10000, Loss: 6.1329, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 413/10000, Loss: 6.1285, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 414/10000, Loss: 6.1242, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 415/10000, Loss: 6.1199, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 416/10000, Loss: 6.1156, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 417/10000, Loss: 6.1112, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 418/10000, Loss: 6.1069, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 419/10000, Loss: 6.1025, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 420/10000, Loss: 6.0982, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 421/10000, Loss: 6.0938, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 422/10000, Loss: 6.0895, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 423/10000, Loss: 6.0852, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 424/10000, Loss: 6.0808, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 425/10000, Loss: 6.0764, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 426/10000, Loss: 6.0721, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 427/10000, Loss: 6.0677, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 428/10000, Loss: 6.0634, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 429/10000, Loss: 6.0590, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 430/10000, Loss: 6.0547, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 431/10000, Loss: 6.0503, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 432/10000, Loss: 6.0459, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 433/10000, Loss: 6.0415, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 434/10000, Loss: 6.0372, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 435/10000, Loss: 6.0328, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 436/10000, Loss: 6.0284, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 437/10000, Loss: 6.0241, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 438/10000, Loss: 6.0197, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 439/10000, Loss: 6.0153, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 440/10000, Loss: 6.0109, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 441/10000, Loss: 6.0065, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 442/10000, Loss: 6.0021, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 443/10000, Loss: 5.9978, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 444/10000, Loss: 5.9934, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 445/10000, Loss: 5.9890, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 446/10000, Loss: 5.9846, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 447/10000, Loss: 5.9802, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 448/10000, Loss: 5.9758, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 449/10000, Loss: 5.9714, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 450/10000, Loss: 5.9670, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 451/10000, Loss: 5.9626, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 452/10000, Loss: 5.9582, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 453/10000, Loss: 5.9538, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 454/10000, Loss: 5.9494, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 455/10000, Loss: 5.9450, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 456/10000, Loss: 5.9406, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 457/10000, Loss: 5.9362, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 458/10000, Loss: 5.9317, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 459/10000, Loss: 5.9273, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 460/10000, Loss: 5.9229, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 461/10000, Loss: 5.9185, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 462/10000, Loss: 5.9141, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 463/10000, Loss: 5.9096, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 464/10000, Loss: 5.9052, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 465/10000, Loss: 5.9008, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 466/10000, Loss: 5.8963, Accuracy: 0.4991, Learning Rate: 0.000100\n",
      "Epoch 467/10000, Loss: 5.8919, Accuracy: 0.4991, Learning Rate: 0.000100\n",
      "Epoch 468/10000, Loss: 5.8875, Accuracy: 0.4991, Learning Rate: 0.000100\n",
      "Epoch 469/10000, Loss: 5.8830, Accuracy: 0.4991, Learning Rate: 0.000100\n",
      "Epoch 470/10000, Loss: 5.8786, Accuracy: 0.4991, Learning Rate: 0.000100\n",
      "Epoch 471/10000, Loss: 5.8742, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 472/10000, Loss: 5.8697, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 473/10000, Loss: 5.8653, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 474/10000, Loss: 5.8608, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 475/10000, Loss: 5.8564, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 476/10000, Loss: 5.8519, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 477/10000, Loss: 5.8474, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 478/10000, Loss: 5.8430, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 479/10000, Loss: 5.8385, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 480/10000, Loss: 5.8341, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 481/10000, Loss: 5.8296, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 482/10000, Loss: 5.8251, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 483/10000, Loss: 5.8207, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 484/10000, Loss: 5.8162, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 485/10000, Loss: 5.8117, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 486/10000, Loss: 5.8072, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 487/10000, Loss: 5.8028, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 488/10000, Loss: 5.7983, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 489/10000, Loss: 5.7938, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 490/10000, Loss: 5.7893, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 491/10000, Loss: 5.7848, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 492/10000, Loss: 5.7803, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 493/10000, Loss: 5.7758, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 494/10000, Loss: 5.7713, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 495/10000, Loss: 5.7669, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 496/10000, Loss: 5.7624, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 497/10000, Loss: 5.7579, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 498/10000, Loss: 5.7534, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 499/10000, Loss: 5.7489, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 500/10000, Loss: 5.7443, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 501/10000, Loss: 5.7398, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 502/10000, Loss: 5.7353, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 503/10000, Loss: 5.7308, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 504/10000, Loss: 5.7263, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 505/10000, Loss: 5.7218, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 506/10000, Loss: 5.7173, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 507/10000, Loss: 5.7128, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 508/10000, Loss: 5.7082, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 509/10000, Loss: 5.7037, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 510/10000, Loss: 5.6992, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 511/10000, Loss: 5.6947, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 512/10000, Loss: 5.6901, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 513/10000, Loss: 5.6856, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 514/10000, Loss: 5.6811, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 515/10000, Loss: 5.6765, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 516/10000, Loss: 5.6720, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 517/10000, Loss: 5.6675, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 518/10000, Loss: 5.6629, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 519/10000, Loss: 5.6584, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 520/10000, Loss: 5.6538, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 521/10000, Loss: 5.6493, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 522/10000, Loss: 5.6447, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 523/10000, Loss: 5.6402, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 524/10000, Loss: 5.6356, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 525/10000, Loss: 5.6310, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 526/10000, Loss: 5.6265, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 527/10000, Loss: 5.6219, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 528/10000, Loss: 5.6174, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 529/10000, Loss: 5.6128, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 530/10000, Loss: 5.6082, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 531/10000, Loss: 5.6036, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 532/10000, Loss: 5.5991, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 533/10000, Loss: 5.5945, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 534/10000, Loss: 5.5899, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 535/10000, Loss: 5.5853, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 536/10000, Loss: 5.5808, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 537/10000, Loss: 5.5762, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 538/10000, Loss: 5.5716, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 539/10000, Loss: 5.5670, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 540/10000, Loss: 5.5624, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 541/10000, Loss: 5.5578, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 542/10000, Loss: 5.5532, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 543/10000, Loss: 5.5486, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 544/10000, Loss: 5.5440, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 545/10000, Loss: 5.5394, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 546/10000, Loss: 5.5348, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 547/10000, Loss: 5.5302, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 548/10000, Loss: 5.5256, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 549/10000, Loss: 5.5210, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 550/10000, Loss: 5.5164, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 551/10000, Loss: 5.5118, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 552/10000, Loss: 5.5072, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 553/10000, Loss: 5.5026, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 554/10000, Loss: 5.4980, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 555/10000, Loss: 5.4934, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 556/10000, Loss: 5.4888, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 557/10000, Loss: 5.4841, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 558/10000, Loss: 5.4795, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 559/10000, Loss: 5.4749, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 560/10000, Loss: 5.4703, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 561/10000, Loss: 5.4657, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 562/10000, Loss: 5.4611, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 563/10000, Loss: 5.4564, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 564/10000, Loss: 5.4518, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 565/10000, Loss: 5.4472, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 566/10000, Loss: 5.4426, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 567/10000, Loss: 5.4380, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 568/10000, Loss: 5.4333, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 569/10000, Loss: 5.4287, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 570/10000, Loss: 5.4241, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 571/10000, Loss: 5.4195, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 572/10000, Loss: 5.4148, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 573/10000, Loss: 5.4102, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 574/10000, Loss: 5.4056, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 575/10000, Loss: 5.4009, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 576/10000, Loss: 5.3963, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 577/10000, Loss: 5.3917, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 578/10000, Loss: 5.3871, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 579/10000, Loss: 5.3824, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 580/10000, Loss: 5.3778, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 581/10000, Loss: 5.3732, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 582/10000, Loss: 5.3685, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 583/10000, Loss: 5.3639, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 584/10000, Loss: 5.3593, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 585/10000, Loss: 5.3546, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 586/10000, Loss: 5.3500, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 587/10000, Loss: 5.3453, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 588/10000, Loss: 5.3407, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 589/10000, Loss: 5.3361, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 590/10000, Loss: 5.3314, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 591/10000, Loss: 5.3268, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 592/10000, Loss: 5.3221, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 593/10000, Loss: 5.3175, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 594/10000, Loss: 5.3128, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 595/10000, Loss: 5.3082, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 596/10000, Loss: 5.3035, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 597/10000, Loss: 5.2989, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 598/10000, Loss: 5.2942, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 599/10000, Loss: 5.2896, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 600/10000, Loss: 5.2849, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 601/10000, Loss: 5.2803, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 602/10000, Loss: 5.2756, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 603/10000, Loss: 5.2710, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 604/10000, Loss: 5.2663, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 605/10000, Loss: 5.2616, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 606/10000, Loss: 5.2570, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 607/10000, Loss: 5.2523, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 608/10000, Loss: 5.2476, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 609/10000, Loss: 5.2430, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 610/10000, Loss: 5.2383, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 611/10000, Loss: 5.2336, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 612/10000, Loss: 5.2289, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 613/10000, Loss: 5.2243, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 614/10000, Loss: 5.2196, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 615/10000, Loss: 5.2149, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 616/10000, Loss: 5.2102, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 617/10000, Loss: 5.2055, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 618/10000, Loss: 5.2008, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 619/10000, Loss: 5.1961, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 620/10000, Loss: 5.1914, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 621/10000, Loss: 5.1867, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 622/10000, Loss: 5.1820, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 623/10000, Loss: 5.1773, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 624/10000, Loss: 5.1726, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 625/10000, Loss: 5.1679, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 626/10000, Loss: 5.1632, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 627/10000, Loss: 5.1585, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 628/10000, Loss: 5.1538, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 629/10000, Loss: 5.1491, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 630/10000, Loss: 5.1443, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 631/10000, Loss: 5.1396, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 632/10000, Loss: 5.1349, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 633/10000, Loss: 5.1302, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 634/10000, Loss: 5.1254, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 635/10000, Loss: 5.1207, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 636/10000, Loss: 5.1160, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 637/10000, Loss: 5.1112, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 638/10000, Loss: 5.1065, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 639/10000, Loss: 5.1017, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 640/10000, Loss: 5.0970, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 641/10000, Loss: 5.0922, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 642/10000, Loss: 5.0875, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 643/10000, Loss: 5.0827, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 644/10000, Loss: 5.0780, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 645/10000, Loss: 5.0732, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 646/10000, Loss: 5.0684, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 647/10000, Loss: 5.0637, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 648/10000, Loss: 5.0589, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 649/10000, Loss: 5.0541, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 650/10000, Loss: 5.0494, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 651/10000, Loss: 5.0446, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 652/10000, Loss: 5.0398, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 653/10000, Loss: 5.0350, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 654/10000, Loss: 5.0303, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 655/10000, Loss: 5.0255, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 656/10000, Loss: 5.0207, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 657/10000, Loss: 5.0159, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 658/10000, Loss: 5.0111, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 659/10000, Loss: 5.0063, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 660/10000, Loss: 5.0015, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 661/10000, Loss: 4.9967, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 662/10000, Loss: 4.9919, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 663/10000, Loss: 4.9871, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 664/10000, Loss: 4.9823, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 665/10000, Loss: 4.9775, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 666/10000, Loss: 4.9727, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 667/10000, Loss: 4.9679, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 668/10000, Loss: 4.9630, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 669/10000, Loss: 4.9582, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 670/10000, Loss: 4.9534, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 671/10000, Loss: 4.9486, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 672/10000, Loss: 4.9437, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 673/10000, Loss: 4.9389, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 674/10000, Loss: 4.9341, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 675/10000, Loss: 4.9292, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 676/10000, Loss: 4.9244, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 677/10000, Loss: 4.9196, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 678/10000, Loss: 4.9147, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 679/10000, Loss: 4.9099, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 680/10000, Loss: 4.9050, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 681/10000, Loss: 4.9002, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 682/10000, Loss: 4.8953, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 683/10000, Loss: 4.8904, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 684/10000, Loss: 4.8856, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 685/10000, Loss: 4.8807, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 686/10000, Loss: 4.8758, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 687/10000, Loss: 4.8710, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 688/10000, Loss: 4.8661, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 689/10000, Loss: 4.8612, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 690/10000, Loss: 4.8563, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 691/10000, Loss: 4.8514, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 692/10000, Loss: 4.8466, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 693/10000, Loss: 4.8417, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 694/10000, Loss: 4.8368, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 695/10000, Loss: 4.8319, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 696/10000, Loss: 4.8270, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 697/10000, Loss: 4.8221, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 698/10000, Loss: 4.8172, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 699/10000, Loss: 4.8123, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 700/10000, Loss: 4.8074, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 701/10000, Loss: 4.8024, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 702/10000, Loss: 4.7975, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 703/10000, Loss: 4.7926, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 704/10000, Loss: 4.7877, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 705/10000, Loss: 4.7828, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 706/10000, Loss: 4.7778, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 707/10000, Loss: 4.7729, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 708/10000, Loss: 4.7680, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 709/10000, Loss: 4.7631, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 710/10000, Loss: 4.7581, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 711/10000, Loss: 4.7532, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 712/10000, Loss: 4.7482, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 713/10000, Loss: 4.7433, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 714/10000, Loss: 4.7384, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 715/10000, Loss: 4.7334, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 716/10000, Loss: 4.7285, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 717/10000, Loss: 4.7235, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 718/10000, Loss: 4.7186, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 719/10000, Loss: 4.7136, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 720/10000, Loss: 4.7086, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 721/10000, Loss: 4.7037, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 722/10000, Loss: 4.6987, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 723/10000, Loss: 4.6938, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 724/10000, Loss: 4.6888, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 725/10000, Loss: 4.6838, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 726/10000, Loss: 4.6789, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 727/10000, Loss: 4.6739, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 728/10000, Loss: 4.6689, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 729/10000, Loss: 4.6640, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 730/10000, Loss: 4.6590, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 731/10000, Loss: 4.6540, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 732/10000, Loss: 4.6490, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 733/10000, Loss: 4.6441, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 734/10000, Loss: 4.6391, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 735/10000, Loss: 4.6341, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 736/10000, Loss: 4.6291, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 737/10000, Loss: 4.6241, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 738/10000, Loss: 4.6192, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 739/10000, Loss: 4.6142, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 740/10000, Loss: 4.6092, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 741/10000, Loss: 4.6042, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 742/10000, Loss: 4.5992, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 743/10000, Loss: 4.5943, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 744/10000, Loss: 4.5893, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 745/10000, Loss: 4.5843, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 746/10000, Loss: 4.5793, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 747/10000, Loss: 4.5743, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 748/10000, Loss: 4.5693, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 749/10000, Loss: 4.5644, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 750/10000, Loss: 4.5594, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 751/10000, Loss: 4.5544, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 752/10000, Loss: 4.5494, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 753/10000, Loss: 4.5444, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 754/10000, Loss: 4.5395, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 755/10000, Loss: 4.5345, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 756/10000, Loss: 4.5295, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 757/10000, Loss: 4.5245, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 758/10000, Loss: 4.5196, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 759/10000, Loss: 4.5146, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 760/10000, Loss: 4.5096, Accuracy: 0.5196, Learning Rate: 0.000100\n",
      "Epoch 761/10000, Loss: 4.5047, Accuracy: 0.5196, Learning Rate: 0.000100\n",
      "Epoch 762/10000, Loss: 4.4997, Accuracy: 0.5196, Learning Rate: 0.000100\n",
      "Epoch 763/10000, Loss: 4.4947, Accuracy: 0.5196, Learning Rate: 0.000100\n",
      "Epoch 764/10000, Loss: 4.4898, Accuracy: 0.5196, Learning Rate: 0.000100\n",
      "Epoch 765/10000, Loss: 4.4848, Accuracy: 0.5196, Learning Rate: 0.000100\n",
      "Epoch 766/10000, Loss: 4.4799, Accuracy: 0.5196, Learning Rate: 0.000100\n",
      "Epoch 767/10000, Loss: 4.4749, Accuracy: 0.5196, Learning Rate: 0.000100\n",
      "Epoch 768/10000, Loss: 4.4699, Accuracy: 0.5196, Learning Rate: 0.000100\n",
      "Epoch 769/10000, Loss: 4.4650, Accuracy: 0.5214, Learning Rate: 0.000100\n",
      "Epoch 770/10000, Loss: 4.4600, Accuracy: 0.5233, Learning Rate: 0.000100\n",
      "Epoch 771/10000, Loss: 4.4551, Accuracy: 0.5233, Learning Rate: 0.000100\n",
      "Epoch 772/10000, Loss: 4.4502, Accuracy: 0.5233, Learning Rate: 0.000100\n",
      "Epoch 773/10000, Loss: 4.4452, Accuracy: 0.5233, Learning Rate: 0.000100\n",
      "Epoch 774/10000, Loss: 4.4403, Accuracy: 0.5233, Learning Rate: 0.000100\n",
      "Epoch 775/10000, Loss: 4.4354, Accuracy: 0.5233, Learning Rate: 0.000100\n",
      "Epoch 776/10000, Loss: 4.4304, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 777/10000, Loss: 4.4255, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 778/10000, Loss: 4.4206, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 779/10000, Loss: 4.4157, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 780/10000, Loss: 4.4107, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 781/10000, Loss: 4.4058, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 782/10000, Loss: 4.4009, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 783/10000, Loss: 4.3960, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 784/10000, Loss: 4.3911, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 785/10000, Loss: 4.3862, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 786/10000, Loss: 4.3814, Accuracy: 0.5270, Learning Rate: 0.000100\n",
      "Epoch 787/10000, Loss: 4.3765, Accuracy: 0.5270, Learning Rate: 0.000100\n",
      "Epoch 788/10000, Loss: 4.3716, Accuracy: 0.5270, Learning Rate: 0.000100\n",
      "Epoch 789/10000, Loss: 4.3667, Accuracy: 0.5270, Learning Rate: 0.000100\n",
      "Epoch 790/10000, Loss: 4.3618, Accuracy: 0.5270, Learning Rate: 0.000100\n",
      "Epoch 791/10000, Loss: 4.3570, Accuracy: 0.5270, Learning Rate: 0.000100\n",
      "Epoch 792/10000, Loss: 4.3521, Accuracy: 0.5270, Learning Rate: 0.000100\n",
      "Epoch 793/10000, Loss: 4.3473, Accuracy: 0.5289, Learning Rate: 0.000100\n",
      "Epoch 794/10000, Loss: 4.3424, Accuracy: 0.5289, Learning Rate: 0.000100\n",
      "Epoch 795/10000, Loss: 4.3376, Accuracy: 0.5289, Learning Rate: 0.000100\n",
      "Epoch 796/10000, Loss: 4.3327, Accuracy: 0.5289, Learning Rate: 0.000100\n",
      "Epoch 797/10000, Loss: 4.3279, Accuracy: 0.5289, Learning Rate: 0.000100\n",
      "Epoch 798/10000, Loss: 4.3231, Accuracy: 0.5289, Learning Rate: 0.000100\n",
      "Epoch 799/10000, Loss: 4.3183, Accuracy: 0.5289, Learning Rate: 0.000100\n",
      "Epoch 800/10000, Loss: 4.3134, Accuracy: 0.5307, Learning Rate: 0.000100\n",
      "Epoch 801/10000, Loss: 4.3086, Accuracy: 0.5307, Learning Rate: 0.000100\n",
      "Epoch 802/10000, Loss: 4.3038, Accuracy: 0.5307, Learning Rate: 0.000100\n",
      "Epoch 803/10000, Loss: 4.2990, Accuracy: 0.5307, Learning Rate: 0.000100\n",
      "Epoch 804/10000, Loss: 4.2942, Accuracy: 0.5307, Learning Rate: 0.000100\n",
      "Epoch 805/10000, Loss: 4.2895, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 806/10000, Loss: 4.2847, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 807/10000, Loss: 4.2799, Accuracy: 0.5345, Learning Rate: 0.000100\n",
      "Epoch 808/10000, Loss: 4.2751, Accuracy: 0.5345, Learning Rate: 0.000100\n",
      "Epoch 809/10000, Loss: 4.2704, Accuracy: 0.5363, Learning Rate: 0.000100\n",
      "Epoch 810/10000, Loss: 4.2656, Accuracy: 0.5363, Learning Rate: 0.000100\n",
      "Epoch 811/10000, Loss: 4.2609, Accuracy: 0.5363, Learning Rate: 0.000100\n",
      "Epoch 812/10000, Loss: 4.2562, Accuracy: 0.5363, Learning Rate: 0.000100\n",
      "Epoch 813/10000, Loss: 4.2514, Accuracy: 0.5363, Learning Rate: 0.000100\n",
      "Epoch 814/10000, Loss: 4.2467, Accuracy: 0.5345, Learning Rate: 0.000100\n",
      "Epoch 815/10000, Loss: 4.2420, Accuracy: 0.5345, Learning Rate: 0.000100\n",
      "Epoch 816/10000, Loss: 4.2373, Accuracy: 0.5363, Learning Rate: 0.000100\n",
      "Epoch 817/10000, Loss: 4.2326, Accuracy: 0.5363, Learning Rate: 0.000100\n",
      "Epoch 818/10000, Loss: 4.2279, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 819/10000, Loss: 4.2232, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 820/10000, Loss: 4.2185, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 821/10000, Loss: 4.2138, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 822/10000, Loss: 4.2092, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 823/10000, Loss: 4.2045, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 824/10000, Loss: 4.1999, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 825/10000, Loss: 4.1952, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 826/10000, Loss: 4.1906, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 827/10000, Loss: 4.1860, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 828/10000, Loss: 4.1814, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 829/10000, Loss: 4.1768, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 830/10000, Loss: 4.1722, Accuracy: 0.5345, Learning Rate: 0.000100\n",
      "Epoch 831/10000, Loss: 4.1676, Accuracy: 0.5363, Learning Rate: 0.000100\n",
      "Epoch 832/10000, Loss: 4.1630, Accuracy: 0.5363, Learning Rate: 0.000100\n",
      "Epoch 833/10000, Loss: 4.1584, Accuracy: 0.5382, Learning Rate: 0.000100\n",
      "Epoch 834/10000, Loss: 4.1538, Accuracy: 0.5382, Learning Rate: 0.000100\n",
      "Epoch 835/10000, Loss: 4.1493, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 836/10000, Loss: 4.1447, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 837/10000, Loss: 4.1402, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 838/10000, Loss: 4.1356, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 839/10000, Loss: 4.1311, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 840/10000, Loss: 4.1266, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 841/10000, Loss: 4.1221, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 842/10000, Loss: 4.1176, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 843/10000, Loss: 4.1131, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 844/10000, Loss: 4.1086, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 845/10000, Loss: 4.1042, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 846/10000, Loss: 4.0997, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 847/10000, Loss: 4.0952, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 848/10000, Loss: 4.0908, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 849/10000, Loss: 4.0863, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 850/10000, Loss: 4.0819, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 851/10000, Loss: 4.0775, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 852/10000, Loss: 4.0731, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 853/10000, Loss: 4.0687, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 854/10000, Loss: 4.0643, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 855/10000, Loss: 4.0599, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 856/10000, Loss: 4.0555, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 857/10000, Loss: 4.0511, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 858/10000, Loss: 4.0468, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 859/10000, Loss: 4.0424, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 860/10000, Loss: 4.0381, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 861/10000, Loss: 4.0337, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 862/10000, Loss: 4.0294, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 863/10000, Loss: 4.0251, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 864/10000, Loss: 4.0208, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 865/10000, Loss: 4.0164, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 866/10000, Loss: 4.0121, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 867/10000, Loss: 4.0079, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 868/10000, Loss: 4.0036, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 869/10000, Loss: 3.9993, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 870/10000, Loss: 3.9950, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 871/10000, Loss: 3.9908, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 872/10000, Loss: 3.9865, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 873/10000, Loss: 3.9823, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 874/10000, Loss: 3.9780, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 875/10000, Loss: 3.9738, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 876/10000, Loss: 3.9696, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 877/10000, Loss: 3.9654, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 878/10000, Loss: 3.9612, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 879/10000, Loss: 3.9569, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 880/10000, Loss: 3.9528, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 881/10000, Loss: 3.9486, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 882/10000, Loss: 3.9444, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 883/10000, Loss: 3.9402, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 884/10000, Loss: 3.9360, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 885/10000, Loss: 3.9319, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 886/10000, Loss: 3.9277, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 887/10000, Loss: 3.9236, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 888/10000, Loss: 3.9194, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 889/10000, Loss: 3.9153, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 890/10000, Loss: 3.9112, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 891/10000, Loss: 3.9071, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 892/10000, Loss: 3.9029, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 893/10000, Loss: 3.8988, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 894/10000, Loss: 3.8947, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 895/10000, Loss: 3.8906, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 896/10000, Loss: 3.8866, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 897/10000, Loss: 3.8825, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 898/10000, Loss: 3.8784, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 899/10000, Loss: 3.8743, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 900/10000, Loss: 3.8703, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 901/10000, Loss: 3.8662, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 902/10000, Loss: 3.8621, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 903/10000, Loss: 3.8581, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 904/10000, Loss: 3.8540, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 905/10000, Loss: 3.8500, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 906/10000, Loss: 3.8460, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 907/10000, Loss: 3.8420, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 908/10000, Loss: 3.8379, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 909/10000, Loss: 3.8339, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 910/10000, Loss: 3.8299, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 911/10000, Loss: 3.8259, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 912/10000, Loss: 3.8219, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 913/10000, Loss: 3.8179, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 914/10000, Loss: 3.8139, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 915/10000, Loss: 3.8099, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 916/10000, Loss: 3.8060, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 917/10000, Loss: 3.8020, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 918/10000, Loss: 3.7980, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 919/10000, Loss: 3.7941, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 920/10000, Loss: 3.7901, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 921/10000, Loss: 3.7862, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 922/10000, Loss: 3.7822, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 923/10000, Loss: 3.7783, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 924/10000, Loss: 3.7743, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 925/10000, Loss: 3.7704, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 926/10000, Loss: 3.7665, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 927/10000, Loss: 3.7626, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 928/10000, Loss: 3.7586, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 929/10000, Loss: 3.7547, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 930/10000, Loss: 3.7508, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 931/10000, Loss: 3.7469, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 932/10000, Loss: 3.7430, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 933/10000, Loss: 3.7391, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 934/10000, Loss: 3.7353, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 935/10000, Loss: 3.7314, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 936/10000, Loss: 3.7275, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 937/10000, Loss: 3.7236, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 938/10000, Loss: 3.7198, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 939/10000, Loss: 3.7159, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 940/10000, Loss: 3.7121, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 941/10000, Loss: 3.7082, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 942/10000, Loss: 3.7044, Accuracy: 0.5531, Learning Rate: 0.000100\n",
      "Epoch 943/10000, Loss: 3.7005, Accuracy: 0.5531, Learning Rate: 0.000100\n",
      "Epoch 944/10000, Loss: 3.6967, Accuracy: 0.5531, Learning Rate: 0.000100\n",
      "Epoch 945/10000, Loss: 3.6929, Accuracy: 0.5531, Learning Rate: 0.000100\n",
      "Epoch 946/10000, Loss: 3.6890, Accuracy: 0.5531, Learning Rate: 0.000100\n",
      "Epoch 947/10000, Loss: 3.6852, Accuracy: 0.5531, Learning Rate: 0.000100\n",
      "Epoch 948/10000, Loss: 3.6814, Accuracy: 0.5531, Learning Rate: 0.000100\n",
      "Epoch 949/10000, Loss: 3.6776, Accuracy: 0.5531, Learning Rate: 0.000100\n",
      "Epoch 950/10000, Loss: 3.6738, Accuracy: 0.5531, Learning Rate: 0.000100\n",
      "Epoch 951/10000, Loss: 3.6700, Accuracy: 0.5531, Learning Rate: 0.000100\n",
      "Epoch 952/10000, Loss: 3.6662, Accuracy: 0.5531, Learning Rate: 0.000100\n",
      "Epoch 953/10000, Loss: 3.6624, Accuracy: 0.5531, Learning Rate: 0.000100\n",
      "Epoch 954/10000, Loss: 3.6587, Accuracy: 0.5549, Learning Rate: 0.000100\n",
      "Epoch 955/10000, Loss: 3.6549, Accuracy: 0.5549, Learning Rate: 0.000100\n",
      "Epoch 956/10000, Loss: 3.6511, Accuracy: 0.5549, Learning Rate: 0.000100\n",
      "Epoch 957/10000, Loss: 3.6473, Accuracy: 0.5549, Learning Rate: 0.000100\n",
      "Epoch 958/10000, Loss: 3.6436, Accuracy: 0.5549, Learning Rate: 0.000100\n",
      "Epoch 959/10000, Loss: 3.6398, Accuracy: 0.5549, Learning Rate: 0.000100\n",
      "Epoch 960/10000, Loss: 3.6361, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 961/10000, Loss: 3.6323, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 962/10000, Loss: 3.6286, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 963/10000, Loss: 3.6249, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 964/10000, Loss: 3.6211, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 965/10000, Loss: 3.6174, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 966/10000, Loss: 3.6137, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 967/10000, Loss: 3.6100, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 968/10000, Loss: 3.6063, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 969/10000, Loss: 3.6026, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 970/10000, Loss: 3.5989, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 971/10000, Loss: 3.5952, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 972/10000, Loss: 3.5915, Accuracy: 0.5587, Learning Rate: 0.000100\n",
      "Epoch 973/10000, Loss: 3.5878, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 974/10000, Loss: 3.5842, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 975/10000, Loss: 3.5805, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 976/10000, Loss: 3.5768, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 977/10000, Loss: 3.5732, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 978/10000, Loss: 3.5695, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 979/10000, Loss: 3.5659, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 980/10000, Loss: 3.5622, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 981/10000, Loss: 3.5586, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 982/10000, Loss: 3.5550, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 983/10000, Loss: 3.5514, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 984/10000, Loss: 3.5477, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 985/10000, Loss: 3.5441, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 986/10000, Loss: 3.5405, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 987/10000, Loss: 3.5369, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 988/10000, Loss: 3.5333, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 989/10000, Loss: 3.5297, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 990/10000, Loss: 3.5262, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 991/10000, Loss: 3.5226, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 992/10000, Loss: 3.5190, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 993/10000, Loss: 3.5155, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 994/10000, Loss: 3.5119, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 995/10000, Loss: 3.5084, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 996/10000, Loss: 3.5048, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 997/10000, Loss: 3.5013, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 998/10000, Loss: 3.4977, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 999/10000, Loss: 3.4942, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 1000/10000, Loss: 3.4907, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 1001/10000, Loss: 3.4872, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 1002/10000, Loss: 3.4837, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 1003/10000, Loss: 3.4802, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 1004/10000, Loss: 3.4767, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 1005/10000, Loss: 3.4732, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 1006/10000, Loss: 3.4697, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 1007/10000, Loss: 3.4662, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 1008/10000, Loss: 3.4628, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 1009/10000, Loss: 3.4593, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 1010/10000, Loss: 3.4558, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 1011/10000, Loss: 3.4524, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 1012/10000, Loss: 3.4489, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 1013/10000, Loss: 3.4455, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 1014/10000, Loss: 3.4421, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 1015/10000, Loss: 3.4386, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1016/10000, Loss: 3.4352, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1017/10000, Loss: 3.4318, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1018/10000, Loss: 3.4284, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1019/10000, Loss: 3.4250, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1020/10000, Loss: 3.4216, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1021/10000, Loss: 3.4182, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1022/10000, Loss: 3.4148, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1023/10000, Loss: 3.4115, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1024/10000, Loss: 3.4081, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1025/10000, Loss: 3.4047, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1026/10000, Loss: 3.4014, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1027/10000, Loss: 3.3980, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1028/10000, Loss: 3.3947, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1029/10000, Loss: 3.3913, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1030/10000, Loss: 3.3880, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1031/10000, Loss: 3.3847, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1032/10000, Loss: 3.3814, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1033/10000, Loss: 3.3780, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1034/10000, Loss: 3.3747, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1035/10000, Loss: 3.3714, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1036/10000, Loss: 3.3681, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1037/10000, Loss: 3.3648, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1038/10000, Loss: 3.3616, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1039/10000, Loss: 3.3583, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1040/10000, Loss: 3.3550, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1041/10000, Loss: 3.3518, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1042/10000, Loss: 3.3485, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1043/10000, Loss: 3.3452, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1044/10000, Loss: 3.3420, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1045/10000, Loss: 3.3388, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1046/10000, Loss: 3.3355, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1047/10000, Loss: 3.3323, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1048/10000, Loss: 3.3291, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1049/10000, Loss: 3.3259, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1050/10000, Loss: 3.3227, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1051/10000, Loss: 3.3195, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1052/10000, Loss: 3.3163, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1053/10000, Loss: 3.3131, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1054/10000, Loss: 3.3099, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1055/10000, Loss: 3.3067, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1056/10000, Loss: 3.3035, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1057/10000, Loss: 3.3004, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1058/10000, Loss: 3.2972, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1059/10000, Loss: 3.2940, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1060/10000, Loss: 3.2909, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1061/10000, Loss: 3.2877, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1062/10000, Loss: 3.2846, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1063/10000, Loss: 3.2815, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1064/10000, Loss: 3.2784, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1065/10000, Loss: 3.2752, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1066/10000, Loss: 3.2721, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1067/10000, Loss: 3.2690, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1068/10000, Loss: 3.2659, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1069/10000, Loss: 3.2628, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1070/10000, Loss: 3.2597, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1071/10000, Loss: 3.2566, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1072/10000, Loss: 3.2535, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1073/10000, Loss: 3.2505, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1074/10000, Loss: 3.2474, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1075/10000, Loss: 3.2443, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1076/10000, Loss: 3.2413, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1077/10000, Loss: 3.2382, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1078/10000, Loss: 3.2352, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1079/10000, Loss: 3.2321, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1080/10000, Loss: 3.2291, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1081/10000, Loss: 3.2261, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1082/10000, Loss: 3.2230, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1083/10000, Loss: 3.2200, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1084/10000, Loss: 3.2170, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1085/10000, Loss: 3.2140, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1086/10000, Loss: 3.2110, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1087/10000, Loss: 3.2080, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1088/10000, Loss: 3.2050, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1089/10000, Loss: 3.2020, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1090/10000, Loss: 3.1990, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1091/10000, Loss: 3.1960, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1092/10000, Loss: 3.1931, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1093/10000, Loss: 3.1901, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1094/10000, Loss: 3.1871, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1095/10000, Loss: 3.1842, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1096/10000, Loss: 3.1812, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1097/10000, Loss: 3.1783, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1098/10000, Loss: 3.1753, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1099/10000, Loss: 3.1724, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1100/10000, Loss: 3.1695, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1101/10000, Loss: 3.1665, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1102/10000, Loss: 3.1636, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1103/10000, Loss: 3.1607, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1104/10000, Loss: 3.1578, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1105/10000, Loss: 3.1549, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1106/10000, Loss: 3.1520, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1107/10000, Loss: 3.1491, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1108/10000, Loss: 3.1462, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1109/10000, Loss: 3.1433, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1110/10000, Loss: 3.1404, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1111/10000, Loss: 3.1375, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1112/10000, Loss: 3.1347, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1113/10000, Loss: 3.1318, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1114/10000, Loss: 3.1289, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1115/10000, Loss: 3.1261, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1116/10000, Loss: 3.1232, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1117/10000, Loss: 3.1204, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1118/10000, Loss: 3.1175, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1119/10000, Loss: 3.1147, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1120/10000, Loss: 3.1119, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1121/10000, Loss: 3.1090, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1122/10000, Loss: 3.1062, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1123/10000, Loss: 3.1034, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1124/10000, Loss: 3.1006, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1125/10000, Loss: 3.0978, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1126/10000, Loss: 3.0949, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1127/10000, Loss: 3.0921, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1128/10000, Loss: 3.0893, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1129/10000, Loss: 3.0866, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1130/10000, Loss: 3.0838, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1131/10000, Loss: 3.0810, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1132/10000, Loss: 3.0782, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1133/10000, Loss: 3.0754, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1134/10000, Loss: 3.0727, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1135/10000, Loss: 3.0699, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1136/10000, Loss: 3.0671, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1137/10000, Loss: 3.0644, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1138/10000, Loss: 3.0616, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1139/10000, Loss: 3.0589, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1140/10000, Loss: 3.0561, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1141/10000, Loss: 3.0534, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1142/10000, Loss: 3.0507, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1143/10000, Loss: 3.0479, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1144/10000, Loss: 3.0452, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1145/10000, Loss: 3.0425, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1146/10000, Loss: 3.0398, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1147/10000, Loss: 3.0371, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1148/10000, Loss: 3.0343, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1149/10000, Loss: 3.0316, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1150/10000, Loss: 3.0289, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1151/10000, Loss: 3.0263, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1152/10000, Loss: 3.0236, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1153/10000, Loss: 3.0209, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1154/10000, Loss: 3.0182, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1155/10000, Loss: 3.0155, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1156/10000, Loss: 3.0128, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1157/10000, Loss: 3.0102, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1158/10000, Loss: 3.0075, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1159/10000, Loss: 3.0048, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1160/10000, Loss: 3.0022, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1161/10000, Loss: 2.9995, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1162/10000, Loss: 2.9969, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1163/10000, Loss: 2.9943, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1164/10000, Loss: 2.9916, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1165/10000, Loss: 2.9890, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1166/10000, Loss: 2.9863, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1167/10000, Loss: 2.9837, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1168/10000, Loss: 2.9811, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1169/10000, Loss: 2.9785, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1170/10000, Loss: 2.9759, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1171/10000, Loss: 2.9733, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1172/10000, Loss: 2.9706, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1173/10000, Loss: 2.9680, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1174/10000, Loss: 2.9655, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1175/10000, Loss: 2.9629, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1176/10000, Loss: 2.9603, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1177/10000, Loss: 2.9577, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1178/10000, Loss: 2.9551, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1179/10000, Loss: 2.9525, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1180/10000, Loss: 2.9500, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1181/10000, Loss: 2.9474, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1182/10000, Loss: 2.9448, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1183/10000, Loss: 2.9423, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1184/10000, Loss: 2.9397, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1185/10000, Loss: 2.9372, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1186/10000, Loss: 2.9346, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1187/10000, Loss: 2.9321, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1188/10000, Loss: 2.9295, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1189/10000, Loss: 2.9270, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1190/10000, Loss: 2.9244, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1191/10000, Loss: 2.9219, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1192/10000, Loss: 2.9194, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1193/10000, Loss: 2.9169, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1194/10000, Loss: 2.9144, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1195/10000, Loss: 2.9118, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1196/10000, Loss: 2.9093, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1197/10000, Loss: 2.9068, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1198/10000, Loss: 2.9043, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1199/10000, Loss: 2.9018, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1200/10000, Loss: 2.8993, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1201/10000, Loss: 2.8969, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1202/10000, Loss: 2.8944, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1203/10000, Loss: 2.8919, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1204/10000, Loss: 2.8894, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1205/10000, Loss: 2.8869, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1206/10000, Loss: 2.8845, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1207/10000, Loss: 2.8820, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1208/10000, Loss: 2.8796, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1209/10000, Loss: 2.8771, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1210/10000, Loss: 2.8746, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1211/10000, Loss: 2.8722, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1212/10000, Loss: 2.8697, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1213/10000, Loss: 2.8673, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1214/10000, Loss: 2.8649, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1215/10000, Loss: 2.8624, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1216/10000, Loss: 2.8600, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1217/10000, Loss: 2.8576, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1218/10000, Loss: 2.8552, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1219/10000, Loss: 2.8527, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1220/10000, Loss: 2.8503, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1221/10000, Loss: 2.8479, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1222/10000, Loss: 2.8455, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1223/10000, Loss: 2.8431, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1224/10000, Loss: 2.8407, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1225/10000, Loss: 2.8383, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1226/10000, Loss: 2.8359, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1227/10000, Loss: 2.8335, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1228/10000, Loss: 2.8311, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1229/10000, Loss: 2.8288, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1230/10000, Loss: 2.8264, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1231/10000, Loss: 2.8240, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1232/10000, Loss: 2.8217, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1233/10000, Loss: 2.8193, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1234/10000, Loss: 2.8169, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1235/10000, Loss: 2.8146, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1236/10000, Loss: 2.8122, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1237/10000, Loss: 2.8099, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1238/10000, Loss: 2.8075, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1239/10000, Loss: 2.8052, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1240/10000, Loss: 2.8028, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1241/10000, Loss: 2.8005, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1242/10000, Loss: 2.7982, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1243/10000, Loss: 2.7958, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1244/10000, Loss: 2.7935, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1245/10000, Loss: 2.7912, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1246/10000, Loss: 2.7889, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1247/10000, Loss: 2.7866, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1248/10000, Loss: 2.7843, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1249/10000, Loss: 2.7820, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1250/10000, Loss: 2.7796, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1251/10000, Loss: 2.7774, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1252/10000, Loss: 2.7751, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1253/10000, Loss: 2.7728, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1254/10000, Loss: 2.7705, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1255/10000, Loss: 2.7682, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1256/10000, Loss: 2.7659, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1257/10000, Loss: 2.7636, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1258/10000, Loss: 2.7614, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1259/10000, Loss: 2.7591, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1260/10000, Loss: 2.7568, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1261/10000, Loss: 2.7546, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1262/10000, Loss: 2.7523, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1263/10000, Loss: 2.7500, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1264/10000, Loss: 2.7478, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1265/10000, Loss: 2.7455, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1266/10000, Loss: 2.7433, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1267/10000, Loss: 2.7411, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1268/10000, Loss: 2.7388, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1269/10000, Loss: 2.7366, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1270/10000, Loss: 2.7344, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1271/10000, Loss: 2.7321, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1272/10000, Loss: 2.7299, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1273/10000, Loss: 2.7277, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1274/10000, Loss: 2.7255, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1275/10000, Loss: 2.7232, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1276/10000, Loss: 2.7210, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1277/10000, Loss: 2.7188, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1278/10000, Loss: 2.7166, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1279/10000, Loss: 2.7144, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1280/10000, Loss: 2.7122, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1281/10000, Loss: 2.7100, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1282/10000, Loss: 2.7078, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1283/10000, Loss: 2.7057, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1284/10000, Loss: 2.7035, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1285/10000, Loss: 2.7013, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1286/10000, Loss: 2.6991, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1287/10000, Loss: 2.6969, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1288/10000, Loss: 2.6948, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1289/10000, Loss: 2.6926, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1290/10000, Loss: 2.6904, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1291/10000, Loss: 2.6883, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1292/10000, Loss: 2.6861, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1293/10000, Loss: 2.6840, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1294/10000, Loss: 2.6818, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1295/10000, Loss: 2.6797, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1296/10000, Loss: 2.6775, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1297/10000, Loss: 2.6754, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1298/10000, Loss: 2.6732, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1299/10000, Loss: 2.6711, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1300/10000, Loss: 2.6690, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1301/10000, Loss: 2.6668, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1302/10000, Loss: 2.6647, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1303/10000, Loss: 2.6626, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1304/10000, Loss: 2.6605, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1305/10000, Loss: 2.6584, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1306/10000, Loss: 2.6562, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1307/10000, Loss: 2.6541, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1308/10000, Loss: 2.6520, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1309/10000, Loss: 2.6499, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1310/10000, Loss: 2.6478, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1311/10000, Loss: 2.6457, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1312/10000, Loss: 2.6436, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1313/10000, Loss: 2.6415, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1314/10000, Loss: 2.6395, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1315/10000, Loss: 2.6374, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1316/10000, Loss: 2.6353, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1317/10000, Loss: 2.6332, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1318/10000, Loss: 2.6311, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1319/10000, Loss: 2.6291, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1320/10000, Loss: 2.6270, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1321/10000, Loss: 2.6249, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1322/10000, Loss: 2.6229, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1323/10000, Loss: 2.6208, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1324/10000, Loss: 2.6187, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1325/10000, Loss: 2.6167, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1326/10000, Loss: 2.6146, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1327/10000, Loss: 2.6126, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1328/10000, Loss: 2.6105, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1329/10000, Loss: 2.6085, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1330/10000, Loss: 2.6065, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1331/10000, Loss: 2.6044, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1332/10000, Loss: 2.6024, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1333/10000, Loss: 2.6004, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1334/10000, Loss: 2.5983, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1335/10000, Loss: 2.5963, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1336/10000, Loss: 2.5943, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1337/10000, Loss: 2.5923, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1338/10000, Loss: 2.5902, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1339/10000, Loss: 2.5882, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1340/10000, Loss: 2.5862, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1341/10000, Loss: 2.5842, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1342/10000, Loss: 2.5822, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1343/10000, Loss: 2.5802, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1344/10000, Loss: 2.5782, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1345/10000, Loss: 2.5762, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1346/10000, Loss: 2.5742, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1347/10000, Loss: 2.5722, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1348/10000, Loss: 2.5702, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1349/10000, Loss: 2.5682, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1350/10000, Loss: 2.5663, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1351/10000, Loss: 2.5643, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1352/10000, Loss: 2.5623, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1353/10000, Loss: 2.5603, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1354/10000, Loss: 2.5584, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1355/10000, Loss: 2.5564, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1356/10000, Loss: 2.5544, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1357/10000, Loss: 2.5525, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1358/10000, Loss: 2.5505, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1359/10000, Loss: 2.5485, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1360/10000, Loss: 2.5466, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1361/10000, Loss: 2.5446, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1362/10000, Loss: 2.5427, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1363/10000, Loss: 2.5407, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1364/10000, Loss: 2.5388, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1365/10000, Loss: 2.5368, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1366/10000, Loss: 2.5349, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1367/10000, Loss: 2.5330, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1368/10000, Loss: 2.5310, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1369/10000, Loss: 2.5291, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1370/10000, Loss: 2.5272, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1371/10000, Loss: 2.5253, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1372/10000, Loss: 2.5233, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1373/10000, Loss: 2.5214, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1374/10000, Loss: 2.5195, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1375/10000, Loss: 2.5176, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1376/10000, Loss: 2.5157, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1377/10000, Loss: 2.5138, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1378/10000, Loss: 2.5119, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1379/10000, Loss: 2.5099, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1380/10000, Loss: 2.5080, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1381/10000, Loss: 2.5061, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1382/10000, Loss: 2.5042, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1383/10000, Loss: 2.5024, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1384/10000, Loss: 2.5005, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1385/10000, Loss: 2.4986, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1386/10000, Loss: 2.4967, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1387/10000, Loss: 2.4948, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1388/10000, Loss: 2.4929, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1389/10000, Loss: 2.4910, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1390/10000, Loss: 2.4892, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1391/10000, Loss: 2.4873, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1392/10000, Loss: 2.4854, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1393/10000, Loss: 2.4836, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1394/10000, Loss: 2.4817, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1395/10000, Loss: 2.4798, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1396/10000, Loss: 2.4780, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1397/10000, Loss: 2.4761, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1398/10000, Loss: 2.4743, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1399/10000, Loss: 2.4724, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1400/10000, Loss: 2.4706, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1401/10000, Loss: 2.4687, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1402/10000, Loss: 2.4669, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1403/10000, Loss: 2.4650, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1404/10000, Loss: 2.4632, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1405/10000, Loss: 2.4614, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1406/10000, Loss: 2.4595, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1407/10000, Loss: 2.4577, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1408/10000, Loss: 2.4559, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1409/10000, Loss: 2.4540, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1410/10000, Loss: 2.4522, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1411/10000, Loss: 2.4504, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1412/10000, Loss: 2.4486, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1413/10000, Loss: 2.4467, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1414/10000, Loss: 2.4449, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1415/10000, Loss: 2.4431, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1416/10000, Loss: 2.4413, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1417/10000, Loss: 2.4395, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1418/10000, Loss: 2.4377, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1419/10000, Loss: 2.4359, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1420/10000, Loss: 2.4341, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1421/10000, Loss: 2.4323, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1422/10000, Loss: 2.4305, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1423/10000, Loss: 2.4287, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1424/10000, Loss: 2.4269, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1425/10000, Loss: 2.4251, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1426/10000, Loss: 2.4234, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1427/10000, Loss: 2.4216, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1428/10000, Loss: 2.4198, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1429/10000, Loss: 2.4180, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1430/10000, Loss: 2.4162, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1431/10000, Loss: 2.4145, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1432/10000, Loss: 2.4127, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1433/10000, Loss: 2.4109, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1434/10000, Loss: 2.4092, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1435/10000, Loss: 2.4074, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1436/10000, Loss: 2.4057, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1437/10000, Loss: 2.4039, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1438/10000, Loss: 2.4021, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1439/10000, Loss: 2.4004, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1440/10000, Loss: 2.3986, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1441/10000, Loss: 2.3969, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1442/10000, Loss: 2.3951, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1443/10000, Loss: 2.3934, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1444/10000, Loss: 2.3917, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1445/10000, Loss: 2.3899, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1446/10000, Loss: 2.3882, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1447/10000, Loss: 2.3865, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1448/10000, Loss: 2.3847, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1449/10000, Loss: 2.3830, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1450/10000, Loss: 2.3813, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1451/10000, Loss: 2.3796, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1452/10000, Loss: 2.3778, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1453/10000, Loss: 2.3761, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1454/10000, Loss: 2.3744, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1455/10000, Loss: 2.3727, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1456/10000, Loss: 2.3710, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1457/10000, Loss: 2.3693, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1458/10000, Loss: 2.3676, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1459/10000, Loss: 2.3659, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1460/10000, Loss: 2.3642, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1461/10000, Loss: 2.3625, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1462/10000, Loss: 2.3608, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1463/10000, Loss: 2.3591, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1464/10000, Loss: 2.3574, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1465/10000, Loss: 2.3557, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1466/10000, Loss: 2.3540, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1467/10000, Loss: 2.3523, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1468/10000, Loss: 2.3506, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1469/10000, Loss: 2.3490, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1470/10000, Loss: 2.3473, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1471/10000, Loss: 2.3456, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1472/10000, Loss: 2.3439, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1473/10000, Loss: 2.3423, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1474/10000, Loss: 2.3406, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1475/10000, Loss: 2.3389, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1476/10000, Loss: 2.3373, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1477/10000, Loss: 2.3356, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1478/10000, Loss: 2.3339, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1479/10000, Loss: 2.3323, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1480/10000, Loss: 2.3306, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1481/10000, Loss: 2.3290, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1482/10000, Loss: 2.3273, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1483/10000, Loss: 2.3257, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1484/10000, Loss: 2.3240, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1485/10000, Loss: 2.3224, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1486/10000, Loss: 2.3208, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1487/10000, Loss: 2.3191, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1488/10000, Loss: 2.3175, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1489/10000, Loss: 2.3159, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1490/10000, Loss: 2.3142, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1491/10000, Loss: 2.3126, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1492/10000, Loss: 2.3110, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1493/10000, Loss: 2.3094, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1494/10000, Loss: 2.3077, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1495/10000, Loss: 2.3061, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1496/10000, Loss: 2.3045, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1497/10000, Loss: 2.3029, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1498/10000, Loss: 2.3013, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1499/10000, Loss: 2.2997, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1500/10000, Loss: 2.2981, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1501/10000, Loss: 2.2965, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1502/10000, Loss: 2.2949, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1503/10000, Loss: 2.2933, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1504/10000, Loss: 2.2917, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1505/10000, Loss: 2.2901, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1506/10000, Loss: 2.2885, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1507/10000, Loss: 2.2869, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1508/10000, Loss: 2.2853, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1509/10000, Loss: 2.2837, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1510/10000, Loss: 2.2821, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1511/10000, Loss: 2.2805, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1512/10000, Loss: 2.2790, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1513/10000, Loss: 2.2774, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1514/10000, Loss: 2.2758, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1515/10000, Loss: 2.2742, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1516/10000, Loss: 2.2727, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1517/10000, Loss: 2.2711, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1518/10000, Loss: 2.2695, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1519/10000, Loss: 2.2680, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1520/10000, Loss: 2.2664, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1521/10000, Loss: 2.2649, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1522/10000, Loss: 2.2633, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1523/10000, Loss: 2.2618, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1524/10000, Loss: 2.2602, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1525/10000, Loss: 2.2587, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1526/10000, Loss: 2.2571, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1527/10000, Loss: 2.2556, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1528/10000, Loss: 2.2540, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1529/10000, Loss: 2.2525, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1530/10000, Loss: 2.2509, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1531/10000, Loss: 2.2494, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1532/10000, Loss: 2.2479, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1533/10000, Loss: 2.2463, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1534/10000, Loss: 2.2448, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1535/10000, Loss: 2.2433, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1536/10000, Loss: 2.2418, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1537/10000, Loss: 2.2402, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1538/10000, Loss: 2.2387, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1539/10000, Loss: 2.2372, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1540/10000, Loss: 2.2357, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1541/10000, Loss: 2.2342, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1542/10000, Loss: 2.2327, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1543/10000, Loss: 2.2312, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1544/10000, Loss: 2.2297, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1545/10000, Loss: 2.2282, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1546/10000, Loss: 2.2267, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1547/10000, Loss: 2.2252, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1548/10000, Loss: 2.2237, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1549/10000, Loss: 2.2222, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1550/10000, Loss: 2.2207, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1551/10000, Loss: 2.2192, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1552/10000, Loss: 2.2177, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1553/10000, Loss: 2.2162, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1554/10000, Loss: 2.2147, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1555/10000, Loss: 2.2133, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1556/10000, Loss: 2.2118, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1557/10000, Loss: 2.2103, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1558/10000, Loss: 2.2088, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1559/10000, Loss: 2.2074, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1560/10000, Loss: 2.2059, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1561/10000, Loss: 2.2044, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1562/10000, Loss: 2.2030, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1563/10000, Loss: 2.2015, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1564/10000, Loss: 2.2000, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1565/10000, Loss: 2.1986, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1566/10000, Loss: 2.1971, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1567/10000, Loss: 2.1957, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1568/10000, Loss: 2.1942, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1569/10000, Loss: 2.1928, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1570/10000, Loss: 2.1913, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1571/10000, Loss: 2.1899, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1572/10000, Loss: 2.1884, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1573/10000, Loss: 2.1870, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1574/10000, Loss: 2.1856, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1575/10000, Loss: 2.1841, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1576/10000, Loss: 2.1827, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1577/10000, Loss: 2.1813, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1578/10000, Loss: 2.1798, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1579/10000, Loss: 2.1784, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1580/10000, Loss: 2.1770, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1581/10000, Loss: 2.1756, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1582/10000, Loss: 2.1741, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1583/10000, Loss: 2.1727, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1584/10000, Loss: 2.1713, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1585/10000, Loss: 2.1699, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1586/10000, Loss: 2.1685, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1587/10000, Loss: 2.1671, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1588/10000, Loss: 2.1657, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1589/10000, Loss: 2.1643, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1590/10000, Loss: 2.1629, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1591/10000, Loss: 2.1615, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1592/10000, Loss: 2.1601, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1593/10000, Loss: 2.1587, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1594/10000, Loss: 2.1573, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1595/10000, Loss: 2.1559, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1596/10000, Loss: 2.1545, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1597/10000, Loss: 2.1531, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1598/10000, Loss: 2.1517, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1599/10000, Loss: 2.1503, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1600/10000, Loss: 2.1490, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1601/10000, Loss: 2.1476, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1602/10000, Loss: 2.1462, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1603/10000, Loss: 2.1448, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1604/10000, Loss: 2.1435, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1605/10000, Loss: 2.1421, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1606/10000, Loss: 2.1407, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1607/10000, Loss: 2.1393, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1608/10000, Loss: 2.1380, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1609/10000, Loss: 2.1366, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1610/10000, Loss: 2.1353, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1611/10000, Loss: 2.1339, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1612/10000, Loss: 2.1326, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1613/10000, Loss: 2.1312, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1614/10000, Loss: 2.1299, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1615/10000, Loss: 2.1285, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1616/10000, Loss: 2.1272, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1617/10000, Loss: 2.1258, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1618/10000, Loss: 2.1245, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1619/10000, Loss: 2.1231, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1620/10000, Loss: 2.1218, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1621/10000, Loss: 2.1205, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1622/10000, Loss: 2.1191, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1623/10000, Loss: 2.1178, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1624/10000, Loss: 2.1165, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1625/10000, Loss: 2.1151, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1626/10000, Loss: 2.1138, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1627/10000, Loss: 2.1125, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1628/10000, Loss: 2.1112, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1629/10000, Loss: 2.1099, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1630/10000, Loss: 2.1085, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1631/10000, Loss: 2.1072, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1632/10000, Loss: 2.1059, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1633/10000, Loss: 2.1046, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1634/10000, Loss: 2.1033, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1635/10000, Loss: 2.1020, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1636/10000, Loss: 2.1007, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1637/10000, Loss: 2.0994, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1638/10000, Loss: 2.0981, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1639/10000, Loss: 2.0968, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1640/10000, Loss: 2.0955, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1641/10000, Loss: 2.0942, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1642/10000, Loss: 2.0929, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1643/10000, Loss: 2.0916, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1644/10000, Loss: 2.0903, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1645/10000, Loss: 2.0890, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1646/10000, Loss: 2.0878, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1647/10000, Loss: 2.0865, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1648/10000, Loss: 2.0852, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1649/10000, Loss: 2.0839, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1650/10000, Loss: 2.0826, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1651/10000, Loss: 2.0814, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1652/10000, Loss: 2.0801, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1653/10000, Loss: 2.0788, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1654/10000, Loss: 2.0776, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1655/10000, Loss: 2.0763, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1656/10000, Loss: 2.0750, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1657/10000, Loss: 2.0738, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1658/10000, Loss: 2.0725, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1659/10000, Loss: 2.0713, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1660/10000, Loss: 2.0700, Accuracy: 0.5866, Learning Rate: 0.000100\n",
      "Epoch 1661/10000, Loss: 2.0687, Accuracy: 0.5866, Learning Rate: 0.000100\n",
      "Epoch 1662/10000, Loss: 2.0675, Accuracy: 0.5866, Learning Rate: 0.000100\n",
      "Epoch 1663/10000, Loss: 2.0662, Accuracy: 0.5866, Learning Rate: 0.000100\n",
      "Epoch 1664/10000, Loss: 2.0650, Accuracy: 0.5866, Learning Rate: 0.000100\n",
      "Epoch 1665/10000, Loss: 2.0637, Accuracy: 0.5866, Learning Rate: 0.000100\n",
      "Epoch 1666/10000, Loss: 2.0625, Accuracy: 0.5866, Learning Rate: 0.000100\n",
      "Epoch 1667/10000, Loss: 2.0613, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1668/10000, Loss: 2.0600, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1669/10000, Loss: 2.0588, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1670/10000, Loss: 2.0576, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1671/10000, Loss: 2.0563, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1672/10000, Loss: 2.0551, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1673/10000, Loss: 2.0539, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1674/10000, Loss: 2.0526, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1675/10000, Loss: 2.0514, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1676/10000, Loss: 2.0502, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1677/10000, Loss: 2.0490, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1678/10000, Loss: 2.0477, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1679/10000, Loss: 2.0465, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1680/10000, Loss: 2.0453, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1681/10000, Loss: 2.0441, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1682/10000, Loss: 2.0429, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1683/10000, Loss: 2.0417, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1684/10000, Loss: 2.0405, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1685/10000, Loss: 2.0392, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1686/10000, Loss: 2.0380, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1687/10000, Loss: 2.0368, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1688/10000, Loss: 2.0356, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1689/10000, Loss: 2.0344, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1690/10000, Loss: 2.0332, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1691/10000, Loss: 2.0320, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1692/10000, Loss: 2.0308, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1693/10000, Loss: 2.0297, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1694/10000, Loss: 2.0285, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1695/10000, Loss: 2.0273, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1696/10000, Loss: 2.0261, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1697/10000, Loss: 2.0249, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1698/10000, Loss: 2.0237, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1699/10000, Loss: 2.0225, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1700/10000, Loss: 2.0214, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1701/10000, Loss: 2.0202, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1702/10000, Loss: 2.0190, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1703/10000, Loss: 2.0178, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1704/10000, Loss: 2.0167, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1705/10000, Loss: 2.0155, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1706/10000, Loss: 2.0143, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1707/10000, Loss: 2.0132, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1708/10000, Loss: 2.0120, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1709/10000, Loss: 2.0108, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1710/10000, Loss: 2.0097, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1711/10000, Loss: 2.0085, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1712/10000, Loss: 2.0073, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1713/10000, Loss: 2.0062, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1714/10000, Loss: 2.0050, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1715/10000, Loss: 2.0039, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1716/10000, Loss: 2.0027, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1717/10000, Loss: 2.0016, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1718/10000, Loss: 2.0004, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1719/10000, Loss: 1.9993, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1720/10000, Loss: 1.9981, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1721/10000, Loss: 1.9970, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1722/10000, Loss: 1.9959, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1723/10000, Loss: 1.9947, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1724/10000, Loss: 1.9936, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1725/10000, Loss: 1.9924, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1726/10000, Loss: 1.9913, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1727/10000, Loss: 1.9902, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1728/10000, Loss: 1.9891, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1729/10000, Loss: 1.9879, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1730/10000, Loss: 1.9868, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1731/10000, Loss: 1.9857, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1732/10000, Loss: 1.9845, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1733/10000, Loss: 1.9834, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1734/10000, Loss: 1.9823, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1735/10000, Loss: 1.9812, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1736/10000, Loss: 1.9801, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1737/10000, Loss: 1.9789, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1738/10000, Loss: 1.9778, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1739/10000, Loss: 1.9767, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1740/10000, Loss: 1.9756, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1741/10000, Loss: 1.9745, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1742/10000, Loss: 1.9734, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1743/10000, Loss: 1.9723, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1744/10000, Loss: 1.9712, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1745/10000, Loss: 1.9701, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1746/10000, Loss: 1.9690, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1747/10000, Loss: 1.9679, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1748/10000, Loss: 1.9668, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1749/10000, Loss: 1.9657, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1750/10000, Loss: 1.9646, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1751/10000, Loss: 1.9635, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1752/10000, Loss: 1.9624, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1753/10000, Loss: 1.9613, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1754/10000, Loss: 1.9602, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1755/10000, Loss: 1.9591, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1756/10000, Loss: 1.9580, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1757/10000, Loss: 1.9570, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1758/10000, Loss: 1.9559, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1759/10000, Loss: 1.9548, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1760/10000, Loss: 1.9537, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1761/10000, Loss: 1.9526, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1762/10000, Loss: 1.9515, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1763/10000, Loss: 1.9505, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1764/10000, Loss: 1.9494, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1765/10000, Loss: 1.9483, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1766/10000, Loss: 1.9473, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1767/10000, Loss: 1.9462, Accuracy: 0.5996, Learning Rate: 0.000100\n",
      "Epoch 1768/10000, Loss: 1.9451, Accuracy: 0.5996, Learning Rate: 0.000100\n",
      "Epoch 1769/10000, Loss: 1.9440, Accuracy: 0.5996, Learning Rate: 0.000100\n",
      "Epoch 1770/10000, Loss: 1.9430, Accuracy: 0.5996, Learning Rate: 0.000100\n",
      "Epoch 1771/10000, Loss: 1.9419, Accuracy: 0.5996, Learning Rate: 0.000100\n",
      "Epoch 1772/10000, Loss: 1.9409, Accuracy: 0.6015, Learning Rate: 0.000100\n",
      "Epoch 1773/10000, Loss: 1.9398, Accuracy: 0.6015, Learning Rate: 0.000100\n",
      "Epoch 1774/10000, Loss: 1.9387, Accuracy: 0.6015, Learning Rate: 0.000100\n",
      "Epoch 1775/10000, Loss: 1.9377, Accuracy: 0.6015, Learning Rate: 0.000100\n",
      "Epoch 1776/10000, Loss: 1.9366, Accuracy: 0.6015, Learning Rate: 0.000100\n",
      "Epoch 1777/10000, Loss: 1.9356, Accuracy: 0.6015, Learning Rate: 0.000100\n",
      "Epoch 1778/10000, Loss: 1.9345, Accuracy: 0.6015, Learning Rate: 0.000100\n",
      "Epoch 1779/10000, Loss: 1.9335, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1780/10000, Loss: 1.9324, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1781/10000, Loss: 1.9314, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1782/10000, Loss: 1.9303, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1783/10000, Loss: 1.9293, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1784/10000, Loss: 1.9282, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1785/10000, Loss: 1.9272, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1786/10000, Loss: 1.9261, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1787/10000, Loss: 1.9251, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1788/10000, Loss: 1.9240, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1789/10000, Loss: 1.9230, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1790/10000, Loss: 1.9220, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1791/10000, Loss: 1.9209, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1792/10000, Loss: 1.9199, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1793/10000, Loss: 1.9189, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1794/10000, Loss: 1.9178, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1795/10000, Loss: 1.9168, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1796/10000, Loss: 1.9158, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1797/10000, Loss: 1.9147, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1798/10000, Loss: 1.9137, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1799/10000, Loss: 1.9127, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1800/10000, Loss: 1.9117, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1801/10000, Loss: 1.9106, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1802/10000, Loss: 1.9096, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1803/10000, Loss: 1.9086, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1804/10000, Loss: 1.9076, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1805/10000, Loss: 1.9066, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1806/10000, Loss: 1.9055, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1807/10000, Loss: 1.9045, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1808/10000, Loss: 1.9035, Accuracy: 0.6071, Learning Rate: 0.000100\n",
      "Epoch 1809/10000, Loss: 1.9025, Accuracy: 0.6071, Learning Rate: 0.000100\n",
      "Epoch 1810/10000, Loss: 1.9015, Accuracy: 0.6071, Learning Rate: 0.000100\n",
      "Epoch 1811/10000, Loss: 1.9005, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1812/10000, Loss: 1.8995, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1813/10000, Loss: 1.8985, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1814/10000, Loss: 1.8974, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1815/10000, Loss: 1.8964, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1816/10000, Loss: 1.8954, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1817/10000, Loss: 1.8944, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1818/10000, Loss: 1.8934, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1819/10000, Loss: 1.8924, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1820/10000, Loss: 1.8914, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1821/10000, Loss: 1.8904, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1822/10000, Loss: 1.8894, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1823/10000, Loss: 1.8884, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1824/10000, Loss: 1.8874, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1825/10000, Loss: 1.8865, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1826/10000, Loss: 1.8855, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1827/10000, Loss: 1.8845, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1828/10000, Loss: 1.8835, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1829/10000, Loss: 1.8825, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1830/10000, Loss: 1.8815, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1831/10000, Loss: 1.8805, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1832/10000, Loss: 1.8795, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1833/10000, Loss: 1.8785, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1834/10000, Loss: 1.8776, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1835/10000, Loss: 1.8766, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1836/10000, Loss: 1.8756, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1837/10000, Loss: 1.8746, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1838/10000, Loss: 1.8736, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1839/10000, Loss: 1.8727, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1840/10000, Loss: 1.8717, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1841/10000, Loss: 1.8707, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1842/10000, Loss: 1.8697, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1843/10000, Loss: 1.8688, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1844/10000, Loss: 1.8678, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1845/10000, Loss: 1.8668, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1846/10000, Loss: 1.8659, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1847/10000, Loss: 1.8649, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1848/10000, Loss: 1.8639, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1849/10000, Loss: 1.8630, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1850/10000, Loss: 1.8620, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1851/10000, Loss: 1.8610, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1852/10000, Loss: 1.8601, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1853/10000, Loss: 1.8591, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1854/10000, Loss: 1.8581, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1855/10000, Loss: 1.8572, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1856/10000, Loss: 1.8562, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1857/10000, Loss: 1.8553, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1858/10000, Loss: 1.8543, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1859/10000, Loss: 1.8534, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1860/10000, Loss: 1.8524, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1861/10000, Loss: 1.8515, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1862/10000, Loss: 1.8505, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1863/10000, Loss: 1.8495, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1864/10000, Loss: 1.8486, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1865/10000, Loss: 1.8477, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1866/10000, Loss: 1.8467, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1867/10000, Loss: 1.8458, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1868/10000, Loss: 1.8448, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1869/10000, Loss: 1.8439, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1870/10000, Loss: 1.8429, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1871/10000, Loss: 1.8420, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1872/10000, Loss: 1.8410, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1873/10000, Loss: 1.8401, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1874/10000, Loss: 1.8392, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1875/10000, Loss: 1.8382, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1876/10000, Loss: 1.8373, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1877/10000, Loss: 1.8363, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1878/10000, Loss: 1.8354, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1879/10000, Loss: 1.8345, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1880/10000, Loss: 1.8335, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1881/10000, Loss: 1.8326, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1882/10000, Loss: 1.8317, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1883/10000, Loss: 1.8307, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1884/10000, Loss: 1.8298, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1885/10000, Loss: 1.8289, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1886/10000, Loss: 1.8280, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1887/10000, Loss: 1.8270, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1888/10000, Loss: 1.8261, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1889/10000, Loss: 1.8252, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1890/10000, Loss: 1.8243, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1891/10000, Loss: 1.8233, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1892/10000, Loss: 1.8224, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1893/10000, Loss: 1.8215, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1894/10000, Loss: 1.8206, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1895/10000, Loss: 1.8197, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1896/10000, Loss: 1.8187, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1897/10000, Loss: 1.8178, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1898/10000, Loss: 1.8169, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1899/10000, Loss: 1.8160, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1900/10000, Loss: 1.8151, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1901/10000, Loss: 1.8142, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1902/10000, Loss: 1.8133, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1903/10000, Loss: 1.8123, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1904/10000, Loss: 1.8114, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1905/10000, Loss: 1.8105, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1906/10000, Loss: 1.8096, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1907/10000, Loss: 1.8087, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1908/10000, Loss: 1.8078, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1909/10000, Loss: 1.8069, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1910/10000, Loss: 1.8060, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1911/10000, Loss: 1.8051, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1912/10000, Loss: 1.8042, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1913/10000, Loss: 1.8033, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1914/10000, Loss: 1.8024, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1915/10000, Loss: 1.8015, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1916/10000, Loss: 1.8006, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1917/10000, Loss: 1.7997, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1918/10000, Loss: 1.7988, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1919/10000, Loss: 1.7979, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1920/10000, Loss: 1.7970, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1921/10000, Loss: 1.7961, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1922/10000, Loss: 1.7952, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1923/10000, Loss: 1.7943, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1924/10000, Loss: 1.7934, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1925/10000, Loss: 1.7925, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1926/10000, Loss: 1.7916, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1927/10000, Loss: 1.7907, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1928/10000, Loss: 1.7898, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1929/10000, Loss: 1.7890, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1930/10000, Loss: 1.7881, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1931/10000, Loss: 1.7872, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1932/10000, Loss: 1.7863, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1933/10000, Loss: 1.7854, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1934/10000, Loss: 1.7845, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1935/10000, Loss: 1.7836, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1936/10000, Loss: 1.7828, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1937/10000, Loss: 1.7819, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1938/10000, Loss: 1.7810, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1939/10000, Loss: 1.7801, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1940/10000, Loss: 1.7792, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1941/10000, Loss: 1.7784, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1942/10000, Loss: 1.7775, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1943/10000, Loss: 1.7766, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1944/10000, Loss: 1.7757, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1945/10000, Loss: 1.7749, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1946/10000, Loss: 1.7740, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1947/10000, Loss: 1.7731, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1948/10000, Loss: 1.7722, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1949/10000, Loss: 1.7714, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1950/10000, Loss: 1.7705, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1951/10000, Loss: 1.7696, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1952/10000, Loss: 1.7688, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1953/10000, Loss: 1.7679, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1954/10000, Loss: 1.7670, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1955/10000, Loss: 1.7661, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1956/10000, Loss: 1.7653, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1957/10000, Loss: 1.7644, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1958/10000, Loss: 1.7636, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1959/10000, Loss: 1.7627, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1960/10000, Loss: 1.7618, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1961/10000, Loss: 1.7610, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1962/10000, Loss: 1.7601, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1963/10000, Loss: 1.7592, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1964/10000, Loss: 1.7584, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1965/10000, Loss: 1.7575, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1966/10000, Loss: 1.7567, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1967/10000, Loss: 1.7558, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1968/10000, Loss: 1.7549, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1969/10000, Loss: 1.7541, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1970/10000, Loss: 1.7532, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1971/10000, Loss: 1.7524, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1972/10000, Loss: 1.7515, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1973/10000, Loss: 1.7507, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1974/10000, Loss: 1.7498, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1975/10000, Loss: 1.7490, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1976/10000, Loss: 1.7481, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1977/10000, Loss: 1.7473, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1978/10000, Loss: 1.7464, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1979/10000, Loss: 1.7456, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1980/10000, Loss: 1.7447, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1981/10000, Loss: 1.7439, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1982/10000, Loss: 1.7430, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1983/10000, Loss: 1.7422, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1984/10000, Loss: 1.7413, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1985/10000, Loss: 1.7405, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1986/10000, Loss: 1.7397, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1987/10000, Loss: 1.7388, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1988/10000, Loss: 1.7380, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1989/10000, Loss: 1.7371, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1990/10000, Loss: 1.7363, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1991/10000, Loss: 1.7354, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1992/10000, Loss: 1.7346, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1993/10000, Loss: 1.7338, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1994/10000, Loss: 1.7329, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1995/10000, Loss: 1.7321, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1996/10000, Loss: 1.7313, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1997/10000, Loss: 1.7304, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1998/10000, Loss: 1.7296, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1999/10000, Loss: 1.7288, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2000/10000, Loss: 1.7279, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2001/10000, Loss: 1.7271, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2002/10000, Loss: 1.7263, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2003/10000, Loss: 1.7254, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2004/10000, Loss: 1.7246, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2005/10000, Loss: 1.7238, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2006/10000, Loss: 1.7229, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2007/10000, Loss: 1.7221, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2008/10000, Loss: 1.7213, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2009/10000, Loss: 1.7205, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2010/10000, Loss: 1.7196, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2011/10000, Loss: 1.7188, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2012/10000, Loss: 1.7180, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2013/10000, Loss: 1.7172, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2014/10000, Loss: 1.7163, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2015/10000, Loss: 1.7155, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2016/10000, Loss: 1.7147, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2017/10000, Loss: 1.7139, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2018/10000, Loss: 1.7130, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2019/10000, Loss: 1.7122, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2020/10000, Loss: 1.7114, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2021/10000, Loss: 1.7106, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2022/10000, Loss: 1.7098, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2023/10000, Loss: 1.7090, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2024/10000, Loss: 1.7081, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2025/10000, Loss: 1.7073, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2026/10000, Loss: 1.7065, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2027/10000, Loss: 1.7057, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2028/10000, Loss: 1.7049, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2029/10000, Loss: 1.7041, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2030/10000, Loss: 1.7032, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2031/10000, Loss: 1.7024, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2032/10000, Loss: 1.7016, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2033/10000, Loss: 1.7008, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2034/10000, Loss: 1.7000, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2035/10000, Loss: 1.6992, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2036/10000, Loss: 1.6984, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2037/10000, Loss: 1.6976, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2038/10000, Loss: 1.6968, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2039/10000, Loss: 1.6960, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2040/10000, Loss: 1.6952, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2041/10000, Loss: 1.6944, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2042/10000, Loss: 1.6935, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2043/10000, Loss: 1.6927, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2044/10000, Loss: 1.6919, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2045/10000, Loss: 1.6911, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2046/10000, Loss: 1.6903, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2047/10000, Loss: 1.6895, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2048/10000, Loss: 1.6887, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2049/10000, Loss: 1.6879, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2050/10000, Loss: 1.6871, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2051/10000, Loss: 1.6863, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2052/10000, Loss: 1.6855, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2053/10000, Loss: 1.6847, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2054/10000, Loss: 1.6839, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2055/10000, Loss: 1.6831, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2056/10000, Loss: 1.6824, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2057/10000, Loss: 1.6816, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2058/10000, Loss: 1.6808, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2059/10000, Loss: 1.6800, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2060/10000, Loss: 1.6792, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2061/10000, Loss: 1.6784, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2062/10000, Loss: 1.6776, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2063/10000, Loss: 1.6768, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2064/10000, Loss: 1.6760, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2065/10000, Loss: 1.6752, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2066/10000, Loss: 1.6744, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2067/10000, Loss: 1.6736, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2068/10000, Loss: 1.6729, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2069/10000, Loss: 1.6721, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2070/10000, Loss: 1.6713, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2071/10000, Loss: 1.6705, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2072/10000, Loss: 1.6697, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2073/10000, Loss: 1.6689, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2074/10000, Loss: 1.6681, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2075/10000, Loss: 1.6674, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2076/10000, Loss: 1.6666, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2077/10000, Loss: 1.6658, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2078/10000, Loss: 1.6650, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2079/10000, Loss: 1.6642, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2080/10000, Loss: 1.6634, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2081/10000, Loss: 1.6627, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2082/10000, Loss: 1.6619, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2083/10000, Loss: 1.6611, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2084/10000, Loss: 1.6603, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2085/10000, Loss: 1.6596, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2086/10000, Loss: 1.6588, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2087/10000, Loss: 1.6580, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2088/10000, Loss: 1.6572, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2089/10000, Loss: 1.6564, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2090/10000, Loss: 1.6557, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2091/10000, Loss: 1.6549, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2092/10000, Loss: 1.6541, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2093/10000, Loss: 1.6534, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2094/10000, Loss: 1.6526, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2095/10000, Loss: 1.6518, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2096/10000, Loss: 1.6510, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2097/10000, Loss: 1.6503, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2098/10000, Loss: 1.6495, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2099/10000, Loss: 1.6487, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2100/10000, Loss: 1.6480, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2101/10000, Loss: 1.6472, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2102/10000, Loss: 1.6464, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2103/10000, Loss: 1.6457, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2104/10000, Loss: 1.6449, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2105/10000, Loss: 1.6441, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2106/10000, Loss: 1.6434, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2107/10000, Loss: 1.6426, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2108/10000, Loss: 1.6418, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2109/10000, Loss: 1.6411, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2110/10000, Loss: 1.6403, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2111/10000, Loss: 1.6395, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2112/10000, Loss: 1.6388, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2113/10000, Loss: 1.6380, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2114/10000, Loss: 1.6373, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2115/10000, Loss: 1.6365, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2116/10000, Loss: 1.6357, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2117/10000, Loss: 1.6350, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2118/10000, Loss: 1.6342, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2119/10000, Loss: 1.6335, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2120/10000, Loss: 1.6327, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2121/10000, Loss: 1.6320, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2122/10000, Loss: 1.6312, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2123/10000, Loss: 1.6305, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2124/10000, Loss: 1.6297, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2125/10000, Loss: 1.6289, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2126/10000, Loss: 1.6282, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2127/10000, Loss: 1.6274, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2128/10000, Loss: 1.6267, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2129/10000, Loss: 1.6259, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2130/10000, Loss: 1.6252, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2131/10000, Loss: 1.6244, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2132/10000, Loss: 1.6237, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2133/10000, Loss: 1.6229, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2134/10000, Loss: 1.6222, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2135/10000, Loss: 1.6214, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2136/10000, Loss: 1.6207, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2137/10000, Loss: 1.6199, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2138/10000, Loss: 1.6192, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2139/10000, Loss: 1.6185, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2140/10000, Loss: 1.6177, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2141/10000, Loss: 1.6170, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2142/10000, Loss: 1.6162, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2143/10000, Loss: 1.6155, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2144/10000, Loss: 1.6147, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2145/10000, Loss: 1.6140, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2146/10000, Loss: 1.6132, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2147/10000, Loss: 1.6125, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2148/10000, Loss: 1.6118, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2149/10000, Loss: 1.6110, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2150/10000, Loss: 1.6103, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2151/10000, Loss: 1.6095, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2152/10000, Loss: 1.6088, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2153/10000, Loss: 1.6081, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2154/10000, Loss: 1.6073, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2155/10000, Loss: 1.6066, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2156/10000, Loss: 1.6059, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2157/10000, Loss: 1.6051, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2158/10000, Loss: 1.6044, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2159/10000, Loss: 1.6037, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2160/10000, Loss: 1.6029, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2161/10000, Loss: 1.6022, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2162/10000, Loss: 1.6015, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2163/10000, Loss: 1.6007, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2164/10000, Loss: 1.6000, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2165/10000, Loss: 1.5993, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2166/10000, Loss: 1.5985, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2167/10000, Loss: 1.5978, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2168/10000, Loss: 1.5971, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2169/10000, Loss: 1.5963, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2170/10000, Loss: 1.5956, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2171/10000, Loss: 1.5949, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2172/10000, Loss: 1.5942, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2173/10000, Loss: 1.5934, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2174/10000, Loss: 1.5927, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2175/10000, Loss: 1.5920, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2176/10000, Loss: 1.5913, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2177/10000, Loss: 1.5905, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2178/10000, Loss: 1.5898, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2179/10000, Loss: 1.5891, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2180/10000, Loss: 1.5884, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2181/10000, Loss: 1.5876, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2182/10000, Loss: 1.5869, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2183/10000, Loss: 1.5862, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2184/10000, Loss: 1.5855, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2185/10000, Loss: 1.5847, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2186/10000, Loss: 1.5840, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2187/10000, Loss: 1.5833, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2188/10000, Loss: 1.5826, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2189/10000, Loss: 1.5819, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2190/10000, Loss: 1.5812, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2191/10000, Loss: 1.5804, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2192/10000, Loss: 1.5797, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2193/10000, Loss: 1.5790, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2194/10000, Loss: 1.5783, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2195/10000, Loss: 1.5776, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2196/10000, Loss: 1.5769, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2197/10000, Loss: 1.5761, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2198/10000, Loss: 1.5754, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2199/10000, Loss: 1.5747, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2200/10000, Loss: 1.5740, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2201/10000, Loss: 1.5733, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2202/10000, Loss: 1.5726, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2203/10000, Loss: 1.5719, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2204/10000, Loss: 1.5712, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2205/10000, Loss: 1.5705, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2206/10000, Loss: 1.5697, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2207/10000, Loss: 1.5690, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2208/10000, Loss: 1.5683, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2209/10000, Loss: 1.5676, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2210/10000, Loss: 1.5669, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2211/10000, Loss: 1.5662, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2212/10000, Loss: 1.5655, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2213/10000, Loss: 1.5648, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2214/10000, Loss: 1.5641, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2215/10000, Loss: 1.5634, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2216/10000, Loss: 1.5627, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2217/10000, Loss: 1.5620, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2218/10000, Loss: 1.5613, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2219/10000, Loss: 1.5606, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2220/10000, Loss: 1.5599, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2221/10000, Loss: 1.5592, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2222/10000, Loss: 1.5585, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2223/10000, Loss: 1.5578, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2224/10000, Loss: 1.5571, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2225/10000, Loss: 1.5564, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2226/10000, Loss: 1.5557, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2227/10000, Loss: 1.5550, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2228/10000, Loss: 1.5543, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2229/10000, Loss: 1.5536, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2230/10000, Loss: 1.5529, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2231/10000, Loss: 1.5522, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2232/10000, Loss: 1.5515, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2233/10000, Loss: 1.5508, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2234/10000, Loss: 1.5501, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2235/10000, Loss: 1.5494, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2236/10000, Loss: 1.5487, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2237/10000, Loss: 1.5480, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2238/10000, Loss: 1.5473, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2239/10000, Loss: 1.5466, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2240/10000, Loss: 1.5459, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2241/10000, Loss: 1.5453, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2242/10000, Loss: 1.5446, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2243/10000, Loss: 1.5439, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2244/10000, Loss: 1.5432, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2245/10000, Loss: 1.5425, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2246/10000, Loss: 1.5418, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2247/10000, Loss: 1.5411, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2248/10000, Loss: 1.5404, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2249/10000, Loss: 1.5397, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2250/10000, Loss: 1.5391, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2251/10000, Loss: 1.5384, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2252/10000, Loss: 1.5377, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2253/10000, Loss: 1.5370, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2254/10000, Loss: 1.5363, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2255/10000, Loss: 1.5356, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2256/10000, Loss: 1.5350, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2257/10000, Loss: 1.5343, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2258/10000, Loss: 1.5336, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2259/10000, Loss: 1.5329, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2260/10000, Loss: 1.5322, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2261/10000, Loss: 1.5315, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2262/10000, Loss: 1.5309, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2263/10000, Loss: 1.5302, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2264/10000, Loss: 1.5295, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2265/10000, Loss: 1.5288, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2266/10000, Loss: 1.5281, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2267/10000, Loss: 1.5275, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2268/10000, Loss: 1.5268, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2269/10000, Loss: 1.5261, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2270/10000, Loss: 1.5254, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2271/10000, Loss: 1.5248, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2272/10000, Loss: 1.5241, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2273/10000, Loss: 1.5234, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2274/10000, Loss: 1.5227, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2275/10000, Loss: 1.5221, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2276/10000, Loss: 1.5214, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2277/10000, Loss: 1.5207, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2278/10000, Loss: 1.5200, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2279/10000, Loss: 1.5194, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2280/10000, Loss: 1.5187, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2281/10000, Loss: 1.5180, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2282/10000, Loss: 1.5174, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2283/10000, Loss: 1.5167, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2284/10000, Loss: 1.5160, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2285/10000, Loss: 1.5153, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2286/10000, Loss: 1.5147, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2287/10000, Loss: 1.5140, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2288/10000, Loss: 1.5133, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2289/10000, Loss: 1.5127, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2290/10000, Loss: 1.5120, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2291/10000, Loss: 1.5113, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2292/10000, Loss: 1.5107, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2293/10000, Loss: 1.5100, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2294/10000, Loss: 1.5093, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2295/10000, Loss: 1.5087, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2296/10000, Loss: 1.5080, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2297/10000, Loss: 1.5074, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2298/10000, Loss: 1.5067, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2299/10000, Loss: 1.5060, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2300/10000, Loss: 1.5054, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2301/10000, Loss: 1.5047, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2302/10000, Loss: 1.5040, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2303/10000, Loss: 1.5034, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2304/10000, Loss: 1.5027, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2305/10000, Loss: 1.5021, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2306/10000, Loss: 1.5014, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2307/10000, Loss: 1.5007, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2308/10000, Loss: 1.5001, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2309/10000, Loss: 1.4994, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2310/10000, Loss: 1.4988, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2311/10000, Loss: 1.4981, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2312/10000, Loss: 1.4975, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2313/10000, Loss: 1.4968, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2314/10000, Loss: 1.4962, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2315/10000, Loss: 1.4955, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2316/10000, Loss: 1.4948, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2317/10000, Loss: 1.4942, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2318/10000, Loss: 1.4935, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2319/10000, Loss: 1.4929, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2320/10000, Loss: 1.4922, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2321/10000, Loss: 1.4916, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2322/10000, Loss: 1.4909, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2323/10000, Loss: 1.4903, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2324/10000, Loss: 1.4896, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2325/10000, Loss: 1.4890, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2326/10000, Loss: 1.4883, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2327/10000, Loss: 1.4877, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2328/10000, Loss: 1.4870, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2329/10000, Loss: 1.4864, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2330/10000, Loss: 1.4857, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2331/10000, Loss: 1.4851, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2332/10000, Loss: 1.4844, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2333/10000, Loss: 1.4838, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2334/10000, Loss: 1.4832, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2335/10000, Loss: 1.4825, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2336/10000, Loss: 1.4819, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2337/10000, Loss: 1.4812, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2338/10000, Loss: 1.4806, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2339/10000, Loss: 1.4799, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2340/10000, Loss: 1.4793, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2341/10000, Loss: 1.4786, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2342/10000, Loss: 1.4780, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2343/10000, Loss: 1.4774, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2344/10000, Loss: 1.4767, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2345/10000, Loss: 1.4761, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2346/10000, Loss: 1.4754, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2347/10000, Loss: 1.4748, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2348/10000, Loss: 1.4742, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2349/10000, Loss: 1.4735, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2350/10000, Loss: 1.4729, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2351/10000, Loss: 1.4722, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2352/10000, Loss: 1.4716, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2353/10000, Loss: 1.4710, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2354/10000, Loss: 1.4703, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2355/10000, Loss: 1.4697, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2356/10000, Loss: 1.4691, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2357/10000, Loss: 1.4684, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2358/10000, Loss: 1.4678, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2359/10000, Loss: 1.4672, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2360/10000, Loss: 1.4665, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2361/10000, Loss: 1.4659, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2362/10000, Loss: 1.4653, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2363/10000, Loss: 1.4646, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2364/10000, Loss: 1.4640, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2365/10000, Loss: 1.4634, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2366/10000, Loss: 1.4627, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2367/10000, Loss: 1.4621, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2368/10000, Loss: 1.4615, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2369/10000, Loss: 1.4608, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2370/10000, Loss: 1.4602, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2371/10000, Loss: 1.4596, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2372/10000, Loss: 1.4590, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2373/10000, Loss: 1.4583, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2374/10000, Loss: 1.4577, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2375/10000, Loss: 1.4571, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2376/10000, Loss: 1.4565, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2377/10000, Loss: 1.4558, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2378/10000, Loss: 1.4552, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2379/10000, Loss: 1.4546, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2380/10000, Loss: 1.4540, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2381/10000, Loss: 1.4533, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2382/10000, Loss: 1.4527, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2383/10000, Loss: 1.4521, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2384/10000, Loss: 1.4515, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2385/10000, Loss: 1.4508, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2386/10000, Loss: 1.4502, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2387/10000, Loss: 1.4496, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2388/10000, Loss: 1.4490, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2389/10000, Loss: 1.4484, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2390/10000, Loss: 1.4477, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2391/10000, Loss: 1.4471, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2392/10000, Loss: 1.4465, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2393/10000, Loss: 1.4459, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2394/10000, Loss: 1.4453, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2395/10000, Loss: 1.4446, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2396/10000, Loss: 1.4440, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2397/10000, Loss: 1.4434, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2398/10000, Loss: 1.4428, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2399/10000, Loss: 1.4422, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2400/10000, Loss: 1.4416, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2401/10000, Loss: 1.4409, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2402/10000, Loss: 1.4403, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2403/10000, Loss: 1.4397, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2404/10000, Loss: 1.4391, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2405/10000, Loss: 1.4385, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2406/10000, Loss: 1.4379, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2407/10000, Loss: 1.4373, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2408/10000, Loss: 1.4367, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2409/10000, Loss: 1.4360, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2410/10000, Loss: 1.4354, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2411/10000, Loss: 1.4348, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2412/10000, Loss: 1.4342, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2413/10000, Loss: 1.4336, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2414/10000, Loss: 1.4330, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2415/10000, Loss: 1.4324, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2416/10000, Loss: 1.4318, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2417/10000, Loss: 1.4312, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2418/10000, Loss: 1.4306, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2419/10000, Loss: 1.4300, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2420/10000, Loss: 1.4294, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2421/10000, Loss: 1.4287, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2422/10000, Loss: 1.4281, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2423/10000, Loss: 1.4275, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2424/10000, Loss: 1.4269, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2425/10000, Loss: 1.4263, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2426/10000, Loss: 1.4257, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2427/10000, Loss: 1.4251, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2428/10000, Loss: 1.4245, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2429/10000, Loss: 1.4239, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2430/10000, Loss: 1.4233, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2431/10000, Loss: 1.4227, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2432/10000, Loss: 1.4221, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2433/10000, Loss: 1.4215, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2434/10000, Loss: 1.4209, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2435/10000, Loss: 1.4203, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2436/10000, Loss: 1.4197, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2437/10000, Loss: 1.4191, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2438/10000, Loss: 1.4185, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2439/10000, Loss: 1.4179, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2440/10000, Loss: 1.4173, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2441/10000, Loss: 1.4167, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2442/10000, Loss: 1.4161, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2443/10000, Loss: 1.4155, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2444/10000, Loss: 1.4149, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2445/10000, Loss: 1.4143, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2446/10000, Loss: 1.4137, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2447/10000, Loss: 1.4131, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2448/10000, Loss: 1.4126, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2449/10000, Loss: 1.4120, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2450/10000, Loss: 1.4114, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2451/10000, Loss: 1.4108, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2452/10000, Loss: 1.4102, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2453/10000, Loss: 1.4096, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2454/10000, Loss: 1.4090, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2455/10000, Loss: 1.4084, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2456/10000, Loss: 1.4078, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2457/10000, Loss: 1.4072, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2458/10000, Loss: 1.4066, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2459/10000, Loss: 1.4060, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2460/10000, Loss: 1.4055, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2461/10000, Loss: 1.4049, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2462/10000, Loss: 1.4043, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2463/10000, Loss: 1.4037, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2464/10000, Loss: 1.4031, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2465/10000, Loss: 1.4025, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2466/10000, Loss: 1.4019, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2467/10000, Loss: 1.4013, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2468/10000, Loss: 1.4008, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2469/10000, Loss: 1.4002, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2470/10000, Loss: 1.3996, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2471/10000, Loss: 1.3990, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2472/10000, Loss: 1.3984, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2473/10000, Loss: 1.3978, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2474/10000, Loss: 1.3973, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2475/10000, Loss: 1.3967, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2476/10000, Loss: 1.3961, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2477/10000, Loss: 1.3955, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2478/10000, Loss: 1.3949, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2479/10000, Loss: 1.3944, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2480/10000, Loss: 1.3938, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2481/10000, Loss: 1.3932, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2482/10000, Loss: 1.3926, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2483/10000, Loss: 1.3920, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2484/10000, Loss: 1.3915, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2485/10000, Loss: 1.3909, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2486/10000, Loss: 1.3903, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2487/10000, Loss: 1.3897, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2488/10000, Loss: 1.3891, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2489/10000, Loss: 1.3886, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2490/10000, Loss: 1.3880, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2491/10000, Loss: 1.3874, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2492/10000, Loss: 1.3868, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2493/10000, Loss: 1.3863, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2494/10000, Loss: 1.3857, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2495/10000, Loss: 1.3851, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2496/10000, Loss: 1.3845, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2497/10000, Loss: 1.3840, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2498/10000, Loss: 1.3834, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2499/10000, Loss: 1.3828, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2500/10000, Loss: 1.3823, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2501/10000, Loss: 1.3817, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2502/10000, Loss: 1.3811, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2503/10000, Loss: 1.3805, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2504/10000, Loss: 1.3800, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2505/10000, Loss: 1.3794, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2506/10000, Loss: 1.3788, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2507/10000, Loss: 1.3783, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2508/10000, Loss: 1.3777, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2509/10000, Loss: 1.3771, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2510/10000, Loss: 1.3766, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2511/10000, Loss: 1.3760, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2512/10000, Loss: 1.3754, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2513/10000, Loss: 1.3749, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2514/10000, Loss: 1.3743, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2515/10000, Loss: 1.3737, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2516/10000, Loss: 1.3732, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2517/10000, Loss: 1.3726, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2518/10000, Loss: 1.3720, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2519/10000, Loss: 1.3715, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2520/10000, Loss: 1.3709, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2521/10000, Loss: 1.3703, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2522/10000, Loss: 1.3698, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2523/10000, Loss: 1.3692, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2524/10000, Loss: 1.3687, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2525/10000, Loss: 1.3681, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2526/10000, Loss: 1.3675, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2527/10000, Loss: 1.3670, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2528/10000, Loss: 1.3664, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2529/10000, Loss: 1.3659, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2530/10000, Loss: 1.3653, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2531/10000, Loss: 1.3647, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2532/10000, Loss: 1.3642, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2533/10000, Loss: 1.3636, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2534/10000, Loss: 1.3631, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2535/10000, Loss: 1.3625, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2536/10000, Loss: 1.3620, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2537/10000, Loss: 1.3614, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2538/10000, Loss: 1.3608, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2539/10000, Loss: 1.3603, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2540/10000, Loss: 1.3597, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2541/10000, Loss: 1.3592, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2542/10000, Loss: 1.3586, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2543/10000, Loss: 1.3581, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2544/10000, Loss: 1.3575, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2545/10000, Loss: 1.3570, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2546/10000, Loss: 1.3564, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2547/10000, Loss: 1.3559, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2548/10000, Loss: 1.3553, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2549/10000, Loss: 1.3548, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2550/10000, Loss: 1.3542, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2551/10000, Loss: 1.3537, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2552/10000, Loss: 1.3531, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2553/10000, Loss: 1.3526, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2554/10000, Loss: 1.3520, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2555/10000, Loss: 1.3515, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2556/10000, Loss: 1.3509, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2557/10000, Loss: 1.3504, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2558/10000, Loss: 1.3498, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2559/10000, Loss: 1.3493, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2560/10000, Loss: 1.3487, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2561/10000, Loss: 1.3482, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2562/10000, Loss: 1.3476, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2563/10000, Loss: 1.3471, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2564/10000, Loss: 1.3465, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2565/10000, Loss: 1.3460, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2566/10000, Loss: 1.3455, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2567/10000, Loss: 1.3449, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2568/10000, Loss: 1.3444, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2569/10000, Loss: 1.3438, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2570/10000, Loss: 1.3433, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2571/10000, Loss: 1.3427, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2572/10000, Loss: 1.3422, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2573/10000, Loss: 1.3417, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2574/10000, Loss: 1.3411, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2575/10000, Loss: 1.3406, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2576/10000, Loss: 1.3400, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2577/10000, Loss: 1.3395, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2578/10000, Loss: 1.3390, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2579/10000, Loss: 1.3384, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2580/10000, Loss: 1.3379, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2581/10000, Loss: 1.3374, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2582/10000, Loss: 1.3368, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2583/10000, Loss: 1.3363, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2584/10000, Loss: 1.3357, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2585/10000, Loss: 1.3352, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2586/10000, Loss: 1.3347, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2587/10000, Loss: 1.3341, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2588/10000, Loss: 1.3336, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2589/10000, Loss: 1.3331, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2590/10000, Loss: 1.3325, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2591/10000, Loss: 1.3320, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2592/10000, Loss: 1.3315, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2593/10000, Loss: 1.3309, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2594/10000, Loss: 1.3304, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2595/10000, Loss: 1.3299, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2596/10000, Loss: 1.3293, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2597/10000, Loss: 1.3288, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2598/10000, Loss: 1.3283, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2599/10000, Loss: 1.3277, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2600/10000, Loss: 1.3272, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2601/10000, Loss: 1.3267, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2602/10000, Loss: 1.3262, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2603/10000, Loss: 1.3256, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2604/10000, Loss: 1.3251, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2605/10000, Loss: 1.3246, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2606/10000, Loss: 1.3240, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2607/10000, Loss: 1.3235, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2608/10000, Loss: 1.3230, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2609/10000, Loss: 1.3225, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2610/10000, Loss: 1.3219, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2611/10000, Loss: 1.3214, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2612/10000, Loss: 1.3209, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2613/10000, Loss: 1.3204, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2614/10000, Loss: 1.3198, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2615/10000, Loss: 1.3193, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2616/10000, Loss: 1.3188, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2617/10000, Loss: 1.3183, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2618/10000, Loss: 1.3177, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2619/10000, Loss: 1.3172, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2620/10000, Loss: 1.3167, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2621/10000, Loss: 1.3162, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2622/10000, Loss: 1.3157, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2623/10000, Loss: 1.3151, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2624/10000, Loss: 1.3146, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2625/10000, Loss: 1.3141, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2626/10000, Loss: 1.3136, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2627/10000, Loss: 1.3131, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2628/10000, Loss: 1.3125, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2629/10000, Loss: 1.3120, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2630/10000, Loss: 1.3115, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2631/10000, Loss: 1.3110, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2632/10000, Loss: 1.3105, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2633/10000, Loss: 1.3100, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2634/10000, Loss: 1.3094, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2635/10000, Loss: 1.3089, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2636/10000, Loss: 1.3084, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2637/10000, Loss: 1.3079, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2638/10000, Loss: 1.3074, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2639/10000, Loss: 1.3069, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2640/10000, Loss: 1.3064, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2641/10000, Loss: 1.3058, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2642/10000, Loss: 1.3053, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2643/10000, Loss: 1.3048, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2644/10000, Loss: 1.3043, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2645/10000, Loss: 1.3038, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2646/10000, Loss: 1.3033, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2647/10000, Loss: 1.3028, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2648/10000, Loss: 1.3023, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2649/10000, Loss: 1.3018, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2650/10000, Loss: 1.3012, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2651/10000, Loss: 1.3007, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2652/10000, Loss: 1.3002, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2653/10000, Loss: 1.2997, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2654/10000, Loss: 1.2992, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2655/10000, Loss: 1.2987, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2656/10000, Loss: 1.2982, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2657/10000, Loss: 1.2977, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2658/10000, Loss: 1.2972, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2659/10000, Loss: 1.2967, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2660/10000, Loss: 1.2962, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2661/10000, Loss: 1.2957, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2662/10000, Loss: 1.2952, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2663/10000, Loss: 1.2947, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2664/10000, Loss: 1.2942, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2665/10000, Loss: 1.2937, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2666/10000, Loss: 1.2932, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2667/10000, Loss: 1.2926, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2668/10000, Loss: 1.2921, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2669/10000, Loss: 1.2916, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2670/10000, Loss: 1.2911, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2671/10000, Loss: 1.2906, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2672/10000, Loss: 1.2901, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2673/10000, Loss: 1.2896, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2674/10000, Loss: 1.2891, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2675/10000, Loss: 1.2886, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2676/10000, Loss: 1.2881, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2677/10000, Loss: 1.2876, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2678/10000, Loss: 1.2871, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2679/10000, Loss: 1.2867, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2680/10000, Loss: 1.2862, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2681/10000, Loss: 1.2857, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2682/10000, Loss: 1.2852, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2683/10000, Loss: 1.2847, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2684/10000, Loss: 1.2842, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2685/10000, Loss: 1.2837, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2686/10000, Loss: 1.2832, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2687/10000, Loss: 1.2827, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2688/10000, Loss: 1.2822, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2689/10000, Loss: 1.2817, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2690/10000, Loss: 1.2812, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2691/10000, Loss: 1.2807, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2692/10000, Loss: 1.2802, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2693/10000, Loss: 1.2797, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2694/10000, Loss: 1.2792, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2695/10000, Loss: 1.2787, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2696/10000, Loss: 1.2783, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2697/10000, Loss: 1.2778, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2698/10000, Loss: 1.2773, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2699/10000, Loss: 1.2768, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2700/10000, Loss: 1.2763, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2701/10000, Loss: 1.2758, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2702/10000, Loss: 1.2753, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2703/10000, Loss: 1.2748, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2704/10000, Loss: 1.2743, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2705/10000, Loss: 1.2739, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2706/10000, Loss: 1.2734, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2707/10000, Loss: 1.2729, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2708/10000, Loss: 1.2724, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2709/10000, Loss: 1.2719, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2710/10000, Loss: 1.2714, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2711/10000, Loss: 1.2709, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2712/10000, Loss: 1.2705, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2713/10000, Loss: 1.2700, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2714/10000, Loss: 1.2695, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2715/10000, Loss: 1.2690, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2716/10000, Loss: 1.2685, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2717/10000, Loss: 1.2680, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2718/10000, Loss: 1.2676, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2719/10000, Loss: 1.2671, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2720/10000, Loss: 1.2666, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2721/10000, Loss: 1.2661, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2722/10000, Loss: 1.2656, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2723/10000, Loss: 1.2652, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2724/10000, Loss: 1.2647, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2725/10000, Loss: 1.2642, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2726/10000, Loss: 1.2637, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2727/10000, Loss: 1.2632, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2728/10000, Loss: 1.2628, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2729/10000, Loss: 1.2623, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2730/10000, Loss: 1.2618, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2731/10000, Loss: 1.2613, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2732/10000, Loss: 1.2609, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2733/10000, Loss: 1.2604, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2734/10000, Loss: 1.2599, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2735/10000, Loss: 1.2594, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2736/10000, Loss: 1.2590, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2737/10000, Loss: 1.2585, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2738/10000, Loss: 1.2580, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2739/10000, Loss: 1.2575, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2740/10000, Loss: 1.2571, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2741/10000, Loss: 1.2566, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2742/10000, Loss: 1.2561, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2743/10000, Loss: 1.2556, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2744/10000, Loss: 1.2552, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2745/10000, Loss: 1.2547, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2746/10000, Loss: 1.2542, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2747/10000, Loss: 1.2538, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2748/10000, Loss: 1.2533, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2749/10000, Loss: 1.2528, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2750/10000, Loss: 1.2524, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2751/10000, Loss: 1.2519, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2752/10000, Loss: 1.2514, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2753/10000, Loss: 1.2510, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2754/10000, Loss: 1.2505, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2755/10000, Loss: 1.2500, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2756/10000, Loss: 1.2496, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2757/10000, Loss: 1.2491, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2758/10000, Loss: 1.2486, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2759/10000, Loss: 1.2482, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2760/10000, Loss: 1.2477, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2761/10000, Loss: 1.2472, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2762/10000, Loss: 1.2468, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2763/10000, Loss: 1.2463, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2764/10000, Loss: 1.2458, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2765/10000, Loss: 1.2454, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2766/10000, Loss: 1.2449, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2767/10000, Loss: 1.2444, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2768/10000, Loss: 1.2440, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2769/10000, Loss: 1.2435, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2770/10000, Loss: 1.2431, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2771/10000, Loss: 1.2426, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2772/10000, Loss: 1.2421, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2773/10000, Loss: 1.2417, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2774/10000, Loss: 1.2412, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2775/10000, Loss: 1.2408, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2776/10000, Loss: 1.2403, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2777/10000, Loss: 1.2398, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2778/10000, Loss: 1.2394, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2779/10000, Loss: 1.2389, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2780/10000, Loss: 1.2385, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2781/10000, Loss: 1.2380, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2782/10000, Loss: 1.2376, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2783/10000, Loss: 1.2371, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2784/10000, Loss: 1.2366, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2785/10000, Loss: 1.2362, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2786/10000, Loss: 1.2357, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2787/10000, Loss: 1.2353, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2788/10000, Loss: 1.2348, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2789/10000, Loss: 1.2344, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2790/10000, Loss: 1.2339, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2791/10000, Loss: 1.2335, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2792/10000, Loss: 1.2330, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2793/10000, Loss: 1.2326, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2794/10000, Loss: 1.2321, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2795/10000, Loss: 1.2317, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2796/10000, Loss: 1.2312, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2797/10000, Loss: 1.2308, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2798/10000, Loss: 1.2303, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2799/10000, Loss: 1.2299, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2800/10000, Loss: 1.2294, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2801/10000, Loss: 1.2290, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2802/10000, Loss: 1.2285, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2803/10000, Loss: 1.2281, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2804/10000, Loss: 1.2276, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2805/10000, Loss: 1.2272, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2806/10000, Loss: 1.2267, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2807/10000, Loss: 1.2263, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2808/10000, Loss: 1.2258, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2809/10000, Loss: 1.2254, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2810/10000, Loss: 1.2249, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2811/10000, Loss: 1.2245, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2812/10000, Loss: 1.2241, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2813/10000, Loss: 1.2236, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2814/10000, Loss: 1.2232, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2815/10000, Loss: 1.2227, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2816/10000, Loss: 1.2223, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2817/10000, Loss: 1.2218, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2818/10000, Loss: 1.2214, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2819/10000, Loss: 1.2210, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2820/10000, Loss: 1.2205, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2821/10000, Loss: 1.2201, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2822/10000, Loss: 1.2196, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2823/10000, Loss: 1.2192, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2824/10000, Loss: 1.2188, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2825/10000, Loss: 1.2183, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2826/10000, Loss: 1.2179, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2827/10000, Loss: 1.2174, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2828/10000, Loss: 1.2170, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2829/10000, Loss: 1.2166, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2830/10000, Loss: 1.2161, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2831/10000, Loss: 1.2157, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2832/10000, Loss: 1.2153, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2833/10000, Loss: 1.2148, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2834/10000, Loss: 1.2144, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2835/10000, Loss: 1.2140, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2836/10000, Loss: 1.2135, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2837/10000, Loss: 1.2131, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2838/10000, Loss: 1.2126, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2839/10000, Loss: 1.2122, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2840/10000, Loss: 1.2118, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2841/10000, Loss: 1.2113, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2842/10000, Loss: 1.2109, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2843/10000, Loss: 1.2105, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2844/10000, Loss: 1.2101, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2845/10000, Loss: 1.2096, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2846/10000, Loss: 1.2092, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2847/10000, Loss: 1.2088, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2848/10000, Loss: 1.2083, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2849/10000, Loss: 1.2079, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2850/10000, Loss: 1.2075, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2851/10000, Loss: 1.2070, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2852/10000, Loss: 1.2066, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2853/10000, Loss: 1.2062, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2854/10000, Loss: 1.2058, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2855/10000, Loss: 1.2053, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2856/10000, Loss: 1.2049, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2857/10000, Loss: 1.2045, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2858/10000, Loss: 1.2041, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2859/10000, Loss: 1.2036, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2860/10000, Loss: 1.2032, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2861/10000, Loss: 1.2028, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2862/10000, Loss: 1.2024, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2863/10000, Loss: 1.2019, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2864/10000, Loss: 1.2015, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2865/10000, Loss: 1.2011, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2866/10000, Loss: 1.2007, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2867/10000, Loss: 1.2002, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2868/10000, Loss: 1.1998, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2869/10000, Loss: 1.1994, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2870/10000, Loss: 1.1990, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2871/10000, Loss: 1.1985, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2872/10000, Loss: 1.1981, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2873/10000, Loss: 1.1977, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2874/10000, Loss: 1.1973, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2875/10000, Loss: 1.1969, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2876/10000, Loss: 1.1964, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2877/10000, Loss: 1.1960, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2878/10000, Loss: 1.1956, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2879/10000, Loss: 1.1952, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2880/10000, Loss: 1.1948, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2881/10000, Loss: 1.1944, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2882/10000, Loss: 1.1939, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2883/10000, Loss: 1.1935, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2884/10000, Loss: 1.1931, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2885/10000, Loss: 1.1927, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2886/10000, Loss: 1.1923, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2887/10000, Loss: 1.1919, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2888/10000, Loss: 1.1914, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2889/10000, Loss: 1.1910, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2890/10000, Loss: 1.1906, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2891/10000, Loss: 1.1902, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2892/10000, Loss: 1.1898, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2893/10000, Loss: 1.1894, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2894/10000, Loss: 1.1890, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2895/10000, Loss: 1.1886, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2896/10000, Loss: 1.1881, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2897/10000, Loss: 1.1877, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2898/10000, Loss: 1.1873, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2899/10000, Loss: 1.1869, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2900/10000, Loss: 1.1865, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2901/10000, Loss: 1.1861, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2902/10000, Loss: 1.1857, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2903/10000, Loss: 1.1853, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2904/10000, Loss: 1.1849, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2905/10000, Loss: 1.1845, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2906/10000, Loss: 1.1841, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2907/10000, Loss: 1.1836, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2908/10000, Loss: 1.1832, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2909/10000, Loss: 1.1828, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2910/10000, Loss: 1.1824, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2911/10000, Loss: 1.1820, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2912/10000, Loss: 1.1816, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2913/10000, Loss: 1.1812, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2914/10000, Loss: 1.1808, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2915/10000, Loss: 1.1804, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2916/10000, Loss: 1.1800, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2917/10000, Loss: 1.1796, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2918/10000, Loss: 1.1792, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2919/10000, Loss: 1.1788, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2920/10000, Loss: 1.1784, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2921/10000, Loss: 1.1780, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2922/10000, Loss: 1.1776, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2923/10000, Loss: 1.1772, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2924/10000, Loss: 1.1768, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2925/10000, Loss: 1.1764, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2926/10000, Loss: 1.1760, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2927/10000, Loss: 1.1756, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2928/10000, Loss: 1.1752, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2929/10000, Loss: 1.1748, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2930/10000, Loss: 1.1744, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2931/10000, Loss: 1.1740, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2932/10000, Loss: 1.1736, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2933/10000, Loss: 1.1732, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2934/10000, Loss: 1.1728, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2935/10000, Loss: 1.1724, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2936/10000, Loss: 1.1720, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2937/10000, Loss: 1.1716, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2938/10000, Loss: 1.1712, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2939/10000, Loss: 1.1708, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2940/10000, Loss: 1.1704, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2941/10000, Loss: 1.1700, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2942/10000, Loss: 1.1696, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2943/10000, Loss: 1.1692, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2944/10000, Loss: 1.1689, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2945/10000, Loss: 1.1685, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2946/10000, Loss: 1.1681, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2947/10000, Loss: 1.1677, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2948/10000, Loss: 1.1673, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2949/10000, Loss: 1.1669, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2950/10000, Loss: 1.1665, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2951/10000, Loss: 1.1661, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2952/10000, Loss: 1.1657, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2953/10000, Loss: 1.1653, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2954/10000, Loss: 1.1649, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2955/10000, Loss: 1.1646, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2956/10000, Loss: 1.1642, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2957/10000, Loss: 1.1638, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2958/10000, Loss: 1.1634, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2959/10000, Loss: 1.1630, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2960/10000, Loss: 1.1626, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2961/10000, Loss: 1.1622, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2962/10000, Loss: 1.1618, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2963/10000, Loss: 1.1615, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2964/10000, Loss: 1.1611, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2965/10000, Loss: 1.1607, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2966/10000, Loss: 1.1603, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2967/10000, Loss: 1.1599, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2968/10000, Loss: 1.1595, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2969/10000, Loss: 1.1592, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2970/10000, Loss: 1.1588, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2971/10000, Loss: 1.1584, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2972/10000, Loss: 1.1580, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2973/10000, Loss: 1.1576, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2974/10000, Loss: 1.1572, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2975/10000, Loss: 1.1569, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2976/10000, Loss: 1.1565, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2977/10000, Loss: 1.1561, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2978/10000, Loss: 1.1557, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2979/10000, Loss: 1.1553, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2980/10000, Loss: 1.1550, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2981/10000, Loss: 1.1546, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2982/10000, Loss: 1.1542, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2983/10000, Loss: 1.1538, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2984/10000, Loss: 1.1534, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2985/10000, Loss: 1.1531, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2986/10000, Loss: 1.1527, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2987/10000, Loss: 1.1523, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2988/10000, Loss: 1.1519, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2989/10000, Loss: 1.1516, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2990/10000, Loss: 1.1512, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2991/10000, Loss: 1.1508, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2992/10000, Loss: 1.1504, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2993/10000, Loss: 1.1501, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2994/10000, Loss: 1.1497, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2995/10000, Loss: 1.1493, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2996/10000, Loss: 1.1489, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2997/10000, Loss: 1.1486, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2998/10000, Loss: 1.1482, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2999/10000, Loss: 1.1478, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3000/10000, Loss: 1.1474, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3001/10000, Loss: 1.1471, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3002/10000, Loss: 1.1467, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3003/10000, Loss: 1.1463, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3004/10000, Loss: 1.1460, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3005/10000, Loss: 1.1456, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3006/10000, Loss: 1.1452, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3007/10000, Loss: 1.1449, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3008/10000, Loss: 1.1445, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3009/10000, Loss: 1.1441, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3010/10000, Loss: 1.1437, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3011/10000, Loss: 1.1434, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3012/10000, Loss: 1.1430, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3013/10000, Loss: 1.1426, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3014/10000, Loss: 1.1423, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3015/10000, Loss: 1.1419, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3016/10000, Loss: 1.1415, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3017/10000, Loss: 1.1412, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3018/10000, Loss: 1.1408, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3019/10000, Loss: 1.1404, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3020/10000, Loss: 1.1401, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3021/10000, Loss: 1.1397, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3022/10000, Loss: 1.1394, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3023/10000, Loss: 1.1390, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3024/10000, Loss: 1.1386, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3025/10000, Loss: 1.1383, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3026/10000, Loss: 1.1379, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3027/10000, Loss: 1.1375, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3028/10000, Loss: 1.1372, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3029/10000, Loss: 1.1368, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3030/10000, Loss: 1.1365, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3031/10000, Loss: 1.1361, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3032/10000, Loss: 1.1357, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3033/10000, Loss: 1.1354, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3034/10000, Loss: 1.1350, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3035/10000, Loss: 1.1347, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3036/10000, Loss: 1.1343, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3037/10000, Loss: 1.1339, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3038/10000, Loss: 1.1336, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3039/10000, Loss: 1.1332, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3040/10000, Loss: 1.1329, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3041/10000, Loss: 1.1325, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3042/10000, Loss: 1.1322, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3043/10000, Loss: 1.1318, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3044/10000, Loss: 1.1314, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3045/10000, Loss: 1.1311, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3046/10000, Loss: 1.1307, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3047/10000, Loss: 1.1304, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3048/10000, Loss: 1.1300, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3049/10000, Loss: 1.1297, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3050/10000, Loss: 1.1293, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3051/10000, Loss: 1.1290, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3052/10000, Loss: 1.1286, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3053/10000, Loss: 1.1283, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3054/10000, Loss: 1.1279, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3055/10000, Loss: 1.1275, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3056/10000, Loss: 1.1272, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3057/10000, Loss: 1.1268, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3058/10000, Loss: 1.1265, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3059/10000, Loss: 1.1261, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3060/10000, Loss: 1.1258, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3061/10000, Loss: 1.1254, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3062/10000, Loss: 1.1251, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3063/10000, Loss: 1.1247, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3064/10000, Loss: 1.1244, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3065/10000, Loss: 1.1240, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 3066/10000, Loss: 1.1237, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 3067/10000, Loss: 1.1233, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 3068/10000, Loss: 1.1230, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 3069/10000, Loss: 1.1227, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 3070/10000, Loss: 1.1223, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 3071/10000, Loss: 1.1220, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 3072/10000, Loss: 1.1216, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 3073/10000, Loss: 1.1213, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 3074/10000, Loss: 1.1209, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 3075/10000, Loss: 1.1206, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 3076/10000, Loss: 1.1202, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 3077/10000, Loss: 1.1199, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3078/10000, Loss: 1.1195, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3079/10000, Loss: 1.1192, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3080/10000, Loss: 1.1189, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3081/10000, Loss: 1.1185, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3082/10000, Loss: 1.1182, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3083/10000, Loss: 1.1178, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3084/10000, Loss: 1.1175, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3085/10000, Loss: 1.1171, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3086/10000, Loss: 1.1168, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3087/10000, Loss: 1.1165, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3088/10000, Loss: 1.1161, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3089/10000, Loss: 1.1158, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3090/10000, Loss: 1.1154, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3091/10000, Loss: 1.1151, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3092/10000, Loss: 1.1148, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3093/10000, Loss: 1.1144, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3094/10000, Loss: 1.1141, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3095/10000, Loss: 1.1138, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3096/10000, Loss: 1.1134, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3097/10000, Loss: 1.1131, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3098/10000, Loss: 1.1127, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3099/10000, Loss: 1.1124, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3100/10000, Loss: 1.1121, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3101/10000, Loss: 1.1117, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3102/10000, Loss: 1.1114, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3103/10000, Loss: 1.1111, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3104/10000, Loss: 1.1107, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3105/10000, Loss: 1.1104, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3106/10000, Loss: 1.1101, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3107/10000, Loss: 1.1097, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3108/10000, Loss: 1.1094, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3109/10000, Loss: 1.1091, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3110/10000, Loss: 1.1087, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3111/10000, Loss: 1.1084, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3112/10000, Loss: 1.1081, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3113/10000, Loss: 1.1077, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3114/10000, Loss: 1.1074, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3115/10000, Loss: 1.1071, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3116/10000, Loss: 1.1067, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3117/10000, Loss: 1.1064, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3118/10000, Loss: 1.1061, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3119/10000, Loss: 1.1057, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3120/10000, Loss: 1.1054, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3121/10000, Loss: 1.1051, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3122/10000, Loss: 1.1048, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3123/10000, Loss: 1.1044, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3124/10000, Loss: 1.1041, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3125/10000, Loss: 1.1038, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3126/10000, Loss: 1.1034, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3127/10000, Loss: 1.1031, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3128/10000, Loss: 1.1028, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3129/10000, Loss: 1.1025, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3130/10000, Loss: 1.1021, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3131/10000, Loss: 1.1018, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3132/10000, Loss: 1.1015, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3133/10000, Loss: 1.1012, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3134/10000, Loss: 1.1008, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3135/10000, Loss: 1.1005, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3136/10000, Loss: 1.1002, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3137/10000, Loss: 1.0999, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3138/10000, Loss: 1.0995, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3139/10000, Loss: 1.0992, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3140/10000, Loss: 1.0989, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3141/10000, Loss: 1.0986, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3142/10000, Loss: 1.0983, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3143/10000, Loss: 1.0979, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3144/10000, Loss: 1.0976, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3145/10000, Loss: 1.0973, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3146/10000, Loss: 1.0970, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3147/10000, Loss: 1.0966, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3148/10000, Loss: 1.0963, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3149/10000, Loss: 1.0960, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3150/10000, Loss: 1.0957, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3151/10000, Loss: 1.0954, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3152/10000, Loss: 1.0950, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3153/10000, Loss: 1.0947, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3154/10000, Loss: 1.0944, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3155/10000, Loss: 1.0941, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3156/10000, Loss: 1.0938, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3157/10000, Loss: 1.0935, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3158/10000, Loss: 1.0931, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3159/10000, Loss: 1.0928, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3160/10000, Loss: 1.0925, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3161/10000, Loss: 1.0922, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3162/10000, Loss: 1.0919, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3163/10000, Loss: 1.0916, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 3164/10000, Loss: 1.0912, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3165/10000, Loss: 1.0909, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3166/10000, Loss: 1.0906, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3167/10000, Loss: 1.0903, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3168/10000, Loss: 1.0900, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3169/10000, Loss: 1.0897, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3170/10000, Loss: 1.0894, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3171/10000, Loss: 1.0891, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3172/10000, Loss: 1.0887, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3173/10000, Loss: 1.0884, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3174/10000, Loss: 1.0881, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3175/10000, Loss: 1.0878, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3176/10000, Loss: 1.0875, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3177/10000, Loss: 1.0872, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3178/10000, Loss: 1.0869, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3179/10000, Loss: 1.0866, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3180/10000, Loss: 1.0863, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3181/10000, Loss: 1.0859, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3182/10000, Loss: 1.0856, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3183/10000, Loss: 1.0853, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3184/10000, Loss: 1.0850, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3185/10000, Loss: 1.0847, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3186/10000, Loss: 1.0844, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3187/10000, Loss: 1.0841, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3188/10000, Loss: 1.0838, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3189/10000, Loss: 1.0835, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3190/10000, Loss: 1.0832, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3191/10000, Loss: 1.0829, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3192/10000, Loss: 1.0826, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3193/10000, Loss: 1.0823, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3194/10000, Loss: 1.0820, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3195/10000, Loss: 1.0817, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3196/10000, Loss: 1.0813, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3197/10000, Loss: 1.0810, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3198/10000, Loss: 1.0807, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3199/10000, Loss: 1.0804, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3200/10000, Loss: 1.0801, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3201/10000, Loss: 1.0798, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3202/10000, Loss: 1.0795, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3203/10000, Loss: 1.0792, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3204/10000, Loss: 1.0789, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3205/10000, Loss: 1.0786, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3206/10000, Loss: 1.0783, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3207/10000, Loss: 1.0780, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3208/10000, Loss: 1.0777, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3209/10000, Loss: 1.0774, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3210/10000, Loss: 1.0771, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3211/10000, Loss: 1.0768, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3212/10000, Loss: 1.0765, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3213/10000, Loss: 1.0762, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3214/10000, Loss: 1.0759, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3215/10000, Loss: 1.0756, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3216/10000, Loss: 1.0753, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3217/10000, Loss: 1.0750, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3218/10000, Loss: 1.0747, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3219/10000, Loss: 1.0744, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3220/10000, Loss: 1.0741, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3221/10000, Loss: 1.0738, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3222/10000, Loss: 1.0735, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3223/10000, Loss: 1.0732, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3224/10000, Loss: 1.0729, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3225/10000, Loss: 1.0727, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3226/10000, Loss: 1.0724, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3227/10000, Loss: 1.0721, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3228/10000, Loss: 1.0718, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3229/10000, Loss: 1.0715, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3230/10000, Loss: 1.0712, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3231/10000, Loss: 1.0709, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3232/10000, Loss: 1.0706, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3233/10000, Loss: 1.0703, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3234/10000, Loss: 1.0700, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3235/10000, Loss: 1.0697, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3236/10000, Loss: 1.0694, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3237/10000, Loss: 1.0691, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3238/10000, Loss: 1.0688, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3239/10000, Loss: 1.0685, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3240/10000, Loss: 1.0683, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3241/10000, Loss: 1.0680, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3242/10000, Loss: 1.0677, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3243/10000, Loss: 1.0674, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3244/10000, Loss: 1.0671, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3245/10000, Loss: 1.0668, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3246/10000, Loss: 1.0665, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3247/10000, Loss: 1.0662, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3248/10000, Loss: 1.0659, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3249/10000, Loss: 1.0656, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3250/10000, Loss: 1.0654, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3251/10000, Loss: 1.0651, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3252/10000, Loss: 1.0648, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3253/10000, Loss: 1.0645, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3254/10000, Loss: 1.0642, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3255/10000, Loss: 1.0639, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3256/10000, Loss: 1.0636, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3257/10000, Loss: 1.0634, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3258/10000, Loss: 1.0631, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3259/10000, Loss: 1.0628, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3260/10000, Loss: 1.0625, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3261/10000, Loss: 1.0622, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3262/10000, Loss: 1.0619, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3263/10000, Loss: 1.0616, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3264/10000, Loss: 1.0614, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3265/10000, Loss: 1.0611, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3266/10000, Loss: 1.0608, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3267/10000, Loss: 1.0605, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3268/10000, Loss: 1.0602, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3269/10000, Loss: 1.0599, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3270/10000, Loss: 1.0597, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3271/10000, Loss: 1.0594, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3272/10000, Loss: 1.0591, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3273/10000, Loss: 1.0588, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3274/10000, Loss: 1.0585, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3275/10000, Loss: 1.0583, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3276/10000, Loss: 1.0580, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3277/10000, Loss: 1.0577, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3278/10000, Loss: 1.0574, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3279/10000, Loss: 1.0571, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3280/10000, Loss: 1.0569, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3281/10000, Loss: 1.0566, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3282/10000, Loss: 1.0563, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3283/10000, Loss: 1.0560, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3284/10000, Loss: 1.0557, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3285/10000, Loss: 1.0555, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3286/10000, Loss: 1.0552, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3287/10000, Loss: 1.0549, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3288/10000, Loss: 1.0546, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3289/10000, Loss: 1.0544, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3290/10000, Loss: 1.0541, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3291/10000, Loss: 1.0538, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3292/10000, Loss: 1.0535, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3293/10000, Loss: 1.0533, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3294/10000, Loss: 1.0530, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3295/10000, Loss: 1.0527, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3296/10000, Loss: 1.0524, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3297/10000, Loss: 1.0522, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3298/10000, Loss: 1.0519, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3299/10000, Loss: 1.0516, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3300/10000, Loss: 1.0513, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3301/10000, Loss: 1.0511, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3302/10000, Loss: 1.0508, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3303/10000, Loss: 1.0505, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3304/10000, Loss: 1.0502, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3305/10000, Loss: 1.0500, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3306/10000, Loss: 1.0497, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3307/10000, Loss: 1.0494, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3308/10000, Loss: 1.0492, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3309/10000, Loss: 1.0489, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3310/10000, Loss: 1.0486, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3311/10000, Loss: 1.0483, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3312/10000, Loss: 1.0481, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3313/10000, Loss: 1.0478, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3314/10000, Loss: 1.0475, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3315/10000, Loss: 1.0473, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3316/10000, Loss: 1.0470, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3317/10000, Loss: 1.0467, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3318/10000, Loss: 1.0465, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3319/10000, Loss: 1.0462, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3320/10000, Loss: 1.0459, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3321/10000, Loss: 1.0457, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3322/10000, Loss: 1.0454, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3323/10000, Loss: 1.0451, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3324/10000, Loss: 1.0449, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3325/10000, Loss: 1.0446, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3326/10000, Loss: 1.0443, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3327/10000, Loss: 1.0441, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3328/10000, Loss: 1.0438, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3329/10000, Loss: 1.0435, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3330/10000, Loss: 1.0433, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3331/10000, Loss: 1.0430, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3332/10000, Loss: 1.0427, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3333/10000, Loss: 1.0425, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3334/10000, Loss: 1.0422, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3335/10000, Loss: 1.0419, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3336/10000, Loss: 1.0417, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3337/10000, Loss: 1.0414, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3338/10000, Loss: 1.0412, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3339/10000, Loss: 1.0409, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3340/10000, Loss: 1.0406, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3341/10000, Loss: 1.0404, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3342/10000, Loss: 1.0401, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 3343/10000, Loss: 1.0398, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 3344/10000, Loss: 1.0396, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3345/10000, Loss: 1.0393, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3346/10000, Loss: 1.0391, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3347/10000, Loss: 1.0388, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3348/10000, Loss: 1.0385, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3349/10000, Loss: 1.0383, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3350/10000, Loss: 1.0380, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3351/10000, Loss: 1.0378, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3352/10000, Loss: 1.0375, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3353/10000, Loss: 1.0372, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3354/10000, Loss: 1.0370, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3355/10000, Loss: 1.0367, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3356/10000, Loss: 1.0365, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3357/10000, Loss: 1.0362, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3358/10000, Loss: 1.0360, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3359/10000, Loss: 1.0357, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3360/10000, Loss: 1.0354, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3361/10000, Loss: 1.0352, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3362/10000, Loss: 1.0349, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3363/10000, Loss: 1.0347, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3364/10000, Loss: 1.0344, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3365/10000, Loss: 1.0342, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3366/10000, Loss: 1.0339, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3367/10000, Loss: 1.0336, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3368/10000, Loss: 1.0334, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3369/10000, Loss: 1.0331, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3370/10000, Loss: 1.0329, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3371/10000, Loss: 1.0326, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3372/10000, Loss: 1.0324, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3373/10000, Loss: 1.0321, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3374/10000, Loss: 1.0319, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3375/10000, Loss: 1.0316, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3376/10000, Loss: 1.0314, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3377/10000, Loss: 1.0311, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3378/10000, Loss: 1.0309, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3379/10000, Loss: 1.0306, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3380/10000, Loss: 1.0303, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3381/10000, Loss: 1.0301, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3382/10000, Loss: 1.0298, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3383/10000, Loss: 1.0296, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3384/10000, Loss: 1.0293, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3385/10000, Loss: 1.0291, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3386/10000, Loss: 1.0288, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3387/10000, Loss: 1.0286, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3388/10000, Loss: 1.0283, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3389/10000, Loss: 1.0281, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3390/10000, Loss: 1.0278, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3391/10000, Loss: 1.0276, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3392/10000, Loss: 1.0273, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3393/10000, Loss: 1.0271, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3394/10000, Loss: 1.0268, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3395/10000, Loss: 1.0266, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3396/10000, Loss: 1.0264, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3397/10000, Loss: 1.0261, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3398/10000, Loss: 1.0259, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3399/10000, Loss: 1.0256, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3400/10000, Loss: 1.0254, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3401/10000, Loss: 1.0251, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3402/10000, Loss: 1.0249, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3403/10000, Loss: 1.0246, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3404/10000, Loss: 1.0244, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3405/10000, Loss: 1.0241, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3406/10000, Loss: 1.0239, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3407/10000, Loss: 1.0236, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3408/10000, Loss: 1.0234, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3409/10000, Loss: 1.0232, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3410/10000, Loss: 1.0229, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3411/10000, Loss: 1.0227, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3412/10000, Loss: 1.0224, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3413/10000, Loss: 1.0222, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3414/10000, Loss: 1.0219, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3415/10000, Loss: 1.0217, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3416/10000, Loss: 1.0214, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3417/10000, Loss: 1.0212, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3418/10000, Loss: 1.0210, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3419/10000, Loss: 1.0207, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3420/10000, Loss: 1.0205, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3421/10000, Loss: 1.0202, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3422/10000, Loss: 1.0200, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3423/10000, Loss: 1.0198, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3424/10000, Loss: 1.0195, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3425/10000, Loss: 1.0193, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3426/10000, Loss: 1.0190, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3427/10000, Loss: 1.0188, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3428/10000, Loss: 1.0186, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3429/10000, Loss: 1.0183, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3430/10000, Loss: 1.0181, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3431/10000, Loss: 1.0178, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3432/10000, Loss: 1.0176, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3433/10000, Loss: 1.0174, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3434/10000, Loss: 1.0171, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3435/10000, Loss: 1.0169, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3436/10000, Loss: 1.0166, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3437/10000, Loss: 1.0164, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3438/10000, Loss: 1.0162, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3439/10000, Loss: 1.0159, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3440/10000, Loss: 1.0157, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3441/10000, Loss: 1.0155, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3442/10000, Loss: 1.0152, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3443/10000, Loss: 1.0150, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3444/10000, Loss: 1.0147, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3445/10000, Loss: 1.0145, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3446/10000, Loss: 1.0143, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3447/10000, Loss: 1.0140, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3448/10000, Loss: 1.0138, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3449/10000, Loss: 1.0136, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3450/10000, Loss: 1.0133, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3451/10000, Loss: 1.0131, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3452/10000, Loss: 1.0129, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3453/10000, Loss: 1.0126, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3454/10000, Loss: 1.0124, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3455/10000, Loss: 1.0122, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3456/10000, Loss: 1.0119, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3457/10000, Loss: 1.0117, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3458/10000, Loss: 1.0115, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3459/10000, Loss: 1.0112, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3460/10000, Loss: 1.0110, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3461/10000, Loss: 1.0108, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3462/10000, Loss: 1.0105, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3463/10000, Loss: 1.0103, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3464/10000, Loss: 1.0101, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3465/10000, Loss: 1.0098, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3466/10000, Loss: 1.0096, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3467/10000, Loss: 1.0094, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3468/10000, Loss: 1.0091, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3469/10000, Loss: 1.0089, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3470/10000, Loss: 1.0087, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3471/10000, Loss: 1.0085, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3472/10000, Loss: 1.0082, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3473/10000, Loss: 1.0080, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3474/10000, Loss: 1.0078, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3475/10000, Loss: 1.0075, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3476/10000, Loss: 1.0073, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3477/10000, Loss: 1.0071, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3478/10000, Loss: 1.0069, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3479/10000, Loss: 1.0066, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3480/10000, Loss: 1.0064, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3481/10000, Loss: 1.0062, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3482/10000, Loss: 1.0059, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3483/10000, Loss: 1.0057, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3484/10000, Loss: 1.0055, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3485/10000, Loss: 1.0053, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3486/10000, Loss: 1.0050, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3487/10000, Loss: 1.0048, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3488/10000, Loss: 1.0046, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3489/10000, Loss: 1.0044, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3490/10000, Loss: 1.0041, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3491/10000, Loss: 1.0039, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3492/10000, Loss: 1.0037, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3493/10000, Loss: 1.0035, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3494/10000, Loss: 1.0032, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3495/10000, Loss: 1.0030, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3496/10000, Loss: 1.0028, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3497/10000, Loss: 1.0026, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3498/10000, Loss: 1.0023, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3499/10000, Loss: 1.0021, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3500/10000, Loss: 1.0019, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3501/10000, Loss: 1.0017, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3502/10000, Loss: 1.0014, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3503/10000, Loss: 1.0012, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3504/10000, Loss: 1.0010, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3505/10000, Loss: 1.0008, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3506/10000, Loss: 1.0005, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3507/10000, Loss: 1.0003, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3508/10000, Loss: 1.0001, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3509/10000, Loss: 0.9999, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3510/10000, Loss: 0.9997, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3511/10000, Loss: 0.9994, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3512/10000, Loss: 0.9992, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3513/10000, Loss: 0.9990, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3514/10000, Loss: 0.9988, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3515/10000, Loss: 0.9986, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3516/10000, Loss: 0.9983, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3517/10000, Loss: 0.9981, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3518/10000, Loss: 0.9979, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3519/10000, Loss: 0.9977, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3520/10000, Loss: 0.9975, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3521/10000, Loss: 0.9972, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3522/10000, Loss: 0.9970, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3523/10000, Loss: 0.9968, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3524/10000, Loss: 0.9966, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3525/10000, Loss: 0.9964, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3526/10000, Loss: 0.9962, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3527/10000, Loss: 0.9959, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3528/10000, Loss: 0.9957, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3529/10000, Loss: 0.9955, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3530/10000, Loss: 0.9953, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3531/10000, Loss: 0.9951, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3532/10000, Loss: 0.9949, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3533/10000, Loss: 0.9946, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3534/10000, Loss: 0.9944, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3535/10000, Loss: 0.9942, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3536/10000, Loss: 0.9940, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3537/10000, Loss: 0.9938, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3538/10000, Loss: 0.9936, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3539/10000, Loss: 0.9933, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3540/10000, Loss: 0.9931, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3541/10000, Loss: 0.9929, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3542/10000, Loss: 0.9927, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3543/10000, Loss: 0.9925, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3544/10000, Loss: 0.9923, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3545/10000, Loss: 0.9921, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3546/10000, Loss: 0.9918, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3547/10000, Loss: 0.9916, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3548/10000, Loss: 0.9914, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3549/10000, Loss: 0.9912, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3550/10000, Loss: 0.9910, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3551/10000, Loss: 0.9908, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3552/10000, Loss: 0.9906, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3553/10000, Loss: 0.9904, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3554/10000, Loss: 0.9901, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3555/10000, Loss: 0.9899, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3556/10000, Loss: 0.9897, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3557/10000, Loss: 0.9895, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3558/10000, Loss: 0.9893, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3559/10000, Loss: 0.9891, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3560/10000, Loss: 0.9889, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3561/10000, Loss: 0.9887, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3562/10000, Loss: 0.9885, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3563/10000, Loss: 0.9882, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3564/10000, Loss: 0.9880, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3565/10000, Loss: 0.9878, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3566/10000, Loss: 0.9876, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3567/10000, Loss: 0.9874, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3568/10000, Loss: 0.9872, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3569/10000, Loss: 0.9870, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3570/10000, Loss: 0.9868, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3571/10000, Loss: 0.9866, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3572/10000, Loss: 0.9864, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3573/10000, Loss: 0.9862, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3574/10000, Loss: 0.9859, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3575/10000, Loss: 0.9857, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3576/10000, Loss: 0.9855, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3577/10000, Loss: 0.9853, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3578/10000, Loss: 0.9851, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3579/10000, Loss: 0.9849, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3580/10000, Loss: 0.9847, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3581/10000, Loss: 0.9845, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3582/10000, Loss: 0.9843, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3583/10000, Loss: 0.9841, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3584/10000, Loss: 0.9839, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3585/10000, Loss: 0.9837, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3586/10000, Loss: 0.9835, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3587/10000, Loss: 0.9833, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3588/10000, Loss: 0.9831, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3589/10000, Loss: 0.9829, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3590/10000, Loss: 0.9826, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3591/10000, Loss: 0.9824, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3592/10000, Loss: 0.9822, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3593/10000, Loss: 0.9820, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3594/10000, Loss: 0.9818, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3595/10000, Loss: 0.9816, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3596/10000, Loss: 0.9814, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3597/10000, Loss: 0.9812, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3598/10000, Loss: 0.9810, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3599/10000, Loss: 0.9808, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3600/10000, Loss: 0.9806, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3601/10000, Loss: 0.9804, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3602/10000, Loss: 0.9802, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3603/10000, Loss: 0.9800, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3604/10000, Loss: 0.9798, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3605/10000, Loss: 0.9796, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3606/10000, Loss: 0.9794, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3607/10000, Loss: 0.9792, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3608/10000, Loss: 0.9790, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3609/10000, Loss: 0.9788, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3610/10000, Loss: 0.9786, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3611/10000, Loss: 0.9784, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3612/10000, Loss: 0.9782, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3613/10000, Loss: 0.9780, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3614/10000, Loss: 0.9778, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3615/10000, Loss: 0.9776, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3616/10000, Loss: 0.9774, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3617/10000, Loss: 0.9772, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3618/10000, Loss: 0.9770, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3619/10000, Loss: 0.9768, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3620/10000, Loss: 0.9766, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3621/10000, Loss: 0.9764, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3622/10000, Loss: 0.9762, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3623/10000, Loss: 0.9760, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3624/10000, Loss: 0.9758, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3625/10000, Loss: 0.9756, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3626/10000, Loss: 0.9754, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3627/10000, Loss: 0.9752, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3628/10000, Loss: 0.9750, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3629/10000, Loss: 0.9748, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3630/10000, Loss: 0.9746, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3631/10000, Loss: 0.9744, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3632/10000, Loss: 0.9742, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3633/10000, Loss: 0.9740, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3634/10000, Loss: 0.9738, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3635/10000, Loss: 0.9736, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3636/10000, Loss: 0.9734, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3637/10000, Loss: 0.9732, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3638/10000, Loss: 0.9731, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3639/10000, Loss: 0.9729, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3640/10000, Loss: 0.9727, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3641/10000, Loss: 0.9725, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3642/10000, Loss: 0.9723, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3643/10000, Loss: 0.9721, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3644/10000, Loss: 0.9719, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3645/10000, Loss: 0.9717, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3646/10000, Loss: 0.9715, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3647/10000, Loss: 0.9713, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3648/10000, Loss: 0.9711, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3649/10000, Loss: 0.9709, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3650/10000, Loss: 0.9707, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3651/10000, Loss: 0.9705, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3652/10000, Loss: 0.9703, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3653/10000, Loss: 0.9701, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3654/10000, Loss: 0.9700, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3655/10000, Loss: 0.9698, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3656/10000, Loss: 0.9696, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3657/10000, Loss: 0.9694, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3658/10000, Loss: 0.9692, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3659/10000, Loss: 0.9690, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3660/10000, Loss: 0.9688, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3661/10000, Loss: 0.9686, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3662/10000, Loss: 0.9684, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3663/10000, Loss: 0.9682, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3664/10000, Loss: 0.9680, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3665/10000, Loss: 0.9678, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3666/10000, Loss: 0.9677, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3667/10000, Loss: 0.9675, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3668/10000, Loss: 0.9673, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3669/10000, Loss: 0.9671, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3670/10000, Loss: 0.9669, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3671/10000, Loss: 0.9667, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3672/10000, Loss: 0.9665, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3673/10000, Loss: 0.9663, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3674/10000, Loss: 0.9661, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3675/10000, Loss: 0.9660, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3676/10000, Loss: 0.9658, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3677/10000, Loss: 0.9656, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3678/10000, Loss: 0.9654, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3679/10000, Loss: 0.9652, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3680/10000, Loss: 0.9650, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3681/10000, Loss: 0.9648, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3682/10000, Loss: 0.9646, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3683/10000, Loss: 0.9645, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3684/10000, Loss: 0.9643, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3685/10000, Loss: 0.9641, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3686/10000, Loss: 0.9639, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3687/10000, Loss: 0.9637, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3688/10000, Loss: 0.9635, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3689/10000, Loss: 0.9633, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3690/10000, Loss: 0.9631, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3691/10000, Loss: 0.9630, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3692/10000, Loss: 0.9628, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3693/10000, Loss: 0.9626, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3694/10000, Loss: 0.9624, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3695/10000, Loss: 0.9622, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3696/10000, Loss: 0.9620, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3697/10000, Loss: 0.9618, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3698/10000, Loss: 0.9617, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3699/10000, Loss: 0.9615, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3700/10000, Loss: 0.9613, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3701/10000, Loss: 0.9611, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3702/10000, Loss: 0.9609, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3703/10000, Loss: 0.9607, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3704/10000, Loss: 0.9606, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3705/10000, Loss: 0.9604, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3706/10000, Loss: 0.9602, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3707/10000, Loss: 0.9600, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3708/10000, Loss: 0.9598, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3709/10000, Loss: 0.9596, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3710/10000, Loss: 0.9595, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3711/10000, Loss: 0.9593, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3712/10000, Loss: 0.9591, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3713/10000, Loss: 0.9589, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3714/10000, Loss: 0.9587, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3715/10000, Loss: 0.9586, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3716/10000, Loss: 0.9584, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3717/10000, Loss: 0.9582, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3718/10000, Loss: 0.9580, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3719/10000, Loss: 0.9578, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3720/10000, Loss: 0.9577, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3721/10000, Loss: 0.9575, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3722/10000, Loss: 0.9573, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3723/10000, Loss: 0.9571, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3724/10000, Loss: 0.9569, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3725/10000, Loss: 0.9568, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3726/10000, Loss: 0.9566, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3727/10000, Loss: 0.9564, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3728/10000, Loss: 0.9562, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3729/10000, Loss: 0.9560, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3730/10000, Loss: 0.9559, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3731/10000, Loss: 0.9557, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3732/10000, Loss: 0.9555, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3733/10000, Loss: 0.9553, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3734/10000, Loss: 0.9551, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3735/10000, Loss: 0.9550, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3736/10000, Loss: 0.9548, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3737/10000, Loss: 0.9546, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3738/10000, Loss: 0.9544, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3739/10000, Loss: 0.9543, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3740/10000, Loss: 0.9541, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3741/10000, Loss: 0.9539, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3742/10000, Loss: 0.9537, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3743/10000, Loss: 0.9535, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3744/10000, Loss: 0.9534, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3745/10000, Loss: 0.9532, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3746/10000, Loss: 0.9530, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3747/10000, Loss: 0.9528, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3748/10000, Loss: 0.9527, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3749/10000, Loss: 0.9525, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3750/10000, Loss: 0.9523, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3751/10000, Loss: 0.9521, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3752/10000, Loss: 0.9520, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3753/10000, Loss: 0.9518, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3754/10000, Loss: 0.9516, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3755/10000, Loss: 0.9514, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3756/10000, Loss: 0.9513, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3757/10000, Loss: 0.9511, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3758/10000, Loss: 0.9509, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3759/10000, Loss: 0.9507, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3760/10000, Loss: 0.9506, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3761/10000, Loss: 0.9504, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3762/10000, Loss: 0.9502, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3763/10000, Loss: 0.9500, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3764/10000, Loss: 0.9499, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3765/10000, Loss: 0.9497, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3766/10000, Loss: 0.9495, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3767/10000, Loss: 0.9494, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3768/10000, Loss: 0.9492, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3769/10000, Loss: 0.9490, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3770/10000, Loss: 0.9488, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3771/10000, Loss: 0.9487, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3772/10000, Loss: 0.9485, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3773/10000, Loss: 0.9483, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3774/10000, Loss: 0.9481, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3775/10000, Loss: 0.9480, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3776/10000, Loss: 0.9478, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3777/10000, Loss: 0.9476, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3778/10000, Loss: 0.9475, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3779/10000, Loss: 0.9473, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3780/10000, Loss: 0.9471, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3781/10000, Loss: 0.9470, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3782/10000, Loss: 0.9468, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3783/10000, Loss: 0.9466, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3784/10000, Loss: 0.9464, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3785/10000, Loss: 0.9463, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3786/10000, Loss: 0.9461, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3787/10000, Loss: 0.9459, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3788/10000, Loss: 0.9458, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3789/10000, Loss: 0.9456, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3790/10000, Loss: 0.9454, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3791/10000, Loss: 0.9453, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3792/10000, Loss: 0.9451, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3793/10000, Loss: 0.9449, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3794/10000, Loss: 0.9447, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3795/10000, Loss: 0.9446, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3796/10000, Loss: 0.9444, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3797/10000, Loss: 0.9442, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3798/10000, Loss: 0.9441, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3799/10000, Loss: 0.9439, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3800/10000, Loss: 0.9437, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3801/10000, Loss: 0.9436, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3802/10000, Loss: 0.9434, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3803/10000, Loss: 0.9432, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3804/10000, Loss: 0.9431, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3805/10000, Loss: 0.9429, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3806/10000, Loss: 0.9427, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3807/10000, Loss: 0.9426, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3808/10000, Loss: 0.9424, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3809/10000, Loss: 0.9422, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3810/10000, Loss: 0.9421, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3811/10000, Loss: 0.9419, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3812/10000, Loss: 0.9417, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3813/10000, Loss: 0.9416, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3814/10000, Loss: 0.9414, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3815/10000, Loss: 0.9413, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3816/10000, Loss: 0.9411, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3817/10000, Loss: 0.9409, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3818/10000, Loss: 0.9408, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3819/10000, Loss: 0.9406, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3820/10000, Loss: 0.9404, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3821/10000, Loss: 0.9403, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3822/10000, Loss: 0.9401, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3823/10000, Loss: 0.9399, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3824/10000, Loss: 0.9398, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3825/10000, Loss: 0.9396, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3826/10000, Loss: 0.9394, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3827/10000, Loss: 0.9393, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3828/10000, Loss: 0.9391, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3829/10000, Loss: 0.9390, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3830/10000, Loss: 0.9388, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3831/10000, Loss: 0.9386, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3832/10000, Loss: 0.9385, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3833/10000, Loss: 0.9383, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3834/10000, Loss: 0.9381, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3835/10000, Loss: 0.9380, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3836/10000, Loss: 0.9378, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3837/10000, Loss: 0.9377, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3838/10000, Loss: 0.9375, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3839/10000, Loss: 0.9373, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3840/10000, Loss: 0.9372, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3841/10000, Loss: 0.9370, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3842/10000, Loss: 0.9369, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3843/10000, Loss: 0.9367, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3844/10000, Loss: 0.9365, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3845/10000, Loss: 0.9364, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3846/10000, Loss: 0.9362, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3847/10000, Loss: 0.9361, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3848/10000, Loss: 0.9359, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3849/10000, Loss: 0.9357, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3850/10000, Loss: 0.9356, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3851/10000, Loss: 0.9354, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3852/10000, Loss: 0.9353, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3853/10000, Loss: 0.9351, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3854/10000, Loss: 0.9349, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3855/10000, Loss: 0.9348, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3856/10000, Loss: 0.9346, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3857/10000, Loss: 0.9345, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3858/10000, Loss: 0.9343, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3859/10000, Loss: 0.9341, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3860/10000, Loss: 0.9340, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3861/10000, Loss: 0.9338, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3862/10000, Loss: 0.9337, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3863/10000, Loss: 0.9335, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3864/10000, Loss: 0.9334, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3865/10000, Loss: 0.9332, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3866/10000, Loss: 0.9330, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3867/10000, Loss: 0.9329, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3868/10000, Loss: 0.9327, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3869/10000, Loss: 0.9326, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3870/10000, Loss: 0.9324, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3871/10000, Loss: 0.9323, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3872/10000, Loss: 0.9321, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3873/10000, Loss: 0.9319, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3874/10000, Loss: 0.9318, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3875/10000, Loss: 0.9316, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3876/10000, Loss: 0.9315, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3877/10000, Loss: 0.9313, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3878/10000, Loss: 0.9312, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3879/10000, Loss: 0.9310, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3880/10000, Loss: 0.9309, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3881/10000, Loss: 0.9307, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3882/10000, Loss: 0.9305, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3883/10000, Loss: 0.9304, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3884/10000, Loss: 0.9302, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3885/10000, Loss: 0.9301, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3886/10000, Loss: 0.9299, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3887/10000, Loss: 0.9298, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3888/10000, Loss: 0.9296, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3889/10000, Loss: 0.9295, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3890/10000, Loss: 0.9293, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3891/10000, Loss: 0.9292, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3892/10000, Loss: 0.9290, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3893/10000, Loss: 0.9289, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3894/10000, Loss: 0.9287, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3895/10000, Loss: 0.9285, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3896/10000, Loss: 0.9284, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3897/10000, Loss: 0.9282, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3898/10000, Loss: 0.9281, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3899/10000, Loss: 0.9279, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3900/10000, Loss: 0.9278, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3901/10000, Loss: 0.9276, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3902/10000, Loss: 0.9275, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3903/10000, Loss: 0.9273, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3904/10000, Loss: 0.9272, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3905/10000, Loss: 0.9270, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3906/10000, Loss: 0.9269, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3907/10000, Loss: 0.9267, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3908/10000, Loss: 0.9266, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3909/10000, Loss: 0.9264, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3910/10000, Loss: 0.9263, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3911/10000, Loss: 0.9261, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3912/10000, Loss: 0.9260, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3913/10000, Loss: 0.9258, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3914/10000, Loss: 0.9257, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3915/10000, Loss: 0.9255, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3916/10000, Loss: 0.9254, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3917/10000, Loss: 0.9252, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3918/10000, Loss: 0.9251, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3919/10000, Loss: 0.9249, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3920/10000, Loss: 0.9248, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3921/10000, Loss: 0.9246, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3922/10000, Loss: 0.9245, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3923/10000, Loss: 0.9243, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3924/10000, Loss: 0.9242, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3925/10000, Loss: 0.9240, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3926/10000, Loss: 0.9239, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3927/10000, Loss: 0.9237, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3928/10000, Loss: 0.9236, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3929/10000, Loss: 0.9234, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3930/10000, Loss: 0.9233, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3931/10000, Loss: 0.9231, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3932/10000, Loss: 0.9230, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3933/10000, Loss: 0.9228, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3934/10000, Loss: 0.9227, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3935/10000, Loss: 0.9226, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3936/10000, Loss: 0.9224, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3937/10000, Loss: 0.9223, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3938/10000, Loss: 0.9221, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3939/10000, Loss: 0.9220, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3940/10000, Loss: 0.9218, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3941/10000, Loss: 0.9217, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3942/10000, Loss: 0.9215, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3943/10000, Loss: 0.9214, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3944/10000, Loss: 0.9212, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3945/10000, Loss: 0.9211, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3946/10000, Loss: 0.9209, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3947/10000, Loss: 0.9208, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3948/10000, Loss: 0.9207, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3949/10000, Loss: 0.9205, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3950/10000, Loss: 0.9204, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3951/10000, Loss: 0.9202, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3952/10000, Loss: 0.9201, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3953/10000, Loss: 0.9199, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3954/10000, Loss: 0.9198, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3955/10000, Loss: 0.9196, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3956/10000, Loss: 0.9195, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3957/10000, Loss: 0.9193, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3958/10000, Loss: 0.9192, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3959/10000, Loss: 0.9191, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3960/10000, Loss: 0.9189, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3961/10000, Loss: 0.9188, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3962/10000, Loss: 0.9186, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3963/10000, Loss: 0.9185, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3964/10000, Loss: 0.9183, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3965/10000, Loss: 0.9182, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3966/10000, Loss: 0.9181, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3967/10000, Loss: 0.9179, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3968/10000, Loss: 0.9178, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3969/10000, Loss: 0.9176, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3970/10000, Loss: 0.9175, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3971/10000, Loss: 0.9173, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3972/10000, Loss: 0.9172, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3973/10000, Loss: 0.9171, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3974/10000, Loss: 0.9169, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3975/10000, Loss: 0.9168, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3976/10000, Loss: 0.9166, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3977/10000, Loss: 0.9165, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3978/10000, Loss: 0.9164, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3979/10000, Loss: 0.9162, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3980/10000, Loss: 0.9161, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3981/10000, Loss: 0.9159, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3982/10000, Loss: 0.9158, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3983/10000, Loss: 0.9157, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3984/10000, Loss: 0.9155, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3985/10000, Loss: 0.9154, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3986/10000, Loss: 0.9152, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3987/10000, Loss: 0.9151, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3988/10000, Loss: 0.9149, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3989/10000, Loss: 0.9148, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3990/10000, Loss: 0.9147, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3991/10000, Loss: 0.9145, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3992/10000, Loss: 0.9144, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3993/10000, Loss: 0.9143, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3994/10000, Loss: 0.9141, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3995/10000, Loss: 0.9140, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3996/10000, Loss: 0.9138, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3997/10000, Loss: 0.9137, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3998/10000, Loss: 0.9136, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3999/10000, Loss: 0.9134, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4000/10000, Loss: 0.9133, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4001/10000, Loss: 0.9131, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4002/10000, Loss: 0.9130, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4003/10000, Loss: 0.9129, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4004/10000, Loss: 0.9127, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4005/10000, Loss: 0.9126, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4006/10000, Loss: 0.9125, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4007/10000, Loss: 0.9123, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4008/10000, Loss: 0.9122, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4009/10000, Loss: 0.9120, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4010/10000, Loss: 0.9119, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4011/10000, Loss: 0.9118, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4012/10000, Loss: 0.9116, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4013/10000, Loss: 0.9115, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4014/10000, Loss: 0.9114, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4015/10000, Loss: 0.9112, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4016/10000, Loss: 0.9111, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4017/10000, Loss: 0.9110, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4018/10000, Loss: 0.9108, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4019/10000, Loss: 0.9107, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4020/10000, Loss: 0.9105, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4021/10000, Loss: 0.9104, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4022/10000, Loss: 0.9103, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4023/10000, Loss: 0.9101, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4024/10000, Loss: 0.9100, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4025/10000, Loss: 0.9099, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4026/10000, Loss: 0.9097, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4027/10000, Loss: 0.9096, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4028/10000, Loss: 0.9095, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4029/10000, Loss: 0.9093, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4030/10000, Loss: 0.9092, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4031/10000, Loss: 0.9091, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4032/10000, Loss: 0.9089, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4033/10000, Loss: 0.9088, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4034/10000, Loss: 0.9087, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4035/10000, Loss: 0.9085, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4036/10000, Loss: 0.9084, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4037/10000, Loss: 0.9083, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4038/10000, Loss: 0.9081, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4039/10000, Loss: 0.9080, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4040/10000, Loss: 0.9079, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4041/10000, Loss: 0.9077, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4042/10000, Loss: 0.9076, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4043/10000, Loss: 0.9075, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4044/10000, Loss: 0.9073, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4045/10000, Loss: 0.9072, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4046/10000, Loss: 0.9071, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4047/10000, Loss: 0.9069, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4048/10000, Loss: 0.9068, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4049/10000, Loss: 0.9067, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4050/10000, Loss: 0.9065, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4051/10000, Loss: 0.9064, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4052/10000, Loss: 0.9063, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4053/10000, Loss: 0.9061, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4054/10000, Loss: 0.9060, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4055/10000, Loss: 0.9059, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4056/10000, Loss: 0.9057, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4057/10000, Loss: 0.9056, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4058/10000, Loss: 0.9055, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4059/10000, Loss: 0.9054, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4060/10000, Loss: 0.9052, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4061/10000, Loss: 0.9051, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4062/10000, Loss: 0.9050, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4063/10000, Loss: 0.9048, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4064/10000, Loss: 0.9047, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4065/10000, Loss: 0.9046, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4066/10000, Loss: 0.9044, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4067/10000, Loss: 0.9043, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4068/10000, Loss: 0.9042, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4069/10000, Loss: 0.9041, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4070/10000, Loss: 0.9039, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4071/10000, Loss: 0.9038, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4072/10000, Loss: 0.9037, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4073/10000, Loss: 0.9035, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4074/10000, Loss: 0.9034, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4075/10000, Loss: 0.9033, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4076/10000, Loss: 0.9031, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4077/10000, Loss: 0.9030, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4078/10000, Loss: 0.9029, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4079/10000, Loss: 0.9028, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4080/10000, Loss: 0.9026, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4081/10000, Loss: 0.9025, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4082/10000, Loss: 0.9024, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4083/10000, Loss: 0.9023, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4084/10000, Loss: 0.9021, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4085/10000, Loss: 0.9020, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4086/10000, Loss: 0.9019, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4087/10000, Loss: 0.9017, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4088/10000, Loss: 0.9016, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4089/10000, Loss: 0.9015, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4090/10000, Loss: 0.9014, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4091/10000, Loss: 0.9012, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4092/10000, Loss: 0.9011, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4093/10000, Loss: 0.9010, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4094/10000, Loss: 0.9009, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4095/10000, Loss: 0.9007, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4096/10000, Loss: 0.9006, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4097/10000, Loss: 0.9005, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4098/10000, Loss: 0.9003, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4099/10000, Loss: 0.9002, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4100/10000, Loss: 0.9001, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4101/10000, Loss: 0.9000, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4102/10000, Loss: 0.8998, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4103/10000, Loss: 0.8997, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4104/10000, Loss: 0.8996, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4105/10000, Loss: 0.8995, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4106/10000, Loss: 0.8993, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4107/10000, Loss: 0.8992, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4108/10000, Loss: 0.8991, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4109/10000, Loss: 0.8990, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4110/10000, Loss: 0.8988, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4111/10000, Loss: 0.8987, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4112/10000, Loss: 0.8986, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4113/10000, Loss: 0.8985, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4114/10000, Loss: 0.8983, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4115/10000, Loss: 0.8982, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4116/10000, Loss: 0.8981, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4117/10000, Loss: 0.8980, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4118/10000, Loss: 0.8979, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4119/10000, Loss: 0.8977, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4120/10000, Loss: 0.8976, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4121/10000, Loss: 0.8975, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4122/10000, Loss: 0.8974, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4123/10000, Loss: 0.8972, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4124/10000, Loss: 0.8971, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4125/10000, Loss: 0.8970, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4126/10000, Loss: 0.8969, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4127/10000, Loss: 0.8967, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4128/10000, Loss: 0.8966, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4129/10000, Loss: 0.8965, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4130/10000, Loss: 0.8964, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4131/10000, Loss: 0.8963, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4132/10000, Loss: 0.8961, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4133/10000, Loss: 0.8960, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4134/10000, Loss: 0.8959, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4135/10000, Loss: 0.8958, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4136/10000, Loss: 0.8956, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4137/10000, Loss: 0.8955, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4138/10000, Loss: 0.8954, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4139/10000, Loss: 0.8953, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4140/10000, Loss: 0.8952, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4141/10000, Loss: 0.8950, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4142/10000, Loss: 0.8949, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4143/10000, Loss: 0.8948, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4144/10000, Loss: 0.8947, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4145/10000, Loss: 0.8946, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4146/10000, Loss: 0.8944, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4147/10000, Loss: 0.8943, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4148/10000, Loss: 0.8942, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4149/10000, Loss: 0.8941, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4150/10000, Loss: 0.8940, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4151/10000, Loss: 0.8938, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4152/10000, Loss: 0.8937, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4153/10000, Loss: 0.8936, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4154/10000, Loss: 0.8935, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4155/10000, Loss: 0.8934, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4156/10000, Loss: 0.8932, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4157/10000, Loss: 0.8931, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4158/10000, Loss: 0.8930, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4159/10000, Loss: 0.8929, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4160/10000, Loss: 0.8928, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4161/10000, Loss: 0.8926, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4162/10000, Loss: 0.8925, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4163/10000, Loss: 0.8924, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4164/10000, Loss: 0.8923, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4165/10000, Loss: 0.8922, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4166/10000, Loss: 0.8920, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4167/10000, Loss: 0.8919, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4168/10000, Loss: 0.8918, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4169/10000, Loss: 0.8917, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4170/10000, Loss: 0.8916, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4171/10000, Loss: 0.8915, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4172/10000, Loss: 0.8913, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4173/10000, Loss: 0.8912, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4174/10000, Loss: 0.8911, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4175/10000, Loss: 0.8910, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4176/10000, Loss: 0.8909, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4177/10000, Loss: 0.8908, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4178/10000, Loss: 0.8906, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4179/10000, Loss: 0.8905, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4180/10000, Loss: 0.8904, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4181/10000, Loss: 0.8903, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4182/10000, Loss: 0.8902, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4183/10000, Loss: 0.8900, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4184/10000, Loss: 0.8899, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4185/10000, Loss: 0.8898, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4186/10000, Loss: 0.8897, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4187/10000, Loss: 0.8896, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4188/10000, Loss: 0.8895, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4189/10000, Loss: 0.8894, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4190/10000, Loss: 0.8892, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4191/10000, Loss: 0.8891, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4192/10000, Loss: 0.8890, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4193/10000, Loss: 0.8889, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4194/10000, Loss: 0.8888, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4195/10000, Loss: 0.8887, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4196/10000, Loss: 0.8885, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4197/10000, Loss: 0.8884, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4198/10000, Loss: 0.8883, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4199/10000, Loss: 0.8882, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4200/10000, Loss: 0.8881, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4201/10000, Loss: 0.8880, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4202/10000, Loss: 0.8879, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4203/10000, Loss: 0.8877, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4204/10000, Loss: 0.8876, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4205/10000, Loss: 0.8875, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4206/10000, Loss: 0.8874, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4207/10000, Loss: 0.8873, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4208/10000, Loss: 0.8872, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4209/10000, Loss: 0.8871, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4210/10000, Loss: 0.8869, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4211/10000, Loss: 0.8868, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4212/10000, Loss: 0.8867, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4213/10000, Loss: 0.8866, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4214/10000, Loss: 0.8865, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4215/10000, Loss: 0.8864, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4216/10000, Loss: 0.8863, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4217/10000, Loss: 0.8861, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4218/10000, Loss: 0.8860, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4219/10000, Loss: 0.8859, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4220/10000, Loss: 0.8858, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4221/10000, Loss: 0.8857, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4222/10000, Loss: 0.8856, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4223/10000, Loss: 0.8855, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4224/10000, Loss: 0.8854, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4225/10000, Loss: 0.8852, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4226/10000, Loss: 0.8851, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4227/10000, Loss: 0.8850, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4228/10000, Loss: 0.8849, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4229/10000, Loss: 0.8848, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4230/10000, Loss: 0.8847, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4231/10000, Loss: 0.8846, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4232/10000, Loss: 0.8845, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4233/10000, Loss: 0.8844, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4234/10000, Loss: 0.8842, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4235/10000, Loss: 0.8841, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4236/10000, Loss: 0.8840, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4237/10000, Loss: 0.8839, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4238/10000, Loss: 0.8838, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4239/10000, Loss: 0.8837, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4240/10000, Loss: 0.8836, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4241/10000, Loss: 0.8835, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4242/10000, Loss: 0.8834, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4243/10000, Loss: 0.8832, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4244/10000, Loss: 0.8831, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4245/10000, Loss: 0.8830, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4246/10000, Loss: 0.8829, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4247/10000, Loss: 0.8828, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4248/10000, Loss: 0.8827, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4249/10000, Loss: 0.8826, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4250/10000, Loss: 0.8825, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4251/10000, Loss: 0.8824, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4252/10000, Loss: 0.8823, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4253/10000, Loss: 0.8821, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4254/10000, Loss: 0.8820, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4255/10000, Loss: 0.8819, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4256/10000, Loss: 0.8818, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4257/10000, Loss: 0.8817, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4258/10000, Loss: 0.8816, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4259/10000, Loss: 0.8815, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4260/10000, Loss: 0.8814, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4261/10000, Loss: 0.8813, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4262/10000, Loss: 0.8812, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4263/10000, Loss: 0.8811, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4264/10000, Loss: 0.8809, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4265/10000, Loss: 0.8808, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4266/10000, Loss: 0.8807, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4267/10000, Loss: 0.8806, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4268/10000, Loss: 0.8805, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4269/10000, Loss: 0.8804, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4270/10000, Loss: 0.8803, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4271/10000, Loss: 0.8802, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4272/10000, Loss: 0.8801, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4273/10000, Loss: 0.8800, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4274/10000, Loss: 0.8799, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4275/10000, Loss: 0.8798, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4276/10000, Loss: 0.8797, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4277/10000, Loss: 0.8795, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4278/10000, Loss: 0.8794, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4279/10000, Loss: 0.8793, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4280/10000, Loss: 0.8792, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4281/10000, Loss: 0.8791, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4282/10000, Loss: 0.8790, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4283/10000, Loss: 0.8789, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4284/10000, Loss: 0.8788, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4285/10000, Loss: 0.8787, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4286/10000, Loss: 0.8786, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4287/10000, Loss: 0.8785, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4288/10000, Loss: 0.8784, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4289/10000, Loss: 0.8783, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4290/10000, Loss: 0.8782, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4291/10000, Loss: 0.8781, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4292/10000, Loss: 0.8780, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4293/10000, Loss: 0.8778, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4294/10000, Loss: 0.8777, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4295/10000, Loss: 0.8776, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4296/10000, Loss: 0.8775, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4297/10000, Loss: 0.8774, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4298/10000, Loss: 0.8773, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4299/10000, Loss: 0.8772, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4300/10000, Loss: 0.8771, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4301/10000, Loss: 0.8770, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4302/10000, Loss: 0.8769, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4303/10000, Loss: 0.8768, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4304/10000, Loss: 0.8767, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4305/10000, Loss: 0.8766, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4306/10000, Loss: 0.8765, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4307/10000, Loss: 0.8764, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4308/10000, Loss: 0.8763, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4309/10000, Loss: 0.8762, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4310/10000, Loss: 0.8761, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4311/10000, Loss: 0.8760, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4312/10000, Loss: 0.8759, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4313/10000, Loss: 0.8758, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4314/10000, Loss: 0.8756, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4315/10000, Loss: 0.8755, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4316/10000, Loss: 0.8754, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4317/10000, Loss: 0.8753, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4318/10000, Loss: 0.8752, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4319/10000, Loss: 0.8751, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4320/10000, Loss: 0.8750, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4321/10000, Loss: 0.8749, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4322/10000, Loss: 0.8748, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4323/10000, Loss: 0.8747, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4324/10000, Loss: 0.8746, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4325/10000, Loss: 0.8745, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4326/10000, Loss: 0.8744, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4327/10000, Loss: 0.8743, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4328/10000, Loss: 0.8742, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4329/10000, Loss: 0.8741, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4330/10000, Loss: 0.8740, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4331/10000, Loss: 0.8739, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4332/10000, Loss: 0.8738, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4333/10000, Loss: 0.8737, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4334/10000, Loss: 0.8736, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4335/10000, Loss: 0.8735, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4336/10000, Loss: 0.8734, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4337/10000, Loss: 0.8733, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4338/10000, Loss: 0.8732, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4339/10000, Loss: 0.8731, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4340/10000, Loss: 0.8730, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4341/10000, Loss: 0.8729, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4342/10000, Loss: 0.8728, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4343/10000, Loss: 0.8727, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4344/10000, Loss: 0.8726, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4345/10000, Loss: 0.8725, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4346/10000, Loss: 0.8724, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4347/10000, Loss: 0.8723, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4348/10000, Loss: 0.8722, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4349/10000, Loss: 0.8721, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4350/10000, Loss: 0.8720, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4351/10000, Loss: 0.8719, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4352/10000, Loss: 0.8718, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4353/10000, Loss: 0.8717, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4354/10000, Loss: 0.8716, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4355/10000, Loss: 0.8715, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4356/10000, Loss: 0.8714, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4357/10000, Loss: 0.8713, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4358/10000, Loss: 0.8712, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4359/10000, Loss: 0.8711, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4360/10000, Loss: 0.8710, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4361/10000, Loss: 0.8709, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4362/10000, Loss: 0.8708, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4363/10000, Loss: 0.8707, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4364/10000, Loss: 0.8706, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4365/10000, Loss: 0.8705, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4366/10000, Loss: 0.8704, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4367/10000, Loss: 0.8703, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4368/10000, Loss: 0.8702, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4369/10000, Loss: 0.8701, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4370/10000, Loss: 0.8700, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4371/10000, Loss: 0.8699, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4372/10000, Loss: 0.8698, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4373/10000, Loss: 0.8697, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4374/10000, Loss: 0.8696, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4375/10000, Loss: 0.8695, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4376/10000, Loss: 0.8694, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4377/10000, Loss: 0.8693, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4378/10000, Loss: 0.8692, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4379/10000, Loss: 0.8691, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4380/10000, Loss: 0.8690, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4381/10000, Loss: 0.8689, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4382/10000, Loss: 0.8688, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4383/10000, Loss: 0.8687, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4384/10000, Loss: 0.8686, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4385/10000, Loss: 0.8685, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4386/10000, Loss: 0.8684, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4387/10000, Loss: 0.8683, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4388/10000, Loss: 0.8682, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4389/10000, Loss: 0.8681, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4390/10000, Loss: 0.8680, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4391/10000, Loss: 0.8679, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4392/10000, Loss: 0.8678, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4393/10000, Loss: 0.8677, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4394/10000, Loss: 0.8676, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4395/10000, Loss: 0.8675, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4396/10000, Loss: 0.8674, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4397/10000, Loss: 0.8673, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4398/10000, Loss: 0.8672, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4399/10000, Loss: 0.8671, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4400/10000, Loss: 0.8670, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4401/10000, Loss: 0.8669, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4402/10000, Loss: 0.8669, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4403/10000, Loss: 0.8668, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4404/10000, Loss: 0.8667, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4405/10000, Loss: 0.8666, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4406/10000, Loss: 0.8665, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4407/10000, Loss: 0.8664, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4408/10000, Loss: 0.8663, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4409/10000, Loss: 0.8662, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4410/10000, Loss: 0.8661, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4411/10000, Loss: 0.8660, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4412/10000, Loss: 0.8659, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4413/10000, Loss: 0.8658, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4414/10000, Loss: 0.8657, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4415/10000, Loss: 0.8656, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4416/10000, Loss: 0.8655, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4417/10000, Loss: 0.8654, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4418/10000, Loss: 0.8653, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4419/10000, Loss: 0.8652, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4420/10000, Loss: 0.8651, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4421/10000, Loss: 0.8650, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4422/10000, Loss: 0.8649, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4423/10000, Loss: 0.8648, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4424/10000, Loss: 0.8648, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4425/10000, Loss: 0.8647, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4426/10000, Loss: 0.8646, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4427/10000, Loss: 0.8645, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4428/10000, Loss: 0.8644, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4429/10000, Loss: 0.8643, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4430/10000, Loss: 0.8642, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4431/10000, Loss: 0.8641, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4432/10000, Loss: 0.8640, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4433/10000, Loss: 0.8639, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4434/10000, Loss: 0.8638, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4435/10000, Loss: 0.8637, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4436/10000, Loss: 0.8636, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4437/10000, Loss: 0.8635, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4438/10000, Loss: 0.8634, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4439/10000, Loss: 0.8633, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4440/10000, Loss: 0.8632, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4441/10000, Loss: 0.8632, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4442/10000, Loss: 0.8631, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4443/10000, Loss: 0.8630, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4444/10000, Loss: 0.8629, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4445/10000, Loss: 0.8628, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4446/10000, Loss: 0.8627, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4447/10000, Loss: 0.8626, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4448/10000, Loss: 0.8625, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4449/10000, Loss: 0.8624, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4450/10000, Loss: 0.8623, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4451/10000, Loss: 0.8622, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4452/10000, Loss: 0.8621, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4453/10000, Loss: 0.8620, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4454/10000, Loss: 0.8619, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4455/10000, Loss: 0.8619, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4456/10000, Loss: 0.8618, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4457/10000, Loss: 0.8617, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4458/10000, Loss: 0.8616, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4459/10000, Loss: 0.8615, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4460/10000, Loss: 0.8614, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4461/10000, Loss: 0.8613, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4462/10000, Loss: 0.8612, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4463/10000, Loss: 0.8611, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4464/10000, Loss: 0.8610, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4465/10000, Loss: 0.8609, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4466/10000, Loss: 0.8608, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4467/10000, Loss: 0.8608, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4468/10000, Loss: 0.8607, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4469/10000, Loss: 0.8606, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4470/10000, Loss: 0.8605, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4471/10000, Loss: 0.8604, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4472/10000, Loss: 0.8603, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4473/10000, Loss: 0.8602, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4474/10000, Loss: 0.8601, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4475/10000, Loss: 0.8600, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4476/10000, Loss: 0.8599, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4477/10000, Loss: 0.8598, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4478/10000, Loss: 0.8598, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4479/10000, Loss: 0.8597, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4480/10000, Loss: 0.8596, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4481/10000, Loss: 0.8595, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4482/10000, Loss: 0.8594, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4483/10000, Loss: 0.8593, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4484/10000, Loss: 0.8592, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4485/10000, Loss: 0.8591, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4486/10000, Loss: 0.8590, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4487/10000, Loss: 0.8589, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4488/10000, Loss: 0.8589, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4489/10000, Loss: 0.8588, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4490/10000, Loss: 0.8587, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4491/10000, Loss: 0.8586, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4492/10000, Loss: 0.8585, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4493/10000, Loss: 0.8584, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4494/10000, Loss: 0.8583, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4495/10000, Loss: 0.8582, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4496/10000, Loss: 0.8581, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4497/10000, Loss: 0.8580, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4498/10000, Loss: 0.8580, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4499/10000, Loss: 0.8579, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4500/10000, Loss: 0.8578, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4501/10000, Loss: 0.8577, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4502/10000, Loss: 0.8576, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4503/10000, Loss: 0.8575, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4504/10000, Loss: 0.8574, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4505/10000, Loss: 0.8573, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4506/10000, Loss: 0.8572, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4507/10000, Loss: 0.8572, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4508/10000, Loss: 0.8571, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4509/10000, Loss: 0.8570, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4510/10000, Loss: 0.8569, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4511/10000, Loss: 0.8568, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4512/10000, Loss: 0.8567, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4513/10000, Loss: 0.8566, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4514/10000, Loss: 0.8565, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4515/10000, Loss: 0.8565, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4516/10000, Loss: 0.8564, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4517/10000, Loss: 0.8563, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4518/10000, Loss: 0.8562, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4519/10000, Loss: 0.8561, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4520/10000, Loss: 0.8560, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4521/10000, Loss: 0.8559, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4522/10000, Loss: 0.8558, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4523/10000, Loss: 0.8558, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4524/10000, Loss: 0.8557, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4525/10000, Loss: 0.8556, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4526/10000, Loss: 0.8555, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4527/10000, Loss: 0.8554, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4528/10000, Loss: 0.8553, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4529/10000, Loss: 0.8552, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4530/10000, Loss: 0.8551, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4531/10000, Loss: 0.8551, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4532/10000, Loss: 0.8550, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4533/10000, Loss: 0.8549, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4534/10000, Loss: 0.8548, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4535/10000, Loss: 0.8547, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4536/10000, Loss: 0.8546, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4537/10000, Loss: 0.8545, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4538/10000, Loss: 0.8545, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4539/10000, Loss: 0.8544, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4540/10000, Loss: 0.8543, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4541/10000, Loss: 0.8542, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4542/10000, Loss: 0.8541, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4543/10000, Loss: 0.8540, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4544/10000, Loss: 0.8539, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4545/10000, Loss: 0.8538, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4546/10000, Loss: 0.8538, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4547/10000, Loss: 0.8537, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4548/10000, Loss: 0.8536, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4549/10000, Loss: 0.8535, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4550/10000, Loss: 0.8534, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4551/10000, Loss: 0.8533, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4552/10000, Loss: 0.8532, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4553/10000, Loss: 0.8532, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4554/10000, Loss: 0.8531, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4555/10000, Loss: 0.8530, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4556/10000, Loss: 0.8529, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4557/10000, Loss: 0.8528, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4558/10000, Loss: 0.8527, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4559/10000, Loss: 0.8527, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4560/10000, Loss: 0.8526, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4561/10000, Loss: 0.8525, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4562/10000, Loss: 0.8524, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4563/10000, Loss: 0.8523, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4564/10000, Loss: 0.8522, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4565/10000, Loss: 0.8521, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4566/10000, Loss: 0.8521, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4567/10000, Loss: 0.8520, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4568/10000, Loss: 0.8519, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4569/10000, Loss: 0.8518, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4570/10000, Loss: 0.8517, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4571/10000, Loss: 0.8516, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4572/10000, Loss: 0.8516, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4573/10000, Loss: 0.8515, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4574/10000, Loss: 0.8514, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4575/10000, Loss: 0.8513, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4576/10000, Loss: 0.8512, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4577/10000, Loss: 0.8511, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4578/10000, Loss: 0.8511, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4579/10000, Loss: 0.8510, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4580/10000, Loss: 0.8509, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4581/10000, Loss: 0.8508, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4582/10000, Loss: 0.8507, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4583/10000, Loss: 0.8506, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4584/10000, Loss: 0.8506, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4585/10000, Loss: 0.8505, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4586/10000, Loss: 0.8504, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4587/10000, Loss: 0.8503, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4588/10000, Loss: 0.8502, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4589/10000, Loss: 0.8501, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4590/10000, Loss: 0.8501, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4591/10000, Loss: 0.8500, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4592/10000, Loss: 0.8499, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4593/10000, Loss: 0.8498, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4594/10000, Loss: 0.8497, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4595/10000, Loss: 0.8496, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4596/10000, Loss: 0.8496, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4597/10000, Loss: 0.8495, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4598/10000, Loss: 0.8494, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4599/10000, Loss: 0.8493, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4600/10000, Loss: 0.8492, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4601/10000, Loss: 0.8491, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4602/10000, Loss: 0.8491, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4603/10000, Loss: 0.8490, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4604/10000, Loss: 0.8489, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4605/10000, Loss: 0.8488, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4606/10000, Loss: 0.8487, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4607/10000, Loss: 0.8487, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4608/10000, Loss: 0.8486, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4609/10000, Loss: 0.8485, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4610/10000, Loss: 0.8484, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4611/10000, Loss: 0.8483, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4612/10000, Loss: 0.8482, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4613/10000, Loss: 0.8482, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4614/10000, Loss: 0.8481, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4615/10000, Loss: 0.8480, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4616/10000, Loss: 0.8479, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4617/10000, Loss: 0.8478, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4618/10000, Loss: 0.8478, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4619/10000, Loss: 0.8477, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4620/10000, Loss: 0.8476, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4621/10000, Loss: 0.8475, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4622/10000, Loss: 0.8474, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4623/10000, Loss: 0.8474, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4624/10000, Loss: 0.8473, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4625/10000, Loss: 0.8472, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4626/10000, Loss: 0.8471, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4627/10000, Loss: 0.8470, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4628/10000, Loss: 0.8469, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4629/10000, Loss: 0.8469, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4630/10000, Loss: 0.8468, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4631/10000, Loss: 0.8467, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4632/10000, Loss: 0.8466, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4633/10000, Loss: 0.8465, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4634/10000, Loss: 0.8465, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4635/10000, Loss: 0.8464, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4636/10000, Loss: 0.8463, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4637/10000, Loss: 0.8462, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4638/10000, Loss: 0.8461, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4639/10000, Loss: 0.8461, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4640/10000, Loss: 0.8460, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4641/10000, Loss: 0.8459, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4642/10000, Loss: 0.8458, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4643/10000, Loss: 0.8457, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4644/10000, Loss: 0.8457, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4645/10000, Loss: 0.8456, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4646/10000, Loss: 0.8455, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4647/10000, Loss: 0.8454, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4648/10000, Loss: 0.8454, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4649/10000, Loss: 0.8453, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4650/10000, Loss: 0.8452, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4651/10000, Loss: 0.8451, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4652/10000, Loss: 0.8450, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4653/10000, Loss: 0.8450, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4654/10000, Loss: 0.8449, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4655/10000, Loss: 0.8448, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4656/10000, Loss: 0.8447, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4657/10000, Loss: 0.8446, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4658/10000, Loss: 0.8446, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4659/10000, Loss: 0.8445, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4660/10000, Loss: 0.8444, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4661/10000, Loss: 0.8443, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4662/10000, Loss: 0.8442, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4663/10000, Loss: 0.8442, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4664/10000, Loss: 0.8441, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4665/10000, Loss: 0.8440, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4666/10000, Loss: 0.8439, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4667/10000, Loss: 0.8439, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4668/10000, Loss: 0.8438, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4669/10000, Loss: 0.8437, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4670/10000, Loss: 0.8436, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4671/10000, Loss: 0.8435, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4672/10000, Loss: 0.8435, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4673/10000, Loss: 0.8434, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4674/10000, Loss: 0.8433, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4675/10000, Loss: 0.8432, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4676/10000, Loss: 0.8432, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4677/10000, Loss: 0.8431, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4678/10000, Loss: 0.8430, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4679/10000, Loss: 0.8429, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4680/10000, Loss: 0.8428, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4681/10000, Loss: 0.8428, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4682/10000, Loss: 0.8427, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4683/10000, Loss: 0.8426, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4684/10000, Loss: 0.8425, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4685/10000, Loss: 0.8425, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4686/10000, Loss: 0.8424, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4687/10000, Loss: 0.8423, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4688/10000, Loss: 0.8422, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4689/10000, Loss: 0.8422, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4690/10000, Loss: 0.8421, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4691/10000, Loss: 0.8420, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4692/10000, Loss: 0.8419, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4693/10000, Loss: 0.8418, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4694/10000, Loss: 0.8418, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4695/10000, Loss: 0.8417, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4696/10000, Loss: 0.8416, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4697/10000, Loss: 0.8415, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4698/10000, Loss: 0.8415, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4699/10000, Loss: 0.8414, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4700/10000, Loss: 0.8413, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4701/10000, Loss: 0.8412, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4702/10000, Loss: 0.8412, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4703/10000, Loss: 0.8411, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4704/10000, Loss: 0.8410, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4705/10000, Loss: 0.8409, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4706/10000, Loss: 0.8409, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4707/10000, Loss: 0.8408, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4708/10000, Loss: 0.8407, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4709/10000, Loss: 0.8406, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4710/10000, Loss: 0.8406, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4711/10000, Loss: 0.8405, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4712/10000, Loss: 0.8404, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4713/10000, Loss: 0.8403, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4714/10000, Loss: 0.8402, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4715/10000, Loss: 0.8402, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4716/10000, Loss: 0.8401, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4717/10000, Loss: 0.8400, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4718/10000, Loss: 0.8399, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4719/10000, Loss: 0.8399, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4720/10000, Loss: 0.8398, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4721/10000, Loss: 0.8397, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4722/10000, Loss: 0.8396, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4723/10000, Loss: 0.8396, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4724/10000, Loss: 0.8395, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4725/10000, Loss: 0.8394, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4726/10000, Loss: 0.8393, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4727/10000, Loss: 0.8393, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4728/10000, Loss: 0.8392, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4729/10000, Loss: 0.8391, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4730/10000, Loss: 0.8391, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4731/10000, Loss: 0.8390, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4732/10000, Loss: 0.8389, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4733/10000, Loss: 0.8388, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4734/10000, Loss: 0.8388, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4735/10000, Loss: 0.8387, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4736/10000, Loss: 0.8386, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4737/10000, Loss: 0.8385, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4738/10000, Loss: 0.8385, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4739/10000, Loss: 0.8384, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4740/10000, Loss: 0.8383, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4741/10000, Loss: 0.8382, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4742/10000, Loss: 0.8382, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4743/10000, Loss: 0.8381, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4744/10000, Loss: 0.8380, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4745/10000, Loss: 0.8379, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4746/10000, Loss: 0.8379, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4747/10000, Loss: 0.8378, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4748/10000, Loss: 0.8377, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4749/10000, Loss: 0.8376, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4750/10000, Loss: 0.8376, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4751/10000, Loss: 0.8375, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4752/10000, Loss: 0.8374, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4753/10000, Loss: 0.8374, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4754/10000, Loss: 0.8373, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4755/10000, Loss: 0.8372, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4756/10000, Loss: 0.8371, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4757/10000, Loss: 0.8371, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4758/10000, Loss: 0.8370, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4759/10000, Loss: 0.8369, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4760/10000, Loss: 0.8368, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4761/10000, Loss: 0.8368, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4762/10000, Loss: 0.8367, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4763/10000, Loss: 0.8366, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4764/10000, Loss: 0.8365, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4765/10000, Loss: 0.8365, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4766/10000, Loss: 0.8364, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4767/10000, Loss: 0.8363, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4768/10000, Loss: 0.8363, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4769/10000, Loss: 0.8362, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4770/10000, Loss: 0.8361, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4771/10000, Loss: 0.8360, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4772/10000, Loss: 0.8360, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4773/10000, Loss: 0.8359, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4774/10000, Loss: 0.8358, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4775/10000, Loss: 0.8358, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4776/10000, Loss: 0.8357, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4777/10000, Loss: 0.8356, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4778/10000, Loss: 0.8355, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4779/10000, Loss: 0.8355, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4780/10000, Loss: 0.8354, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4781/10000, Loss: 0.8353, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4782/10000, Loss: 0.8353, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4783/10000, Loss: 0.8352, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4784/10000, Loss: 0.8351, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4785/10000, Loss: 0.8350, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4786/10000, Loss: 0.8350, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4787/10000, Loss: 0.8349, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4788/10000, Loss: 0.8348, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4789/10000, Loss: 0.8348, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4790/10000, Loss: 0.8347, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4791/10000, Loss: 0.8346, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4792/10000, Loss: 0.8345, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4793/10000, Loss: 0.8345, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4794/10000, Loss: 0.8344, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4795/10000, Loss: 0.8343, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4796/10000, Loss: 0.8343, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4797/10000, Loss: 0.8342, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4798/10000, Loss: 0.8341, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4799/10000, Loss: 0.8340, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4800/10000, Loss: 0.8340, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4801/10000, Loss: 0.8339, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4802/10000, Loss: 0.8338, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4803/10000, Loss: 0.8338, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4804/10000, Loss: 0.8337, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4805/10000, Loss: 0.8336, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4806/10000, Loss: 0.8335, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4807/10000, Loss: 0.8335, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4808/10000, Loss: 0.8334, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4809/10000, Loss: 0.8333, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4810/10000, Loss: 0.8333, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4811/10000, Loss: 0.8332, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4812/10000, Loss: 0.8331, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4813/10000, Loss: 0.8331, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4814/10000, Loss: 0.8330, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4815/10000, Loss: 0.8329, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4816/10000, Loss: 0.8328, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4817/10000, Loss: 0.8328, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4818/10000, Loss: 0.8327, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4819/10000, Loss: 0.8326, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4820/10000, Loss: 0.8326, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4821/10000, Loss: 0.8325, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4822/10000, Loss: 0.8324, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4823/10000, Loss: 0.8324, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4824/10000, Loss: 0.8323, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4825/10000, Loss: 0.8322, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4826/10000, Loss: 0.8321, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4827/10000, Loss: 0.8321, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4828/10000, Loss: 0.8320, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4829/10000, Loss: 0.8319, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4830/10000, Loss: 0.8319, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4831/10000, Loss: 0.8318, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4832/10000, Loss: 0.8317, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4833/10000, Loss: 0.8317, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4834/10000, Loss: 0.8316, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4835/10000, Loss: 0.8315, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4836/10000, Loss: 0.8315, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4837/10000, Loss: 0.8314, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4838/10000, Loss: 0.8313, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4839/10000, Loss: 0.8313, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4840/10000, Loss: 0.8312, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4841/10000, Loss: 0.8311, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4842/10000, Loss: 0.8310, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4843/10000, Loss: 0.8310, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4844/10000, Loss: 0.8309, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4845/10000, Loss: 0.8308, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4846/10000, Loss: 0.8308, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4847/10000, Loss: 0.8307, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4848/10000, Loss: 0.8306, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4849/10000, Loss: 0.8306, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4850/10000, Loss: 0.8305, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4851/10000, Loss: 0.8304, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4852/10000, Loss: 0.8304, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4853/10000, Loss: 0.8303, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4854/10000, Loss: 0.8302, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4855/10000, Loss: 0.8302, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4856/10000, Loss: 0.8301, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4857/10000, Loss: 0.8300, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4858/10000, Loss: 0.8300, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4859/10000, Loss: 0.8299, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4860/10000, Loss: 0.8298, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4861/10000, Loss: 0.8298, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4862/10000, Loss: 0.8297, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4863/10000, Loss: 0.8296, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4864/10000, Loss: 0.8295, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4865/10000, Loss: 0.8295, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4866/10000, Loss: 0.8294, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4867/10000, Loss: 0.8293, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4868/10000, Loss: 0.8293, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4869/10000, Loss: 0.8292, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4870/10000, Loss: 0.8291, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4871/10000, Loss: 0.8291, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4872/10000, Loss: 0.8290, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4873/10000, Loss: 0.8289, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4874/10000, Loss: 0.8289, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4875/10000, Loss: 0.8288, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4876/10000, Loss: 0.8287, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4877/10000, Loss: 0.8287, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4878/10000, Loss: 0.8286, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4879/10000, Loss: 0.8285, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4880/10000, Loss: 0.8285, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4881/10000, Loss: 0.8284, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4882/10000, Loss: 0.8283, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4883/10000, Loss: 0.8283, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4884/10000, Loss: 0.8282, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4885/10000, Loss: 0.8281, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4886/10000, Loss: 0.8281, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4887/10000, Loss: 0.8280, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4888/10000, Loss: 0.8279, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4889/10000, Loss: 0.8279, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4890/10000, Loss: 0.8278, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4891/10000, Loss: 0.8277, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4892/10000, Loss: 0.8277, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4893/10000, Loss: 0.8276, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4894/10000, Loss: 0.8275, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4895/10000, Loss: 0.8275, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4896/10000, Loss: 0.8274, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4897/10000, Loss: 0.8273, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4898/10000, Loss: 0.8273, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4899/10000, Loss: 0.8272, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4900/10000, Loss: 0.8272, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4901/10000, Loss: 0.8271, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4902/10000, Loss: 0.8270, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4903/10000, Loss: 0.8270, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4904/10000, Loss: 0.8269, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4905/10000, Loss: 0.8268, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4906/10000, Loss: 0.8268, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4907/10000, Loss: 0.8267, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4908/10000, Loss: 0.8266, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4909/10000, Loss: 0.8266, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4910/10000, Loss: 0.8265, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4911/10000, Loss: 0.8264, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4912/10000, Loss: 0.8264, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4913/10000, Loss: 0.8263, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4914/10000, Loss: 0.8262, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4915/10000, Loss: 0.8262, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4916/10000, Loss: 0.8261, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4917/10000, Loss: 0.8260, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4918/10000, Loss: 0.8260, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4919/10000, Loss: 0.8259, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4920/10000, Loss: 0.8258, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4921/10000, Loss: 0.8258, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4922/10000, Loss: 0.8257, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4923/10000, Loss: 0.8257, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4924/10000, Loss: 0.8256, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4925/10000, Loss: 0.8255, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4926/10000, Loss: 0.8255, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4927/10000, Loss: 0.8254, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4928/10000, Loss: 0.8253, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4929/10000, Loss: 0.8253, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4930/10000, Loss: 0.8252, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4931/10000, Loss: 0.8251, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4932/10000, Loss: 0.8251, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4933/10000, Loss: 0.8250, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4934/10000, Loss: 0.8249, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4935/10000, Loss: 0.8249, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4936/10000, Loss: 0.8248, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4937/10000, Loss: 0.8248, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4938/10000, Loss: 0.8247, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4939/10000, Loss: 0.8246, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4940/10000, Loss: 0.8246, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4941/10000, Loss: 0.8245, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4942/10000, Loss: 0.8244, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4943/10000, Loss: 0.8244, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4944/10000, Loss: 0.8243, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4945/10000, Loss: 0.8242, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4946/10000, Loss: 0.8242, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4947/10000, Loss: 0.8241, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4948/10000, Loss: 0.8241, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4949/10000, Loss: 0.8240, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4950/10000, Loss: 0.8239, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4951/10000, Loss: 0.8239, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4952/10000, Loss: 0.8238, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4953/10000, Loss: 0.8237, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4954/10000, Loss: 0.8237, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4955/10000, Loss: 0.8236, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4956/10000, Loss: 0.8235, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4957/10000, Loss: 0.8235, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4958/10000, Loss: 0.8234, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4959/10000, Loss: 0.8234, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4960/10000, Loss: 0.8233, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4961/10000, Loss: 0.8232, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4962/10000, Loss: 0.8232, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4963/10000, Loss: 0.8231, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4964/10000, Loss: 0.8230, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4965/10000, Loss: 0.8230, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4966/10000, Loss: 0.8229, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4967/10000, Loss: 0.8229, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4968/10000, Loss: 0.8228, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4969/10000, Loss: 0.8227, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4970/10000, Loss: 0.8227, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4971/10000, Loss: 0.8226, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4972/10000, Loss: 0.8225, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4973/10000, Loss: 0.8225, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4974/10000, Loss: 0.8224, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4975/10000, Loss: 0.8224, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4976/10000, Loss: 0.8223, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4977/10000, Loss: 0.8222, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4978/10000, Loss: 0.8222, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4979/10000, Loss: 0.8221, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4980/10000, Loss: 0.8220, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4981/10000, Loss: 0.8220, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4982/10000, Loss: 0.8219, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4983/10000, Loss: 0.8219, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4984/10000, Loss: 0.8218, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4985/10000, Loss: 0.8217, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4986/10000, Loss: 0.8217, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4987/10000, Loss: 0.8216, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4988/10000, Loss: 0.8215, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4989/10000, Loss: 0.8215, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4990/10000, Loss: 0.8214, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4991/10000, Loss: 0.8214, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4992/10000, Loss: 0.8213, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4993/10000, Loss: 0.8212, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4994/10000, Loss: 0.8212, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4995/10000, Loss: 0.8211, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4996/10000, Loss: 0.8211, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4997/10000, Loss: 0.8210, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4998/10000, Loss: 0.8209, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4999/10000, Loss: 0.8209, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5000/10000, Loss: 0.8208, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5001/10000, Loss: 0.8208, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5002/10000, Loss: 0.8207, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5003/10000, Loss: 0.8206, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5004/10000, Loss: 0.8206, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5005/10000, Loss: 0.8205, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5006/10000, Loss: 0.8204, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5007/10000, Loss: 0.8204, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5008/10000, Loss: 0.8203, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5009/10000, Loss: 0.8203, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5010/10000, Loss: 0.8202, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5011/10000, Loss: 0.8201, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5012/10000, Loss: 0.8201, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5013/10000, Loss: 0.8200, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5014/10000, Loss: 0.8200, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5015/10000, Loss: 0.8199, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5016/10000, Loss: 0.8198, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5017/10000, Loss: 0.8198, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5018/10000, Loss: 0.8197, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5019/10000, Loss: 0.8197, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5020/10000, Loss: 0.8196, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5021/10000, Loss: 0.8195, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5022/10000, Loss: 0.8195, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5023/10000, Loss: 0.8194, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5024/10000, Loss: 0.8194, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5025/10000, Loss: 0.8193, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5026/10000, Loss: 0.8192, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5027/10000, Loss: 0.8192, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5028/10000, Loss: 0.8191, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5029/10000, Loss: 0.8191, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5030/10000, Loss: 0.8190, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5031/10000, Loss: 0.8189, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5032/10000, Loss: 0.8189, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5033/10000, Loss: 0.8188, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5034/10000, Loss: 0.8188, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5035/10000, Loss: 0.8187, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5036/10000, Loss: 0.8186, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5037/10000, Loss: 0.8186, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5038/10000, Loss: 0.8185, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5039/10000, Loss: 0.8185, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5040/10000, Loss: 0.8184, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5041/10000, Loss: 0.8183, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5042/10000, Loss: 0.8183, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5043/10000, Loss: 0.8182, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5044/10000, Loss: 0.8182, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5045/10000, Loss: 0.8181, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5046/10000, Loss: 0.8180, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5047/10000, Loss: 0.8180, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5048/10000, Loss: 0.8179, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5049/10000, Loss: 0.8179, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5050/10000, Loss: 0.8178, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5051/10000, Loss: 0.8177, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5052/10000, Loss: 0.8177, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5053/10000, Loss: 0.8176, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5054/10000, Loss: 0.8176, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5055/10000, Loss: 0.8175, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5056/10000, Loss: 0.8175, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5057/10000, Loss: 0.8174, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5058/10000, Loss: 0.8173, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5059/10000, Loss: 0.8173, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5060/10000, Loss: 0.8172, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5061/10000, Loss: 0.8172, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5062/10000, Loss: 0.8171, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5063/10000, Loss: 0.8170, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5064/10000, Loss: 0.8170, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5065/10000, Loss: 0.8169, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5066/10000, Loss: 0.8169, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5067/10000, Loss: 0.8168, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5068/10000, Loss: 0.8168, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5069/10000, Loss: 0.8167, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5070/10000, Loss: 0.8166, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5071/10000, Loss: 0.8166, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5072/10000, Loss: 0.8165, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5073/10000, Loss: 0.8165, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5074/10000, Loss: 0.8164, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5075/10000, Loss: 0.8163, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5076/10000, Loss: 0.8163, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5077/10000, Loss: 0.8162, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5078/10000, Loss: 0.8162, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5079/10000, Loss: 0.8161, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5080/10000, Loss: 0.8161, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5081/10000, Loss: 0.8160, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5082/10000, Loss: 0.8159, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5083/10000, Loss: 0.8159, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5084/10000, Loss: 0.8158, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5085/10000, Loss: 0.8158, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5086/10000, Loss: 0.8157, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5087/10000, Loss: 0.8157, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5088/10000, Loss: 0.8156, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5089/10000, Loss: 0.8155, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5090/10000, Loss: 0.8155, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5091/10000, Loss: 0.8154, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5092/10000, Loss: 0.8154, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5093/10000, Loss: 0.8153, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5094/10000, Loss: 0.8152, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5095/10000, Loss: 0.8152, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5096/10000, Loss: 0.8151, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5097/10000, Loss: 0.8151, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5098/10000, Loss: 0.8150, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5099/10000, Loss: 0.8150, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5100/10000, Loss: 0.8149, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5101/10000, Loss: 0.8148, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5102/10000, Loss: 0.8148, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5103/10000, Loss: 0.8147, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5104/10000, Loss: 0.8147, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5105/10000, Loss: 0.8146, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5106/10000, Loss: 0.8146, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5107/10000, Loss: 0.8145, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5108/10000, Loss: 0.8145, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5109/10000, Loss: 0.8144, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5110/10000, Loss: 0.8143, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5111/10000, Loss: 0.8143, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5112/10000, Loss: 0.8142, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5113/10000, Loss: 0.8142, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5114/10000, Loss: 0.8141, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5115/10000, Loss: 0.8141, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5116/10000, Loss: 0.8140, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5117/10000, Loss: 0.8139, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5118/10000, Loss: 0.8139, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5119/10000, Loss: 0.8138, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5120/10000, Loss: 0.8138, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5121/10000, Loss: 0.8137, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5122/10000, Loss: 0.8137, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5123/10000, Loss: 0.8136, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5124/10000, Loss: 0.8136, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5125/10000, Loss: 0.8135, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5126/10000, Loss: 0.8134, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5127/10000, Loss: 0.8134, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5128/10000, Loss: 0.8133, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5129/10000, Loss: 0.8133, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5130/10000, Loss: 0.8132, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5131/10000, Loss: 0.8132, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5132/10000, Loss: 0.8131, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5133/10000, Loss: 0.8130, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5134/10000, Loss: 0.8130, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5135/10000, Loss: 0.8129, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5136/10000, Loss: 0.8129, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5137/10000, Loss: 0.8128, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5138/10000, Loss: 0.8128, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5139/10000, Loss: 0.8127, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5140/10000, Loss: 0.8127, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5141/10000, Loss: 0.8126, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5142/10000, Loss: 0.8125, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5143/10000, Loss: 0.8125, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5144/10000, Loss: 0.8124, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5145/10000, Loss: 0.8124, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5146/10000, Loss: 0.8123, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5147/10000, Loss: 0.8123, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5148/10000, Loss: 0.8122, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5149/10000, Loss: 0.8122, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5150/10000, Loss: 0.8121, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5151/10000, Loss: 0.8121, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5152/10000, Loss: 0.8120, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5153/10000, Loss: 0.8119, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5154/10000, Loss: 0.8119, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5155/10000, Loss: 0.8118, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5156/10000, Loss: 0.8118, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5157/10000, Loss: 0.8117, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5158/10000, Loss: 0.8117, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5159/10000, Loss: 0.8116, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5160/10000, Loss: 0.8116, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5161/10000, Loss: 0.8115, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5162/10000, Loss: 0.8114, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5163/10000, Loss: 0.8114, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5164/10000, Loss: 0.8113, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5165/10000, Loss: 0.8113, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5166/10000, Loss: 0.8112, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5167/10000, Loss: 0.8112, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5168/10000, Loss: 0.8111, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5169/10000, Loss: 0.8111, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5170/10000, Loss: 0.8110, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5171/10000, Loss: 0.8110, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5172/10000, Loss: 0.8109, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5173/10000, Loss: 0.8108, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5174/10000, Loss: 0.8108, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5175/10000, Loss: 0.8107, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5176/10000, Loss: 0.8107, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5177/10000, Loss: 0.8106, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5178/10000, Loss: 0.8106, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5179/10000, Loss: 0.8105, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5180/10000, Loss: 0.8105, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5181/10000, Loss: 0.8104, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5182/10000, Loss: 0.8104, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5183/10000, Loss: 0.8103, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5184/10000, Loss: 0.8103, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5185/10000, Loss: 0.8102, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5186/10000, Loss: 0.8101, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5187/10000, Loss: 0.8101, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5188/10000, Loss: 0.8100, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5189/10000, Loss: 0.8100, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5190/10000, Loss: 0.8099, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5191/10000, Loss: 0.8099, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5192/10000, Loss: 0.8098, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5193/10000, Loss: 0.8098, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5194/10000, Loss: 0.8097, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5195/10000, Loss: 0.8097, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5196/10000, Loss: 0.8096, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5197/10000, Loss: 0.8096, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5198/10000, Loss: 0.8095, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5199/10000, Loss: 0.8095, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5200/10000, Loss: 0.8094, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5201/10000, Loss: 0.8093, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5202/10000, Loss: 0.8093, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5203/10000, Loss: 0.8092, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5204/10000, Loss: 0.8092, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5205/10000, Loss: 0.8091, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5206/10000, Loss: 0.8091, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5207/10000, Loss: 0.8090, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5208/10000, Loss: 0.8090, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5209/10000, Loss: 0.8089, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5210/10000, Loss: 0.8089, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5211/10000, Loss: 0.8088, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5212/10000, Loss: 0.8088, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5213/10000, Loss: 0.8087, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5214/10000, Loss: 0.8087, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5215/10000, Loss: 0.8086, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5216/10000, Loss: 0.8086, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5217/10000, Loss: 0.8085, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5218/10000, Loss: 0.8084, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5219/10000, Loss: 0.8084, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5220/10000, Loss: 0.8083, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5221/10000, Loss: 0.8083, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5222/10000, Loss: 0.8082, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5223/10000, Loss: 0.8082, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5224/10000, Loss: 0.8081, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5225/10000, Loss: 0.8081, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5226/10000, Loss: 0.8080, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5227/10000, Loss: 0.8080, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5228/10000, Loss: 0.8079, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5229/10000, Loss: 0.8079, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5230/10000, Loss: 0.8078, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5231/10000, Loss: 0.8078, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5232/10000, Loss: 0.8077, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5233/10000, Loss: 0.8077, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5234/10000, Loss: 0.8076, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5235/10000, Loss: 0.8076, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5236/10000, Loss: 0.8075, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5237/10000, Loss: 0.8075, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5238/10000, Loss: 0.8074, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5239/10000, Loss: 0.8074, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5240/10000, Loss: 0.8073, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5241/10000, Loss: 0.8072, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5242/10000, Loss: 0.8072, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5243/10000, Loss: 0.8071, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5244/10000, Loss: 0.8071, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5245/10000, Loss: 0.8070, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5246/10000, Loss: 0.8070, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5247/10000, Loss: 0.8069, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5248/10000, Loss: 0.8069, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5249/10000, Loss: 0.8068, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5250/10000, Loss: 0.8068, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5251/10000, Loss: 0.8067, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5252/10000, Loss: 0.8067, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5253/10000, Loss: 0.8066, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5254/10000, Loss: 0.8066, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5255/10000, Loss: 0.8065, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5256/10000, Loss: 0.8065, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5257/10000, Loss: 0.8064, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5258/10000, Loss: 0.8064, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5259/10000, Loss: 0.8063, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5260/10000, Loss: 0.8063, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5261/10000, Loss: 0.8062, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5262/10000, Loss: 0.8062, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5263/10000, Loss: 0.8061, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5264/10000, Loss: 0.8061, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5265/10000, Loss: 0.8060, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5266/10000, Loss: 0.8060, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5267/10000, Loss: 0.8059, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5268/10000, Loss: 0.8059, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5269/10000, Loss: 0.8058, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5270/10000, Loss: 0.8058, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5271/10000, Loss: 0.8057, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5272/10000, Loss: 0.8057, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5273/10000, Loss: 0.8056, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5274/10000, Loss: 0.8056, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5275/10000, Loss: 0.8055, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5276/10000, Loss: 0.8055, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5277/10000, Loss: 0.8054, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5278/10000, Loss: 0.8054, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5279/10000, Loss: 0.8053, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5280/10000, Loss: 0.8053, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5281/10000, Loss: 0.8052, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5282/10000, Loss: 0.8052, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5283/10000, Loss: 0.8051, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5284/10000, Loss: 0.8051, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5285/10000, Loss: 0.8050, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5286/10000, Loss: 0.8050, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5287/10000, Loss: 0.8049, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5288/10000, Loss: 0.8049, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5289/10000, Loss: 0.8048, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5290/10000, Loss: 0.8048, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5291/10000, Loss: 0.8047, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5292/10000, Loss: 0.8047, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5293/10000, Loss: 0.8046, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5294/10000, Loss: 0.8046, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5295/10000, Loss: 0.8045, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5296/10000, Loss: 0.8045, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5297/10000, Loss: 0.8044, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5298/10000, Loss: 0.8044, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5299/10000, Loss: 0.8043, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5300/10000, Loss: 0.8043, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5301/10000, Loss: 0.8042, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5302/10000, Loss: 0.8042, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5303/10000, Loss: 0.8041, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5304/10000, Loss: 0.8041, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5305/10000, Loss: 0.8040, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5306/10000, Loss: 0.8040, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5307/10000, Loss: 0.8039, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5308/10000, Loss: 0.8039, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5309/10000, Loss: 0.8038, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5310/10000, Loss: 0.8038, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5311/10000, Loss: 0.8037, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5312/10000, Loss: 0.8037, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5313/10000, Loss: 0.8036, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5314/10000, Loss: 0.8036, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5315/10000, Loss: 0.8035, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5316/10000, Loss: 0.8035, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5317/10000, Loss: 0.8034, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5318/10000, Loss: 0.8034, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5319/10000, Loss: 0.8033, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5320/10000, Loss: 0.8033, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5321/10000, Loss: 0.8032, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5322/10000, Loss: 0.8032, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5323/10000, Loss: 0.8031, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5324/10000, Loss: 0.8031, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5325/10000, Loss: 0.8030, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5326/10000, Loss: 0.8030, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5327/10000, Loss: 0.8029, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5328/10000, Loss: 0.8029, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5329/10000, Loss: 0.8028, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5330/10000, Loss: 0.8028, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5331/10000, Loss: 0.8027, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5332/10000, Loss: 0.8027, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5333/10000, Loss: 0.8026, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5334/10000, Loss: 0.8026, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5335/10000, Loss: 0.8025, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5336/10000, Loss: 0.8025, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5337/10000, Loss: 0.8024, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5338/10000, Loss: 0.8024, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5339/10000, Loss: 0.8023, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5340/10000, Loss: 0.8023, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5341/10000, Loss: 0.8022, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5342/10000, Loss: 0.8022, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5343/10000, Loss: 0.8021, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5344/10000, Loss: 0.8021, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5345/10000, Loss: 0.8020, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5346/10000, Loss: 0.8020, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5347/10000, Loss: 0.8020, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5348/10000, Loss: 0.8019, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5349/10000, Loss: 0.8019, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5350/10000, Loss: 0.8018, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5351/10000, Loss: 0.8018, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5352/10000, Loss: 0.8017, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5353/10000, Loss: 0.8017, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5354/10000, Loss: 0.8016, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5355/10000, Loss: 0.8016, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5356/10000, Loss: 0.8015, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5357/10000, Loss: 0.8015, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5358/10000, Loss: 0.8014, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5359/10000, Loss: 0.8014, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5360/10000, Loss: 0.8013, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5361/10000, Loss: 0.8013, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5362/10000, Loss: 0.8012, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5363/10000, Loss: 0.8012, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5364/10000, Loss: 0.8011, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5365/10000, Loss: 0.8011, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5366/10000, Loss: 0.8010, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5367/10000, Loss: 0.8010, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5368/10000, Loss: 0.8009, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5369/10000, Loss: 0.8009, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5370/10000, Loss: 0.8008, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5371/10000, Loss: 0.8008, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5372/10000, Loss: 0.8008, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5373/10000, Loss: 0.8007, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5374/10000, Loss: 0.8007, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5375/10000, Loss: 0.8006, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5376/10000, Loss: 0.8006, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5377/10000, Loss: 0.8005, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5378/10000, Loss: 0.8005, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5379/10000, Loss: 0.8004, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5380/10000, Loss: 0.8004, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5381/10000, Loss: 0.8003, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5382/10000, Loss: 0.8003, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5383/10000, Loss: 0.8002, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5384/10000, Loss: 0.8002, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5385/10000, Loss: 0.8001, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5386/10000, Loss: 0.8001, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5387/10000, Loss: 0.8000, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5388/10000, Loss: 0.8000, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5389/10000, Loss: 0.8000, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5390/10000, Loss: 0.7999, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5391/10000, Loss: 0.7999, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5392/10000, Loss: 0.7998, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5393/10000, Loss: 0.7998, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5394/10000, Loss: 0.7997, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5395/10000, Loss: 0.7997, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5396/10000, Loss: 0.7996, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5397/10000, Loss: 0.7996, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5398/10000, Loss: 0.7995, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5399/10000, Loss: 0.7995, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5400/10000, Loss: 0.7994, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5401/10000, Loss: 0.7994, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5402/10000, Loss: 0.7993, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5403/10000, Loss: 0.7993, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5404/10000, Loss: 0.7993, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5405/10000, Loss: 0.7992, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5406/10000, Loss: 0.7992, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5407/10000, Loss: 0.7991, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5408/10000, Loss: 0.7991, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5409/10000, Loss: 0.7990, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5410/10000, Loss: 0.7990, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5411/10000, Loss: 0.7989, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5412/10000, Loss: 0.7989, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5413/10000, Loss: 0.7988, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5414/10000, Loss: 0.7988, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5415/10000, Loss: 0.7987, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5416/10000, Loss: 0.7987, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5417/10000, Loss: 0.7986, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5418/10000, Loss: 0.7986, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5419/10000, Loss: 0.7986, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5420/10000, Loss: 0.7985, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5421/10000, Loss: 0.7985, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5422/10000, Loss: 0.7984, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5423/10000, Loss: 0.7984, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5424/10000, Loss: 0.7983, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5425/10000, Loss: 0.7983, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5426/10000, Loss: 0.7982, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5427/10000, Loss: 0.7982, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5428/10000, Loss: 0.7981, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5429/10000, Loss: 0.7981, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5430/10000, Loss: 0.7981, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5431/10000, Loss: 0.7980, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5432/10000, Loss: 0.7980, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5433/10000, Loss: 0.7979, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5434/10000, Loss: 0.7979, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5435/10000, Loss: 0.7978, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5436/10000, Loss: 0.7978, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5437/10000, Loss: 0.7977, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5438/10000, Loss: 0.7977, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5439/10000, Loss: 0.7976, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5440/10000, Loss: 0.7976, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5441/10000, Loss: 0.7975, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5442/10000, Loss: 0.7975, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5443/10000, Loss: 0.7975, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5444/10000, Loss: 0.7974, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5445/10000, Loss: 0.7974, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5446/10000, Loss: 0.7973, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5447/10000, Loss: 0.7973, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5448/10000, Loss: 0.7972, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5449/10000, Loss: 0.7972, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5450/10000, Loss: 0.7971, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5451/10000, Loss: 0.7971, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5452/10000, Loss: 0.7971, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5453/10000, Loss: 0.7970, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5454/10000, Loss: 0.7970, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5455/10000, Loss: 0.7969, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5456/10000, Loss: 0.7969, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5457/10000, Loss: 0.7968, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5458/10000, Loss: 0.7968, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5459/10000, Loss: 0.7967, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5460/10000, Loss: 0.7967, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5461/10000, Loss: 0.7966, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5462/10000, Loss: 0.7966, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5463/10000, Loss: 0.7966, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5464/10000, Loss: 0.7965, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5465/10000, Loss: 0.7965, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5466/10000, Loss: 0.7964, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5467/10000, Loss: 0.7964, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5468/10000, Loss: 0.7963, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5469/10000, Loss: 0.7963, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5470/10000, Loss: 0.7962, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5471/10000, Loss: 0.7962, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5472/10000, Loss: 0.7962, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5473/10000, Loss: 0.7961, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5474/10000, Loss: 0.7961, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5475/10000, Loss: 0.7960, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5476/10000, Loss: 0.7960, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5477/10000, Loss: 0.7959, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5478/10000, Loss: 0.7959, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5479/10000, Loss: 0.7958, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5480/10000, Loss: 0.7958, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5481/10000, Loss: 0.7958, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5482/10000, Loss: 0.7957, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5483/10000, Loss: 0.7957, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5484/10000, Loss: 0.7956, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5485/10000, Loss: 0.7956, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5486/10000, Loss: 0.7955, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5487/10000, Loss: 0.7955, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5488/10000, Loss: 0.7954, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5489/10000, Loss: 0.7954, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5490/10000, Loss: 0.7954, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5491/10000, Loss: 0.7953, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5492/10000, Loss: 0.7953, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5493/10000, Loss: 0.7952, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5494/10000, Loss: 0.7952, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5495/10000, Loss: 0.7951, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5496/10000, Loss: 0.7951, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5497/10000, Loss: 0.7950, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5498/10000, Loss: 0.7950, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5499/10000, Loss: 0.7950, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5500/10000, Loss: 0.7949, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5501/10000, Loss: 0.7949, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5502/10000, Loss: 0.7948, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5503/10000, Loss: 0.7948, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5504/10000, Loss: 0.7947, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5505/10000, Loss: 0.7947, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5506/10000, Loss: 0.7947, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5507/10000, Loss: 0.7946, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5508/10000, Loss: 0.7946, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5509/10000, Loss: 0.7945, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5510/10000, Loss: 0.7945, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5511/10000, Loss: 0.7944, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5512/10000, Loss: 0.7944, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5513/10000, Loss: 0.7944, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5514/10000, Loss: 0.7943, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5515/10000, Loss: 0.7943, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5516/10000, Loss: 0.7942, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5517/10000, Loss: 0.7942, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5518/10000, Loss: 0.7941, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5519/10000, Loss: 0.7941, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5520/10000, Loss: 0.7940, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5521/10000, Loss: 0.7940, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5522/10000, Loss: 0.7940, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5523/10000, Loss: 0.7939, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5524/10000, Loss: 0.7939, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5525/10000, Loss: 0.7938, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5526/10000, Loss: 0.7938, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5527/10000, Loss: 0.7937, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5528/10000, Loss: 0.7937, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5529/10000, Loss: 0.7937, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5530/10000, Loss: 0.7936, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5531/10000, Loss: 0.7936, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5532/10000, Loss: 0.7935, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5533/10000, Loss: 0.7935, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5534/10000, Loss: 0.7934, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5535/10000, Loss: 0.7934, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5536/10000, Loss: 0.7934, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5537/10000, Loss: 0.7933, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5538/10000, Loss: 0.7933, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5539/10000, Loss: 0.7932, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5540/10000, Loss: 0.7932, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5541/10000, Loss: 0.7931, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5542/10000, Loss: 0.7931, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5543/10000, Loss: 0.7931, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5544/10000, Loss: 0.7930, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5545/10000, Loss: 0.7930, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5546/10000, Loss: 0.7929, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5547/10000, Loss: 0.7929, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5548/10000, Loss: 0.7928, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5549/10000, Loss: 0.7928, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5550/10000, Loss: 0.7928, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5551/10000, Loss: 0.7927, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5552/10000, Loss: 0.7927, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5553/10000, Loss: 0.7926, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5554/10000, Loss: 0.7926, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5555/10000, Loss: 0.7925, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5556/10000, Loss: 0.7925, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5557/10000, Loss: 0.7925, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5558/10000, Loss: 0.7924, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5559/10000, Loss: 0.7924, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5560/10000, Loss: 0.7923, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5561/10000, Loss: 0.7923, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5562/10000, Loss: 0.7923, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5563/10000, Loss: 0.7922, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5564/10000, Loss: 0.7922, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5565/10000, Loss: 0.7921, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5566/10000, Loss: 0.7921, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5567/10000, Loss: 0.7920, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5568/10000, Loss: 0.7920, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5569/10000, Loss: 0.7920, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5570/10000, Loss: 0.7919, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5571/10000, Loss: 0.7919, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5572/10000, Loss: 0.7918, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5573/10000, Loss: 0.7918, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5574/10000, Loss: 0.7917, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5575/10000, Loss: 0.7917, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5576/10000, Loss: 0.7917, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5577/10000, Loss: 0.7916, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5578/10000, Loss: 0.7916, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5579/10000, Loss: 0.7915, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5580/10000, Loss: 0.7915, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5581/10000, Loss: 0.7915, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5582/10000, Loss: 0.7914, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5583/10000, Loss: 0.7914, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5584/10000, Loss: 0.7913, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5585/10000, Loss: 0.7913, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5586/10000, Loss: 0.7912, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5587/10000, Loss: 0.7912, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5588/10000, Loss: 0.7912, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5589/10000, Loss: 0.7911, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5590/10000, Loss: 0.7911, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5591/10000, Loss: 0.7910, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5592/10000, Loss: 0.7910, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5593/10000, Loss: 0.7910, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5594/10000, Loss: 0.7909, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5595/10000, Loss: 0.7909, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5596/10000, Loss: 0.7908, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5597/10000, Loss: 0.7908, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5598/10000, Loss: 0.7907, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5599/10000, Loss: 0.7907, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5600/10000, Loss: 0.7907, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5601/10000, Loss: 0.7906, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5602/10000, Loss: 0.7906, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5603/10000, Loss: 0.7905, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5604/10000, Loss: 0.7905, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5605/10000, Loss: 0.7905, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5606/10000, Loss: 0.7904, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5607/10000, Loss: 0.7904, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5608/10000, Loss: 0.7903, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5609/10000, Loss: 0.7903, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5610/10000, Loss: 0.7903, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5611/10000, Loss: 0.7902, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5612/10000, Loss: 0.7902, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5613/10000, Loss: 0.7901, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5614/10000, Loss: 0.7901, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5615/10000, Loss: 0.7901, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5616/10000, Loss: 0.7900, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5617/10000, Loss: 0.7900, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5618/10000, Loss: 0.7899, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5619/10000, Loss: 0.7899, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5620/10000, Loss: 0.7898, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5621/10000, Loss: 0.7898, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5622/10000, Loss: 0.7898, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5623/10000, Loss: 0.7897, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5624/10000, Loss: 0.7897, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5625/10000, Loss: 0.7896, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5626/10000, Loss: 0.7896, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5627/10000, Loss: 0.7896, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5628/10000, Loss: 0.7895, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5629/10000, Loss: 0.7895, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5630/10000, Loss: 0.7894, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5631/10000, Loss: 0.7894, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5632/10000, Loss: 0.7894, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5633/10000, Loss: 0.7893, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5634/10000, Loss: 0.7893, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5635/10000, Loss: 0.7892, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5636/10000, Loss: 0.7892, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5637/10000, Loss: 0.7892, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5638/10000, Loss: 0.7891, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5639/10000, Loss: 0.7891, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5640/10000, Loss: 0.7890, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5641/10000, Loss: 0.7890, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5642/10000, Loss: 0.7890, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5643/10000, Loss: 0.7889, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5644/10000, Loss: 0.7889, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5645/10000, Loss: 0.7888, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5646/10000, Loss: 0.7888, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5647/10000, Loss: 0.7888, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5648/10000, Loss: 0.7887, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5649/10000, Loss: 0.7887, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5650/10000, Loss: 0.7886, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5651/10000, Loss: 0.7886, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5652/10000, Loss: 0.7886, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5653/10000, Loss: 0.7885, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5654/10000, Loss: 0.7885, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5655/10000, Loss: 0.7884, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5656/10000, Loss: 0.7884, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5657/10000, Loss: 0.7884, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5658/10000, Loss: 0.7883, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5659/10000, Loss: 0.7883, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5660/10000, Loss: 0.7882, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5661/10000, Loss: 0.7882, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5662/10000, Loss: 0.7882, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5663/10000, Loss: 0.7881, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5664/10000, Loss: 0.7881, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5665/10000, Loss: 0.7880, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5666/10000, Loss: 0.7880, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5667/10000, Loss: 0.7880, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5668/10000, Loss: 0.7879, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5669/10000, Loss: 0.7879, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5670/10000, Loss: 0.7878, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5671/10000, Loss: 0.7878, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5672/10000, Loss: 0.7878, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5673/10000, Loss: 0.7877, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5674/10000, Loss: 0.7877, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5675/10000, Loss: 0.7876, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5676/10000, Loss: 0.7876, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5677/10000, Loss: 0.7876, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5678/10000, Loss: 0.7875, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5679/10000, Loss: 0.7875, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5680/10000, Loss: 0.7874, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5681/10000, Loss: 0.7874, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5682/10000, Loss: 0.7874, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5683/10000, Loss: 0.7873, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5684/10000, Loss: 0.7873, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5685/10000, Loss: 0.7872, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5686/10000, Loss: 0.7872, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5687/10000, Loss: 0.7872, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5688/10000, Loss: 0.7871, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5689/10000, Loss: 0.7871, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5690/10000, Loss: 0.7870, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5691/10000, Loss: 0.7870, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5692/10000, Loss: 0.7870, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5693/10000, Loss: 0.7869, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5694/10000, Loss: 0.7869, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5695/10000, Loss: 0.7869, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5696/10000, Loss: 0.7868, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5697/10000, Loss: 0.7868, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5698/10000, Loss: 0.7867, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5699/10000, Loss: 0.7867, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5700/10000, Loss: 0.7867, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5701/10000, Loss: 0.7866, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5702/10000, Loss: 0.7866, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5703/10000, Loss: 0.7865, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5704/10000, Loss: 0.7865, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5705/10000, Loss: 0.7865, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5706/10000, Loss: 0.7864, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5707/10000, Loss: 0.7864, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5708/10000, Loss: 0.7863, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5709/10000, Loss: 0.7863, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5710/10000, Loss: 0.7863, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5711/10000, Loss: 0.7862, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5712/10000, Loss: 0.7862, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5713/10000, Loss: 0.7862, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5714/10000, Loss: 0.7861, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5715/10000, Loss: 0.7861, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5716/10000, Loss: 0.7860, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5717/10000, Loss: 0.7860, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5718/10000, Loss: 0.7860, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5719/10000, Loss: 0.7859, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5720/10000, Loss: 0.7859, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5721/10000, Loss: 0.7858, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5722/10000, Loss: 0.7858, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5723/10000, Loss: 0.7858, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5724/10000, Loss: 0.7857, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5725/10000, Loss: 0.7857, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5726/10000, Loss: 0.7857, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5727/10000, Loss: 0.7856, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5728/10000, Loss: 0.7856, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5729/10000, Loss: 0.7855, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5730/10000, Loss: 0.7855, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5731/10000, Loss: 0.7855, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5732/10000, Loss: 0.7854, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5733/10000, Loss: 0.7854, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5734/10000, Loss: 0.7853, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5735/10000, Loss: 0.7853, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5736/10000, Loss: 0.7853, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5737/10000, Loss: 0.7852, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5738/10000, Loss: 0.7852, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5739/10000, Loss: 0.7852, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5740/10000, Loss: 0.7851, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5741/10000, Loss: 0.7851, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5742/10000, Loss: 0.7850, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5743/10000, Loss: 0.7850, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5744/10000, Loss: 0.7850, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5745/10000, Loss: 0.7849, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5746/10000, Loss: 0.7849, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5747/10000, Loss: 0.7848, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5748/10000, Loss: 0.7848, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5749/10000, Loss: 0.7848, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5750/10000, Loss: 0.7847, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5751/10000, Loss: 0.7847, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5752/10000, Loss: 0.7847, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5753/10000, Loss: 0.7846, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5754/10000, Loss: 0.7846, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5755/10000, Loss: 0.7845, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5756/10000, Loss: 0.7845, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5757/10000, Loss: 0.7845, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5758/10000, Loss: 0.7844, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5759/10000, Loss: 0.7844, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5760/10000, Loss: 0.7844, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5761/10000, Loss: 0.7843, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5762/10000, Loss: 0.7843, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5763/10000, Loss: 0.7842, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5764/10000, Loss: 0.7842, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5765/10000, Loss: 0.7842, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5766/10000, Loss: 0.7841, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5767/10000, Loss: 0.7841, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5768/10000, Loss: 0.7841, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5769/10000, Loss: 0.7840, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5770/10000, Loss: 0.7840, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5771/10000, Loss: 0.7839, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5772/10000, Loss: 0.7839, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5773/10000, Loss: 0.7839, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5774/10000, Loss: 0.7838, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5775/10000, Loss: 0.7838, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5776/10000, Loss: 0.7838, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5777/10000, Loss: 0.7837, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5778/10000, Loss: 0.7837, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5779/10000, Loss: 0.7836, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5780/10000, Loss: 0.7836, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5781/10000, Loss: 0.7836, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5782/10000, Loss: 0.7835, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5783/10000, Loss: 0.7835, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5784/10000, Loss: 0.7835, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5785/10000, Loss: 0.7834, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5786/10000, Loss: 0.7834, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5787/10000, Loss: 0.7833, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5788/10000, Loss: 0.7833, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5789/10000, Loss: 0.7833, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5790/10000, Loss: 0.7832, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5791/10000, Loss: 0.7832, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5792/10000, Loss: 0.7832, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5793/10000, Loss: 0.7831, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5794/10000, Loss: 0.7831, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5795/10000, Loss: 0.7831, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5796/10000, Loss: 0.7830, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5797/10000, Loss: 0.7830, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5798/10000, Loss: 0.7829, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5799/10000, Loss: 0.7829, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5800/10000, Loss: 0.7829, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5801/10000, Loss: 0.7828, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5802/10000, Loss: 0.7828, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5803/10000, Loss: 0.7828, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5804/10000, Loss: 0.7827, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5805/10000, Loss: 0.7827, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5806/10000, Loss: 0.7826, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5807/10000, Loss: 0.7826, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5808/10000, Loss: 0.7826, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5809/10000, Loss: 0.7825, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5810/10000, Loss: 0.7825, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5811/10000, Loss: 0.7825, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5812/10000, Loss: 0.7824, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5813/10000, Loss: 0.7824, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5814/10000, Loss: 0.7824, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5815/10000, Loss: 0.7823, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5816/10000, Loss: 0.7823, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5817/10000, Loss: 0.7822, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5818/10000, Loss: 0.7822, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5819/10000, Loss: 0.7822, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5820/10000, Loss: 0.7821, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5821/10000, Loss: 0.7821, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5822/10000, Loss: 0.7821, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5823/10000, Loss: 0.7820, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5824/10000, Loss: 0.7820, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5825/10000, Loss: 0.7819, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5826/10000, Loss: 0.7819, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5827/10000, Loss: 0.7819, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5828/10000, Loss: 0.7818, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5829/10000, Loss: 0.7818, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5830/10000, Loss: 0.7818, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5831/10000, Loss: 0.7817, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5832/10000, Loss: 0.7817, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5833/10000, Loss: 0.7817, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5834/10000, Loss: 0.7816, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5835/10000, Loss: 0.7816, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5836/10000, Loss: 0.7816, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5837/10000, Loss: 0.7815, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5838/10000, Loss: 0.7815, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5839/10000, Loss: 0.7814, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5840/10000, Loss: 0.7814, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5841/10000, Loss: 0.7814, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5842/10000, Loss: 0.7813, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5843/10000, Loss: 0.7813, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5844/10000, Loss: 0.7813, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5845/10000, Loss: 0.7812, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5846/10000, Loss: 0.7812, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5847/10000, Loss: 0.7812, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5848/10000, Loss: 0.7811, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5849/10000, Loss: 0.7811, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5850/10000, Loss: 0.7810, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5851/10000, Loss: 0.7810, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5852/10000, Loss: 0.7810, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5853/10000, Loss: 0.7809, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5854/10000, Loss: 0.7809, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5855/10000, Loss: 0.7809, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5856/10000, Loss: 0.7808, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5857/10000, Loss: 0.7808, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5858/10000, Loss: 0.7808, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5859/10000, Loss: 0.7807, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5860/10000, Loss: 0.7807, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5861/10000, Loss: 0.7807, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5862/10000, Loss: 0.7806, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5863/10000, Loss: 0.7806, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5864/10000, Loss: 0.7805, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5865/10000, Loss: 0.7805, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5866/10000, Loss: 0.7805, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5867/10000, Loss: 0.7804, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5868/10000, Loss: 0.7804, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5869/10000, Loss: 0.7804, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5870/10000, Loss: 0.7803, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5871/10000, Loss: 0.7803, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5872/10000, Loss: 0.7803, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5873/10000, Loss: 0.7802, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5874/10000, Loss: 0.7802, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5875/10000, Loss: 0.7802, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5876/10000, Loss: 0.7801, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5877/10000, Loss: 0.7801, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5878/10000, Loss: 0.7800, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5879/10000, Loss: 0.7800, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5880/10000, Loss: 0.7800, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5881/10000, Loss: 0.7799, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5882/10000, Loss: 0.7799, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5883/10000, Loss: 0.7799, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5884/10000, Loss: 0.7798, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5885/10000, Loss: 0.7798, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5886/10000, Loss: 0.7798, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5887/10000, Loss: 0.7797, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5888/10000, Loss: 0.7797, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5889/10000, Loss: 0.7797, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5890/10000, Loss: 0.7796, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5891/10000, Loss: 0.7796, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5892/10000, Loss: 0.7796, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5893/10000, Loss: 0.7795, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5894/10000, Loss: 0.7795, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5895/10000, Loss: 0.7794, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5896/10000, Loss: 0.7794, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5897/10000, Loss: 0.7794, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5898/10000, Loss: 0.7793, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5899/10000, Loss: 0.7793, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5900/10000, Loss: 0.7793, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5901/10000, Loss: 0.7792, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5902/10000, Loss: 0.7792, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5903/10000, Loss: 0.7792, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5904/10000, Loss: 0.7791, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5905/10000, Loss: 0.7791, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5906/10000, Loss: 0.7791, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5907/10000, Loss: 0.7790, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5908/10000, Loss: 0.7790, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5909/10000, Loss: 0.7790, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5910/10000, Loss: 0.7789, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5911/10000, Loss: 0.7789, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5912/10000, Loss: 0.7789, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5913/10000, Loss: 0.7788, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5914/10000, Loss: 0.7788, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5915/10000, Loss: 0.7787, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5916/10000, Loss: 0.7787, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5917/10000, Loss: 0.7787, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5918/10000, Loss: 0.7786, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5919/10000, Loss: 0.7786, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5920/10000, Loss: 0.7786, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5921/10000, Loss: 0.7785, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5922/10000, Loss: 0.7785, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5923/10000, Loss: 0.7785, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5924/10000, Loss: 0.7784, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5925/10000, Loss: 0.7784, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5926/10000, Loss: 0.7784, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5927/10000, Loss: 0.7783, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5928/10000, Loss: 0.7783, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5929/10000, Loss: 0.7783, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5930/10000, Loss: 0.7782, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5931/10000, Loss: 0.7782, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5932/10000, Loss: 0.7782, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5933/10000, Loss: 0.7781, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5934/10000, Loss: 0.7781, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5935/10000, Loss: 0.7781, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5936/10000, Loss: 0.7780, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5937/10000, Loss: 0.7780, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5938/10000, Loss: 0.7780, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5939/10000, Loss: 0.7779, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5940/10000, Loss: 0.7779, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5941/10000, Loss: 0.7778, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5942/10000, Loss: 0.7778, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5943/10000, Loss: 0.7778, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5944/10000, Loss: 0.7777, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5945/10000, Loss: 0.7777, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5946/10000, Loss: 0.7777, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5947/10000, Loss: 0.7776, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5948/10000, Loss: 0.7776, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5949/10000, Loss: 0.7776, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5950/10000, Loss: 0.7775, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5951/10000, Loss: 0.7775, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5952/10000, Loss: 0.7775, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5953/10000, Loss: 0.7774, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5954/10000, Loss: 0.7774, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5955/10000, Loss: 0.7774, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5956/10000, Loss: 0.7773, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5957/10000, Loss: 0.7773, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5958/10000, Loss: 0.7773, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5959/10000, Loss: 0.7772, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5960/10000, Loss: 0.7772, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5961/10000, Loss: 0.7772, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5962/10000, Loss: 0.7771, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5963/10000, Loss: 0.7771, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5964/10000, Loss: 0.7771, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5965/10000, Loss: 0.7770, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5966/10000, Loss: 0.7770, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5967/10000, Loss: 0.7770, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5968/10000, Loss: 0.7769, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5969/10000, Loss: 0.7769, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5970/10000, Loss: 0.7769, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5971/10000, Loss: 0.7768, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5972/10000, Loss: 0.7768, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5973/10000, Loss: 0.7768, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5974/10000, Loss: 0.7767, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5975/10000, Loss: 0.7767, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5976/10000, Loss: 0.7767, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5977/10000, Loss: 0.7766, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5978/10000, Loss: 0.7766, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5979/10000, Loss: 0.7766, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5980/10000, Loss: 0.7765, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5981/10000, Loss: 0.7765, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5982/10000, Loss: 0.7765, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5983/10000, Loss: 0.7764, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5984/10000, Loss: 0.7764, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5985/10000, Loss: 0.7764, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5986/10000, Loss: 0.7763, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5987/10000, Loss: 0.7763, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5988/10000, Loss: 0.7763, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5989/10000, Loss: 0.7762, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5990/10000, Loss: 0.7762, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5991/10000, Loss: 0.7762, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5992/10000, Loss: 0.7761, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5993/10000, Loss: 0.7761, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5994/10000, Loss: 0.7761, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5995/10000, Loss: 0.7760, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5996/10000, Loss: 0.7760, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5997/10000, Loss: 0.7760, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5998/10000, Loss: 0.7759, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5999/10000, Loss: 0.7759, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6000/10000, Loss: 0.7759, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6001/10000, Loss: 0.7758, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6002/10000, Loss: 0.7758, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6003/10000, Loss: 0.7758, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6004/10000, Loss: 0.7757, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6005/10000, Loss: 0.7757, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6006/10000, Loss: 0.7757, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6007/10000, Loss: 0.7756, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6008/10000, Loss: 0.7756, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6009/10000, Loss: 0.7756, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6010/10000, Loss: 0.7755, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6011/10000, Loss: 0.7755, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6012/10000, Loss: 0.7755, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6013/10000, Loss: 0.7754, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6014/10000, Loss: 0.7754, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6015/10000, Loss: 0.7754, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6016/10000, Loss: 0.7753, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6017/10000, Loss: 0.7753, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6018/10000, Loss: 0.7753, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6019/10000, Loss: 0.7752, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6020/10000, Loss: 0.7752, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6021/10000, Loss: 0.7752, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6022/10000, Loss: 0.7751, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6023/10000, Loss: 0.7751, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6024/10000, Loss: 0.7751, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6025/10000, Loss: 0.7750, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6026/10000, Loss: 0.7750, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6027/10000, Loss: 0.7750, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6028/10000, Loss: 0.7749, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6029/10000, Loss: 0.7749, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6030/10000, Loss: 0.7749, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6031/10000, Loss: 0.7748, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6032/10000, Loss: 0.7748, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6033/10000, Loss: 0.7748, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6034/10000, Loss: 0.7747, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6035/10000, Loss: 0.7747, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6036/10000, Loss: 0.7747, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6037/10000, Loss: 0.7746, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6038/10000, Loss: 0.7746, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6039/10000, Loss: 0.7746, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6040/10000, Loss: 0.7745, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6041/10000, Loss: 0.7745, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6042/10000, Loss: 0.7745, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6043/10000, Loss: 0.7744, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6044/10000, Loss: 0.7744, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6045/10000, Loss: 0.7744, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6046/10000, Loss: 0.7743, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6047/10000, Loss: 0.7743, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6048/10000, Loss: 0.7743, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6049/10000, Loss: 0.7742, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6050/10000, Loss: 0.7742, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6051/10000, Loss: 0.7742, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6052/10000, Loss: 0.7741, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6053/10000, Loss: 0.7741, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6054/10000, Loss: 0.7741, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6055/10000, Loss: 0.7740, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6056/10000, Loss: 0.7740, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6057/10000, Loss: 0.7740, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6058/10000, Loss: 0.7739, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6059/10000, Loss: 0.7739, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6060/10000, Loss: 0.7739, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6061/10000, Loss: 0.7738, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6062/10000, Loss: 0.7738, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6063/10000, Loss: 0.7738, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6064/10000, Loss: 0.7737, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6065/10000, Loss: 0.7737, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6066/10000, Loss: 0.7737, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6067/10000, Loss: 0.7737, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6068/10000, Loss: 0.7736, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6069/10000, Loss: 0.7736, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6070/10000, Loss: 0.7736, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6071/10000, Loss: 0.7735, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6072/10000, Loss: 0.7735, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6073/10000, Loss: 0.7735, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6074/10000, Loss: 0.7734, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6075/10000, Loss: 0.7734, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6076/10000, Loss: 0.7734, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6077/10000, Loss: 0.7733, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6078/10000, Loss: 0.7733, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6079/10000, Loss: 0.7733, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6080/10000, Loss: 0.7732, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6081/10000, Loss: 0.7732, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6082/10000, Loss: 0.7732, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6083/10000, Loss: 0.7731, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6084/10000, Loss: 0.7731, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6085/10000, Loss: 0.7731, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6086/10000, Loss: 0.7730, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6087/10000, Loss: 0.7730, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6088/10000, Loss: 0.7730, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6089/10000, Loss: 0.7729, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6090/10000, Loss: 0.7729, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6091/10000, Loss: 0.7729, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6092/10000, Loss: 0.7728, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6093/10000, Loss: 0.7728, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6094/10000, Loss: 0.7728, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6095/10000, Loss: 0.7727, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6096/10000, Loss: 0.7727, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6097/10000, Loss: 0.7727, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6098/10000, Loss: 0.7727, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6099/10000, Loss: 0.7726, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6100/10000, Loss: 0.7726, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6101/10000, Loss: 0.7726, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6102/10000, Loss: 0.7725, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6103/10000, Loss: 0.7725, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6104/10000, Loss: 0.7725, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6105/10000, Loss: 0.7724, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6106/10000, Loss: 0.7724, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6107/10000, Loss: 0.7724, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6108/10000, Loss: 0.7723, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6109/10000, Loss: 0.7723, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6110/10000, Loss: 0.7723, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6111/10000, Loss: 0.7722, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6112/10000, Loss: 0.7722, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6113/10000, Loss: 0.7722, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6114/10000, Loss: 0.7721, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6115/10000, Loss: 0.7721, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6116/10000, Loss: 0.7721, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6117/10000, Loss: 0.7721, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6118/10000, Loss: 0.7720, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6119/10000, Loss: 0.7720, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6120/10000, Loss: 0.7720, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6121/10000, Loss: 0.7719, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6122/10000, Loss: 0.7719, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6123/10000, Loss: 0.7719, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6124/10000, Loss: 0.7718, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6125/10000, Loss: 0.7718, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6126/10000, Loss: 0.7718, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6127/10000, Loss: 0.7717, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6128/10000, Loss: 0.7717, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6129/10000, Loss: 0.7717, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6130/10000, Loss: 0.7716, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6131/10000, Loss: 0.7716, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6132/10000, Loss: 0.7716, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6133/10000, Loss: 0.7715, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6134/10000, Loss: 0.7715, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6135/10000, Loss: 0.7715, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6136/10000, Loss: 0.7715, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6137/10000, Loss: 0.7714, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6138/10000, Loss: 0.7714, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6139/10000, Loss: 0.7714, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6140/10000, Loss: 0.7713, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6141/10000, Loss: 0.7713, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6142/10000, Loss: 0.7713, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6143/10000, Loss: 0.7712, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6144/10000, Loss: 0.7712, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6145/10000, Loss: 0.7712, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6146/10000, Loss: 0.7711, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6147/10000, Loss: 0.7711, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6148/10000, Loss: 0.7711, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6149/10000, Loss: 0.7710, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6150/10000, Loss: 0.7710, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6151/10000, Loss: 0.7710, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6152/10000, Loss: 0.7710, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6153/10000, Loss: 0.7709, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6154/10000, Loss: 0.7709, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6155/10000, Loss: 0.7709, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6156/10000, Loss: 0.7708, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6157/10000, Loss: 0.7708, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6158/10000, Loss: 0.7708, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6159/10000, Loss: 0.7707, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6160/10000, Loss: 0.7707, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6161/10000, Loss: 0.7707, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6162/10000, Loss: 0.7706, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6163/10000, Loss: 0.7706, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6164/10000, Loss: 0.7706, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6165/10000, Loss: 0.7705, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6166/10000, Loss: 0.7705, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6167/10000, Loss: 0.7705, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6168/10000, Loss: 0.7705, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6169/10000, Loss: 0.7704, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6170/10000, Loss: 0.7704, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6171/10000, Loss: 0.7704, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6172/10000, Loss: 0.7703, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6173/10000, Loss: 0.7703, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6174/10000, Loss: 0.7703, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6175/10000, Loss: 0.7702, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6176/10000, Loss: 0.7702, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6177/10000, Loss: 0.7702, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6178/10000, Loss: 0.7701, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6179/10000, Loss: 0.7701, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6180/10000, Loss: 0.7701, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6181/10000, Loss: 0.7701, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6182/10000, Loss: 0.7700, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6183/10000, Loss: 0.7700, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6184/10000, Loss: 0.7700, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6185/10000, Loss: 0.7699, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6186/10000, Loss: 0.7699, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6187/10000, Loss: 0.7699, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6188/10000, Loss: 0.7698, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6189/10000, Loss: 0.7698, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6190/10000, Loss: 0.7698, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6191/10000, Loss: 0.7697, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6192/10000, Loss: 0.7697, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6193/10000, Loss: 0.7697, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6194/10000, Loss: 0.7697, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6195/10000, Loss: 0.7696, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6196/10000, Loss: 0.7696, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6197/10000, Loss: 0.7696, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6198/10000, Loss: 0.7695, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6199/10000, Loss: 0.7695, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6200/10000, Loss: 0.7695, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6201/10000, Loss: 0.7694, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6202/10000, Loss: 0.7694, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6203/10000, Loss: 0.7694, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6204/10000, Loss: 0.7693, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6205/10000, Loss: 0.7693, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6206/10000, Loss: 0.7693, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6207/10000, Loss: 0.7693, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6208/10000, Loss: 0.7692, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6209/10000, Loss: 0.7692, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6210/10000, Loss: 0.7692, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6211/10000, Loss: 0.7691, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6212/10000, Loss: 0.7691, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6213/10000, Loss: 0.7691, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6214/10000, Loss: 0.7690, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6215/10000, Loss: 0.7690, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6216/10000, Loss: 0.7690, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6217/10000, Loss: 0.7690, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6218/10000, Loss: 0.7689, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6219/10000, Loss: 0.7689, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6220/10000, Loss: 0.7689, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6221/10000, Loss: 0.7688, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6222/10000, Loss: 0.7688, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6223/10000, Loss: 0.7688, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6224/10000, Loss: 0.7687, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6225/10000, Loss: 0.7687, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6226/10000, Loss: 0.7687, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6227/10000, Loss: 0.7686, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6228/10000, Loss: 0.7686, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6229/10000, Loss: 0.7686, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6230/10000, Loss: 0.7686, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6231/10000, Loss: 0.7685, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6232/10000, Loss: 0.7685, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6233/10000, Loss: 0.7685, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6234/10000, Loss: 0.7684, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6235/10000, Loss: 0.7684, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6236/10000, Loss: 0.7684, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6237/10000, Loss: 0.7683, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6238/10000, Loss: 0.7683, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6239/10000, Loss: 0.7683, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6240/10000, Loss: 0.7683, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6241/10000, Loss: 0.7682, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6242/10000, Loss: 0.7682, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6243/10000, Loss: 0.7682, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6244/10000, Loss: 0.7681, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6245/10000, Loss: 0.7681, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6246/10000, Loss: 0.7681, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6247/10000, Loss: 0.7680, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6248/10000, Loss: 0.7680, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6249/10000, Loss: 0.7680, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6250/10000, Loss: 0.7680, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6251/10000, Loss: 0.7679, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6252/10000, Loss: 0.7679, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6253/10000, Loss: 0.7679, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6254/10000, Loss: 0.7678, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6255/10000, Loss: 0.7678, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6256/10000, Loss: 0.7678, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6257/10000, Loss: 0.7677, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6258/10000, Loss: 0.7677, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6259/10000, Loss: 0.7677, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6260/10000, Loss: 0.7677, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6261/10000, Loss: 0.7676, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6262/10000, Loss: 0.7676, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6263/10000, Loss: 0.7676, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6264/10000, Loss: 0.7675, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6265/10000, Loss: 0.7675, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6266/10000, Loss: 0.7675, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6267/10000, Loss: 0.7675, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6268/10000, Loss: 0.7674, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6269/10000, Loss: 0.7674, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6270/10000, Loss: 0.7674, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6271/10000, Loss: 0.7673, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6272/10000, Loss: 0.7673, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6273/10000, Loss: 0.7673, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6274/10000, Loss: 0.7672, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6275/10000, Loss: 0.7672, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6276/10000, Loss: 0.7672, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6277/10000, Loss: 0.7672, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6278/10000, Loss: 0.7671, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6279/10000, Loss: 0.7671, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6280/10000, Loss: 0.7671, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6281/10000, Loss: 0.7670, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6282/10000, Loss: 0.7670, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6283/10000, Loss: 0.7670, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6284/10000, Loss: 0.7669, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6285/10000, Loss: 0.7669, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6286/10000, Loss: 0.7669, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6287/10000, Loss: 0.7669, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6288/10000, Loss: 0.7668, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6289/10000, Loss: 0.7668, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6290/10000, Loss: 0.7668, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6291/10000, Loss: 0.7667, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6292/10000, Loss: 0.7667, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6293/10000, Loss: 0.7667, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6294/10000, Loss: 0.7667, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6295/10000, Loss: 0.7666, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6296/10000, Loss: 0.7666, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6297/10000, Loss: 0.7666, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6298/10000, Loss: 0.7665, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6299/10000, Loss: 0.7665, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6300/10000, Loss: 0.7665, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6301/10000, Loss: 0.7664, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6302/10000, Loss: 0.7664, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6303/10000, Loss: 0.7664, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6304/10000, Loss: 0.7664, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6305/10000, Loss: 0.7663, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6306/10000, Loss: 0.7663, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6307/10000, Loss: 0.7663, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6308/10000, Loss: 0.7662, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6309/10000, Loss: 0.7662, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6310/10000, Loss: 0.7662, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6311/10000, Loss: 0.7662, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6312/10000, Loss: 0.7661, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6313/10000, Loss: 0.7661, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6314/10000, Loss: 0.7661, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6315/10000, Loss: 0.7660, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6316/10000, Loss: 0.7660, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6317/10000, Loss: 0.7660, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6318/10000, Loss: 0.7660, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6319/10000, Loss: 0.7659, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6320/10000, Loss: 0.7659, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6321/10000, Loss: 0.7659, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6322/10000, Loss: 0.7658, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6323/10000, Loss: 0.7658, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6324/10000, Loss: 0.7658, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6325/10000, Loss: 0.7657, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6326/10000, Loss: 0.7657, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6327/10000, Loss: 0.7657, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6328/10000, Loss: 0.7657, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6329/10000, Loss: 0.7656, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6330/10000, Loss: 0.7656, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6331/10000, Loss: 0.7656, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6332/10000, Loss: 0.7655, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6333/10000, Loss: 0.7655, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6334/10000, Loss: 0.7655, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6335/10000, Loss: 0.7655, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6336/10000, Loss: 0.7654, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6337/10000, Loss: 0.7654, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6338/10000, Loss: 0.7654, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6339/10000, Loss: 0.7653, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6340/10000, Loss: 0.7653, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6341/10000, Loss: 0.7653, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6342/10000, Loss: 0.7653, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6343/10000, Loss: 0.7652, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6344/10000, Loss: 0.7652, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6345/10000, Loss: 0.7652, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6346/10000, Loss: 0.7651, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6347/10000, Loss: 0.7651, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6348/10000, Loss: 0.7651, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6349/10000, Loss: 0.7651, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6350/10000, Loss: 0.7650, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6351/10000, Loss: 0.7650, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6352/10000, Loss: 0.7650, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6353/10000, Loss: 0.7649, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6354/10000, Loss: 0.7649, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6355/10000, Loss: 0.7649, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6356/10000, Loss: 0.7649, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6357/10000, Loss: 0.7648, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6358/10000, Loss: 0.7648, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6359/10000, Loss: 0.7648, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6360/10000, Loss: 0.7647, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6361/10000, Loss: 0.7647, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6362/10000, Loss: 0.7647, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6363/10000, Loss: 0.7647, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6364/10000, Loss: 0.7646, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6365/10000, Loss: 0.7646, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6366/10000, Loss: 0.7646, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6367/10000, Loss: 0.7645, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6368/10000, Loss: 0.7645, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6369/10000, Loss: 0.7645, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6370/10000, Loss: 0.7645, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6371/10000, Loss: 0.7644, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6372/10000, Loss: 0.7644, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6373/10000, Loss: 0.7644, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6374/10000, Loss: 0.7643, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6375/10000, Loss: 0.7643, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6376/10000, Loss: 0.7643, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6377/10000, Loss: 0.7643, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6378/10000, Loss: 0.7642, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6379/10000, Loss: 0.7642, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6380/10000, Loss: 0.7642, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6381/10000, Loss: 0.7641, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6382/10000, Loss: 0.7641, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6383/10000, Loss: 0.7641, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6384/10000, Loss: 0.7641, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6385/10000, Loss: 0.7640, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6386/10000, Loss: 0.7640, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6387/10000, Loss: 0.7640, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6388/10000, Loss: 0.7639, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6389/10000, Loss: 0.7639, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6390/10000, Loss: 0.7639, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6391/10000, Loss: 0.7639, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6392/10000, Loss: 0.7638, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6393/10000, Loss: 0.7638, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6394/10000, Loss: 0.7638, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6395/10000, Loss: 0.7637, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6396/10000, Loss: 0.7637, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6397/10000, Loss: 0.7637, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6398/10000, Loss: 0.7637, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6399/10000, Loss: 0.7636, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6400/10000, Loss: 0.7636, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6401/10000, Loss: 0.7636, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6402/10000, Loss: 0.7635, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6403/10000, Loss: 0.7635, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6404/10000, Loss: 0.7635, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6405/10000, Loss: 0.7635, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6406/10000, Loss: 0.7634, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6407/10000, Loss: 0.7634, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6408/10000, Loss: 0.7634, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6409/10000, Loss: 0.7633, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6410/10000, Loss: 0.7633, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6411/10000, Loss: 0.7633, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6412/10000, Loss: 0.7633, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6413/10000, Loss: 0.7632, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6414/10000, Loss: 0.7632, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6415/10000, Loss: 0.7632, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6416/10000, Loss: 0.7631, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6417/10000, Loss: 0.7631, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6418/10000, Loss: 0.7631, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6419/10000, Loss: 0.7631, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6420/10000, Loss: 0.7630, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6421/10000, Loss: 0.7630, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6422/10000, Loss: 0.7630, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6423/10000, Loss: 0.7630, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6424/10000, Loss: 0.7629, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6425/10000, Loss: 0.7629, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6426/10000, Loss: 0.7629, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6427/10000, Loss: 0.7628, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6428/10000, Loss: 0.7628, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6429/10000, Loss: 0.7628, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6430/10000, Loss: 0.7628, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6431/10000, Loss: 0.7627, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6432/10000, Loss: 0.7627, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6433/10000, Loss: 0.7627, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6434/10000, Loss: 0.7626, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6435/10000, Loss: 0.7626, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6436/10000, Loss: 0.7626, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6437/10000, Loss: 0.7626, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6438/10000, Loss: 0.7625, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6439/10000, Loss: 0.7625, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6440/10000, Loss: 0.7625, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6441/10000, Loss: 0.7624, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6442/10000, Loss: 0.7624, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6443/10000, Loss: 0.7624, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6444/10000, Loss: 0.7624, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6445/10000, Loss: 0.7623, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6446/10000, Loss: 0.7623, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6447/10000, Loss: 0.7623, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6448/10000, Loss: 0.7623, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6449/10000, Loss: 0.7622, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6450/10000, Loss: 0.7622, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6451/10000, Loss: 0.7622, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6452/10000, Loss: 0.7621, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6453/10000, Loss: 0.7621, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6454/10000, Loss: 0.7621, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6455/10000, Loss: 0.7621, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6456/10000, Loss: 0.7620, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6457/10000, Loss: 0.7620, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6458/10000, Loss: 0.7620, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6459/10000, Loss: 0.7619, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6460/10000, Loss: 0.7619, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6461/10000, Loss: 0.7619, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6462/10000, Loss: 0.7619, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6463/10000, Loss: 0.7618, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6464/10000, Loss: 0.7618, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6465/10000, Loss: 0.7618, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6466/10000, Loss: 0.7618, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6467/10000, Loss: 0.7617, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6468/10000, Loss: 0.7617, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6469/10000, Loss: 0.7617, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6470/10000, Loss: 0.7616, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6471/10000, Loss: 0.7616, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6472/10000, Loss: 0.7616, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6473/10000, Loss: 0.7616, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6474/10000, Loss: 0.7615, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6475/10000, Loss: 0.7615, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6476/10000, Loss: 0.7615, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6477/10000, Loss: 0.7615, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6478/10000, Loss: 0.7614, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6479/10000, Loss: 0.7614, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6480/10000, Loss: 0.7614, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6481/10000, Loss: 0.7613, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6482/10000, Loss: 0.7613, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6483/10000, Loss: 0.7613, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6484/10000, Loss: 0.7613, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6485/10000, Loss: 0.7612, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6486/10000, Loss: 0.7612, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6487/10000, Loss: 0.7612, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6488/10000, Loss: 0.7611, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6489/10000, Loss: 0.7611, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6490/10000, Loss: 0.7611, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6491/10000, Loss: 0.7611, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6492/10000, Loss: 0.7610, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6493/10000, Loss: 0.7610, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6494/10000, Loss: 0.7610, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6495/10000, Loss: 0.7610, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6496/10000, Loss: 0.7609, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6497/10000, Loss: 0.7609, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6498/10000, Loss: 0.7609, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6499/10000, Loss: 0.7608, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6500/10000, Loss: 0.7608, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6501/10000, Loss: 0.7608, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6502/10000, Loss: 0.7608, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6503/10000, Loss: 0.7607, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6504/10000, Loss: 0.7607, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6505/10000, Loss: 0.7607, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6506/10000, Loss: 0.7607, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6507/10000, Loss: 0.7606, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6508/10000, Loss: 0.7606, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6509/10000, Loss: 0.7606, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6510/10000, Loss: 0.7605, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6511/10000, Loss: 0.7605, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6512/10000, Loss: 0.7605, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6513/10000, Loss: 0.7605, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6514/10000, Loss: 0.7604, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6515/10000, Loss: 0.7604, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6516/10000, Loss: 0.7604, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6517/10000, Loss: 0.7604, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6518/10000, Loss: 0.7603, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6519/10000, Loss: 0.7603, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6520/10000, Loss: 0.7603, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6521/10000, Loss: 0.7602, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6522/10000, Loss: 0.7602, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6523/10000, Loss: 0.7602, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6524/10000, Loss: 0.7602, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6525/10000, Loss: 0.7601, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6526/10000, Loss: 0.7601, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6527/10000, Loss: 0.7601, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6528/10000, Loss: 0.7601, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6529/10000, Loss: 0.7600, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6530/10000, Loss: 0.7600, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6531/10000, Loss: 0.7600, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6532/10000, Loss: 0.7600, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6533/10000, Loss: 0.7599, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6534/10000, Loss: 0.7599, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6535/10000, Loss: 0.7599, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6536/10000, Loss: 0.7598, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6537/10000, Loss: 0.7598, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6538/10000, Loss: 0.7598, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6539/10000, Loss: 0.7598, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6540/10000, Loss: 0.7597, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6541/10000, Loss: 0.7597, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6542/10000, Loss: 0.7597, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6543/10000, Loss: 0.7597, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6544/10000, Loss: 0.7596, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6545/10000, Loss: 0.7596, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6546/10000, Loss: 0.7596, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6547/10000, Loss: 0.7595, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6548/10000, Loss: 0.7595, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6549/10000, Loss: 0.7595, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6550/10000, Loss: 0.7595, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6551/10000, Loss: 0.7594, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6552/10000, Loss: 0.7594, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6553/10000, Loss: 0.7594, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6554/10000, Loss: 0.7594, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6555/10000, Loss: 0.7593, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6556/10000, Loss: 0.7593, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6557/10000, Loss: 0.7593, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6558/10000, Loss: 0.7593, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6559/10000, Loss: 0.7592, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6560/10000, Loss: 0.7592, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6561/10000, Loss: 0.7592, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6562/10000, Loss: 0.7591, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6563/10000, Loss: 0.7591, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6564/10000, Loss: 0.7591, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6565/10000, Loss: 0.7591, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6566/10000, Loss: 0.7590, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6567/10000, Loss: 0.7590, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6568/10000, Loss: 0.7590, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6569/10000, Loss: 0.7590, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6570/10000, Loss: 0.7589, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6571/10000, Loss: 0.7589, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6572/10000, Loss: 0.7589, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6573/10000, Loss: 0.7589, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6574/10000, Loss: 0.7588, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6575/10000, Loss: 0.7588, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6576/10000, Loss: 0.7588, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6577/10000, Loss: 0.7587, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6578/10000, Loss: 0.7587, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6579/10000, Loss: 0.7587, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6580/10000, Loss: 0.7587, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6581/10000, Loss: 0.7586, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6582/10000, Loss: 0.7586, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6583/10000, Loss: 0.7586, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6584/10000, Loss: 0.7586, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6585/10000, Loss: 0.7585, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6586/10000, Loss: 0.7585, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6587/10000, Loss: 0.7585, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6588/10000, Loss: 0.7585, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6589/10000, Loss: 0.7584, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6590/10000, Loss: 0.7584, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6591/10000, Loss: 0.7584, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6592/10000, Loss: 0.7583, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6593/10000, Loss: 0.7583, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6594/10000, Loss: 0.7583, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6595/10000, Loss: 0.7583, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6596/10000, Loss: 0.7582, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6597/10000, Loss: 0.7582, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6598/10000, Loss: 0.7582, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6599/10000, Loss: 0.7582, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6600/10000, Loss: 0.7581, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6601/10000, Loss: 0.7581, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6602/10000, Loss: 0.7581, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6603/10000, Loss: 0.7581, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6604/10000, Loss: 0.7580, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6605/10000, Loss: 0.7580, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6606/10000, Loss: 0.7580, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6607/10000, Loss: 0.7580, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6608/10000, Loss: 0.7579, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6609/10000, Loss: 0.7579, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6610/10000, Loss: 0.7579, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6611/10000, Loss: 0.7578, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6612/10000, Loss: 0.7578, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6613/10000, Loss: 0.7578, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6614/10000, Loss: 0.7578, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6615/10000, Loss: 0.7577, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6616/10000, Loss: 0.7577, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6617/10000, Loss: 0.7577, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6618/10000, Loss: 0.7577, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6619/10000, Loss: 0.7576, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6620/10000, Loss: 0.7576, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6621/10000, Loss: 0.7576, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6622/10000, Loss: 0.7576, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6623/10000, Loss: 0.7575, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6624/10000, Loss: 0.7575, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6625/10000, Loss: 0.7575, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6626/10000, Loss: 0.7575, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6627/10000, Loss: 0.7574, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6628/10000, Loss: 0.7574, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6629/10000, Loss: 0.7574, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6630/10000, Loss: 0.7573, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6631/10000, Loss: 0.7573, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6632/10000, Loss: 0.7573, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6633/10000, Loss: 0.7573, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6634/10000, Loss: 0.7572, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6635/10000, Loss: 0.7572, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6636/10000, Loss: 0.7572, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6637/10000, Loss: 0.7572, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6638/10000, Loss: 0.7571, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6639/10000, Loss: 0.7571, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6640/10000, Loss: 0.7571, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6641/10000, Loss: 0.7571, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6642/10000, Loss: 0.7570, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6643/10000, Loss: 0.7570, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6644/10000, Loss: 0.7570, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6645/10000, Loss: 0.7570, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6646/10000, Loss: 0.7569, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6647/10000, Loss: 0.7569, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6648/10000, Loss: 0.7569, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6649/10000, Loss: 0.7569, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6650/10000, Loss: 0.7568, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6651/10000, Loss: 0.7568, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6652/10000, Loss: 0.7568, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6653/10000, Loss: 0.7567, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6654/10000, Loss: 0.7567, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6655/10000, Loss: 0.7567, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6656/10000, Loss: 0.7567, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6657/10000, Loss: 0.7566, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6658/10000, Loss: 0.7566, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6659/10000, Loss: 0.7566, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6660/10000, Loss: 0.7566, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6661/10000, Loss: 0.7565, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6662/10000, Loss: 0.7565, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6663/10000, Loss: 0.7565, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6664/10000, Loss: 0.7565, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6665/10000, Loss: 0.7564, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6666/10000, Loss: 0.7564, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6667/10000, Loss: 0.7564, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6668/10000, Loss: 0.7564, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6669/10000, Loss: 0.7563, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6670/10000, Loss: 0.7563, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6671/10000, Loss: 0.7563, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6672/10000, Loss: 0.7563, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6673/10000, Loss: 0.7562, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6674/10000, Loss: 0.7562, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6675/10000, Loss: 0.7562, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6676/10000, Loss: 0.7562, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6677/10000, Loss: 0.7561, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6678/10000, Loss: 0.7561, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6679/10000, Loss: 0.7561, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6680/10000, Loss: 0.7560, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6681/10000, Loss: 0.7560, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6682/10000, Loss: 0.7560, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6683/10000, Loss: 0.7560, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6684/10000, Loss: 0.7559, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6685/10000, Loss: 0.7559, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6686/10000, Loss: 0.7559, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6687/10000, Loss: 0.7559, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6688/10000, Loss: 0.7558, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6689/10000, Loss: 0.7558, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6690/10000, Loss: 0.7558, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6691/10000, Loss: 0.7558, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6692/10000, Loss: 0.7557, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6693/10000, Loss: 0.7557, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6694/10000, Loss: 0.7557, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6695/10000, Loss: 0.7557, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6696/10000, Loss: 0.7556, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6697/10000, Loss: 0.7556, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6698/10000, Loss: 0.7556, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6699/10000, Loss: 0.7556, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6700/10000, Loss: 0.7555, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6701/10000, Loss: 0.7555, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6702/10000, Loss: 0.7555, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6703/10000, Loss: 0.7555, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6704/10000, Loss: 0.7554, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6705/10000, Loss: 0.7554, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6706/10000, Loss: 0.7554, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6707/10000, Loss: 0.7554, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6708/10000, Loss: 0.7553, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6709/10000, Loss: 0.7553, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6710/10000, Loss: 0.7553, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6711/10000, Loss: 0.7553, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6712/10000, Loss: 0.7552, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6713/10000, Loss: 0.7552, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6714/10000, Loss: 0.7552, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6715/10000, Loss: 0.7552, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6716/10000, Loss: 0.7551, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6717/10000, Loss: 0.7551, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6718/10000, Loss: 0.7551, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6719/10000, Loss: 0.7550, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6720/10000, Loss: 0.7550, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6721/10000, Loss: 0.7550, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6722/10000, Loss: 0.7550, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6723/10000, Loss: 0.7549, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6724/10000, Loss: 0.7549, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6725/10000, Loss: 0.7549, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6726/10000, Loss: 0.7549, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6727/10000, Loss: 0.7548, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6728/10000, Loss: 0.7548, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6729/10000, Loss: 0.7548, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6730/10000, Loss: 0.7548, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6731/10000, Loss: 0.7547, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6732/10000, Loss: 0.7547, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6733/10000, Loss: 0.7547, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6734/10000, Loss: 0.7547, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6735/10000, Loss: 0.7546, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6736/10000, Loss: 0.7546, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6737/10000, Loss: 0.7546, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6738/10000, Loss: 0.7546, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6739/10000, Loss: 0.7545, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6740/10000, Loss: 0.7545, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6741/10000, Loss: 0.7545, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6742/10000, Loss: 0.7545, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6743/10000, Loss: 0.7544, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6744/10000, Loss: 0.7544, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6745/10000, Loss: 0.7544, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6746/10000, Loss: 0.7544, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6747/10000, Loss: 0.7543, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6748/10000, Loss: 0.7543, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6749/10000, Loss: 0.7543, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6750/10000, Loss: 0.7543, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6751/10000, Loss: 0.7542, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6752/10000, Loss: 0.7542, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6753/10000, Loss: 0.7542, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6754/10000, Loss: 0.7542, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6755/10000, Loss: 0.7541, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6756/10000, Loss: 0.7541, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6757/10000, Loss: 0.7541, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6758/10000, Loss: 0.7541, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6759/10000, Loss: 0.7540, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6760/10000, Loss: 0.7540, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6761/10000, Loss: 0.7540, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6762/10000, Loss: 0.7540, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6763/10000, Loss: 0.7539, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6764/10000, Loss: 0.7539, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6765/10000, Loss: 0.7539, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6766/10000, Loss: 0.7539, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6767/10000, Loss: 0.7538, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6768/10000, Loss: 0.7538, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6769/10000, Loss: 0.7538, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6770/10000, Loss: 0.7538, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6771/10000, Loss: 0.7537, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6772/10000, Loss: 0.7537, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6773/10000, Loss: 0.7537, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6774/10000, Loss: 0.7537, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6775/10000, Loss: 0.7536, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6776/10000, Loss: 0.7536, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6777/10000, Loss: 0.7536, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6778/10000, Loss: 0.7536, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6779/10000, Loss: 0.7535, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6780/10000, Loss: 0.7535, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6781/10000, Loss: 0.7535, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6782/10000, Loss: 0.7535, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6783/10000, Loss: 0.7534, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6784/10000, Loss: 0.7534, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6785/10000, Loss: 0.7534, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6786/10000, Loss: 0.7534, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6787/10000, Loss: 0.7533, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6788/10000, Loss: 0.7533, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6789/10000, Loss: 0.7533, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6790/10000, Loss: 0.7533, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6791/10000, Loss: 0.7532, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6792/10000, Loss: 0.7532, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6793/10000, Loss: 0.7532, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6794/10000, Loss: 0.7532, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6795/10000, Loss: 0.7531, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6796/10000, Loss: 0.7531, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6797/10000, Loss: 0.7531, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6798/10000, Loss: 0.7531, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6799/10000, Loss: 0.7530, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6800/10000, Loss: 0.7530, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6801/10000, Loss: 0.7530, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6802/10000, Loss: 0.7530, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6803/10000, Loss: 0.7529, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6804/10000, Loss: 0.7529, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6805/10000, Loss: 0.7529, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6806/10000, Loss: 0.7529, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6807/10000, Loss: 0.7528, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6808/10000, Loss: 0.7528, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6809/10000, Loss: 0.7528, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6810/10000, Loss: 0.7528, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6811/10000, Loss: 0.7527, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6812/10000, Loss: 0.7527, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6813/10000, Loss: 0.7527, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6814/10000, Loss: 0.7527, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6815/10000, Loss: 0.7526, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6816/10000, Loss: 0.7526, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6817/10000, Loss: 0.7526, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6818/10000, Loss: 0.7526, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6819/10000, Loss: 0.7525, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6820/10000, Loss: 0.7525, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6821/10000, Loss: 0.7525, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6822/10000, Loss: 0.7525, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6823/10000, Loss: 0.7524, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6824/10000, Loss: 0.7524, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6825/10000, Loss: 0.7524, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6826/10000, Loss: 0.7524, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6827/10000, Loss: 0.7523, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6828/10000, Loss: 0.7523, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6829/10000, Loss: 0.7523, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6830/10000, Loss: 0.7523, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6831/10000, Loss: 0.7522, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6832/10000, Loss: 0.7522, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6833/10000, Loss: 0.7522, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6834/10000, Loss: 0.7522, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6835/10000, Loss: 0.7521, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6836/10000, Loss: 0.7521, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6837/10000, Loss: 0.7521, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6838/10000, Loss: 0.7521, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6839/10000, Loss: 0.7520, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6840/10000, Loss: 0.7520, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6841/10000, Loss: 0.7520, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6842/10000, Loss: 0.7520, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6843/10000, Loss: 0.7519, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6844/10000, Loss: 0.7519, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6845/10000, Loss: 0.7519, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6846/10000, Loss: 0.7519, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6847/10000, Loss: 0.7518, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6848/10000, Loss: 0.7518, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6849/10000, Loss: 0.7518, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6850/10000, Loss: 0.7518, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6851/10000, Loss: 0.7517, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6852/10000, Loss: 0.7517, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6853/10000, Loss: 0.7517, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6854/10000, Loss: 0.7517, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6855/10000, Loss: 0.7516, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6856/10000, Loss: 0.7516, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6857/10000, Loss: 0.7516, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6858/10000, Loss: 0.7516, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6859/10000, Loss: 0.7516, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6860/10000, Loss: 0.7515, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6861/10000, Loss: 0.7515, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6862/10000, Loss: 0.7515, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6863/10000, Loss: 0.7515, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6864/10000, Loss: 0.7514, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6865/10000, Loss: 0.7514, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6866/10000, Loss: 0.7514, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6867/10000, Loss: 0.7514, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6868/10000, Loss: 0.7513, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6869/10000, Loss: 0.7513, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6870/10000, Loss: 0.7513, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6871/10000, Loss: 0.7513, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6872/10000, Loss: 0.7512, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6873/10000, Loss: 0.7512, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6874/10000, Loss: 0.7512, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6875/10000, Loss: 0.7512, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6876/10000, Loss: 0.7511, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6877/10000, Loss: 0.7511, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6878/10000, Loss: 0.7511, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6879/10000, Loss: 0.7511, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6880/10000, Loss: 0.7510, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6881/10000, Loss: 0.7510, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6882/10000, Loss: 0.7510, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6883/10000, Loss: 0.7510, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6884/10000, Loss: 0.7509, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6885/10000, Loss: 0.7509, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6886/10000, Loss: 0.7509, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6887/10000, Loss: 0.7509, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6888/10000, Loss: 0.7508, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6889/10000, Loss: 0.7508, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6890/10000, Loss: 0.7508, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6891/10000, Loss: 0.7508, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6892/10000, Loss: 0.7507, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6893/10000, Loss: 0.7507, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6894/10000, Loss: 0.7507, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6895/10000, Loss: 0.7507, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6896/10000, Loss: 0.7506, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6897/10000, Loss: 0.7506, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6898/10000, Loss: 0.7506, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6899/10000, Loss: 0.7506, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6900/10000, Loss: 0.7506, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6901/10000, Loss: 0.7505, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6902/10000, Loss: 0.7505, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6903/10000, Loss: 0.7505, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6904/10000, Loss: 0.7505, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6905/10000, Loss: 0.7504, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6906/10000, Loss: 0.7504, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6907/10000, Loss: 0.7504, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6908/10000, Loss: 0.7504, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6909/10000, Loss: 0.7503, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6910/10000, Loss: 0.7503, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6911/10000, Loss: 0.7503, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6912/10000, Loss: 0.7503, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6913/10000, Loss: 0.7502, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6914/10000, Loss: 0.7502, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6915/10000, Loss: 0.7502, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6916/10000, Loss: 0.7502, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6917/10000, Loss: 0.7501, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6918/10000, Loss: 0.7501, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6919/10000, Loss: 0.7501, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6920/10000, Loss: 0.7501, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6921/10000, Loss: 0.7500, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6922/10000, Loss: 0.7500, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6923/10000, Loss: 0.7500, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6924/10000, Loss: 0.7500, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6925/10000, Loss: 0.7499, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6926/10000, Loss: 0.7499, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6927/10000, Loss: 0.7499, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6928/10000, Loss: 0.7499, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6929/10000, Loss: 0.7499, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6930/10000, Loss: 0.7498, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6931/10000, Loss: 0.7498, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6932/10000, Loss: 0.7498, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6933/10000, Loss: 0.7498, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6934/10000, Loss: 0.7497, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6935/10000, Loss: 0.7497, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6936/10000, Loss: 0.7497, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6937/10000, Loss: 0.7497, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6938/10000, Loss: 0.7496, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6939/10000, Loss: 0.7496, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6940/10000, Loss: 0.7496, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6941/10000, Loss: 0.7496, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6942/10000, Loss: 0.7495, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6943/10000, Loss: 0.7495, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6944/10000, Loss: 0.7495, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6945/10000, Loss: 0.7495, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6946/10000, Loss: 0.7494, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6947/10000, Loss: 0.7494, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6948/10000, Loss: 0.7494, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6949/10000, Loss: 0.7494, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6950/10000, Loss: 0.7493, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6951/10000, Loss: 0.7493, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6952/10000, Loss: 0.7493, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6953/10000, Loss: 0.7493, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6954/10000, Loss: 0.7493, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6955/10000, Loss: 0.7492, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6956/10000, Loss: 0.7492, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6957/10000, Loss: 0.7492, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6958/10000, Loss: 0.7492, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6959/10000, Loss: 0.7491, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6960/10000, Loss: 0.7491, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6961/10000, Loss: 0.7491, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6962/10000, Loss: 0.7491, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6963/10000, Loss: 0.7490, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6964/10000, Loss: 0.7490, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6965/10000, Loss: 0.7490, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6966/10000, Loss: 0.7490, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6967/10000, Loss: 0.7489, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6968/10000, Loss: 0.7489, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6969/10000, Loss: 0.7489, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6970/10000, Loss: 0.7489, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6971/10000, Loss: 0.7488, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6972/10000, Loss: 0.7488, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6973/10000, Loss: 0.7488, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6974/10000, Loss: 0.7488, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6975/10000, Loss: 0.7487, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6976/10000, Loss: 0.7487, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6977/10000, Loss: 0.7487, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6978/10000, Loss: 0.7487, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6979/10000, Loss: 0.7487, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6980/10000, Loss: 0.7486, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6981/10000, Loss: 0.7486, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6982/10000, Loss: 0.7486, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6983/10000, Loss: 0.7486, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6984/10000, Loss: 0.7485, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6985/10000, Loss: 0.7485, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6986/10000, Loss: 0.7485, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6987/10000, Loss: 0.7485, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6988/10000, Loss: 0.7484, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6989/10000, Loss: 0.7484, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6990/10000, Loss: 0.7484, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6991/10000, Loss: 0.7484, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6992/10000, Loss: 0.7483, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6993/10000, Loss: 0.7483, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6994/10000, Loss: 0.7483, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6995/10000, Loss: 0.7483, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6996/10000, Loss: 0.7483, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6997/10000, Loss: 0.7482, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6998/10000, Loss: 0.7482, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6999/10000, Loss: 0.7482, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7000/10000, Loss: 0.7482, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7001/10000, Loss: 0.7481, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7002/10000, Loss: 0.7481, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7003/10000, Loss: 0.7481, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7004/10000, Loss: 0.7481, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7005/10000, Loss: 0.7480, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7006/10000, Loss: 0.7480, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7007/10000, Loss: 0.7480, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7008/10000, Loss: 0.7480, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7009/10000, Loss: 0.7479, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7010/10000, Loss: 0.7479, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7011/10000, Loss: 0.7479, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7012/10000, Loss: 0.7479, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7013/10000, Loss: 0.7478, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7014/10000, Loss: 0.7478, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7015/10000, Loss: 0.7478, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7016/10000, Loss: 0.7478, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7017/10000, Loss: 0.7478, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7018/10000, Loss: 0.7477, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7019/10000, Loss: 0.7477, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7020/10000, Loss: 0.7477, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7021/10000, Loss: 0.7477, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7022/10000, Loss: 0.7476, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7023/10000, Loss: 0.7476, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7024/10000, Loss: 0.7476, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7025/10000, Loss: 0.7476, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7026/10000, Loss: 0.7475, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7027/10000, Loss: 0.7475, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7028/10000, Loss: 0.7475, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7029/10000, Loss: 0.7475, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7030/10000, Loss: 0.7474, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7031/10000, Loss: 0.7474, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7032/10000, Loss: 0.7474, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7033/10000, Loss: 0.7474, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7034/10000, Loss: 0.7474, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7035/10000, Loss: 0.7473, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7036/10000, Loss: 0.7473, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7037/10000, Loss: 0.7473, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7038/10000, Loss: 0.7473, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7039/10000, Loss: 0.7472, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7040/10000, Loss: 0.7472, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7041/10000, Loss: 0.7472, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7042/10000, Loss: 0.7472, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7043/10000, Loss: 0.7471, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7044/10000, Loss: 0.7471, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7045/10000, Loss: 0.7471, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7046/10000, Loss: 0.7471, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7047/10000, Loss: 0.7471, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7048/10000, Loss: 0.7470, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7049/10000, Loss: 0.7470, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7050/10000, Loss: 0.7470, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7051/10000, Loss: 0.7470, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7052/10000, Loss: 0.7469, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7053/10000, Loss: 0.7469, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7054/10000, Loss: 0.7469, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7055/10000, Loss: 0.7469, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7056/10000, Loss: 0.7468, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7057/10000, Loss: 0.7468, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7058/10000, Loss: 0.7468, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7059/10000, Loss: 0.7468, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7060/10000, Loss: 0.7467, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7061/10000, Loss: 0.7467, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7062/10000, Loss: 0.7467, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7063/10000, Loss: 0.7467, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7064/10000, Loss: 0.7467, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7065/10000, Loss: 0.7466, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7066/10000, Loss: 0.7466, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7067/10000, Loss: 0.7466, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7068/10000, Loss: 0.7466, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7069/10000, Loss: 0.7465, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7070/10000, Loss: 0.7465, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7071/10000, Loss: 0.7465, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7072/10000, Loss: 0.7465, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7073/10000, Loss: 0.7464, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7074/10000, Loss: 0.7464, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7075/10000, Loss: 0.7464, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7076/10000, Loss: 0.7464, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7077/10000, Loss: 0.7464, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7078/10000, Loss: 0.7463, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7079/10000, Loss: 0.7463, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7080/10000, Loss: 0.7463, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7081/10000, Loss: 0.7463, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7082/10000, Loss: 0.7462, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7083/10000, Loss: 0.7462, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7084/10000, Loss: 0.7462, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7085/10000, Loss: 0.7462, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7086/10000, Loss: 0.7461, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7087/10000, Loss: 0.7461, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7088/10000, Loss: 0.7461, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7089/10000, Loss: 0.7461, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7090/10000, Loss: 0.7460, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7091/10000, Loss: 0.7460, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7092/10000, Loss: 0.7460, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7093/10000, Loss: 0.7460, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7094/10000, Loss: 0.7460, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7095/10000, Loss: 0.7459, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7096/10000, Loss: 0.7459, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7097/10000, Loss: 0.7459, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7098/10000, Loss: 0.7459, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7099/10000, Loss: 0.7458, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7100/10000, Loss: 0.7458, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7101/10000, Loss: 0.7458, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7102/10000, Loss: 0.7458, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7103/10000, Loss: 0.7457, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7104/10000, Loss: 0.7457, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7105/10000, Loss: 0.7457, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7106/10000, Loss: 0.7457, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7107/10000, Loss: 0.7457, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7108/10000, Loss: 0.7456, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7109/10000, Loss: 0.7456, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7110/10000, Loss: 0.7456, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7111/10000, Loss: 0.7456, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7112/10000, Loss: 0.7455, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7113/10000, Loss: 0.7455, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7114/10000, Loss: 0.7455, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7115/10000, Loss: 0.7455, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7116/10000, Loss: 0.7454, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7117/10000, Loss: 0.7454, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7118/10000, Loss: 0.7454, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7119/10000, Loss: 0.7454, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7120/10000, Loss: 0.7454, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7121/10000, Loss: 0.7453, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7122/10000, Loss: 0.7453, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7123/10000, Loss: 0.7453, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7124/10000, Loss: 0.7453, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7125/10000, Loss: 0.7452, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7126/10000, Loss: 0.7452, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7127/10000, Loss: 0.7452, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7128/10000, Loss: 0.7452, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7129/10000, Loss: 0.7451, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7130/10000, Loss: 0.7451, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7131/10000, Loss: 0.7451, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7132/10000, Loss: 0.7451, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7133/10000, Loss: 0.7451, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7134/10000, Loss: 0.7450, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7135/10000, Loss: 0.7450, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7136/10000, Loss: 0.7450, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7137/10000, Loss: 0.7450, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7138/10000, Loss: 0.7449, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7139/10000, Loss: 0.7449, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7140/10000, Loss: 0.7449, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7141/10000, Loss: 0.7449, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7142/10000, Loss: 0.7449, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7143/10000, Loss: 0.7448, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7144/10000, Loss: 0.7448, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7145/10000, Loss: 0.7448, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7146/10000, Loss: 0.7448, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7147/10000, Loss: 0.7447, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7148/10000, Loss: 0.7447, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7149/10000, Loss: 0.7447, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7150/10000, Loss: 0.7447, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7151/10000, Loss: 0.7446, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7152/10000, Loss: 0.7446, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7153/10000, Loss: 0.7446, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7154/10000, Loss: 0.7446, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7155/10000, Loss: 0.7446, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7156/10000, Loss: 0.7445, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7157/10000, Loss: 0.7445, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7158/10000, Loss: 0.7445, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7159/10000, Loss: 0.7445, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7160/10000, Loss: 0.7444, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7161/10000, Loss: 0.7444, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7162/10000, Loss: 0.7444, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7163/10000, Loss: 0.7444, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7164/10000, Loss: 0.7443, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7165/10000, Loss: 0.7443, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7166/10000, Loss: 0.7443, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7167/10000, Loss: 0.7443, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7168/10000, Loss: 0.7443, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7169/10000, Loss: 0.7442, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7170/10000, Loss: 0.7442, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7171/10000, Loss: 0.7442, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7172/10000, Loss: 0.7442, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7173/10000, Loss: 0.7441, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7174/10000, Loss: 0.7441, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7175/10000, Loss: 0.7441, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7176/10000, Loss: 0.7441, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7177/10000, Loss: 0.7441, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7178/10000, Loss: 0.7440, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7179/10000, Loss: 0.7440, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7180/10000, Loss: 0.7440, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7181/10000, Loss: 0.7440, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7182/10000, Loss: 0.7439, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7183/10000, Loss: 0.7439, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7184/10000, Loss: 0.7439, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7185/10000, Loss: 0.7439, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7186/10000, Loss: 0.7438, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7187/10000, Loss: 0.7438, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7188/10000, Loss: 0.7438, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7189/10000, Loss: 0.7438, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7190/10000, Loss: 0.7438, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7191/10000, Loss: 0.7437, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7192/10000, Loss: 0.7437, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7193/10000, Loss: 0.7437, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7194/10000, Loss: 0.7437, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7195/10000, Loss: 0.7436, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7196/10000, Loss: 0.7436, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7197/10000, Loss: 0.7436, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7198/10000, Loss: 0.7436, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7199/10000, Loss: 0.7436, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7200/10000, Loss: 0.7435, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7201/10000, Loss: 0.7435, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7202/10000, Loss: 0.7435, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7203/10000, Loss: 0.7435, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7204/10000, Loss: 0.7434, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7205/10000, Loss: 0.7434, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7206/10000, Loss: 0.7434, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7207/10000, Loss: 0.7434, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7208/10000, Loss: 0.7434, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7209/10000, Loss: 0.7433, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7210/10000, Loss: 0.7433, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7211/10000, Loss: 0.7433, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7212/10000, Loss: 0.7433, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7213/10000, Loss: 0.7432, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7214/10000, Loss: 0.7432, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7215/10000, Loss: 0.7432, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7216/10000, Loss: 0.7432, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7217/10000, Loss: 0.7431, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7218/10000, Loss: 0.7431, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7219/10000, Loss: 0.7431, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7220/10000, Loss: 0.7431, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7221/10000, Loss: 0.7431, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7222/10000, Loss: 0.7430, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7223/10000, Loss: 0.7430, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7224/10000, Loss: 0.7430, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7225/10000, Loss: 0.7430, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7226/10000, Loss: 0.7429, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7227/10000, Loss: 0.7429, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7228/10000, Loss: 0.7429, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7229/10000, Loss: 0.7429, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7230/10000, Loss: 0.7429, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7231/10000, Loss: 0.7428, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7232/10000, Loss: 0.7428, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7233/10000, Loss: 0.7428, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7234/10000, Loss: 0.7428, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7235/10000, Loss: 0.7427, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7236/10000, Loss: 0.7427, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7237/10000, Loss: 0.7427, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7238/10000, Loss: 0.7427, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7239/10000, Loss: 0.7427, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7240/10000, Loss: 0.7426, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7241/10000, Loss: 0.7426, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7242/10000, Loss: 0.7426, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7243/10000, Loss: 0.7426, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7244/10000, Loss: 0.7425, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7245/10000, Loss: 0.7425, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7246/10000, Loss: 0.7425, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7247/10000, Loss: 0.7425, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7248/10000, Loss: 0.7425, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7249/10000, Loss: 0.7424, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7250/10000, Loss: 0.7424, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7251/10000, Loss: 0.7424, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7252/10000, Loss: 0.7424, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7253/10000, Loss: 0.7423, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7254/10000, Loss: 0.7423, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7255/10000, Loss: 0.7423, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7256/10000, Loss: 0.7423, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7257/10000, Loss: 0.7422, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7258/10000, Loss: 0.7422, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7259/10000, Loss: 0.7422, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7260/10000, Loss: 0.7422, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7261/10000, Loss: 0.7422, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7262/10000, Loss: 0.7421, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7263/10000, Loss: 0.7421, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7264/10000, Loss: 0.7421, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7265/10000, Loss: 0.7421, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7266/10000, Loss: 0.7420, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7267/10000, Loss: 0.7420, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7268/10000, Loss: 0.7420, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7269/10000, Loss: 0.7420, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7270/10000, Loss: 0.7420, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7271/10000, Loss: 0.7419, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7272/10000, Loss: 0.7419, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7273/10000, Loss: 0.7419, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7274/10000, Loss: 0.7419, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7275/10000, Loss: 0.7418, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7276/10000, Loss: 0.7418, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7277/10000, Loss: 0.7418, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7278/10000, Loss: 0.7418, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7279/10000, Loss: 0.7418, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7280/10000, Loss: 0.7417, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7281/10000, Loss: 0.7417, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7282/10000, Loss: 0.7417, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7283/10000, Loss: 0.7417, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7284/10000, Loss: 0.7416, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7285/10000, Loss: 0.7416, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7286/10000, Loss: 0.7416, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7287/10000, Loss: 0.7416, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7288/10000, Loss: 0.7416, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7289/10000, Loss: 0.7415, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7290/10000, Loss: 0.7415, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7291/10000, Loss: 0.7415, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7292/10000, Loss: 0.7415, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7293/10000, Loss: 0.7414, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7294/10000, Loss: 0.7414, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7295/10000, Loss: 0.7414, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7296/10000, Loss: 0.7414, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7297/10000, Loss: 0.7414, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7298/10000, Loss: 0.7413, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7299/10000, Loss: 0.7413, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7300/10000, Loss: 0.7413, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7301/10000, Loss: 0.7413, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7302/10000, Loss: 0.7412, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7303/10000, Loss: 0.7412, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7304/10000, Loss: 0.7412, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7305/10000, Loss: 0.7412, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7306/10000, Loss: 0.7412, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7307/10000, Loss: 0.7411, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7308/10000, Loss: 0.7411, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7309/10000, Loss: 0.7411, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7310/10000, Loss: 0.7411, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7311/10000, Loss: 0.7410, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7312/10000, Loss: 0.7410, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7313/10000, Loss: 0.7410, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7314/10000, Loss: 0.7410, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7315/10000, Loss: 0.7410, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7316/10000, Loss: 0.7409, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7317/10000, Loss: 0.7409, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7318/10000, Loss: 0.7409, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7319/10000, Loss: 0.7409, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7320/10000, Loss: 0.7409, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7321/10000, Loss: 0.7408, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7322/10000, Loss: 0.7408, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7323/10000, Loss: 0.7408, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7324/10000, Loss: 0.7408, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7325/10000, Loss: 0.7407, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7326/10000, Loss: 0.7407, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7327/10000, Loss: 0.7407, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7328/10000, Loss: 0.7407, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7329/10000, Loss: 0.7407, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7330/10000, Loss: 0.7406, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7331/10000, Loss: 0.7406, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7332/10000, Loss: 0.7406, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7333/10000, Loss: 0.7406, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7334/10000, Loss: 0.7405, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7335/10000, Loss: 0.7405, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7336/10000, Loss: 0.7405, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7337/10000, Loss: 0.7405, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7338/10000, Loss: 0.7405, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7339/10000, Loss: 0.7404, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7340/10000, Loss: 0.7404, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7341/10000, Loss: 0.7404, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7342/10000, Loss: 0.7404, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7343/10000, Loss: 0.7403, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7344/10000, Loss: 0.7403, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7345/10000, Loss: 0.7403, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7346/10000, Loss: 0.7403, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7347/10000, Loss: 0.7403, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7348/10000, Loss: 0.7402, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7349/10000, Loss: 0.7402, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7350/10000, Loss: 0.7402, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7351/10000, Loss: 0.7402, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7352/10000, Loss: 0.7401, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7353/10000, Loss: 0.7401, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7354/10000, Loss: 0.7401, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7355/10000, Loss: 0.7401, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7356/10000, Loss: 0.7401, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7357/10000, Loss: 0.7400, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7358/10000, Loss: 0.7400, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7359/10000, Loss: 0.7400, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7360/10000, Loss: 0.7400, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7361/10000, Loss: 0.7399, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7362/10000, Loss: 0.7399, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7363/10000, Loss: 0.7399, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7364/10000, Loss: 0.7399, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7365/10000, Loss: 0.7399, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7366/10000, Loss: 0.7398, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7367/10000, Loss: 0.7398, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7368/10000, Loss: 0.7398, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7369/10000, Loss: 0.7398, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7370/10000, Loss: 0.7398, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7371/10000, Loss: 0.7397, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7372/10000, Loss: 0.7397, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7373/10000, Loss: 0.7397, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7374/10000, Loss: 0.7397, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7375/10000, Loss: 0.7396, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7376/10000, Loss: 0.7396, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7377/10000, Loss: 0.7396, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7378/10000, Loss: 0.7396, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7379/10000, Loss: 0.7396, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7380/10000, Loss: 0.7395, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7381/10000, Loss: 0.7395, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7382/10000, Loss: 0.7395, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7383/10000, Loss: 0.7395, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7384/10000, Loss: 0.7394, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7385/10000, Loss: 0.7394, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7386/10000, Loss: 0.7394, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7387/10000, Loss: 0.7394, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7388/10000, Loss: 0.7394, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7389/10000, Loss: 0.7393, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7390/10000, Loss: 0.7393, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7391/10000, Loss: 0.7393, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7392/10000, Loss: 0.7393, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7393/10000, Loss: 0.7393, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7394/10000, Loss: 0.7392, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7395/10000, Loss: 0.7392, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7396/10000, Loss: 0.7392, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7397/10000, Loss: 0.7392, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7398/10000, Loss: 0.7391, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7399/10000, Loss: 0.7391, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7400/10000, Loss: 0.7391, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7401/10000, Loss: 0.7391, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7402/10000, Loss: 0.7391, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7403/10000, Loss: 0.7390, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7404/10000, Loss: 0.7390, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7405/10000, Loss: 0.7390, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7406/10000, Loss: 0.7390, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7407/10000, Loss: 0.7389, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7408/10000, Loss: 0.7389, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7409/10000, Loss: 0.7389, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7410/10000, Loss: 0.7389, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7411/10000, Loss: 0.7389, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7412/10000, Loss: 0.7388, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7413/10000, Loss: 0.7388, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7414/10000, Loss: 0.7388, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7415/10000, Loss: 0.7388, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7416/10000, Loss: 0.7388, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7417/10000, Loss: 0.7387, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7418/10000, Loss: 0.7387, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7419/10000, Loss: 0.7387, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7420/10000, Loss: 0.7387, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7421/10000, Loss: 0.7386, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7422/10000, Loss: 0.7386, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7423/10000, Loss: 0.7386, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7424/10000, Loss: 0.7386, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7425/10000, Loss: 0.7386, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7426/10000, Loss: 0.7385, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7427/10000, Loss: 0.7385, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7428/10000, Loss: 0.7385, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7429/10000, Loss: 0.7385, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7430/10000, Loss: 0.7384, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7431/10000, Loss: 0.7384, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7432/10000, Loss: 0.7384, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7433/10000, Loss: 0.7384, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7434/10000, Loss: 0.7384, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7435/10000, Loss: 0.7383, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7436/10000, Loss: 0.7383, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7437/10000, Loss: 0.7383, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7438/10000, Loss: 0.7383, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7439/10000, Loss: 0.7383, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7440/10000, Loss: 0.7382, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7441/10000, Loss: 0.7382, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7442/10000, Loss: 0.7382, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7443/10000, Loss: 0.7382, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7444/10000, Loss: 0.7381, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7445/10000, Loss: 0.7381, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7446/10000, Loss: 0.7381, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7447/10000, Loss: 0.7381, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7448/10000, Loss: 0.7381, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7449/10000, Loss: 0.7380, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7450/10000, Loss: 0.7380, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7451/10000, Loss: 0.7380, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7452/10000, Loss: 0.7380, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7453/10000, Loss: 0.7380, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7454/10000, Loss: 0.7379, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7455/10000, Loss: 0.7379, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7456/10000, Loss: 0.7379, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7457/10000, Loss: 0.7379, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7458/10000, Loss: 0.7378, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7459/10000, Loss: 0.7378, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7460/10000, Loss: 0.7378, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7461/10000, Loss: 0.7378, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7462/10000, Loss: 0.7378, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7463/10000, Loss: 0.7377, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7464/10000, Loss: 0.7377, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7465/10000, Loss: 0.7377, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7466/10000, Loss: 0.7377, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7467/10000, Loss: 0.7377, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7468/10000, Loss: 0.7376, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7469/10000, Loss: 0.7376, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7470/10000, Loss: 0.7376, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7471/10000, Loss: 0.7376, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7472/10000, Loss: 0.7375, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7473/10000, Loss: 0.7375, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7474/10000, Loss: 0.7375, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7475/10000, Loss: 0.7375, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7476/10000, Loss: 0.7375, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7477/10000, Loss: 0.7374, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7478/10000, Loss: 0.7374, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7479/10000, Loss: 0.7374, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7480/10000, Loss: 0.7374, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7481/10000, Loss: 0.7374, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7482/10000, Loss: 0.7373, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7483/10000, Loss: 0.7373, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7484/10000, Loss: 0.7373, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7485/10000, Loss: 0.7373, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7486/10000, Loss: 0.7372, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7487/10000, Loss: 0.7372, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7488/10000, Loss: 0.7372, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7489/10000, Loss: 0.7372, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7490/10000, Loss: 0.7372, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7491/10000, Loss: 0.7371, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7492/10000, Loss: 0.7371, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7493/10000, Loss: 0.7371, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7494/10000, Loss: 0.7371, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7495/10000, Loss: 0.7371, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7496/10000, Loss: 0.7370, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7497/10000, Loss: 0.7370, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7498/10000, Loss: 0.7370, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7499/10000, Loss: 0.7370, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7500/10000, Loss: 0.7369, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7501/10000, Loss: 0.7369, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7502/10000, Loss: 0.7369, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7503/10000, Loss: 0.7369, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7504/10000, Loss: 0.7369, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7505/10000, Loss: 0.7368, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7506/10000, Loss: 0.7368, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7507/10000, Loss: 0.7368, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7508/10000, Loss: 0.7368, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7509/10000, Loss: 0.7368, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7510/10000, Loss: 0.7367, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7511/10000, Loss: 0.7367, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7512/10000, Loss: 0.7367, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7513/10000, Loss: 0.7367, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7514/10000, Loss: 0.7366, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7515/10000, Loss: 0.7366, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7516/10000, Loss: 0.7366, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7517/10000, Loss: 0.7366, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7518/10000, Loss: 0.7366, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7519/10000, Loss: 0.7365, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7520/10000, Loss: 0.7365, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7521/10000, Loss: 0.7365, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7522/10000, Loss: 0.7365, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7523/10000, Loss: 0.7365, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7524/10000, Loss: 0.7364, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7525/10000, Loss: 0.7364, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7526/10000, Loss: 0.7364, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7527/10000, Loss: 0.7364, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7528/10000, Loss: 0.7364, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7529/10000, Loss: 0.7363, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7530/10000, Loss: 0.7363, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7531/10000, Loss: 0.7363, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7532/10000, Loss: 0.7363, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7533/10000, Loss: 0.7362, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7534/10000, Loss: 0.7362, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7535/10000, Loss: 0.7362, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7536/10000, Loss: 0.7362, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7537/10000, Loss: 0.7362, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7538/10000, Loss: 0.7361, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7539/10000, Loss: 0.7361, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7540/10000, Loss: 0.7361, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7541/10000, Loss: 0.7361, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7542/10000, Loss: 0.7361, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7543/10000, Loss: 0.7360, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7544/10000, Loss: 0.7360, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7545/10000, Loss: 0.7360, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7546/10000, Loss: 0.7360, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7547/10000, Loss: 0.7359, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7548/10000, Loss: 0.7359, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7549/10000, Loss: 0.7359, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7550/10000, Loss: 0.7359, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7551/10000, Loss: 0.7359, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7552/10000, Loss: 0.7358, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7553/10000, Loss: 0.7358, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7554/10000, Loss: 0.7358, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7555/10000, Loss: 0.7358, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7556/10000, Loss: 0.7358, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7557/10000, Loss: 0.7357, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7558/10000, Loss: 0.7357, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7559/10000, Loss: 0.7357, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7560/10000, Loss: 0.7357, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7561/10000, Loss: 0.7357, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7562/10000, Loss: 0.7356, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7563/10000, Loss: 0.7356, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7564/10000, Loss: 0.7356, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7565/10000, Loss: 0.7356, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7566/10000, Loss: 0.7355, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7567/10000, Loss: 0.7355, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7568/10000, Loss: 0.7355, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7569/10000, Loss: 0.7355, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7570/10000, Loss: 0.7355, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7571/10000, Loss: 0.7354, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7572/10000, Loss: 0.7354, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7573/10000, Loss: 0.7354, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7574/10000, Loss: 0.7354, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7575/10000, Loss: 0.7354, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7576/10000, Loss: 0.7353, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7577/10000, Loss: 0.7353, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7578/10000, Loss: 0.7353, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7579/10000, Loss: 0.7353, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7580/10000, Loss: 0.7353, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7581/10000, Loss: 0.7352, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7582/10000, Loss: 0.7352, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7583/10000, Loss: 0.7352, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7584/10000, Loss: 0.7352, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7585/10000, Loss: 0.7351, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7586/10000, Loss: 0.7351, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7587/10000, Loss: 0.7351, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7588/10000, Loss: 0.7351, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7589/10000, Loss: 0.7351, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7590/10000, Loss: 0.7350, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7591/10000, Loss: 0.7350, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7592/10000, Loss: 0.7350, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7593/10000, Loss: 0.7350, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7594/10000, Loss: 0.7350, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7595/10000, Loss: 0.7349, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7596/10000, Loss: 0.7349, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7597/10000, Loss: 0.7349, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7598/10000, Loss: 0.7349, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7599/10000, Loss: 0.7349, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7600/10000, Loss: 0.7348, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7601/10000, Loss: 0.7348, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7602/10000, Loss: 0.7348, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7603/10000, Loss: 0.7348, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7604/10000, Loss: 0.7347, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7605/10000, Loss: 0.7347, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7606/10000, Loss: 0.7347, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7607/10000, Loss: 0.7347, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7608/10000, Loss: 0.7347, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7609/10000, Loss: 0.7346, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7610/10000, Loss: 0.7346, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7611/10000, Loss: 0.7346, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7612/10000, Loss: 0.7346, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7613/10000, Loss: 0.7346, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7614/10000, Loss: 0.7345, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7615/10000, Loss: 0.7345, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7616/10000, Loss: 0.7345, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7617/10000, Loss: 0.7345, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7618/10000, Loss: 0.7345, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7619/10000, Loss: 0.7344, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7620/10000, Loss: 0.7344, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7621/10000, Loss: 0.7344, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7622/10000, Loss: 0.7344, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7623/10000, Loss: 0.7344, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7624/10000, Loss: 0.7343, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7625/10000, Loss: 0.7343, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7626/10000, Loss: 0.7343, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7627/10000, Loss: 0.7343, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7628/10000, Loss: 0.7342, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7629/10000, Loss: 0.7342, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7630/10000, Loss: 0.7342, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7631/10000, Loss: 0.7342, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7632/10000, Loss: 0.7342, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7633/10000, Loss: 0.7341, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7634/10000, Loss: 0.7341, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7635/10000, Loss: 0.7341, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7636/10000, Loss: 0.7341, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7637/10000, Loss: 0.7341, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7638/10000, Loss: 0.7340, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7639/10000, Loss: 0.7340, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7640/10000, Loss: 0.7340, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7641/10000, Loss: 0.7340, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7642/10000, Loss: 0.7340, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7643/10000, Loss: 0.7339, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7644/10000, Loss: 0.7339, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7645/10000, Loss: 0.7339, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7646/10000, Loss: 0.7339, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7647/10000, Loss: 0.7339, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7648/10000, Loss: 0.7338, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7649/10000, Loss: 0.7338, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7650/10000, Loss: 0.7338, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7651/10000, Loss: 0.7338, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7652/10000, Loss: 0.7337, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7653/10000, Loss: 0.7337, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7654/10000, Loss: 0.7337, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7655/10000, Loss: 0.7337, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7656/10000, Loss: 0.7337, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7657/10000, Loss: 0.7336, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7658/10000, Loss: 0.7336, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7659/10000, Loss: 0.7336, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7660/10000, Loss: 0.7336, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7661/10000, Loss: 0.7336, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7662/10000, Loss: 0.7335, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7663/10000, Loss: 0.7335, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7664/10000, Loss: 0.7335, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7665/10000, Loss: 0.7335, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7666/10000, Loss: 0.7335, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7667/10000, Loss: 0.7334, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7668/10000, Loss: 0.7334, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7669/10000, Loss: 0.7334, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7670/10000, Loss: 0.7334, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7671/10000, Loss: 0.7334, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7672/10000, Loss: 0.7333, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7673/10000, Loss: 0.7333, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7674/10000, Loss: 0.7333, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7675/10000, Loss: 0.7333, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7676/10000, Loss: 0.7332, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7677/10000, Loss: 0.7332, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7678/10000, Loss: 0.7332, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7679/10000, Loss: 0.7332, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7680/10000, Loss: 0.7332, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7681/10000, Loss: 0.7331, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7682/10000, Loss: 0.7331, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7683/10000, Loss: 0.7331, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7684/10000, Loss: 0.7331, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7685/10000, Loss: 0.7331, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7686/10000, Loss: 0.7330, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7687/10000, Loss: 0.7330, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7688/10000, Loss: 0.7330, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7689/10000, Loss: 0.7330, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7690/10000, Loss: 0.7330, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7691/10000, Loss: 0.7329, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7692/10000, Loss: 0.7329, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7693/10000, Loss: 0.7329, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7694/10000, Loss: 0.7329, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7695/10000, Loss: 0.7329, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7696/10000, Loss: 0.7328, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7697/10000, Loss: 0.7328, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7698/10000, Loss: 0.7328, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7699/10000, Loss: 0.7328, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7700/10000, Loss: 0.7328, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7701/10000, Loss: 0.7327, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7702/10000, Loss: 0.7327, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7703/10000, Loss: 0.7327, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7704/10000, Loss: 0.7327, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7705/10000, Loss: 0.7327, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7706/10000, Loss: 0.7326, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7707/10000, Loss: 0.7326, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7708/10000, Loss: 0.7326, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7709/10000, Loss: 0.7326, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7710/10000, Loss: 0.7325, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7711/10000, Loss: 0.7325, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7712/10000, Loss: 0.7325, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7713/10000, Loss: 0.7325, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7714/10000, Loss: 0.7325, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7715/10000, Loss: 0.7324, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7716/10000, Loss: 0.7324, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7717/10000, Loss: 0.7324, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7718/10000, Loss: 0.7324, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7719/10000, Loss: 0.7324, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7720/10000, Loss: 0.7323, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7721/10000, Loss: 0.7323, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7722/10000, Loss: 0.7323, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7723/10000, Loss: 0.7323, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7724/10000, Loss: 0.7323, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7725/10000, Loss: 0.7322, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7726/10000, Loss: 0.7322, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7727/10000, Loss: 0.7322, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7728/10000, Loss: 0.7322, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7729/10000, Loss: 0.7322, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7730/10000, Loss: 0.7321, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7731/10000, Loss: 0.7321, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7732/10000, Loss: 0.7321, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7733/10000, Loss: 0.7321, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7734/10000, Loss: 0.7321, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7735/10000, Loss: 0.7320, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7736/10000, Loss: 0.7320, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7737/10000, Loss: 0.7320, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7738/10000, Loss: 0.7320, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7739/10000, Loss: 0.7320, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7740/10000, Loss: 0.7319, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7741/10000, Loss: 0.7319, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7742/10000, Loss: 0.7319, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7743/10000, Loss: 0.7319, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7744/10000, Loss: 0.7319, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7745/10000, Loss: 0.7318, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7746/10000, Loss: 0.7318, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7747/10000, Loss: 0.7318, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7748/10000, Loss: 0.7318, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7749/10000, Loss: 0.7317, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7750/10000, Loss: 0.7317, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7751/10000, Loss: 0.7317, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7752/10000, Loss: 0.7317, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7753/10000, Loss: 0.7317, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7754/10000, Loss: 0.7316, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7755/10000, Loss: 0.7316, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7756/10000, Loss: 0.7316, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7757/10000, Loss: 0.7316, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7758/10000, Loss: 0.7316, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7759/10000, Loss: 0.7315, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7760/10000, Loss: 0.7315, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7761/10000, Loss: 0.7315, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7762/10000, Loss: 0.7315, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7763/10000, Loss: 0.7315, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7764/10000, Loss: 0.7314, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7765/10000, Loss: 0.7314, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7766/10000, Loss: 0.7314, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7767/10000, Loss: 0.7314, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7768/10000, Loss: 0.7314, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7769/10000, Loss: 0.7313, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7770/10000, Loss: 0.7313, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7771/10000, Loss: 0.7313, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7772/10000, Loss: 0.7313, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7773/10000, Loss: 0.7313, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7774/10000, Loss: 0.7312, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7775/10000, Loss: 0.7312, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7776/10000, Loss: 0.7312, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7777/10000, Loss: 0.7312, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7778/10000, Loss: 0.7312, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7779/10000, Loss: 0.7311, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7780/10000, Loss: 0.7311, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7781/10000, Loss: 0.7311, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7782/10000, Loss: 0.7311, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7783/10000, Loss: 0.7311, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7784/10000, Loss: 0.7310, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7785/10000, Loss: 0.7310, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7786/10000, Loss: 0.7310, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7787/10000, Loss: 0.7310, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7788/10000, Loss: 0.7310, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7789/10000, Loss: 0.7309, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7790/10000, Loss: 0.7309, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7791/10000, Loss: 0.7309, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7792/10000, Loss: 0.7309, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7793/10000, Loss: 0.7309, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7794/10000, Loss: 0.7308, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7795/10000, Loss: 0.7308, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7796/10000, Loss: 0.7308, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7797/10000, Loss: 0.7308, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7798/10000, Loss: 0.7308, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7799/10000, Loss: 0.7307, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7800/10000, Loss: 0.7307, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7801/10000, Loss: 0.7307, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7802/10000, Loss: 0.7307, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7803/10000, Loss: 0.7306, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7804/10000, Loss: 0.7306, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7805/10000, Loss: 0.7306, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7806/10000, Loss: 0.7306, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7807/10000, Loss: 0.7306, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7808/10000, Loss: 0.7305, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7809/10000, Loss: 0.7305, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7810/10000, Loss: 0.7305, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7811/10000, Loss: 0.7305, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7812/10000, Loss: 0.7305, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7813/10000, Loss: 0.7304, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7814/10000, Loss: 0.7304, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7815/10000, Loss: 0.7304, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7816/10000, Loss: 0.7304, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7817/10000, Loss: 0.7304, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7818/10000, Loss: 0.7303, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7819/10000, Loss: 0.7303, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7820/10000, Loss: 0.7303, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7821/10000, Loss: 0.7303, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7822/10000, Loss: 0.7303, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7823/10000, Loss: 0.7302, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7824/10000, Loss: 0.7302, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7825/10000, Loss: 0.7302, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7826/10000, Loss: 0.7302, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7827/10000, Loss: 0.7302, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7828/10000, Loss: 0.7301, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7829/10000, Loss: 0.7301, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7830/10000, Loss: 0.7301, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7831/10000, Loss: 0.7301, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7832/10000, Loss: 0.7301, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7833/10000, Loss: 0.7300, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7834/10000, Loss: 0.7300, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7835/10000, Loss: 0.7300, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7836/10000, Loss: 0.7300, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7837/10000, Loss: 0.7300, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7838/10000, Loss: 0.7299, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7839/10000, Loss: 0.7299, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7840/10000, Loss: 0.7299, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7841/10000, Loss: 0.7299, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7842/10000, Loss: 0.7299, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7843/10000, Loss: 0.7298, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7844/10000, Loss: 0.7298, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7845/10000, Loss: 0.7298, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7846/10000, Loss: 0.7298, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7847/10000, Loss: 0.7298, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7848/10000, Loss: 0.7297, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7849/10000, Loss: 0.7297, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7850/10000, Loss: 0.7297, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7851/10000, Loss: 0.7297, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7852/10000, Loss: 0.7297, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7853/10000, Loss: 0.7296, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7854/10000, Loss: 0.7296, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7855/10000, Loss: 0.7296, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7856/10000, Loss: 0.7296, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7857/10000, Loss: 0.7296, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7858/10000, Loss: 0.7295, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7859/10000, Loss: 0.7295, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7860/10000, Loss: 0.7295, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7861/10000, Loss: 0.7295, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7862/10000, Loss: 0.7295, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7863/10000, Loss: 0.7294, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7864/10000, Loss: 0.7294, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7865/10000, Loss: 0.7294, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7866/10000, Loss: 0.7294, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7867/10000, Loss: 0.7294, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7868/10000, Loss: 0.7293, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7869/10000, Loss: 0.7293, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7870/10000, Loss: 0.7293, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7871/10000, Loss: 0.7293, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7872/10000, Loss: 0.7293, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7873/10000, Loss: 0.7292, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7874/10000, Loss: 0.7292, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7875/10000, Loss: 0.7292, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7876/10000, Loss: 0.7292, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7877/10000, Loss: 0.7292, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7878/10000, Loss: 0.7291, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7879/10000, Loss: 0.7291, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7880/10000, Loss: 0.7291, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7881/10000, Loss: 0.7291, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7882/10000, Loss: 0.7291, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7883/10000, Loss: 0.7290, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7884/10000, Loss: 0.7290, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7885/10000, Loss: 0.7290, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7886/10000, Loss: 0.7290, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7887/10000, Loss: 0.7290, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7888/10000, Loss: 0.7289, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7889/10000, Loss: 0.7289, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7890/10000, Loss: 0.7289, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7891/10000, Loss: 0.7289, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7892/10000, Loss: 0.7289, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7893/10000, Loss: 0.7288, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7894/10000, Loss: 0.7288, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7895/10000, Loss: 0.7288, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7896/10000, Loss: 0.7288, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7897/10000, Loss: 0.7288, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7898/10000, Loss: 0.7287, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7899/10000, Loss: 0.7287, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7900/10000, Loss: 0.7287, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7901/10000, Loss: 0.7287, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7902/10000, Loss: 0.7287, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7903/10000, Loss: 0.7286, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7904/10000, Loss: 0.7286, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7905/10000, Loss: 0.7286, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7906/10000, Loss: 0.7286, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7907/10000, Loss: 0.7286, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7908/10000, Loss: 0.7285, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7909/10000, Loss: 0.7285, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7910/10000, Loss: 0.7285, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7911/10000, Loss: 0.7285, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7912/10000, Loss: 0.7285, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7913/10000, Loss: 0.7284, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7914/10000, Loss: 0.7284, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7915/10000, Loss: 0.7284, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7916/10000, Loss: 0.7284, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7917/10000, Loss: 0.7284, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7918/10000, Loss: 0.7283, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7919/10000, Loss: 0.7283, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7920/10000, Loss: 0.7283, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7921/10000, Loss: 0.7283, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7922/10000, Loss: 0.7283, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7923/10000, Loss: 0.7282, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7924/10000, Loss: 0.7282, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7925/10000, Loss: 0.7282, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7926/10000, Loss: 0.7282, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7927/10000, Loss: 0.7282, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7928/10000, Loss: 0.7281, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7929/10000, Loss: 0.7281, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7930/10000, Loss: 0.7281, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7931/10000, Loss: 0.7281, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7932/10000, Loss: 0.7281, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7933/10000, Loss: 0.7280, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7934/10000, Loss: 0.7280, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7935/10000, Loss: 0.7280, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7936/10000, Loss: 0.7280, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7937/10000, Loss: 0.7280, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7938/10000, Loss: 0.7279, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7939/10000, Loss: 0.7279, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7940/10000, Loss: 0.7279, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7941/10000, Loss: 0.7279, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7942/10000, Loss: 0.7279, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7943/10000, Loss: 0.7278, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7944/10000, Loss: 0.7278, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7945/10000, Loss: 0.7278, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7946/10000, Loss: 0.7278, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7947/10000, Loss: 0.7278, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7948/10000, Loss: 0.7277, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7949/10000, Loss: 0.7277, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7950/10000, Loss: 0.7277, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7951/10000, Loss: 0.7277, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7952/10000, Loss: 0.7277, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7953/10000, Loss: 0.7276, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7954/10000, Loss: 0.7276, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7955/10000, Loss: 0.7276, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7956/10000, Loss: 0.7276, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7957/10000, Loss: 0.7276, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7958/10000, Loss: 0.7275, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7959/10000, Loss: 0.7275, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7960/10000, Loss: 0.7275, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7961/10000, Loss: 0.7275, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7962/10000, Loss: 0.7275, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7963/10000, Loss: 0.7274, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7964/10000, Loss: 0.7274, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7965/10000, Loss: 0.7274, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7966/10000, Loss: 0.7274, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7967/10000, Loss: 0.7274, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7968/10000, Loss: 0.7273, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7969/10000, Loss: 0.7273, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7970/10000, Loss: 0.7273, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7971/10000, Loss: 0.7273, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7972/10000, Loss: 0.7273, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7973/10000, Loss: 0.7272, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7974/10000, Loss: 0.7272, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7975/10000, Loss: 0.7272, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7976/10000, Loss: 0.7272, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7977/10000, Loss: 0.7272, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7978/10000, Loss: 0.7272, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7979/10000, Loss: 0.7271, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7980/10000, Loss: 0.7271, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7981/10000, Loss: 0.7271, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7982/10000, Loss: 0.7271, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7983/10000, Loss: 0.7271, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7984/10000, Loss: 0.7270, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7985/10000, Loss: 0.7270, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7986/10000, Loss: 0.7270, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7987/10000, Loss: 0.7270, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7988/10000, Loss: 0.7270, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7989/10000, Loss: 0.7269, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7990/10000, Loss: 0.7269, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7991/10000, Loss: 0.7269, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7992/10000, Loss: 0.7269, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7993/10000, Loss: 0.7269, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7994/10000, Loss: 0.7268, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7995/10000, Loss: 0.7268, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7996/10000, Loss: 0.7268, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7997/10000, Loss: 0.7268, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7998/10000, Loss: 0.7268, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7999/10000, Loss: 0.7267, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8000/10000, Loss: 0.7267, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8001/10000, Loss: 0.7267, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8002/10000, Loss: 0.7267, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8003/10000, Loss: 0.7267, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8004/10000, Loss: 0.7266, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8005/10000, Loss: 0.7266, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8006/10000, Loss: 0.7266, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8007/10000, Loss: 0.7266, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8008/10000, Loss: 0.7266, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8009/10000, Loss: 0.7265, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8010/10000, Loss: 0.7265, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8011/10000, Loss: 0.7265, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8012/10000, Loss: 0.7265, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8013/10000, Loss: 0.7265, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8014/10000, Loss: 0.7264, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8015/10000, Loss: 0.7264, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8016/10000, Loss: 0.7264, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8017/10000, Loss: 0.7264, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8018/10000, Loss: 0.7264, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8019/10000, Loss: 0.7263, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8020/10000, Loss: 0.7263, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8021/10000, Loss: 0.7263, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8022/10000, Loss: 0.7263, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8023/10000, Loss: 0.7263, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8024/10000, Loss: 0.7262, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8025/10000, Loss: 0.7262, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8026/10000, Loss: 0.7262, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8027/10000, Loss: 0.7262, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8028/10000, Loss: 0.7262, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8029/10000, Loss: 0.7261, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8030/10000, Loss: 0.7261, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8031/10000, Loss: 0.7261, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8032/10000, Loss: 0.7261, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8033/10000, Loss: 0.7261, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8034/10000, Loss: 0.7261, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8035/10000, Loss: 0.7260, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8036/10000, Loss: 0.7260, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8037/10000, Loss: 0.7260, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8038/10000, Loss: 0.7260, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8039/10000, Loss: 0.7260, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8040/10000, Loss: 0.7259, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8041/10000, Loss: 0.7259, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8042/10000, Loss: 0.7259, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8043/10000, Loss: 0.7259, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8044/10000, Loss: 0.7259, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8045/10000, Loss: 0.7258, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8046/10000, Loss: 0.7258, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8047/10000, Loss: 0.7258, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8048/10000, Loss: 0.7258, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8049/10000, Loss: 0.7258, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8050/10000, Loss: 0.7257, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8051/10000, Loss: 0.7257, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8052/10000, Loss: 0.7257, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8053/10000, Loss: 0.7257, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8054/10000, Loss: 0.7257, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8055/10000, Loss: 0.7256, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8056/10000, Loss: 0.7256, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8057/10000, Loss: 0.7256, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8058/10000, Loss: 0.7256, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8059/10000, Loss: 0.7256, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8060/10000, Loss: 0.7255, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8061/10000, Loss: 0.7255, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8062/10000, Loss: 0.7255, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8063/10000, Loss: 0.7255, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8064/10000, Loss: 0.7255, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8065/10000, Loss: 0.7254, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8066/10000, Loss: 0.7254, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8067/10000, Loss: 0.7254, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8068/10000, Loss: 0.7254, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8069/10000, Loss: 0.7254, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8070/10000, Loss: 0.7253, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8071/10000, Loss: 0.7253, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8072/10000, Loss: 0.7253, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8073/10000, Loss: 0.7253, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8074/10000, Loss: 0.7253, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8075/10000, Loss: 0.7253, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8076/10000, Loss: 0.7252, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8077/10000, Loss: 0.7252, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8078/10000, Loss: 0.7252, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8079/10000, Loss: 0.7252, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8080/10000, Loss: 0.7252, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8081/10000, Loss: 0.7251, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8082/10000, Loss: 0.7251, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8083/10000, Loss: 0.7251, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8084/10000, Loss: 0.7251, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8085/10000, Loss: 0.7251, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8086/10000, Loss: 0.7250, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8087/10000, Loss: 0.7250, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8088/10000, Loss: 0.7250, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8089/10000, Loss: 0.7250, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8090/10000, Loss: 0.7250, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8091/10000, Loss: 0.7249, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8092/10000, Loss: 0.7249, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8093/10000, Loss: 0.7249, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8094/10000, Loss: 0.7249, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8095/10000, Loss: 0.7249, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8096/10000, Loss: 0.7248, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8097/10000, Loss: 0.7248, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8098/10000, Loss: 0.7248, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8099/10000, Loss: 0.7248, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8100/10000, Loss: 0.7248, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8101/10000, Loss: 0.7247, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8102/10000, Loss: 0.7247, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8103/10000, Loss: 0.7247, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8104/10000, Loss: 0.7247, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8105/10000, Loss: 0.7247, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8106/10000, Loss: 0.7247, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8107/10000, Loss: 0.7246, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8108/10000, Loss: 0.7246, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8109/10000, Loss: 0.7246, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8110/10000, Loss: 0.7246, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8111/10000, Loss: 0.7246, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8112/10000, Loss: 0.7245, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8113/10000, Loss: 0.7245, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8114/10000, Loss: 0.7245, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8115/10000, Loss: 0.7245, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8116/10000, Loss: 0.7245, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8117/10000, Loss: 0.7244, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8118/10000, Loss: 0.7244, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8119/10000, Loss: 0.7244, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8120/10000, Loss: 0.7244, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8121/10000, Loss: 0.7244, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8122/10000, Loss: 0.7243, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8123/10000, Loss: 0.7243, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8124/10000, Loss: 0.7243, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8125/10000, Loss: 0.7243, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8126/10000, Loss: 0.7243, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8127/10000, Loss: 0.7242, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8128/10000, Loss: 0.7242, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8129/10000, Loss: 0.7242, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8130/10000, Loss: 0.7242, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8131/10000, Loss: 0.7242, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8132/10000, Loss: 0.7241, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8133/10000, Loss: 0.7241, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8134/10000, Loss: 0.7241, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8135/10000, Loss: 0.7241, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8136/10000, Loss: 0.7241, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8137/10000, Loss: 0.7241, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8138/10000, Loss: 0.7240, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8139/10000, Loss: 0.7240, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8140/10000, Loss: 0.7240, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8141/10000, Loss: 0.7240, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8142/10000, Loss: 0.7240, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8143/10000, Loss: 0.7239, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8144/10000, Loss: 0.7239, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8145/10000, Loss: 0.7239, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8146/10000, Loss: 0.7239, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8147/10000, Loss: 0.7239, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8148/10000, Loss: 0.7238, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8149/10000, Loss: 0.7238, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8150/10000, Loss: 0.7238, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8151/10000, Loss: 0.7238, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8152/10000, Loss: 0.7238, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8153/10000, Loss: 0.7237, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8154/10000, Loss: 0.7237, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8155/10000, Loss: 0.7237, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8156/10000, Loss: 0.7237, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8157/10000, Loss: 0.7237, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8158/10000, Loss: 0.7236, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8159/10000, Loss: 0.7236, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8160/10000, Loss: 0.7236, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8161/10000, Loss: 0.7236, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8162/10000, Loss: 0.7236, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8163/10000, Loss: 0.7236, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8164/10000, Loss: 0.7235, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8165/10000, Loss: 0.7235, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8166/10000, Loss: 0.7235, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8167/10000, Loss: 0.7235, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8168/10000, Loss: 0.7235, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8169/10000, Loss: 0.7234, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8170/10000, Loss: 0.7234, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8171/10000, Loss: 0.7234, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8172/10000, Loss: 0.7234, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8173/10000, Loss: 0.7234, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8174/10000, Loss: 0.7233, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8175/10000, Loss: 0.7233, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8176/10000, Loss: 0.7233, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8177/10000, Loss: 0.7233, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8178/10000, Loss: 0.7233, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8179/10000, Loss: 0.7232, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8180/10000, Loss: 0.7232, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8181/10000, Loss: 0.7232, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8182/10000, Loss: 0.7232, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8183/10000, Loss: 0.7232, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8184/10000, Loss: 0.7231, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8185/10000, Loss: 0.7231, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8186/10000, Loss: 0.7231, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8187/10000, Loss: 0.7231, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8188/10000, Loss: 0.7231, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8189/10000, Loss: 0.7231, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8190/10000, Loss: 0.7230, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8191/10000, Loss: 0.7230, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8192/10000, Loss: 0.7230, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8193/10000, Loss: 0.7230, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8194/10000, Loss: 0.7230, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8195/10000, Loss: 0.7229, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8196/10000, Loss: 0.7229, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8197/10000, Loss: 0.7229, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8198/10000, Loss: 0.7229, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8199/10000, Loss: 0.7229, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8200/10000, Loss: 0.7228, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8201/10000, Loss: 0.7228, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8202/10000, Loss: 0.7228, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8203/10000, Loss: 0.7228, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8204/10000, Loss: 0.7228, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8205/10000, Loss: 0.7227, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8206/10000, Loss: 0.7227, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8207/10000, Loss: 0.7227, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8208/10000, Loss: 0.7227, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8209/10000, Loss: 0.7227, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8210/10000, Loss: 0.7227, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8211/10000, Loss: 0.7226, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8212/10000, Loss: 0.7226, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8213/10000, Loss: 0.7226, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8214/10000, Loss: 0.7226, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8215/10000, Loss: 0.7226, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8216/10000, Loss: 0.7225, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8217/10000, Loss: 0.7225, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8218/10000, Loss: 0.7225, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8219/10000, Loss: 0.7225, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8220/10000, Loss: 0.7225, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8221/10000, Loss: 0.7224, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8222/10000, Loss: 0.7224, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8223/10000, Loss: 0.7224, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8224/10000, Loss: 0.7224, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8225/10000, Loss: 0.7224, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8226/10000, Loss: 0.7223, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8227/10000, Loss: 0.7223, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8228/10000, Loss: 0.7223, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8229/10000, Loss: 0.7223, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8230/10000, Loss: 0.7223, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8231/10000, Loss: 0.7223, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8232/10000, Loss: 0.7222, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8233/10000, Loss: 0.7222, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8234/10000, Loss: 0.7222, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8235/10000, Loss: 0.7222, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8236/10000, Loss: 0.7222, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8237/10000, Loss: 0.7221, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8238/10000, Loss: 0.7221, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8239/10000, Loss: 0.7221, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8240/10000, Loss: 0.7221, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8241/10000, Loss: 0.7221, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8242/10000, Loss: 0.7220, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8243/10000, Loss: 0.7220, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8244/10000, Loss: 0.7220, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8245/10000, Loss: 0.7220, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8246/10000, Loss: 0.7220, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8247/10000, Loss: 0.7219, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8248/10000, Loss: 0.7219, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8249/10000, Loss: 0.7219, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8250/10000, Loss: 0.7219, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8251/10000, Loss: 0.7219, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8252/10000, Loss: 0.7219, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8253/10000, Loss: 0.7218, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8254/10000, Loss: 0.7218, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8255/10000, Loss: 0.7218, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8256/10000, Loss: 0.7218, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8257/10000, Loss: 0.7218, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8258/10000, Loss: 0.7217, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8259/10000, Loss: 0.7217, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8260/10000, Loss: 0.7217, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8261/10000, Loss: 0.7217, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8262/10000, Loss: 0.7217, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8263/10000, Loss: 0.7216, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8264/10000, Loss: 0.7216, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8265/10000, Loss: 0.7216, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8266/10000, Loss: 0.7216, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8267/10000, Loss: 0.7216, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8268/10000, Loss: 0.7216, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8269/10000, Loss: 0.7215, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8270/10000, Loss: 0.7215, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8271/10000, Loss: 0.7215, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8272/10000, Loss: 0.7215, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8273/10000, Loss: 0.7215, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8274/10000, Loss: 0.7214, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8275/10000, Loss: 0.7214, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8276/10000, Loss: 0.7214, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8277/10000, Loss: 0.7214, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8278/10000, Loss: 0.7214, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8279/10000, Loss: 0.7213, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8280/10000, Loss: 0.7213, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8281/10000, Loss: 0.7213, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8282/10000, Loss: 0.7213, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8283/10000, Loss: 0.7213, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8284/10000, Loss: 0.7212, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8285/10000, Loss: 0.7212, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8286/10000, Loss: 0.7212, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8287/10000, Loss: 0.7212, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8288/10000, Loss: 0.7212, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8289/10000, Loss: 0.7212, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8290/10000, Loss: 0.7211, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8291/10000, Loss: 0.7211, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8292/10000, Loss: 0.7211, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8293/10000, Loss: 0.7211, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8294/10000, Loss: 0.7211, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8295/10000, Loss: 0.7210, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8296/10000, Loss: 0.7210, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8297/10000, Loss: 0.7210, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8298/10000, Loss: 0.7210, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8299/10000, Loss: 0.7210, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8300/10000, Loss: 0.7209, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8301/10000, Loss: 0.7209, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8302/10000, Loss: 0.7209, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8303/10000, Loss: 0.7209, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8304/10000, Loss: 0.7209, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8305/10000, Loss: 0.7209, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8306/10000, Loss: 0.7208, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8307/10000, Loss: 0.7208, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8308/10000, Loss: 0.7208, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8309/10000, Loss: 0.7208, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8310/10000, Loss: 0.7208, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8311/10000, Loss: 0.7207, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8312/10000, Loss: 0.7207, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8313/10000, Loss: 0.7207, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8314/10000, Loss: 0.7207, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8315/10000, Loss: 0.7207, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8316/10000, Loss: 0.7206, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8317/10000, Loss: 0.7206, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8318/10000, Loss: 0.7206, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8319/10000, Loss: 0.7206, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8320/10000, Loss: 0.7206, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8321/10000, Loss: 0.7206, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8322/10000, Loss: 0.7205, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8323/10000, Loss: 0.7205, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8324/10000, Loss: 0.7205, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8325/10000, Loss: 0.7205, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8326/10000, Loss: 0.7205, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8327/10000, Loss: 0.7204, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8328/10000, Loss: 0.7204, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8329/10000, Loss: 0.7204, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8330/10000, Loss: 0.7204, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8331/10000, Loss: 0.7204, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8332/10000, Loss: 0.7203, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8333/10000, Loss: 0.7203, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8334/10000, Loss: 0.7203, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8335/10000, Loss: 0.7203, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8336/10000, Loss: 0.7203, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8337/10000, Loss: 0.7203, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8338/10000, Loss: 0.7202, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8339/10000, Loss: 0.7202, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8340/10000, Loss: 0.7202, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8341/10000, Loss: 0.7202, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8342/10000, Loss: 0.7202, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8343/10000, Loss: 0.7201, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8344/10000, Loss: 0.7201, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8345/10000, Loss: 0.7201, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8346/10000, Loss: 0.7201, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8347/10000, Loss: 0.7201, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8348/10000, Loss: 0.7200, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8349/10000, Loss: 0.7200, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8350/10000, Loss: 0.7200, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8351/10000, Loss: 0.7200, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8352/10000, Loss: 0.7200, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8353/10000, Loss: 0.7200, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8354/10000, Loss: 0.7199, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8355/10000, Loss: 0.7199, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8356/10000, Loss: 0.7199, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8357/10000, Loss: 0.7199, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8358/10000, Loss: 0.7199, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8359/10000, Loss: 0.7198, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8360/10000, Loss: 0.7198, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8361/10000, Loss: 0.7198, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8362/10000, Loss: 0.7198, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8363/10000, Loss: 0.7198, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8364/10000, Loss: 0.7197, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8365/10000, Loss: 0.7197, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8366/10000, Loss: 0.7197, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8367/10000, Loss: 0.7197, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8368/10000, Loss: 0.7197, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8369/10000, Loss: 0.7197, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8370/10000, Loss: 0.7196, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8371/10000, Loss: 0.7196, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8372/10000, Loss: 0.7196, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8373/10000, Loss: 0.7196, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8374/10000, Loss: 0.7196, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8375/10000, Loss: 0.7195, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8376/10000, Loss: 0.7195, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8377/10000, Loss: 0.7195, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8378/10000, Loss: 0.7195, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8379/10000, Loss: 0.7195, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8380/10000, Loss: 0.7194, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8381/10000, Loss: 0.7194, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8382/10000, Loss: 0.7194, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8383/10000, Loss: 0.7194, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8384/10000, Loss: 0.7194, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8385/10000, Loss: 0.7194, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8386/10000, Loss: 0.7193, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8387/10000, Loss: 0.7193, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8388/10000, Loss: 0.7193, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8389/10000, Loss: 0.7193, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8390/10000, Loss: 0.7193, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8391/10000, Loss: 0.7192, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8392/10000, Loss: 0.7192, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8393/10000, Loss: 0.7192, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8394/10000, Loss: 0.7192, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8395/10000, Loss: 0.7192, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8396/10000, Loss: 0.7192, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8397/10000, Loss: 0.7191, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8398/10000, Loss: 0.7191, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8399/10000, Loss: 0.7191, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8400/10000, Loss: 0.7191, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8401/10000, Loss: 0.7191, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8402/10000, Loss: 0.7190, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8403/10000, Loss: 0.7190, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8404/10000, Loss: 0.7190, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8405/10000, Loss: 0.7190, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8406/10000, Loss: 0.7190, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8407/10000, Loss: 0.7189, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8408/10000, Loss: 0.7189, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8409/10000, Loss: 0.7189, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8410/10000, Loss: 0.7189, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8411/10000, Loss: 0.7189, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8412/10000, Loss: 0.7189, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8413/10000, Loss: 0.7188, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8414/10000, Loss: 0.7188, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8415/10000, Loss: 0.7188, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8416/10000, Loss: 0.7188, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8417/10000, Loss: 0.7188, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8418/10000, Loss: 0.7187, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8419/10000, Loss: 0.7187, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8420/10000, Loss: 0.7187, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8421/10000, Loss: 0.7187, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8422/10000, Loss: 0.7187, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8423/10000, Loss: 0.7186, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8424/10000, Loss: 0.7186, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8425/10000, Loss: 0.7186, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8426/10000, Loss: 0.7186, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8427/10000, Loss: 0.7186, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8428/10000, Loss: 0.7186, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8429/10000, Loss: 0.7185, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8430/10000, Loss: 0.7185, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8431/10000, Loss: 0.7185, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8432/10000, Loss: 0.7185, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8433/10000, Loss: 0.7185, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8434/10000, Loss: 0.7184, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8435/10000, Loss: 0.7184, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8436/10000, Loss: 0.7184, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8437/10000, Loss: 0.7184, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8438/10000, Loss: 0.7184, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8439/10000, Loss: 0.7184, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8440/10000, Loss: 0.7183, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8441/10000, Loss: 0.7183, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8442/10000, Loss: 0.7183, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8443/10000, Loss: 0.7183, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8444/10000, Loss: 0.7183, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8445/10000, Loss: 0.7182, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8446/10000, Loss: 0.7182, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8447/10000, Loss: 0.7182, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8448/10000, Loss: 0.7182, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8449/10000, Loss: 0.7182, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8450/10000, Loss: 0.7182, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8451/10000, Loss: 0.7181, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8452/10000, Loss: 0.7181, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8453/10000, Loss: 0.7181, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8454/10000, Loss: 0.7181, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8455/10000, Loss: 0.7181, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8456/10000, Loss: 0.7180, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8457/10000, Loss: 0.7180, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8458/10000, Loss: 0.7180, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8459/10000, Loss: 0.7180, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8460/10000, Loss: 0.7180, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8461/10000, Loss: 0.7179, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8462/10000, Loss: 0.7179, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8463/10000, Loss: 0.7179, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8464/10000, Loss: 0.7179, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8465/10000, Loss: 0.7179, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8466/10000, Loss: 0.7179, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8467/10000, Loss: 0.7178, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8468/10000, Loss: 0.7178, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8469/10000, Loss: 0.7178, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8470/10000, Loss: 0.7178, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8471/10000, Loss: 0.7178, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8472/10000, Loss: 0.7177, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8473/10000, Loss: 0.7177, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8474/10000, Loss: 0.7177, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8475/10000, Loss: 0.7177, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8476/10000, Loss: 0.7177, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8477/10000, Loss: 0.7177, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8478/10000, Loss: 0.7176, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8479/10000, Loss: 0.7176, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8480/10000, Loss: 0.7176, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8481/10000, Loss: 0.7176, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8482/10000, Loss: 0.7176, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8483/10000, Loss: 0.7175, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8484/10000, Loss: 0.7175, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8485/10000, Loss: 0.7175, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8486/10000, Loss: 0.7175, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8487/10000, Loss: 0.7175, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8488/10000, Loss: 0.7175, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8489/10000, Loss: 0.7174, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8490/10000, Loss: 0.7174, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8491/10000, Loss: 0.7174, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8492/10000, Loss: 0.7174, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8493/10000, Loss: 0.7174, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8494/10000, Loss: 0.7173, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8495/10000, Loss: 0.7173, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8496/10000, Loss: 0.7173, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8497/10000, Loss: 0.7173, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8498/10000, Loss: 0.7173, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8499/10000, Loss: 0.7173, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8500/10000, Loss: 0.7172, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8501/10000, Loss: 0.7172, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8502/10000, Loss: 0.7172, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8503/10000, Loss: 0.7172, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8504/10000, Loss: 0.7172, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8505/10000, Loss: 0.7171, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8506/10000, Loss: 0.7171, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8507/10000, Loss: 0.7171, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8508/10000, Loss: 0.7171, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8509/10000, Loss: 0.7171, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8510/10000, Loss: 0.7170, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8511/10000, Loss: 0.7170, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8512/10000, Loss: 0.7170, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8513/10000, Loss: 0.7170, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8514/10000, Loss: 0.7170, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8515/10000, Loss: 0.7170, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8516/10000, Loss: 0.7169, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8517/10000, Loss: 0.7169, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8518/10000, Loss: 0.7169, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8519/10000, Loss: 0.7169, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8520/10000, Loss: 0.7169, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8521/10000, Loss: 0.7168, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8522/10000, Loss: 0.7168, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8523/10000, Loss: 0.7168, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8524/10000, Loss: 0.7168, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8525/10000, Loss: 0.7168, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8526/10000, Loss: 0.7168, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8527/10000, Loss: 0.7167, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8528/10000, Loss: 0.7167, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8529/10000, Loss: 0.7167, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8530/10000, Loss: 0.7167, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8531/10000, Loss: 0.7167, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8532/10000, Loss: 0.7166, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8533/10000, Loss: 0.7166, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8534/10000, Loss: 0.7166, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8535/10000, Loss: 0.7166, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8536/10000, Loss: 0.7166, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8537/10000, Loss: 0.7166, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8538/10000, Loss: 0.7165, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8539/10000, Loss: 0.7165, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8540/10000, Loss: 0.7165, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8541/10000, Loss: 0.7165, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8542/10000, Loss: 0.7165, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8543/10000, Loss: 0.7164, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8544/10000, Loss: 0.7164, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8545/10000, Loss: 0.7164, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8546/10000, Loss: 0.7164, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8547/10000, Loss: 0.7164, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8548/10000, Loss: 0.7164, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8549/10000, Loss: 0.7163, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8550/10000, Loss: 0.7163, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8551/10000, Loss: 0.7163, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8552/10000, Loss: 0.7163, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8553/10000, Loss: 0.7163, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8554/10000, Loss: 0.7162, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8555/10000, Loss: 0.7162, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8556/10000, Loss: 0.7162, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8557/10000, Loss: 0.7162, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8558/10000, Loss: 0.7162, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8559/10000, Loss: 0.7162, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8560/10000, Loss: 0.7161, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8561/10000, Loss: 0.7161, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8562/10000, Loss: 0.7161, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8563/10000, Loss: 0.7161, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8564/10000, Loss: 0.7161, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8565/10000, Loss: 0.7160, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8566/10000, Loss: 0.7160, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8567/10000, Loss: 0.7160, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8568/10000, Loss: 0.7160, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8569/10000, Loss: 0.7160, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8570/10000, Loss: 0.7160, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8571/10000, Loss: 0.7159, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8572/10000, Loss: 0.7159, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8573/10000, Loss: 0.7159, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8574/10000, Loss: 0.7159, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8575/10000, Loss: 0.7159, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8576/10000, Loss: 0.7158, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8577/10000, Loss: 0.7158, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8578/10000, Loss: 0.7158, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8579/10000, Loss: 0.7158, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8580/10000, Loss: 0.7158, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8581/10000, Loss: 0.7158, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8582/10000, Loss: 0.7157, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8583/10000, Loss: 0.7157, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8584/10000, Loss: 0.7157, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8585/10000, Loss: 0.7157, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8586/10000, Loss: 0.7157, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8587/10000, Loss: 0.7156, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8588/10000, Loss: 0.7156, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8589/10000, Loss: 0.7156, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8590/10000, Loss: 0.7156, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8591/10000, Loss: 0.7156, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8592/10000, Loss: 0.7156, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8593/10000, Loss: 0.7155, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8594/10000, Loss: 0.7155, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8595/10000, Loss: 0.7155, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8596/10000, Loss: 0.7155, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8597/10000, Loss: 0.7155, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8598/10000, Loss: 0.7154, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8599/10000, Loss: 0.7154, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8600/10000, Loss: 0.7154, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8601/10000, Loss: 0.7154, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8602/10000, Loss: 0.7154, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8603/10000, Loss: 0.7154, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8604/10000, Loss: 0.7153, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8605/10000, Loss: 0.7153, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8606/10000, Loss: 0.7153, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8607/10000, Loss: 0.7153, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8608/10000, Loss: 0.7153, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8609/10000, Loss: 0.7152, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8610/10000, Loss: 0.7152, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8611/10000, Loss: 0.7152, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8612/10000, Loss: 0.7152, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8613/10000, Loss: 0.7152, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8614/10000, Loss: 0.7152, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8615/10000, Loss: 0.7151, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8616/10000, Loss: 0.7151, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8617/10000, Loss: 0.7151, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8618/10000, Loss: 0.7151, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8619/10000, Loss: 0.7151, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8620/10000, Loss: 0.7151, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8621/10000, Loss: 0.7150, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8622/10000, Loss: 0.7150, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8623/10000, Loss: 0.7150, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8624/10000, Loss: 0.7150, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8625/10000, Loss: 0.7150, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8626/10000, Loss: 0.7149, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8627/10000, Loss: 0.7149, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8628/10000, Loss: 0.7149, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8629/10000, Loss: 0.7149, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8630/10000, Loss: 0.7149, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8631/10000, Loss: 0.7149, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8632/10000, Loss: 0.7148, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8633/10000, Loss: 0.7148, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8634/10000, Loss: 0.7148, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8635/10000, Loss: 0.7148, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8636/10000, Loss: 0.7148, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8637/10000, Loss: 0.7147, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8638/10000, Loss: 0.7147, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8639/10000, Loss: 0.7147, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8640/10000, Loss: 0.7147, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8641/10000, Loss: 0.7147, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8642/10000, Loss: 0.7147, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8643/10000, Loss: 0.7146, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8644/10000, Loss: 0.7146, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8645/10000, Loss: 0.7146, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8646/10000, Loss: 0.7146, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8647/10000, Loss: 0.7146, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8648/10000, Loss: 0.7145, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8649/10000, Loss: 0.7145, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8650/10000, Loss: 0.7145, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8651/10000, Loss: 0.7145, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8652/10000, Loss: 0.7145, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8653/10000, Loss: 0.7145, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8654/10000, Loss: 0.7144, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8655/10000, Loss: 0.7144, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8656/10000, Loss: 0.7144, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8657/10000, Loss: 0.7144, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8658/10000, Loss: 0.7144, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8659/10000, Loss: 0.7143, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8660/10000, Loss: 0.7143, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8661/10000, Loss: 0.7143, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8662/10000, Loss: 0.7143, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8663/10000, Loss: 0.7143, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8664/10000, Loss: 0.7143, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8665/10000, Loss: 0.7142, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8666/10000, Loss: 0.7142, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8667/10000, Loss: 0.7142, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8668/10000, Loss: 0.7142, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8669/10000, Loss: 0.7142, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8670/10000, Loss: 0.7142, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8671/10000, Loss: 0.7141, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8672/10000, Loss: 0.7141, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8673/10000, Loss: 0.7141, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8674/10000, Loss: 0.7141, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8675/10000, Loss: 0.7141, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8676/10000, Loss: 0.7140, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8677/10000, Loss: 0.7140, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8678/10000, Loss: 0.7140, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8679/10000, Loss: 0.7140, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8680/10000, Loss: 0.7140, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8681/10000, Loss: 0.7140, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8682/10000, Loss: 0.7139, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8683/10000, Loss: 0.7139, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8684/10000, Loss: 0.7139, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8685/10000, Loss: 0.7139, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8686/10000, Loss: 0.7139, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8687/10000, Loss: 0.7138, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8688/10000, Loss: 0.7138, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8689/10000, Loss: 0.7138, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8690/10000, Loss: 0.7138, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8691/10000, Loss: 0.7138, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8692/10000, Loss: 0.7138, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8693/10000, Loss: 0.7137, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8694/10000, Loss: 0.7137, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8695/10000, Loss: 0.7137, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8696/10000, Loss: 0.7137, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8697/10000, Loss: 0.7137, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8698/10000, Loss: 0.7137, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8699/10000, Loss: 0.7136, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8700/10000, Loss: 0.7136, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8701/10000, Loss: 0.7136, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8702/10000, Loss: 0.7136, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8703/10000, Loss: 0.7136, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8704/10000, Loss: 0.7135, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8705/10000, Loss: 0.7135, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8706/10000, Loss: 0.7135, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8707/10000, Loss: 0.7135, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8708/10000, Loss: 0.7135, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8709/10000, Loss: 0.7135, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8710/10000, Loss: 0.7134, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8711/10000, Loss: 0.7134, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8712/10000, Loss: 0.7134, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8713/10000, Loss: 0.7134, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8714/10000, Loss: 0.7134, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8715/10000, Loss: 0.7133, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8716/10000, Loss: 0.7133, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8717/10000, Loss: 0.7133, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8718/10000, Loss: 0.7133, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8719/10000, Loss: 0.7133, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8720/10000, Loss: 0.7133, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8721/10000, Loss: 0.7132, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8722/10000, Loss: 0.7132, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8723/10000, Loss: 0.7132, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8724/10000, Loss: 0.7132, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8725/10000, Loss: 0.7132, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8726/10000, Loss: 0.7132, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8727/10000, Loss: 0.7131, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8728/10000, Loss: 0.7131, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8729/10000, Loss: 0.7131, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8730/10000, Loss: 0.7131, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8731/10000, Loss: 0.7131, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8732/10000, Loss: 0.7130, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8733/10000, Loss: 0.7130, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8734/10000, Loss: 0.7130, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8735/10000, Loss: 0.7130, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8736/10000, Loss: 0.7130, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8737/10000, Loss: 0.7130, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8738/10000, Loss: 0.7129, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8739/10000, Loss: 0.7129, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8740/10000, Loss: 0.7129, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8741/10000, Loss: 0.7129, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8742/10000, Loss: 0.7129, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8743/10000, Loss: 0.7129, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8744/10000, Loss: 0.7128, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8745/10000, Loss: 0.7128, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8746/10000, Loss: 0.7128, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8747/10000, Loss: 0.7128, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8748/10000, Loss: 0.7128, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8749/10000, Loss: 0.7127, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8750/10000, Loss: 0.7127, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8751/10000, Loss: 0.7127, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8752/10000, Loss: 0.7127, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8753/10000, Loss: 0.7127, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8754/10000, Loss: 0.7127, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8755/10000, Loss: 0.7126, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8756/10000, Loss: 0.7126, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8757/10000, Loss: 0.7126, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8758/10000, Loss: 0.7126, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8759/10000, Loss: 0.7126, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8760/10000, Loss: 0.7125, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8761/10000, Loss: 0.7125, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8762/10000, Loss: 0.7125, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8763/10000, Loss: 0.7125, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8764/10000, Loss: 0.7125, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8765/10000, Loss: 0.7125, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8766/10000, Loss: 0.7124, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8767/10000, Loss: 0.7124, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8768/10000, Loss: 0.7124, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8769/10000, Loss: 0.7124, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8770/10000, Loss: 0.7124, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8771/10000, Loss: 0.7124, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8772/10000, Loss: 0.7123, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8773/10000, Loss: 0.7123, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8774/10000, Loss: 0.7123, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8775/10000, Loss: 0.7123, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8776/10000, Loss: 0.7123, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8777/10000, Loss: 0.7122, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8778/10000, Loss: 0.7122, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8779/10000, Loss: 0.7122, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8780/10000, Loss: 0.7122, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8781/10000, Loss: 0.7122, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8782/10000, Loss: 0.7122, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8783/10000, Loss: 0.7121, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8784/10000, Loss: 0.7121, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8785/10000, Loss: 0.7121, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8786/10000, Loss: 0.7121, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8787/10000, Loss: 0.7121, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8788/10000, Loss: 0.7121, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8789/10000, Loss: 0.7120, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8790/10000, Loss: 0.7120, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8791/10000, Loss: 0.7120, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8792/10000, Loss: 0.7120, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8793/10000, Loss: 0.7120, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8794/10000, Loss: 0.7119, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8795/10000, Loss: 0.7119, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8796/10000, Loss: 0.7119, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8797/10000, Loss: 0.7119, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8798/10000, Loss: 0.7119, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8799/10000, Loss: 0.7119, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8800/10000, Loss: 0.7118, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8801/10000, Loss: 0.7118, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8802/10000, Loss: 0.7118, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8803/10000, Loss: 0.7118, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8804/10000, Loss: 0.7118, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8805/10000, Loss: 0.7118, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8806/10000, Loss: 0.7117, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8807/10000, Loss: 0.7117, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8808/10000, Loss: 0.7117, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8809/10000, Loss: 0.7117, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8810/10000, Loss: 0.7117, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8811/10000, Loss: 0.7117, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8812/10000, Loss: 0.7116, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8813/10000, Loss: 0.7116, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8814/10000, Loss: 0.7116, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8815/10000, Loss: 0.7116, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8816/10000, Loss: 0.7116, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8817/10000, Loss: 0.7115, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8818/10000, Loss: 0.7115, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8819/10000, Loss: 0.7115, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8820/10000, Loss: 0.7115, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8821/10000, Loss: 0.7115, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8822/10000, Loss: 0.7115, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8823/10000, Loss: 0.7114, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8824/10000, Loss: 0.7114, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8825/10000, Loss: 0.7114, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8826/10000, Loss: 0.7114, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8827/10000, Loss: 0.7114, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8828/10000, Loss: 0.7114, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8829/10000, Loss: 0.7113, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8830/10000, Loss: 0.7113, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8831/10000, Loss: 0.7113, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8832/10000, Loss: 0.7113, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8833/10000, Loss: 0.7113, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8834/10000, Loss: 0.7112, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8835/10000, Loss: 0.7112, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8836/10000, Loss: 0.7112, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8837/10000, Loss: 0.7112, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8838/10000, Loss: 0.7112, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8839/10000, Loss: 0.7112, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8840/10000, Loss: 0.7111, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8841/10000, Loss: 0.7111, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8842/10000, Loss: 0.7111, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8843/10000, Loss: 0.7111, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8844/10000, Loss: 0.7111, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8845/10000, Loss: 0.7111, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8846/10000, Loss: 0.7110, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8847/10000, Loss: 0.7110, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8848/10000, Loss: 0.7110, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8849/10000, Loss: 0.7110, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8850/10000, Loss: 0.7110, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8851/10000, Loss: 0.7109, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8852/10000, Loss: 0.7109, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8853/10000, Loss: 0.7109, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8854/10000, Loss: 0.7109, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8855/10000, Loss: 0.7109, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8856/10000, Loss: 0.7109, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8857/10000, Loss: 0.7108, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8858/10000, Loss: 0.7108, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8859/10000, Loss: 0.7108, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8860/10000, Loss: 0.7108, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8861/10000, Loss: 0.7108, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8862/10000, Loss: 0.7108, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8863/10000, Loss: 0.7107, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8864/10000, Loss: 0.7107, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8865/10000, Loss: 0.7107, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8866/10000, Loss: 0.7107, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8867/10000, Loss: 0.7107, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8868/10000, Loss: 0.7107, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8869/10000, Loss: 0.7106, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8870/10000, Loss: 0.7106, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8871/10000, Loss: 0.7106, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8872/10000, Loss: 0.7106, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8873/10000, Loss: 0.7106, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8874/10000, Loss: 0.7105, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8875/10000, Loss: 0.7105, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8876/10000, Loss: 0.7105, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8877/10000, Loss: 0.7105, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8878/10000, Loss: 0.7105, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8879/10000, Loss: 0.7105, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8880/10000, Loss: 0.7104, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8881/10000, Loss: 0.7104, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8882/10000, Loss: 0.7104, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8883/10000, Loss: 0.7104, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8884/10000, Loss: 0.7104, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8885/10000, Loss: 0.7104, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8886/10000, Loss: 0.7103, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8887/10000, Loss: 0.7103, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8888/10000, Loss: 0.7103, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8889/10000, Loss: 0.7103, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8890/10000, Loss: 0.7103, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8891/10000, Loss: 0.7103, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8892/10000, Loss: 0.7102, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8893/10000, Loss: 0.7102, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8894/10000, Loss: 0.7102, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8895/10000, Loss: 0.7102, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8896/10000, Loss: 0.7102, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8897/10000, Loss: 0.7101, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8898/10000, Loss: 0.7101, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8899/10000, Loss: 0.7101, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8900/10000, Loss: 0.7101, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8901/10000, Loss: 0.7101, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8902/10000, Loss: 0.7101, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8903/10000, Loss: 0.7100, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8904/10000, Loss: 0.7100, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8905/10000, Loss: 0.7100, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8906/10000, Loss: 0.7100, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8907/10000, Loss: 0.7100, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8908/10000, Loss: 0.7100, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8909/10000, Loss: 0.7099, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8910/10000, Loss: 0.7099, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8911/10000, Loss: 0.7099, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8912/10000, Loss: 0.7099, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8913/10000, Loss: 0.7099, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8914/10000, Loss: 0.7099, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8915/10000, Loss: 0.7098, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8916/10000, Loss: 0.7098, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8917/10000, Loss: 0.7098, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8918/10000, Loss: 0.7098, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8919/10000, Loss: 0.7098, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8920/10000, Loss: 0.7097, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8921/10000, Loss: 0.7097, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8922/10000, Loss: 0.7097, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8923/10000, Loss: 0.7097, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8924/10000, Loss: 0.7097, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8925/10000, Loss: 0.7097, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8926/10000, Loss: 0.7096, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8927/10000, Loss: 0.7096, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8928/10000, Loss: 0.7096, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8929/10000, Loss: 0.7096, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8930/10000, Loss: 0.7096, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8931/10000, Loss: 0.7096, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8932/10000, Loss: 0.7095, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8933/10000, Loss: 0.7095, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8934/10000, Loss: 0.7095, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8935/10000, Loss: 0.7095, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8936/10000, Loss: 0.7095, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8937/10000, Loss: 0.7095, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8938/10000, Loss: 0.7094, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8939/10000, Loss: 0.7094, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8940/10000, Loss: 0.7094, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8941/10000, Loss: 0.7094, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8942/10000, Loss: 0.7094, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8943/10000, Loss: 0.7093, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8944/10000, Loss: 0.7093, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8945/10000, Loss: 0.7093, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8946/10000, Loss: 0.7093, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8947/10000, Loss: 0.7093, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8948/10000, Loss: 0.7093, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8949/10000, Loss: 0.7092, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8950/10000, Loss: 0.7092, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8951/10000, Loss: 0.7092, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8952/10000, Loss: 0.7092, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8953/10000, Loss: 0.7092, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8954/10000, Loss: 0.7092, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8955/10000, Loss: 0.7091, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8956/10000, Loss: 0.7091, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8957/10000, Loss: 0.7091, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8958/10000, Loss: 0.7091, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8959/10000, Loss: 0.7091, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8960/10000, Loss: 0.7091, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8961/10000, Loss: 0.7090, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8962/10000, Loss: 0.7090, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8963/10000, Loss: 0.7090, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8964/10000, Loss: 0.7090, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8965/10000, Loss: 0.7090, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8966/10000, Loss: 0.7090, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8967/10000, Loss: 0.7089, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8968/10000, Loss: 0.7089, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8969/10000, Loss: 0.7089, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8970/10000, Loss: 0.7089, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8971/10000, Loss: 0.7089, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8972/10000, Loss: 0.7088, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8973/10000, Loss: 0.7088, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8974/10000, Loss: 0.7088, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8975/10000, Loss: 0.7088, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8976/10000, Loss: 0.7088, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8977/10000, Loss: 0.7088, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8978/10000, Loss: 0.7087, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8979/10000, Loss: 0.7087, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8980/10000, Loss: 0.7087, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8981/10000, Loss: 0.7087, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8982/10000, Loss: 0.7087, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8983/10000, Loss: 0.7087, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8984/10000, Loss: 0.7086, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8985/10000, Loss: 0.7086, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8986/10000, Loss: 0.7086, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8987/10000, Loss: 0.7086, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8988/10000, Loss: 0.7086, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8989/10000, Loss: 0.7086, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8990/10000, Loss: 0.7085, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8991/10000, Loss: 0.7085, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8992/10000, Loss: 0.7085, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8993/10000, Loss: 0.7085, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8994/10000, Loss: 0.7085, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8995/10000, Loss: 0.7085, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8996/10000, Loss: 0.7084, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8997/10000, Loss: 0.7084, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8998/10000, Loss: 0.7084, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8999/10000, Loss: 0.7084, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9000/10000, Loss: 0.7084, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9001/10000, Loss: 0.7084, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9002/10000, Loss: 0.7083, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9003/10000, Loss: 0.7083, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9004/10000, Loss: 0.7083, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9005/10000, Loss: 0.7083, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9006/10000, Loss: 0.7083, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9007/10000, Loss: 0.7082, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9008/10000, Loss: 0.7082, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9009/10000, Loss: 0.7082, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9010/10000, Loss: 0.7082, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9011/10000, Loss: 0.7082, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9012/10000, Loss: 0.7082, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9013/10000, Loss: 0.7081, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9014/10000, Loss: 0.7081, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9015/10000, Loss: 0.7081, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9016/10000, Loss: 0.7081, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9017/10000, Loss: 0.7081, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9018/10000, Loss: 0.7081, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9019/10000, Loss: 0.7080, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9020/10000, Loss: 0.7080, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9021/10000, Loss: 0.7080, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9022/10000, Loss: 0.7080, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9023/10000, Loss: 0.7080, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9024/10000, Loss: 0.7080, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9025/10000, Loss: 0.7079, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9026/10000, Loss: 0.7079, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9027/10000, Loss: 0.7079, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9028/10000, Loss: 0.7079, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9029/10000, Loss: 0.7079, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9030/10000, Loss: 0.7079, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9031/10000, Loss: 0.7078, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9032/10000, Loss: 0.7078, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9033/10000, Loss: 0.7078, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9034/10000, Loss: 0.7078, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9035/10000, Loss: 0.7078, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9036/10000, Loss: 0.7078, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9037/10000, Loss: 0.7077, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9038/10000, Loss: 0.7077, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9039/10000, Loss: 0.7077, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9040/10000, Loss: 0.7077, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9041/10000, Loss: 0.7077, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9042/10000, Loss: 0.7076, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9043/10000, Loss: 0.7076, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9044/10000, Loss: 0.7076, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9045/10000, Loss: 0.7076, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9046/10000, Loss: 0.7076, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9047/10000, Loss: 0.7076, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9048/10000, Loss: 0.7075, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9049/10000, Loss: 0.7075, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9050/10000, Loss: 0.7075, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9051/10000, Loss: 0.7075, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9052/10000, Loss: 0.7075, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9053/10000, Loss: 0.7075, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9054/10000, Loss: 0.7074, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9055/10000, Loss: 0.7074, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9056/10000, Loss: 0.7074, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9057/10000, Loss: 0.7074, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9058/10000, Loss: 0.7074, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9059/10000, Loss: 0.7074, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9060/10000, Loss: 0.7073, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9061/10000, Loss: 0.7073, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9062/10000, Loss: 0.7073, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9063/10000, Loss: 0.7073, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9064/10000, Loss: 0.7073, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9065/10000, Loss: 0.7073, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9066/10000, Loss: 0.7072, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9067/10000, Loss: 0.7072, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9068/10000, Loss: 0.7072, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9069/10000, Loss: 0.7072, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9070/10000, Loss: 0.7072, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9071/10000, Loss: 0.7072, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9072/10000, Loss: 0.7071, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9073/10000, Loss: 0.7071, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9074/10000, Loss: 0.7071, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9075/10000, Loss: 0.7071, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9076/10000, Loss: 0.7071, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9077/10000, Loss: 0.7071, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9078/10000, Loss: 0.7070, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9079/10000, Loss: 0.7070, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9080/10000, Loss: 0.7070, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9081/10000, Loss: 0.7070, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9082/10000, Loss: 0.7070, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9083/10000, Loss: 0.7070, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9084/10000, Loss: 0.7069, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9085/10000, Loss: 0.7069, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9086/10000, Loss: 0.7069, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9087/10000, Loss: 0.7069, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9088/10000, Loss: 0.7069, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9089/10000, Loss: 0.7069, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9090/10000, Loss: 0.7068, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9091/10000, Loss: 0.7068, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9092/10000, Loss: 0.7068, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9093/10000, Loss: 0.7068, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9094/10000, Loss: 0.7068, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9095/10000, Loss: 0.7067, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9096/10000, Loss: 0.7067, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9097/10000, Loss: 0.7067, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9098/10000, Loss: 0.7067, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9099/10000, Loss: 0.7067, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9100/10000, Loss: 0.7067, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9101/10000, Loss: 0.7066, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9102/10000, Loss: 0.7066, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9103/10000, Loss: 0.7066, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9104/10000, Loss: 0.7066, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9105/10000, Loss: 0.7066, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9106/10000, Loss: 0.7066, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9107/10000, Loss: 0.7065, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9108/10000, Loss: 0.7065, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9109/10000, Loss: 0.7065, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9110/10000, Loss: 0.7065, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9111/10000, Loss: 0.7065, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9112/10000, Loss: 0.7065, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9113/10000, Loss: 0.7064, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9114/10000, Loss: 0.7064, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9115/10000, Loss: 0.7064, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9116/10000, Loss: 0.7064, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9117/10000, Loss: 0.7064, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9118/10000, Loss: 0.7064, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9119/10000, Loss: 0.7063, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9120/10000, Loss: 0.7063, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9121/10000, Loss: 0.7063, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9122/10000, Loss: 0.7063, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9123/10000, Loss: 0.7063, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9124/10000, Loss: 0.7063, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9125/10000, Loss: 0.7062, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9126/10000, Loss: 0.7062, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9127/10000, Loss: 0.7062, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9128/10000, Loss: 0.7062, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9129/10000, Loss: 0.7062, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9130/10000, Loss: 0.7062, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9131/10000, Loss: 0.7061, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9132/10000, Loss: 0.7061, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9133/10000, Loss: 0.7061, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9134/10000, Loss: 0.7061, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9135/10000, Loss: 0.7061, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9136/10000, Loss: 0.7061, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9137/10000, Loss: 0.7060, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9138/10000, Loss: 0.7060, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9139/10000, Loss: 0.7060, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9140/10000, Loss: 0.7060, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9141/10000, Loss: 0.7060, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9142/10000, Loss: 0.7060, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9143/10000, Loss: 0.7059, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9144/10000, Loss: 0.7059, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9145/10000, Loss: 0.7059, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9146/10000, Loss: 0.7059, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9147/10000, Loss: 0.7059, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9148/10000, Loss: 0.7059, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9149/10000, Loss: 0.7058, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9150/10000, Loss: 0.7058, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9151/10000, Loss: 0.7058, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9152/10000, Loss: 0.7058, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9153/10000, Loss: 0.7058, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9154/10000, Loss: 0.7058, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9155/10000, Loss: 0.7057, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9156/10000, Loss: 0.7057, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9157/10000, Loss: 0.7057, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9158/10000, Loss: 0.7057, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9159/10000, Loss: 0.7057, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9160/10000, Loss: 0.7057, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9161/10000, Loss: 0.7056, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9162/10000, Loss: 0.7056, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9163/10000, Loss: 0.7056, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9164/10000, Loss: 0.7056, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9165/10000, Loss: 0.7056, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9166/10000, Loss: 0.7056, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9167/10000, Loss: 0.7055, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9168/10000, Loss: 0.7055, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9169/10000, Loss: 0.7055, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9170/10000, Loss: 0.7055, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9171/10000, Loss: 0.7055, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9172/10000, Loss: 0.7055, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9173/10000, Loss: 0.7054, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9174/10000, Loss: 0.7054, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9175/10000, Loss: 0.7054, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9176/10000, Loss: 0.7054, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9177/10000, Loss: 0.7054, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9178/10000, Loss: 0.7054, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9179/10000, Loss: 0.7053, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9180/10000, Loss: 0.7053, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9181/10000, Loss: 0.7053, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9182/10000, Loss: 0.7053, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9183/10000, Loss: 0.7053, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9184/10000, Loss: 0.7052, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9185/10000, Loss: 0.7052, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9186/10000, Loss: 0.7052, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9187/10000, Loss: 0.7052, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9188/10000, Loss: 0.7052, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9189/10000, Loss: 0.7052, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9190/10000, Loss: 0.7051, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9191/10000, Loss: 0.7051, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9192/10000, Loss: 0.7051, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9193/10000, Loss: 0.7051, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9194/10000, Loss: 0.7051, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9195/10000, Loss: 0.7051, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9196/10000, Loss: 0.7050, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9197/10000, Loss: 0.7050, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9198/10000, Loss: 0.7050, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9199/10000, Loss: 0.7050, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9200/10000, Loss: 0.7050, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9201/10000, Loss: 0.7050, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9202/10000, Loss: 0.7049, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9203/10000, Loss: 0.7049, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9204/10000, Loss: 0.7049, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9205/10000, Loss: 0.7049, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9206/10000, Loss: 0.7049, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9207/10000, Loss: 0.7049, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9208/10000, Loss: 0.7048, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9209/10000, Loss: 0.7048, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9210/10000, Loss: 0.7048, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9211/10000, Loss: 0.7048, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9212/10000, Loss: 0.7048, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9213/10000, Loss: 0.7048, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9214/10000, Loss: 0.7047, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9215/10000, Loss: 0.7047, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9216/10000, Loss: 0.7047, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9217/10000, Loss: 0.7047, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9218/10000, Loss: 0.7047, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9219/10000, Loss: 0.7047, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9220/10000, Loss: 0.7046, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9221/10000, Loss: 0.7046, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9222/10000, Loss: 0.7046, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9223/10000, Loss: 0.7046, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9224/10000, Loss: 0.7046, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9225/10000, Loss: 0.7046, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9226/10000, Loss: 0.7045, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9227/10000, Loss: 0.7045, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9228/10000, Loss: 0.7045, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9229/10000, Loss: 0.7045, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9230/10000, Loss: 0.7045, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9231/10000, Loss: 0.7045, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9232/10000, Loss: 0.7044, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9233/10000, Loss: 0.7044, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9234/10000, Loss: 0.7044, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9235/10000, Loss: 0.7044, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9236/10000, Loss: 0.7044, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9237/10000, Loss: 0.7044, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9238/10000, Loss: 0.7043, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9239/10000, Loss: 0.7043, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9240/10000, Loss: 0.7043, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9241/10000, Loss: 0.7043, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9242/10000, Loss: 0.7043, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9243/10000, Loss: 0.7043, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9244/10000, Loss: 0.7042, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9245/10000, Loss: 0.7042, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9246/10000, Loss: 0.7042, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9247/10000, Loss: 0.7042, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9248/10000, Loss: 0.7042, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9249/10000, Loss: 0.7042, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9250/10000, Loss: 0.7041, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9251/10000, Loss: 0.7041, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9252/10000, Loss: 0.7041, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9253/10000, Loss: 0.7041, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9254/10000, Loss: 0.7041, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9255/10000, Loss: 0.7041, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9256/10000, Loss: 0.7040, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9257/10000, Loss: 0.7040, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9258/10000, Loss: 0.7040, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9259/10000, Loss: 0.7040, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9260/10000, Loss: 0.7040, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9261/10000, Loss: 0.7040, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9262/10000, Loss: 0.7040, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9263/10000, Loss: 0.7039, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9264/10000, Loss: 0.7039, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9265/10000, Loss: 0.7039, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9266/10000, Loss: 0.7039, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9267/10000, Loss: 0.7039, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9268/10000, Loss: 0.7039, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9269/10000, Loss: 0.7038, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9270/10000, Loss: 0.7038, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9271/10000, Loss: 0.7038, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9272/10000, Loss: 0.7038, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9273/10000, Loss: 0.7038, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9274/10000, Loss: 0.7038, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9275/10000, Loss: 0.7037, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9276/10000, Loss: 0.7037, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9277/10000, Loss: 0.7037, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9278/10000, Loss: 0.7037, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9279/10000, Loss: 0.7037, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9280/10000, Loss: 0.7037, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9281/10000, Loss: 0.7036, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9282/10000, Loss: 0.7036, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9283/10000, Loss: 0.7036, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9284/10000, Loss: 0.7036, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9285/10000, Loss: 0.7036, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9286/10000, Loss: 0.7036, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9287/10000, Loss: 0.7035, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9288/10000, Loss: 0.7035, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9289/10000, Loss: 0.7035, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9290/10000, Loss: 0.7035, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9291/10000, Loss: 0.7035, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9292/10000, Loss: 0.7035, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9293/10000, Loss: 0.7034, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9294/10000, Loss: 0.7034, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9295/10000, Loss: 0.7034, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9296/10000, Loss: 0.7034, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9297/10000, Loss: 0.7034, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9298/10000, Loss: 0.7034, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9299/10000, Loss: 0.7033, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9300/10000, Loss: 0.7033, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9301/10000, Loss: 0.7033, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9302/10000, Loss: 0.7033, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9303/10000, Loss: 0.7033, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9304/10000, Loss: 0.7033, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9305/10000, Loss: 0.7032, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9306/10000, Loss: 0.7032, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9307/10000, Loss: 0.7032, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9308/10000, Loss: 0.7032, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9309/10000, Loss: 0.7032, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9310/10000, Loss: 0.7032, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9311/10000, Loss: 0.7031, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9312/10000, Loss: 0.7031, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9313/10000, Loss: 0.7031, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9314/10000, Loss: 0.7031, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9315/10000, Loss: 0.7031, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9316/10000, Loss: 0.7031, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9317/10000, Loss: 0.7030, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9318/10000, Loss: 0.7030, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9319/10000, Loss: 0.7030, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9320/10000, Loss: 0.7030, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9321/10000, Loss: 0.7030, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9322/10000, Loss: 0.7030, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9323/10000, Loss: 0.7029, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9324/10000, Loss: 0.7029, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9325/10000, Loss: 0.7029, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9326/10000, Loss: 0.7029, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9327/10000, Loss: 0.7029, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9328/10000, Loss: 0.7029, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9329/10000, Loss: 0.7028, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9330/10000, Loss: 0.7028, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9331/10000, Loss: 0.7028, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9332/10000, Loss: 0.7028, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9333/10000, Loss: 0.7028, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9334/10000, Loss: 0.7028, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9335/10000, Loss: 0.7027, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9336/10000, Loss: 0.7027, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9337/10000, Loss: 0.7027, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9338/10000, Loss: 0.7027, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9339/10000, Loss: 0.7027, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9340/10000, Loss: 0.7027, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9341/10000, Loss: 0.7026, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9342/10000, Loss: 0.7026, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9343/10000, Loss: 0.7026, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9344/10000, Loss: 0.7026, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9345/10000, Loss: 0.7026, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9346/10000, Loss: 0.7026, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9347/10000, Loss: 0.7025, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9348/10000, Loss: 0.7025, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9349/10000, Loss: 0.7025, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9350/10000, Loss: 0.7025, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9351/10000, Loss: 0.7025, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9352/10000, Loss: 0.7025, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9353/10000, Loss: 0.7025, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9354/10000, Loss: 0.7024, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9355/10000, Loss: 0.7024, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9356/10000, Loss: 0.7024, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9357/10000, Loss: 0.7024, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9358/10000, Loss: 0.7024, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9359/10000, Loss: 0.7024, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9360/10000, Loss: 0.7023, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9361/10000, Loss: 0.7023, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9362/10000, Loss: 0.7023, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9363/10000, Loss: 0.7023, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9364/10000, Loss: 0.7023, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9365/10000, Loss: 0.7023, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9366/10000, Loss: 0.7022, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9367/10000, Loss: 0.7022, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9368/10000, Loss: 0.7022, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9369/10000, Loss: 0.7022, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9370/10000, Loss: 0.7022, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9371/10000, Loss: 0.7022, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9372/10000, Loss: 0.7021, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9373/10000, Loss: 0.7021, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9374/10000, Loss: 0.7021, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9375/10000, Loss: 0.7021, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9376/10000, Loss: 0.7021, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9377/10000, Loss: 0.7021, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9378/10000, Loss: 0.7020, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9379/10000, Loss: 0.7020, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9380/10000, Loss: 0.7020, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9381/10000, Loss: 0.7020, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9382/10000, Loss: 0.7020, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9383/10000, Loss: 0.7020, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9384/10000, Loss: 0.7019, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9385/10000, Loss: 0.7019, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9386/10000, Loss: 0.7019, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9387/10000, Loss: 0.7019, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9388/10000, Loss: 0.7019, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9389/10000, Loss: 0.7019, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9390/10000, Loss: 0.7018, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9391/10000, Loss: 0.7018, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9392/10000, Loss: 0.7018, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9393/10000, Loss: 0.7018, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9394/10000, Loss: 0.7018, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9395/10000, Loss: 0.7018, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9396/10000, Loss: 0.7017, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9397/10000, Loss: 0.7017, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9398/10000, Loss: 0.7017, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9399/10000, Loss: 0.7017, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9400/10000, Loss: 0.7017, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9401/10000, Loss: 0.7017, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9402/10000, Loss: 0.7017, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9403/10000, Loss: 0.7016, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9404/10000, Loss: 0.7016, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9405/10000, Loss: 0.7016, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9406/10000, Loss: 0.7016, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9407/10000, Loss: 0.7016, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9408/10000, Loss: 0.7016, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9409/10000, Loss: 0.7015, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9410/10000, Loss: 0.7015, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9411/10000, Loss: 0.7015, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9412/10000, Loss: 0.7015, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9413/10000, Loss: 0.7015, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9414/10000, Loss: 0.7015, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9415/10000, Loss: 0.7014, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9416/10000, Loss: 0.7014, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9417/10000, Loss: 0.7014, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9418/10000, Loss: 0.7014, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9419/10000, Loss: 0.7014, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9420/10000, Loss: 0.7014, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9421/10000, Loss: 0.7013, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9422/10000, Loss: 0.7013, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9423/10000, Loss: 0.7013, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9424/10000, Loss: 0.7013, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9425/10000, Loss: 0.7013, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9426/10000, Loss: 0.7013, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9427/10000, Loss: 0.7012, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9428/10000, Loss: 0.7012, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9429/10000, Loss: 0.7012, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9430/10000, Loss: 0.7012, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9431/10000, Loss: 0.7012, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9432/10000, Loss: 0.7012, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9433/10000, Loss: 0.7011, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9434/10000, Loss: 0.7011, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9435/10000, Loss: 0.7011, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9436/10000, Loss: 0.7011, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9437/10000, Loss: 0.7011, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9438/10000, Loss: 0.7011, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9439/10000, Loss: 0.7011, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9440/10000, Loss: 0.7010, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9441/10000, Loss: 0.7010, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9442/10000, Loss: 0.7010, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9443/10000, Loss: 0.7010, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9444/10000, Loss: 0.7010, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9445/10000, Loss: 0.7010, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9446/10000, Loss: 0.7009, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9447/10000, Loss: 0.7009, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9448/10000, Loss: 0.7009, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9449/10000, Loss: 0.7009, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9450/10000, Loss: 0.7009, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9451/10000, Loss: 0.7009, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9452/10000, Loss: 0.7008, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9453/10000, Loss: 0.7008, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9454/10000, Loss: 0.7008, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9455/10000, Loss: 0.7008, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9456/10000, Loss: 0.7008, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9457/10000, Loss: 0.7008, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9458/10000, Loss: 0.7007, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9459/10000, Loss: 0.7007, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9460/10000, Loss: 0.7007, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9461/10000, Loss: 0.7007, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9462/10000, Loss: 0.7007, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9463/10000, Loss: 0.7007, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9464/10000, Loss: 0.7006, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9465/10000, Loss: 0.7006, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9466/10000, Loss: 0.7006, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9467/10000, Loss: 0.7006, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9468/10000, Loss: 0.7006, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9469/10000, Loss: 0.7006, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9470/10000, Loss: 0.7005, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9471/10000, Loss: 0.7005, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9472/10000, Loss: 0.7005, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9473/10000, Loss: 0.7005, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9474/10000, Loss: 0.7005, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9475/10000, Loss: 0.7005, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9476/10000, Loss: 0.7005, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9477/10000, Loss: 0.7004, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9478/10000, Loss: 0.7004, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9479/10000, Loss: 0.7004, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9480/10000, Loss: 0.7004, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9481/10000, Loss: 0.7004, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9482/10000, Loss: 0.7004, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9483/10000, Loss: 0.7003, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9484/10000, Loss: 0.7003, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9485/10000, Loss: 0.7003, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9486/10000, Loss: 0.7003, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9487/10000, Loss: 0.7003, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9488/10000, Loss: 0.7003, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9489/10000, Loss: 0.7002, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9490/10000, Loss: 0.7002, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9491/10000, Loss: 0.7002, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9492/10000, Loss: 0.7002, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9493/10000, Loss: 0.7002, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9494/10000, Loss: 0.7002, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9495/10000, Loss: 0.7001, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9496/10000, Loss: 0.7001, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9497/10000, Loss: 0.7001, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9498/10000, Loss: 0.7001, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9499/10000, Loss: 0.7001, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9500/10000, Loss: 0.7001, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9501/10000, Loss: 0.7001, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9502/10000, Loss: 0.7000, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9503/10000, Loss: 0.7000, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9504/10000, Loss: 0.7000, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9505/10000, Loss: 0.7000, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9506/10000, Loss: 0.7000, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9507/10000, Loss: 0.7000, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9508/10000, Loss: 0.6999, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9509/10000, Loss: 0.6999, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9510/10000, Loss: 0.6999, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9511/10000, Loss: 0.6999, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9512/10000, Loss: 0.6999, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9513/10000, Loss: 0.6999, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9514/10000, Loss: 0.6998, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9515/10000, Loss: 0.6998, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9516/10000, Loss: 0.6998, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9517/10000, Loss: 0.6998, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9518/10000, Loss: 0.6998, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9519/10000, Loss: 0.6998, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9520/10000, Loss: 0.6997, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9521/10000, Loss: 0.6997, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9522/10000, Loss: 0.6997, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9523/10000, Loss: 0.6997, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9524/10000, Loss: 0.6997, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9525/10000, Loss: 0.6997, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9526/10000, Loss: 0.6996, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9527/10000, Loss: 0.6996, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9528/10000, Loss: 0.6996, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9529/10000, Loss: 0.6996, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9530/10000, Loss: 0.6996, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9531/10000, Loss: 0.6996, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9532/10000, Loss: 0.6996, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9533/10000, Loss: 0.6995, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9534/10000, Loss: 0.6995, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9535/10000, Loss: 0.6995, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9536/10000, Loss: 0.6995, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9537/10000, Loss: 0.6995, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9538/10000, Loss: 0.6995, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9539/10000, Loss: 0.6994, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9540/10000, Loss: 0.6994, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9541/10000, Loss: 0.6994, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9542/10000, Loss: 0.6994, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9543/10000, Loss: 0.6994, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9544/10000, Loss: 0.6994, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9545/10000, Loss: 0.6993, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9546/10000, Loss: 0.6993, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9547/10000, Loss: 0.6993, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9548/10000, Loss: 0.6993, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9549/10000, Loss: 0.6993, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9550/10000, Loss: 0.6993, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9551/10000, Loss: 0.6992, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9552/10000, Loss: 0.6992, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9553/10000, Loss: 0.6992, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9554/10000, Loss: 0.6992, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9555/10000, Loss: 0.6992, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9556/10000, Loss: 0.6992, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9557/10000, Loss: 0.6992, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9558/10000, Loss: 0.6991, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9559/10000, Loss: 0.6991, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9560/10000, Loss: 0.6991, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9561/10000, Loss: 0.6991, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9562/10000, Loss: 0.6991, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9563/10000, Loss: 0.6991, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9564/10000, Loss: 0.6990, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9565/10000, Loss: 0.6990, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9566/10000, Loss: 0.6990, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9567/10000, Loss: 0.6990, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9568/10000, Loss: 0.6990, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9569/10000, Loss: 0.6990, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9570/10000, Loss: 0.6989, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9571/10000, Loss: 0.6989, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9572/10000, Loss: 0.6989, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9573/10000, Loss: 0.6989, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9574/10000, Loss: 0.6989, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9575/10000, Loss: 0.6989, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9576/10000, Loss: 0.6989, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9577/10000, Loss: 0.6988, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9578/10000, Loss: 0.6988, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9579/10000, Loss: 0.6988, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9580/10000, Loss: 0.6988, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9581/10000, Loss: 0.6988, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9582/10000, Loss: 0.6988, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9583/10000, Loss: 0.6987, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9584/10000, Loss: 0.6987, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9585/10000, Loss: 0.6987, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9586/10000, Loss: 0.6987, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9587/10000, Loss: 0.6987, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9588/10000, Loss: 0.6987, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9589/10000, Loss: 0.6986, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9590/10000, Loss: 0.6986, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9591/10000, Loss: 0.6986, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9592/10000, Loss: 0.6986, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9593/10000, Loss: 0.6986, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9594/10000, Loss: 0.6986, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9595/10000, Loss: 0.6985, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9596/10000, Loss: 0.6985, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9597/10000, Loss: 0.6985, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9598/10000, Loss: 0.6985, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9599/10000, Loss: 0.6985, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9600/10000, Loss: 0.6985, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9601/10000, Loss: 0.6985, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9602/10000, Loss: 0.6984, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9603/10000, Loss: 0.6984, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9604/10000, Loss: 0.6984, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9605/10000, Loss: 0.6984, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9606/10000, Loss: 0.6984, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9607/10000, Loss: 0.6984, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9608/10000, Loss: 0.6983, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9609/10000, Loss: 0.6983, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9610/10000, Loss: 0.6983, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9611/10000, Loss: 0.6983, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9612/10000, Loss: 0.6983, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9613/10000, Loss: 0.6983, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9614/10000, Loss: 0.6982, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9615/10000, Loss: 0.6982, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9616/10000, Loss: 0.6982, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9617/10000, Loss: 0.6982, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9618/10000, Loss: 0.6982, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9619/10000, Loss: 0.6982, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9620/10000, Loss: 0.6982, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9621/10000, Loss: 0.6981, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9622/10000, Loss: 0.6981, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9623/10000, Loss: 0.6981, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9624/10000, Loss: 0.6981, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9625/10000, Loss: 0.6981, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9626/10000, Loss: 0.6981, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9627/10000, Loss: 0.6980, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9628/10000, Loss: 0.6980, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9629/10000, Loss: 0.6980, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9630/10000, Loss: 0.6980, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9631/10000, Loss: 0.6980, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9632/10000, Loss: 0.6980, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9633/10000, Loss: 0.6979, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9634/10000, Loss: 0.6979, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9635/10000, Loss: 0.6979, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9636/10000, Loss: 0.6979, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9637/10000, Loss: 0.6979, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9638/10000, Loss: 0.6979, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9639/10000, Loss: 0.6979, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9640/10000, Loss: 0.6978, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9641/10000, Loss: 0.6978, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9642/10000, Loss: 0.6978, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9643/10000, Loss: 0.6978, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9644/10000, Loss: 0.6978, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9645/10000, Loss: 0.6978, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9646/10000, Loss: 0.6977, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9647/10000, Loss: 0.6977, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9648/10000, Loss: 0.6977, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9649/10000, Loss: 0.6977, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9650/10000, Loss: 0.6977, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9651/10000, Loss: 0.6977, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9652/10000, Loss: 0.6976, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9653/10000, Loss: 0.6976, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9654/10000, Loss: 0.6976, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9655/10000, Loss: 0.6976, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9656/10000, Loss: 0.6976, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9657/10000, Loss: 0.6976, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9658/10000, Loss: 0.6976, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9659/10000, Loss: 0.6975, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9660/10000, Loss: 0.6975, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9661/10000, Loss: 0.6975, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9662/10000, Loss: 0.6975, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9663/10000, Loss: 0.6975, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9664/10000, Loss: 0.6975, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9665/10000, Loss: 0.6974, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9666/10000, Loss: 0.6974, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9667/10000, Loss: 0.6974, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9668/10000, Loss: 0.6974, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9669/10000, Loss: 0.6974, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9670/10000, Loss: 0.6974, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9671/10000, Loss: 0.6973, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9672/10000, Loss: 0.6973, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9673/10000, Loss: 0.6973, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9674/10000, Loss: 0.6973, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9675/10000, Loss: 0.6973, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9676/10000, Loss: 0.6973, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9677/10000, Loss: 0.6973, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9678/10000, Loss: 0.6972, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9679/10000, Loss: 0.6972, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9680/10000, Loss: 0.6972, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9681/10000, Loss: 0.6972, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9682/10000, Loss: 0.6972, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9683/10000, Loss: 0.6972, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9684/10000, Loss: 0.6971, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9685/10000, Loss: 0.6971, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9686/10000, Loss: 0.6971, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9687/10000, Loss: 0.6971, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9688/10000, Loss: 0.6971, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9689/10000, Loss: 0.6971, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9690/10000, Loss: 0.6971, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9691/10000, Loss: 0.6970, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9692/10000, Loss: 0.6970, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9693/10000, Loss: 0.6970, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9694/10000, Loss: 0.6970, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9695/10000, Loss: 0.6970, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9696/10000, Loss: 0.6970, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9697/10000, Loss: 0.6969, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9698/10000, Loss: 0.6969, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9699/10000, Loss: 0.6969, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9700/10000, Loss: 0.6969, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9701/10000, Loss: 0.6969, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9702/10000, Loss: 0.6969, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9703/10000, Loss: 0.6968, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9704/10000, Loss: 0.6968, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9705/10000, Loss: 0.6968, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9706/10000, Loss: 0.6968, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9707/10000, Loss: 0.6968, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9708/10000, Loss: 0.6968, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9709/10000, Loss: 0.6968, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9710/10000, Loss: 0.6967, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9711/10000, Loss: 0.6967, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9712/10000, Loss: 0.6967, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9713/10000, Loss: 0.6967, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9714/10000, Loss: 0.6967, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9715/10000, Loss: 0.6967, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9716/10000, Loss: 0.6966, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9717/10000, Loss: 0.6966, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9718/10000, Loss: 0.6966, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9719/10000, Loss: 0.6966, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9720/10000, Loss: 0.6966, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9721/10000, Loss: 0.6966, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9722/10000, Loss: 0.6966, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9723/10000, Loss: 0.6965, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9724/10000, Loss: 0.6965, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9725/10000, Loss: 0.6965, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9726/10000, Loss: 0.6965, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9727/10000, Loss: 0.6965, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9728/10000, Loss: 0.6965, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9729/10000, Loss: 0.6964, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9730/10000, Loss: 0.6964, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9731/10000, Loss: 0.6964, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9732/10000, Loss: 0.6964, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9733/10000, Loss: 0.6964, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9734/10000, Loss: 0.6964, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9735/10000, Loss: 0.6963, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9736/10000, Loss: 0.6963, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9737/10000, Loss: 0.6963, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9738/10000, Loss: 0.6963, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9739/10000, Loss: 0.6963, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9740/10000, Loss: 0.6963, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9741/10000, Loss: 0.6963, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9742/10000, Loss: 0.6962, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9743/10000, Loss: 0.6962, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9744/10000, Loss: 0.6962, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9745/10000, Loss: 0.6962, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9746/10000, Loss: 0.6962, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9747/10000, Loss: 0.6962, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9748/10000, Loss: 0.6961, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9749/10000, Loss: 0.6961, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9750/10000, Loss: 0.6961, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9751/10000, Loss: 0.6961, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9752/10000, Loss: 0.6961, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9753/10000, Loss: 0.6961, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9754/10000, Loss: 0.6961, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9755/10000, Loss: 0.6960, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9756/10000, Loss: 0.6960, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9757/10000, Loss: 0.6960, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9758/10000, Loss: 0.6960, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9759/10000, Loss: 0.6960, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9760/10000, Loss: 0.6960, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9761/10000, Loss: 0.6959, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9762/10000, Loss: 0.6959, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9763/10000, Loss: 0.6959, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9764/10000, Loss: 0.6959, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9765/10000, Loss: 0.6959, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9766/10000, Loss: 0.6959, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9767/10000, Loss: 0.6959, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9768/10000, Loss: 0.6958, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9769/10000, Loss: 0.6958, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9770/10000, Loss: 0.6958, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9771/10000, Loss: 0.6958, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9772/10000, Loss: 0.6958, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9773/10000, Loss: 0.6958, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9774/10000, Loss: 0.6957, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9775/10000, Loss: 0.6957, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9776/10000, Loss: 0.6957, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9777/10000, Loss: 0.6957, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9778/10000, Loss: 0.6957, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9779/10000, Loss: 0.6957, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9780/10000, Loss: 0.6956, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9781/10000, Loss: 0.6956, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9782/10000, Loss: 0.6956, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9783/10000, Loss: 0.6956, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9784/10000, Loss: 0.6956, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9785/10000, Loss: 0.6956, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9786/10000, Loss: 0.6956, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9787/10000, Loss: 0.6955, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9788/10000, Loss: 0.6955, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9789/10000, Loss: 0.6955, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9790/10000, Loss: 0.6955, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9791/10000, Loss: 0.6955, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9792/10000, Loss: 0.6955, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9793/10000, Loss: 0.6954, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9794/10000, Loss: 0.6954, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9795/10000, Loss: 0.6954, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9796/10000, Loss: 0.6954, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9797/10000, Loss: 0.6954, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9798/10000, Loss: 0.6954, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9799/10000, Loss: 0.6954, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9800/10000, Loss: 0.6953, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9801/10000, Loss: 0.6953, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9802/10000, Loss: 0.6953, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9803/10000, Loss: 0.6953, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9804/10000, Loss: 0.6953, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9805/10000, Loss: 0.6953, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9806/10000, Loss: 0.6952, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9807/10000, Loss: 0.6952, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9808/10000, Loss: 0.6952, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9809/10000, Loss: 0.6952, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9810/10000, Loss: 0.6952, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9811/10000, Loss: 0.6952, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9812/10000, Loss: 0.6952, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9813/10000, Loss: 0.6951, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9814/10000, Loss: 0.6951, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9815/10000, Loss: 0.6951, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9816/10000, Loss: 0.6951, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9817/10000, Loss: 0.6951, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9818/10000, Loss: 0.6951, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9819/10000, Loss: 0.6950, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9820/10000, Loss: 0.6950, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9821/10000, Loss: 0.6950, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9822/10000, Loss: 0.6950, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9823/10000, Loss: 0.6950, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9824/10000, Loss: 0.6950, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9825/10000, Loss: 0.6950, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9826/10000, Loss: 0.6949, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9827/10000, Loss: 0.6949, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9828/10000, Loss: 0.6949, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9829/10000, Loss: 0.6949, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9830/10000, Loss: 0.6949, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9831/10000, Loss: 0.6949, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9832/10000, Loss: 0.6948, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9833/10000, Loss: 0.6948, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9834/10000, Loss: 0.6948, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9835/10000, Loss: 0.6948, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9836/10000, Loss: 0.6948, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9837/10000, Loss: 0.6948, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9838/10000, Loss: 0.6948, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9839/10000, Loss: 0.6947, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9840/10000, Loss: 0.6947, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9841/10000, Loss: 0.6947, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9842/10000, Loss: 0.6947, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9843/10000, Loss: 0.6947, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9844/10000, Loss: 0.6947, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9845/10000, Loss: 0.6946, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9846/10000, Loss: 0.6946, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9847/10000, Loss: 0.6946, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9848/10000, Loss: 0.6946, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9849/10000, Loss: 0.6946, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9850/10000, Loss: 0.6946, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9851/10000, Loss: 0.6946, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9852/10000, Loss: 0.6945, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9853/10000, Loss: 0.6945, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9854/10000, Loss: 0.6945, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9855/10000, Loss: 0.6945, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9856/10000, Loss: 0.6945, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9857/10000, Loss: 0.6945, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9858/10000, Loss: 0.6944, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9859/10000, Loss: 0.6944, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9860/10000, Loss: 0.6944, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9861/10000, Loss: 0.6944, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9862/10000, Loss: 0.6944, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9863/10000, Loss: 0.6944, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9864/10000, Loss: 0.6944, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9865/10000, Loss: 0.6943, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9866/10000, Loss: 0.6943, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9867/10000, Loss: 0.6943, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9868/10000, Loss: 0.6943, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9869/10000, Loss: 0.6943, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9870/10000, Loss: 0.6943, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9871/10000, Loss: 0.6942, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9872/10000, Loss: 0.6942, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9873/10000, Loss: 0.6942, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9874/10000, Loss: 0.6942, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9875/10000, Loss: 0.6942, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9876/10000, Loss: 0.6942, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9877/10000, Loss: 0.6942, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9878/10000, Loss: 0.6941, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9879/10000, Loss: 0.6941, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9880/10000, Loss: 0.6941, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9881/10000, Loss: 0.6941, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9882/10000, Loss: 0.6941, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9883/10000, Loss: 0.6941, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9884/10000, Loss: 0.6940, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9885/10000, Loss: 0.6940, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9886/10000, Loss: 0.6940, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9887/10000, Loss: 0.6940, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9888/10000, Loss: 0.6940, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9889/10000, Loss: 0.6940, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9890/10000, Loss: 0.6940, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9891/10000, Loss: 0.6939, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9892/10000, Loss: 0.6939, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9893/10000, Loss: 0.6939, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9894/10000, Loss: 0.6939, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9895/10000, Loss: 0.6939, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9896/10000, Loss: 0.6939, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9897/10000, Loss: 0.6939, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9898/10000, Loss: 0.6938, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9899/10000, Loss: 0.6938, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9900/10000, Loss: 0.6938, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9901/10000, Loss: 0.6938, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9902/10000, Loss: 0.6938, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9903/10000, Loss: 0.6938, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9904/10000, Loss: 0.6937, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9905/10000, Loss: 0.6937, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9906/10000, Loss: 0.6937, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9907/10000, Loss: 0.6937, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9908/10000, Loss: 0.6937, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9909/10000, Loss: 0.6937, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9910/10000, Loss: 0.6937, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9911/10000, Loss: 0.6936, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9912/10000, Loss: 0.6936, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9913/10000, Loss: 0.6936, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9914/10000, Loss: 0.6936, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9915/10000, Loss: 0.6936, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9916/10000, Loss: 0.6936, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9917/10000, Loss: 0.6935, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9918/10000, Loss: 0.6935, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9919/10000, Loss: 0.6935, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9920/10000, Loss: 0.6935, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9921/10000, Loss: 0.6935, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9922/10000, Loss: 0.6935, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9923/10000, Loss: 0.6935, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9924/10000, Loss: 0.6934, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9925/10000, Loss: 0.6934, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9926/10000, Loss: 0.6934, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9927/10000, Loss: 0.6934, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9928/10000, Loss: 0.6934, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9929/10000, Loss: 0.6934, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9930/10000, Loss: 0.6933, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9931/10000, Loss: 0.6933, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9932/10000, Loss: 0.6933, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9933/10000, Loss: 0.6933, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9934/10000, Loss: 0.6933, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9935/10000, Loss: 0.6933, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9936/10000, Loss: 0.6933, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9937/10000, Loss: 0.6932, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9938/10000, Loss: 0.6932, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9939/10000, Loss: 0.6932, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9940/10000, Loss: 0.6932, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9941/10000, Loss: 0.6932, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9942/10000, Loss: 0.6932, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9943/10000, Loss: 0.6932, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9944/10000, Loss: 0.6931, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9945/10000, Loss: 0.6931, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9946/10000, Loss: 0.6931, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9947/10000, Loss: 0.6931, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9948/10000, Loss: 0.6931, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9949/10000, Loss: 0.6931, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9950/10000, Loss: 0.6930, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9951/10000, Loss: 0.6930, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9952/10000, Loss: 0.6930, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9953/10000, Loss: 0.6930, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9954/10000, Loss: 0.6930, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9955/10000, Loss: 0.6930, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9956/10000, Loss: 0.6930, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9957/10000, Loss: 0.6929, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9958/10000, Loss: 0.6929, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9959/10000, Loss: 0.6929, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9960/10000, Loss: 0.6929, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9961/10000, Loss: 0.6929, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9962/10000, Loss: 0.6929, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9963/10000, Loss: 0.6928, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9964/10000, Loss: 0.6928, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9965/10000, Loss: 0.6928, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9966/10000, Loss: 0.6928, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9967/10000, Loss: 0.6928, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9968/10000, Loss: 0.6928, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9969/10000, Loss: 0.6928, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9970/10000, Loss: 0.6927, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9971/10000, Loss: 0.6927, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9972/10000, Loss: 0.6927, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9973/10000, Loss: 0.6927, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9974/10000, Loss: 0.6927, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9975/10000, Loss: 0.6927, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9976/10000, Loss: 0.6927, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9977/10000, Loss: 0.6926, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9978/10000, Loss: 0.6926, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9979/10000, Loss: 0.6926, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9980/10000, Loss: 0.6926, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9981/10000, Loss: 0.6926, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9982/10000, Loss: 0.6926, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9983/10000, Loss: 0.6925, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9984/10000, Loss: 0.6925, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9985/10000, Loss: 0.6925, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9986/10000, Loss: 0.6925, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9987/10000, Loss: 0.6925, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9988/10000, Loss: 0.6925, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9989/10000, Loss: 0.6925, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9990/10000, Loss: 0.6924, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9991/10000, Loss: 0.6924, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9992/10000, Loss: 0.6924, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9993/10000, Loss: 0.6924, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9994/10000, Loss: 0.6924, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9995/10000, Loss: 0.6924, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9996/10000, Loss: 0.6924, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9997/10000, Loss: 0.6923, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9998/10000, Loss: 0.6923, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9999/10000, Loss: 0.6923, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 10000/10000, Loss: 0.6923, Accuracy: 0.6853, Learning Rate: 0.000100\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(0.0001,10000)\n",
    "\n",
    "lr.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f1a89f6-04e4-44b4-adea-941c8c2e1f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#training loss vs training accuracy\n",
    "\n",
    "lr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3ba315f-cca2-4d54-95ab-0df9c890a1d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000, Loss: 0.8611, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2/10000, Loss: 0.8540, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3/10000, Loss: 0.8502, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4/10000, Loss: 0.8475, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5/10000, Loss: 0.8455, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6/10000, Loss: 0.8439, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7/10000, Loss: 0.8427, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 8/10000, Loss: 0.8417, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 9/10000, Loss: 0.8409, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 10/10000, Loss: 0.8403, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 11/10000, Loss: 0.8397, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 12/10000, Loss: 0.8393, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 13/10000, Loss: 0.8389, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 14/10000, Loss: 0.8385, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 15/10000, Loss: 0.8382, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 16/10000, Loss: 0.8379, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 17/10000, Loss: 0.8376, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 18/10000, Loss: 0.8373, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 19/10000, Loss: 0.8370, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 20/10000, Loss: 0.8368, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 21/10000, Loss: 0.8365, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 22/10000, Loss: 0.8363, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 23/10000, Loss: 0.8360, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 24/10000, Loss: 0.8358, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 25/10000, Loss: 0.8356, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 26/10000, Loss: 0.8353, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 27/10000, Loss: 0.8351, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 28/10000, Loss: 0.8349, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 29/10000, Loss: 0.8346, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 30/10000, Loss: 0.8344, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 31/10000, Loss: 0.8342, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 32/10000, Loss: 0.8340, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 33/10000, Loss: 0.8337, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 34/10000, Loss: 0.8335, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 35/10000, Loss: 0.8333, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 36/10000, Loss: 0.8331, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 37/10000, Loss: 0.8329, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 38/10000, Loss: 0.8326, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 39/10000, Loss: 0.8324, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 40/10000, Loss: 0.8322, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 41/10000, Loss: 0.8320, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 42/10000, Loss: 0.8318, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 43/10000, Loss: 0.8316, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 44/10000, Loss: 0.8314, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 45/10000, Loss: 0.8312, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 46/10000, Loss: 0.8310, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 47/10000, Loss: 0.8307, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 48/10000, Loss: 0.8305, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 49/10000, Loss: 0.8303, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 50/10000, Loss: 0.8301, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 51/10000, Loss: 0.8299, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 52/10000, Loss: 0.8297, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 53/10000, Loss: 0.8295, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 54/10000, Loss: 0.8293, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 55/10000, Loss: 0.8291, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 56/10000, Loss: 0.8289, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 57/10000, Loss: 0.8288, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 58/10000, Loss: 0.8286, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 59/10000, Loss: 0.8284, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 60/10000, Loss: 0.8282, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 61/10000, Loss: 0.8280, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 62/10000, Loss: 0.8278, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 63/10000, Loss: 0.8276, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 64/10000, Loss: 0.8274, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 65/10000, Loss: 0.8272, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 66/10000, Loss: 0.8270, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 67/10000, Loss: 0.8268, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 68/10000, Loss: 0.8267, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 69/10000, Loss: 0.8265, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 70/10000, Loss: 0.8263, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 71/10000, Loss: 0.8261, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 72/10000, Loss: 0.8259, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 73/10000, Loss: 0.8257, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 74/10000, Loss: 0.8256, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 75/10000, Loss: 0.8254, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 76/10000, Loss: 0.8252, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 77/10000, Loss: 0.8250, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 78/10000, Loss: 0.8249, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 79/10000, Loss: 0.8247, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 80/10000, Loss: 0.8245, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 81/10000, Loss: 0.8243, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 82/10000, Loss: 0.8242, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 83/10000, Loss: 0.8240, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 84/10000, Loss: 0.8238, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 85/10000, Loss: 0.8236, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 86/10000, Loss: 0.8235, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 87/10000, Loss: 0.8233, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 88/10000, Loss: 0.8231, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 89/10000, Loss: 0.8230, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 90/10000, Loss: 0.8228, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 91/10000, Loss: 0.8226, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 92/10000, Loss: 0.8225, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 93/10000, Loss: 0.8223, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 94/10000, Loss: 0.8221, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 95/10000, Loss: 0.8220, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 96/10000, Loss: 0.8218, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 97/10000, Loss: 0.8216, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 98/10000, Loss: 0.8215, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 99/10000, Loss: 0.8213, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 100/10000, Loss: 0.8211, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 101/10000, Loss: 0.8210, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 102/10000, Loss: 0.8208, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 103/10000, Loss: 0.8207, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 104/10000, Loss: 0.8205, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 105/10000, Loss: 0.8203, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 106/10000, Loss: 0.8202, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 107/10000, Loss: 0.8200, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 108/10000, Loss: 0.8199, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 109/10000, Loss: 0.8197, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 110/10000, Loss: 0.8195, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 111/10000, Loss: 0.8194, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 112/10000, Loss: 0.8192, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 113/10000, Loss: 0.8191, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 114/10000, Loss: 0.8189, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 115/10000, Loss: 0.8188, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 116/10000, Loss: 0.8186, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 117/10000, Loss: 0.8185, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 118/10000, Loss: 0.8183, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 119/10000, Loss: 0.8182, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 120/10000, Loss: 0.8180, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 121/10000, Loss: 0.8179, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 122/10000, Loss: 0.8177, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 123/10000, Loss: 0.8176, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 124/10000, Loss: 0.8174, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 125/10000, Loss: 0.8173, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 126/10000, Loss: 0.8171, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 127/10000, Loss: 0.8170, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 128/10000, Loss: 0.8168, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 129/10000, Loss: 0.8167, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 130/10000, Loss: 0.8165, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 131/10000, Loss: 0.8164, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 132/10000, Loss: 0.8162, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 133/10000, Loss: 0.8161, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 134/10000, Loss: 0.8160, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 135/10000, Loss: 0.8158, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 136/10000, Loss: 0.8157, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 137/10000, Loss: 0.8155, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 138/10000, Loss: 0.8154, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 139/10000, Loss: 0.8152, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 140/10000, Loss: 0.8151, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 141/10000, Loss: 0.8150, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 142/10000, Loss: 0.8148, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 143/10000, Loss: 0.8147, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 144/10000, Loss: 0.8145, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 145/10000, Loss: 0.8144, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 146/10000, Loss: 0.8143, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 147/10000, Loss: 0.8141, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 148/10000, Loss: 0.8140, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 149/10000, Loss: 0.8139, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 150/10000, Loss: 0.8137, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 151/10000, Loss: 0.8136, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 152/10000, Loss: 0.8134, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 153/10000, Loss: 0.8133, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 154/10000, Loss: 0.8132, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 155/10000, Loss: 0.8130, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 156/10000, Loss: 0.8129, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 157/10000, Loss: 0.8128, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 158/10000, Loss: 0.8126, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 159/10000, Loss: 0.8125, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 160/10000, Loss: 0.8124, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 161/10000, Loss: 0.8122, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 162/10000, Loss: 0.8121, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 163/10000, Loss: 0.8120, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 164/10000, Loss: 0.8118, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 165/10000, Loss: 0.8117, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 166/10000, Loss: 0.8116, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 167/10000, Loss: 0.8114, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 168/10000, Loss: 0.8113, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 169/10000, Loss: 0.8112, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 170/10000, Loss: 0.8111, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 171/10000, Loss: 0.8109, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 172/10000, Loss: 0.8108, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 173/10000, Loss: 0.8107, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 174/10000, Loss: 0.8105, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 175/10000, Loss: 0.8104, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 176/10000, Loss: 0.8103, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 177/10000, Loss: 0.8102, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 178/10000, Loss: 0.8100, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 179/10000, Loss: 0.8099, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 180/10000, Loss: 0.8098, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 181/10000, Loss: 0.8096, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 182/10000, Loss: 0.8095, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 183/10000, Loss: 0.8094, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 184/10000, Loss: 0.8093, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 185/10000, Loss: 0.8091, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 186/10000, Loss: 0.8090, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 187/10000, Loss: 0.8089, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 188/10000, Loss: 0.8088, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 189/10000, Loss: 0.8087, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 190/10000, Loss: 0.8085, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 191/10000, Loss: 0.8084, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 192/10000, Loss: 0.8083, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 193/10000, Loss: 0.8082, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 194/10000, Loss: 0.8080, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 195/10000, Loss: 0.8079, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 196/10000, Loss: 0.8078, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 197/10000, Loss: 0.8077, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 198/10000, Loss: 0.8076, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 199/10000, Loss: 0.8074, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 200/10000, Loss: 0.8073, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 201/10000, Loss: 0.8072, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 202/10000, Loss: 0.8071, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 203/10000, Loss: 0.8070, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 204/10000, Loss: 0.8068, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 205/10000, Loss: 0.8067, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 206/10000, Loss: 0.8066, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 207/10000, Loss: 0.8065, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 208/10000, Loss: 0.8064, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 209/10000, Loss: 0.8062, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 210/10000, Loss: 0.8061, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 211/10000, Loss: 0.8060, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 212/10000, Loss: 0.8059, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 213/10000, Loss: 0.8058, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 214/10000, Loss: 0.8057, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 215/10000, Loss: 0.8055, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 216/10000, Loss: 0.8054, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 217/10000, Loss: 0.8053, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 218/10000, Loss: 0.8052, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 219/10000, Loss: 0.8051, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 220/10000, Loss: 0.8050, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 221/10000, Loss: 0.8048, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 222/10000, Loss: 0.8047, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 223/10000, Loss: 0.8046, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 224/10000, Loss: 0.8045, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 225/10000, Loss: 0.8044, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 226/10000, Loss: 0.8043, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 227/10000, Loss: 0.8042, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 228/10000, Loss: 0.8041, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 229/10000, Loss: 0.8039, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 230/10000, Loss: 0.8038, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 231/10000, Loss: 0.8037, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 232/10000, Loss: 0.8036, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 233/10000, Loss: 0.8035, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 234/10000, Loss: 0.8034, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 235/10000, Loss: 0.8033, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 236/10000, Loss: 0.8032, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 237/10000, Loss: 0.8030, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 238/10000, Loss: 0.8029, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 239/10000, Loss: 0.8028, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 240/10000, Loss: 0.8027, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 241/10000, Loss: 0.8026, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 242/10000, Loss: 0.8025, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 243/10000, Loss: 0.8024, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 244/10000, Loss: 0.8023, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 245/10000, Loss: 0.8022, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 246/10000, Loss: 0.8021, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 247/10000, Loss: 0.8019, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 248/10000, Loss: 0.8018, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 249/10000, Loss: 0.8017, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 250/10000, Loss: 0.8016, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 251/10000, Loss: 0.8015, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 252/10000, Loss: 0.8014, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 253/10000, Loss: 0.8013, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 254/10000, Loss: 0.8012, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 255/10000, Loss: 0.8011, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 256/10000, Loss: 0.8010, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 257/10000, Loss: 0.8009, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 258/10000, Loss: 0.8008, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 259/10000, Loss: 0.8007, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 260/10000, Loss: 0.8005, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 261/10000, Loss: 0.8004, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 262/10000, Loss: 0.8003, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 263/10000, Loss: 0.8002, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 264/10000, Loss: 0.8001, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 265/10000, Loss: 0.8000, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 266/10000, Loss: 0.7999, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 267/10000, Loss: 0.7998, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 268/10000, Loss: 0.7997, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 269/10000, Loss: 0.7996, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 270/10000, Loss: 0.7995, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 271/10000, Loss: 0.7994, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 272/10000, Loss: 0.7993, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 273/10000, Loss: 0.7992, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 274/10000, Loss: 0.7991, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 275/10000, Loss: 0.7990, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 276/10000, Loss: 0.7989, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 277/10000, Loss: 0.7988, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 278/10000, Loss: 0.7987, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 279/10000, Loss: 0.7986, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 280/10000, Loss: 0.7985, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 281/10000, Loss: 0.7984, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 282/10000, Loss: 0.7983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 283/10000, Loss: 0.7982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 284/10000, Loss: 0.7981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 285/10000, Loss: 0.7979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 286/10000, Loss: 0.7978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 287/10000, Loss: 0.7977, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 288/10000, Loss: 0.7976, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 289/10000, Loss: 0.7975, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 290/10000, Loss: 0.7974, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 291/10000, Loss: 0.7973, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 292/10000, Loss: 0.7972, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 293/10000, Loss: 0.7971, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 294/10000, Loss: 0.7970, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 295/10000, Loss: 0.7969, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 296/10000, Loss: 0.7968, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 297/10000, Loss: 0.7967, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 298/10000, Loss: 0.7966, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 299/10000, Loss: 0.7965, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 300/10000, Loss: 0.7964, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 301/10000, Loss: 0.7963, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 302/10000, Loss: 0.7962, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 303/10000, Loss: 0.7961, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 304/10000, Loss: 0.7961, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 305/10000, Loss: 0.7960, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 306/10000, Loss: 0.7959, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 307/10000, Loss: 0.7958, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 308/10000, Loss: 0.7957, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 309/10000, Loss: 0.7956, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 310/10000, Loss: 0.7955, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 311/10000, Loss: 0.7954, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 312/10000, Loss: 0.7953, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 313/10000, Loss: 0.7952, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 314/10000, Loss: 0.7951, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 315/10000, Loss: 0.7950, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 316/10000, Loss: 0.7949, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 317/10000, Loss: 0.7948, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 318/10000, Loss: 0.7947, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 319/10000, Loss: 0.7946, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 320/10000, Loss: 0.7945, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 321/10000, Loss: 0.7944, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 322/10000, Loss: 0.7943, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 323/10000, Loss: 0.7942, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 324/10000, Loss: 0.7941, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 325/10000, Loss: 0.7940, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 326/10000, Loss: 0.7939, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 327/10000, Loss: 0.7938, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 328/10000, Loss: 0.7937, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 329/10000, Loss: 0.7936, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 330/10000, Loss: 0.7935, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 331/10000, Loss: 0.7934, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 332/10000, Loss: 0.7934, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 333/10000, Loss: 0.7933, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 334/10000, Loss: 0.7932, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 335/10000, Loss: 0.7931, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 336/10000, Loss: 0.7930, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 337/10000, Loss: 0.7929, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 338/10000, Loss: 0.7928, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 339/10000, Loss: 0.7927, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 340/10000, Loss: 0.7926, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 341/10000, Loss: 0.7925, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 342/10000, Loss: 0.7924, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 343/10000, Loss: 0.7923, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 344/10000, Loss: 0.7922, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 345/10000, Loss: 0.7921, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 346/10000, Loss: 0.7921, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 347/10000, Loss: 0.7920, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 348/10000, Loss: 0.7919, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 349/10000, Loss: 0.7918, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 350/10000, Loss: 0.7917, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 351/10000, Loss: 0.7916, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 352/10000, Loss: 0.7915, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 353/10000, Loss: 0.7914, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 354/10000, Loss: 0.7913, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 355/10000, Loss: 0.7912, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 356/10000, Loss: 0.7911, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 357/10000, Loss: 0.7910, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 358/10000, Loss: 0.7910, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 359/10000, Loss: 0.7909, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 360/10000, Loss: 0.7908, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 361/10000, Loss: 0.7907, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 362/10000, Loss: 0.7906, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 363/10000, Loss: 0.7905, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 364/10000, Loss: 0.7904, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 365/10000, Loss: 0.7903, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 366/10000, Loss: 0.7902, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 367/10000, Loss: 0.7901, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 368/10000, Loss: 0.7901, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 369/10000, Loss: 0.7900, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 370/10000, Loss: 0.7899, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 371/10000, Loss: 0.7898, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 372/10000, Loss: 0.7897, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 373/10000, Loss: 0.7896, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 374/10000, Loss: 0.7895, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 375/10000, Loss: 0.7894, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 376/10000, Loss: 0.7893, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 377/10000, Loss: 0.7893, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 378/10000, Loss: 0.7892, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 379/10000, Loss: 0.7891, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 380/10000, Loss: 0.7890, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 381/10000, Loss: 0.7889, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 382/10000, Loss: 0.7888, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 383/10000, Loss: 0.7887, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 384/10000, Loss: 0.7886, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 385/10000, Loss: 0.7886, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 386/10000, Loss: 0.7885, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 387/10000, Loss: 0.7884, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 388/10000, Loss: 0.7883, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 389/10000, Loss: 0.7882, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 390/10000, Loss: 0.7881, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 391/10000, Loss: 0.7880, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 392/10000, Loss: 0.7879, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 393/10000, Loss: 0.7879, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 394/10000, Loss: 0.7878, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 395/10000, Loss: 0.7877, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 396/10000, Loss: 0.7876, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 397/10000, Loss: 0.7875, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 398/10000, Loss: 0.7874, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 399/10000, Loss: 0.7873, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 400/10000, Loss: 0.7873, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 401/10000, Loss: 0.7872, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 402/10000, Loss: 0.7871, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 403/10000, Loss: 0.7870, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 404/10000, Loss: 0.7869, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 405/10000, Loss: 0.7868, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 406/10000, Loss: 0.7867, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 407/10000, Loss: 0.7867, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 408/10000, Loss: 0.7866, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 409/10000, Loss: 0.7865, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 410/10000, Loss: 0.7864, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 411/10000, Loss: 0.7863, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 412/10000, Loss: 0.7862, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 413/10000, Loss: 0.7862, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 414/10000, Loss: 0.7861, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 415/10000, Loss: 0.7860, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 416/10000, Loss: 0.7859, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 417/10000, Loss: 0.7858, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 418/10000, Loss: 0.7857, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 419/10000, Loss: 0.7857, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 420/10000, Loss: 0.7856, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 421/10000, Loss: 0.7855, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 422/10000, Loss: 0.7854, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 423/10000, Loss: 0.7853, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 424/10000, Loss: 0.7852, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 425/10000, Loss: 0.7852, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 426/10000, Loss: 0.7851, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 427/10000, Loss: 0.7850, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 428/10000, Loss: 0.7849, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 429/10000, Loss: 0.7848, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 430/10000, Loss: 0.7847, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 431/10000, Loss: 0.7847, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 432/10000, Loss: 0.7846, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 433/10000, Loss: 0.7845, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 434/10000, Loss: 0.7844, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 435/10000, Loss: 0.7843, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 436/10000, Loss: 0.7842, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 437/10000, Loss: 0.7842, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 438/10000, Loss: 0.7841, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 439/10000, Loss: 0.7840, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 440/10000, Loss: 0.7839, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 441/10000, Loss: 0.7838, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 442/10000, Loss: 0.7838, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 443/10000, Loss: 0.7837, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 444/10000, Loss: 0.7836, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 445/10000, Loss: 0.7835, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 446/10000, Loss: 0.7834, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 447/10000, Loss: 0.7834, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 448/10000, Loss: 0.7833, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 449/10000, Loss: 0.7832, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 450/10000, Loss: 0.7831, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 451/10000, Loss: 0.7830, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 452/10000, Loss: 0.7830, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 453/10000, Loss: 0.7829, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 454/10000, Loss: 0.7828, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 455/10000, Loss: 0.7827, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 456/10000, Loss: 0.7826, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 457/10000, Loss: 0.7826, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 458/10000, Loss: 0.7825, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 459/10000, Loss: 0.7824, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 460/10000, Loss: 0.7823, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 461/10000, Loss: 0.7822, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 462/10000, Loss: 0.7822, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 463/10000, Loss: 0.7821, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 464/10000, Loss: 0.7820, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 465/10000, Loss: 0.7819, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 466/10000, Loss: 0.7818, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 467/10000, Loss: 0.7818, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 468/10000, Loss: 0.7817, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 469/10000, Loss: 0.7816, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 470/10000, Loss: 0.7815, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 471/10000, Loss: 0.7814, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 472/10000, Loss: 0.7814, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 473/10000, Loss: 0.7813, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 474/10000, Loss: 0.7812, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 475/10000, Loss: 0.7811, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 476/10000, Loss: 0.7811, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 477/10000, Loss: 0.7810, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 478/10000, Loss: 0.7809, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 479/10000, Loss: 0.7808, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 480/10000, Loss: 0.7807, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 481/10000, Loss: 0.7807, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 482/10000, Loss: 0.7806, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 483/10000, Loss: 0.7805, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 484/10000, Loss: 0.7804, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 485/10000, Loss: 0.7804, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 486/10000, Loss: 0.7803, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 487/10000, Loss: 0.7802, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 488/10000, Loss: 0.7801, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 489/10000, Loss: 0.7801, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 490/10000, Loss: 0.7800, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 491/10000, Loss: 0.7799, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 492/10000, Loss: 0.7798, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 493/10000, Loss: 0.7797, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 494/10000, Loss: 0.7797, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 495/10000, Loss: 0.7796, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 496/10000, Loss: 0.7795, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 497/10000, Loss: 0.7794, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 498/10000, Loss: 0.7794, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 499/10000, Loss: 0.7793, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 500/10000, Loss: 0.7792, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 501/10000, Loss: 0.7791, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 502/10000, Loss: 0.7791, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 503/10000, Loss: 0.7790, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 504/10000, Loss: 0.7789, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 505/10000, Loss: 0.7788, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 506/10000, Loss: 0.7788, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 507/10000, Loss: 0.7787, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 508/10000, Loss: 0.7786, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 509/10000, Loss: 0.7785, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 510/10000, Loss: 0.7785, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 511/10000, Loss: 0.7784, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 512/10000, Loss: 0.7783, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 513/10000, Loss: 0.7782, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 514/10000, Loss: 0.7782, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 515/10000, Loss: 0.7781, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 516/10000, Loss: 0.7780, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 517/10000, Loss: 0.7779, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 518/10000, Loss: 0.7779, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 519/10000, Loss: 0.7778, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 520/10000, Loss: 0.7777, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 521/10000, Loss: 0.7776, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 522/10000, Loss: 0.7776, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 523/10000, Loss: 0.7775, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 524/10000, Loss: 0.7774, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 525/10000, Loss: 0.7773, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 526/10000, Loss: 0.7773, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 527/10000, Loss: 0.7772, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 528/10000, Loss: 0.7771, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 529/10000, Loss: 0.7770, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 530/10000, Loss: 0.7770, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 531/10000, Loss: 0.7769, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 532/10000, Loss: 0.7768, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 533/10000, Loss: 0.7768, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 534/10000, Loss: 0.7767, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 535/10000, Loss: 0.7766, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 536/10000, Loss: 0.7765, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 537/10000, Loss: 0.7765, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 538/10000, Loss: 0.7764, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 539/10000, Loss: 0.7763, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 540/10000, Loss: 0.7762, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 541/10000, Loss: 0.7762, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 542/10000, Loss: 0.7761, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 543/10000, Loss: 0.7760, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 544/10000, Loss: 0.7760, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 545/10000, Loss: 0.7759, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 546/10000, Loss: 0.7758, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 547/10000, Loss: 0.7757, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 548/10000, Loss: 0.7757, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 549/10000, Loss: 0.7756, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 550/10000, Loss: 0.7755, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 551/10000, Loss: 0.7755, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 552/10000, Loss: 0.7754, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 553/10000, Loss: 0.7753, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 554/10000, Loss: 0.7752, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 555/10000, Loss: 0.7752, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 556/10000, Loss: 0.7751, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 557/10000, Loss: 0.7750, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 558/10000, Loss: 0.7750, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 559/10000, Loss: 0.7749, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 560/10000, Loss: 0.7748, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 561/10000, Loss: 0.7747, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 562/10000, Loss: 0.7747, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 563/10000, Loss: 0.7746, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 564/10000, Loss: 0.7745, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 565/10000, Loss: 0.7745, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 566/10000, Loss: 0.7744, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 567/10000, Loss: 0.7743, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 568/10000, Loss: 0.7742, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 569/10000, Loss: 0.7742, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 570/10000, Loss: 0.7741, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 571/10000, Loss: 0.7740, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 572/10000, Loss: 0.7740, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 573/10000, Loss: 0.7739, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 574/10000, Loss: 0.7738, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 575/10000, Loss: 0.7738, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 576/10000, Loss: 0.7737, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 577/10000, Loss: 0.7736, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 578/10000, Loss: 0.7735, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 579/10000, Loss: 0.7735, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 580/10000, Loss: 0.7734, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 581/10000, Loss: 0.7733, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 582/10000, Loss: 0.7733, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 583/10000, Loss: 0.7732, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 584/10000, Loss: 0.7731, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 585/10000, Loss: 0.7731, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 586/10000, Loss: 0.7730, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 587/10000, Loss: 0.7729, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 588/10000, Loss: 0.7728, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 589/10000, Loss: 0.7728, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 590/10000, Loss: 0.7727, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 591/10000, Loss: 0.7726, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 592/10000, Loss: 0.7726, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 593/10000, Loss: 0.7725, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 594/10000, Loss: 0.7724, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 595/10000, Loss: 0.7724, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 596/10000, Loss: 0.7723, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 597/10000, Loss: 0.7722, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 598/10000, Loss: 0.7722, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 599/10000, Loss: 0.7721, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 600/10000, Loss: 0.7720, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 601/10000, Loss: 0.7720, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 602/10000, Loss: 0.7719, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 603/10000, Loss: 0.7718, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 604/10000, Loss: 0.7718, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 605/10000, Loss: 0.7717, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 606/10000, Loss: 0.7716, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 607/10000, Loss: 0.7715, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 608/10000, Loss: 0.7715, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 609/10000, Loss: 0.7714, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 610/10000, Loss: 0.7713, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 611/10000, Loss: 0.7713, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 612/10000, Loss: 0.7712, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 613/10000, Loss: 0.7711, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 614/10000, Loss: 0.7711, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 615/10000, Loss: 0.7710, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 616/10000, Loss: 0.7709, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 617/10000, Loss: 0.7709, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 618/10000, Loss: 0.7708, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 619/10000, Loss: 0.7707, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 620/10000, Loss: 0.7707, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 621/10000, Loss: 0.7706, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 622/10000, Loss: 0.7705, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 623/10000, Loss: 0.7705, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 624/10000, Loss: 0.7704, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 625/10000, Loss: 0.7703, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 626/10000, Loss: 0.7703, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 627/10000, Loss: 0.7702, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 628/10000, Loss: 0.7701, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 629/10000, Loss: 0.7701, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 630/10000, Loss: 0.7700, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 631/10000, Loss: 0.7699, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 632/10000, Loss: 0.7699, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 633/10000, Loss: 0.7698, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 634/10000, Loss: 0.7697, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 635/10000, Loss: 0.7697, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 636/10000, Loss: 0.7696, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 637/10000, Loss: 0.7695, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 638/10000, Loss: 0.7695, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 639/10000, Loss: 0.7694, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 640/10000, Loss: 0.7693, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 641/10000, Loss: 0.7693, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 642/10000, Loss: 0.7692, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 643/10000, Loss: 0.7691, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 644/10000, Loss: 0.7691, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 645/10000, Loss: 0.7690, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 646/10000, Loss: 0.7690, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 647/10000, Loss: 0.7689, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 648/10000, Loss: 0.7688, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 649/10000, Loss: 0.7688, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 650/10000, Loss: 0.7687, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 651/10000, Loss: 0.7686, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 652/10000, Loss: 0.7686, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 653/10000, Loss: 0.7685, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 654/10000, Loss: 0.7684, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 655/10000, Loss: 0.7684, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 656/10000, Loss: 0.7683, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 657/10000, Loss: 0.7682, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 658/10000, Loss: 0.7682, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 659/10000, Loss: 0.7681, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 660/10000, Loss: 0.7680, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 661/10000, Loss: 0.7680, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 662/10000, Loss: 0.7679, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 663/10000, Loss: 0.7679, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 664/10000, Loss: 0.7678, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 665/10000, Loss: 0.7677, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 666/10000, Loss: 0.7677, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 667/10000, Loss: 0.7676, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 668/10000, Loss: 0.7675, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 669/10000, Loss: 0.7675, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 670/10000, Loss: 0.7674, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 671/10000, Loss: 0.7673, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 672/10000, Loss: 0.7673, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 673/10000, Loss: 0.7672, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 674/10000, Loss: 0.7671, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 675/10000, Loss: 0.7671, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 676/10000, Loss: 0.7670, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 677/10000, Loss: 0.7670, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 678/10000, Loss: 0.7669, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 679/10000, Loss: 0.7668, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 680/10000, Loss: 0.7668, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 681/10000, Loss: 0.7667, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 682/10000, Loss: 0.7666, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 683/10000, Loss: 0.7666, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 684/10000, Loss: 0.7665, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 685/10000, Loss: 0.7664, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 686/10000, Loss: 0.7664, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 687/10000, Loss: 0.7663, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 688/10000, Loss: 0.7663, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 689/10000, Loss: 0.7662, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 690/10000, Loss: 0.7661, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 691/10000, Loss: 0.7661, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 692/10000, Loss: 0.7660, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 693/10000, Loss: 0.7659, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 694/10000, Loss: 0.7659, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 695/10000, Loss: 0.7658, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 696/10000, Loss: 0.7658, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 697/10000, Loss: 0.7657, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 698/10000, Loss: 0.7656, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 699/10000, Loss: 0.7656, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 700/10000, Loss: 0.7655, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 701/10000, Loss: 0.7654, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 702/10000, Loss: 0.7654, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 703/10000, Loss: 0.7653, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 704/10000, Loss: 0.7653, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 705/10000, Loss: 0.7652, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 706/10000, Loss: 0.7651, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 707/10000, Loss: 0.7651, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 708/10000, Loss: 0.7650, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 709/10000, Loss: 0.7650, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 710/10000, Loss: 0.7649, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 711/10000, Loss: 0.7648, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 712/10000, Loss: 0.7648, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 713/10000, Loss: 0.7647, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 714/10000, Loss: 0.7646, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 715/10000, Loss: 0.7646, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 716/10000, Loss: 0.7645, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 717/10000, Loss: 0.7645, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 718/10000, Loss: 0.7644, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 719/10000, Loss: 0.7643, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 720/10000, Loss: 0.7643, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 721/10000, Loss: 0.7642, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 722/10000, Loss: 0.7642, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 723/10000, Loss: 0.7641, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 724/10000, Loss: 0.7640, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 725/10000, Loss: 0.7640, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 726/10000, Loss: 0.7639, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 727/10000, Loss: 0.7638, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 728/10000, Loss: 0.7638, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 729/10000, Loss: 0.7637, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 730/10000, Loss: 0.7637, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 731/10000, Loss: 0.7636, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 732/10000, Loss: 0.7635, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 733/10000, Loss: 0.7635, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 734/10000, Loss: 0.7634, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 735/10000, Loss: 0.7634, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 736/10000, Loss: 0.7633, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 737/10000, Loss: 0.7632, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 738/10000, Loss: 0.7632, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 739/10000, Loss: 0.7631, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 740/10000, Loss: 0.7631, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 741/10000, Loss: 0.7630, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 742/10000, Loss: 0.7629, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 743/10000, Loss: 0.7629, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 744/10000, Loss: 0.7628, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 745/10000, Loss: 0.7628, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 746/10000, Loss: 0.7627, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 747/10000, Loss: 0.7626, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 748/10000, Loss: 0.7626, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 749/10000, Loss: 0.7625, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 750/10000, Loss: 0.7625, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 751/10000, Loss: 0.7624, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 752/10000, Loss: 0.7623, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 753/10000, Loss: 0.7623, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 754/10000, Loss: 0.7622, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 755/10000, Loss: 0.7622, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 756/10000, Loss: 0.7621, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 757/10000, Loss: 0.7620, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 758/10000, Loss: 0.7620, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 759/10000, Loss: 0.7619, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 760/10000, Loss: 0.7619, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 761/10000, Loss: 0.7618, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 762/10000, Loss: 0.7618, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 763/10000, Loss: 0.7617, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 764/10000, Loss: 0.7616, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 765/10000, Loss: 0.7616, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 766/10000, Loss: 0.7615, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 767/10000, Loss: 0.7615, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 768/10000, Loss: 0.7614, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 769/10000, Loss: 0.7613, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 770/10000, Loss: 0.7613, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 771/10000, Loss: 0.7612, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 772/10000, Loss: 0.7612, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 773/10000, Loss: 0.7611, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 774/10000, Loss: 0.7610, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 775/10000, Loss: 0.7610, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 776/10000, Loss: 0.7609, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 777/10000, Loss: 0.7609, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 778/10000, Loss: 0.7608, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 779/10000, Loss: 0.7608, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 780/10000, Loss: 0.7607, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 781/10000, Loss: 0.7606, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 782/10000, Loss: 0.7606, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 783/10000, Loss: 0.7605, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 784/10000, Loss: 0.7605, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 785/10000, Loss: 0.7604, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 786/10000, Loss: 0.7603, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 787/10000, Loss: 0.7603, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 788/10000, Loss: 0.7602, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 789/10000, Loss: 0.7602, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 790/10000, Loss: 0.7601, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 791/10000, Loss: 0.7601, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 792/10000, Loss: 0.7600, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 793/10000, Loss: 0.7599, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 794/10000, Loss: 0.7599, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 795/10000, Loss: 0.7598, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 796/10000, Loss: 0.7598, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 797/10000, Loss: 0.7597, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 798/10000, Loss: 0.7597, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 799/10000, Loss: 0.7596, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 800/10000, Loss: 0.7595, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 801/10000, Loss: 0.7595, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 802/10000, Loss: 0.7594, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 803/10000, Loss: 0.7594, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 804/10000, Loss: 0.7593, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 805/10000, Loss: 0.7593, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 806/10000, Loss: 0.7592, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 807/10000, Loss: 0.7591, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 808/10000, Loss: 0.7591, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 809/10000, Loss: 0.7590, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 810/10000, Loss: 0.7590, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 811/10000, Loss: 0.7589, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 812/10000, Loss: 0.7589, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 813/10000, Loss: 0.7588, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 814/10000, Loss: 0.7587, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 815/10000, Loss: 0.7587, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 816/10000, Loss: 0.7586, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 817/10000, Loss: 0.7586, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 818/10000, Loss: 0.7585, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 819/10000, Loss: 0.7585, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 820/10000, Loss: 0.7584, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 821/10000, Loss: 0.7583, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 822/10000, Loss: 0.7583, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 823/10000, Loss: 0.7582, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 824/10000, Loss: 0.7582, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 825/10000, Loss: 0.7581, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 826/10000, Loss: 0.7581, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 827/10000, Loss: 0.7580, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 828/10000, Loss: 0.7580, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 829/10000, Loss: 0.7579, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 830/10000, Loss: 0.7578, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 831/10000, Loss: 0.7578, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 832/10000, Loss: 0.7577, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 833/10000, Loss: 0.7577, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 834/10000, Loss: 0.7576, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 835/10000, Loss: 0.7576, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 836/10000, Loss: 0.7575, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 837/10000, Loss: 0.7574, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 838/10000, Loss: 0.7574, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 839/10000, Loss: 0.7573, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 840/10000, Loss: 0.7573, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 841/10000, Loss: 0.7572, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 842/10000, Loss: 0.7572, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 843/10000, Loss: 0.7571, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 844/10000, Loss: 0.7571, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 845/10000, Loss: 0.7570, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 846/10000, Loss: 0.7569, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 847/10000, Loss: 0.7569, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 848/10000, Loss: 0.7568, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 849/10000, Loss: 0.7568, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 850/10000, Loss: 0.7567, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 851/10000, Loss: 0.7567, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 852/10000, Loss: 0.7566, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 853/10000, Loss: 0.7566, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 854/10000, Loss: 0.7565, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 855/10000, Loss: 0.7565, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 856/10000, Loss: 0.7564, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 857/10000, Loss: 0.7563, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 858/10000, Loss: 0.7563, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 859/10000, Loss: 0.7562, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 860/10000, Loss: 0.7562, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 861/10000, Loss: 0.7561, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 862/10000, Loss: 0.7561, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 863/10000, Loss: 0.7560, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 864/10000, Loss: 0.7560, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 865/10000, Loss: 0.7559, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 866/10000, Loss: 0.7559, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 867/10000, Loss: 0.7558, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 868/10000, Loss: 0.7557, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 869/10000, Loss: 0.7557, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 870/10000, Loss: 0.7556, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 871/10000, Loss: 0.7556, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 872/10000, Loss: 0.7555, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 873/10000, Loss: 0.7555, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 874/10000, Loss: 0.7554, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 875/10000, Loss: 0.7554, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 876/10000, Loss: 0.7553, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 877/10000, Loss: 0.7553, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 878/10000, Loss: 0.7552, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 879/10000, Loss: 0.7551, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 880/10000, Loss: 0.7551, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 881/10000, Loss: 0.7550, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 882/10000, Loss: 0.7550, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 883/10000, Loss: 0.7549, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 884/10000, Loss: 0.7549, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 885/10000, Loss: 0.7548, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 886/10000, Loss: 0.7548, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 887/10000, Loss: 0.7547, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 888/10000, Loss: 0.7547, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 889/10000, Loss: 0.7546, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 890/10000, Loss: 0.7546, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 891/10000, Loss: 0.7545, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 892/10000, Loss: 0.7544, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 893/10000, Loss: 0.7544, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 894/10000, Loss: 0.7543, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 895/10000, Loss: 0.7543, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 896/10000, Loss: 0.7542, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 897/10000, Loss: 0.7542, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 898/10000, Loss: 0.7541, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 899/10000, Loss: 0.7541, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 900/10000, Loss: 0.7540, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 901/10000, Loss: 0.7540, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 902/10000, Loss: 0.7539, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 903/10000, Loss: 0.7539, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 904/10000, Loss: 0.7538, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 905/10000, Loss: 0.7538, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 906/10000, Loss: 0.7537, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 907/10000, Loss: 0.7536, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 908/10000, Loss: 0.7536, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 909/10000, Loss: 0.7535, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 910/10000, Loss: 0.7535, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 911/10000, Loss: 0.7534, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 912/10000, Loss: 0.7534, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 913/10000, Loss: 0.7533, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 914/10000, Loss: 0.7533, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 915/10000, Loss: 0.7532, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 916/10000, Loss: 0.7532, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 917/10000, Loss: 0.7531, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 918/10000, Loss: 0.7531, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 919/10000, Loss: 0.7530, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 920/10000, Loss: 0.7530, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 921/10000, Loss: 0.7529, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 922/10000, Loss: 0.7529, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 923/10000, Loss: 0.7528, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 924/10000, Loss: 0.7528, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 925/10000, Loss: 0.7527, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 926/10000, Loss: 0.7526, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 927/10000, Loss: 0.7526, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 928/10000, Loss: 0.7525, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 929/10000, Loss: 0.7525, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 930/10000, Loss: 0.7524, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 931/10000, Loss: 0.7524, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 932/10000, Loss: 0.7523, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 933/10000, Loss: 0.7523, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 934/10000, Loss: 0.7522, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 935/10000, Loss: 0.7522, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 936/10000, Loss: 0.7521, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 937/10000, Loss: 0.7521, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 938/10000, Loss: 0.7520, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 939/10000, Loss: 0.7520, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 940/10000, Loss: 0.7519, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 941/10000, Loss: 0.7519, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 942/10000, Loss: 0.7518, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 943/10000, Loss: 0.7518, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 944/10000, Loss: 0.7517, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 945/10000, Loss: 0.7517, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 946/10000, Loss: 0.7516, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 947/10000, Loss: 0.7516, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 948/10000, Loss: 0.7515, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 949/10000, Loss: 0.7515, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 950/10000, Loss: 0.7514, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 951/10000, Loss: 0.7514, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 952/10000, Loss: 0.7513, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 953/10000, Loss: 0.7512, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 954/10000, Loss: 0.7512, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 955/10000, Loss: 0.7511, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 956/10000, Loss: 0.7511, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 957/10000, Loss: 0.7510, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 958/10000, Loss: 0.7510, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 959/10000, Loss: 0.7509, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 960/10000, Loss: 0.7509, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 961/10000, Loss: 0.7508, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 962/10000, Loss: 0.7508, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 963/10000, Loss: 0.7507, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 964/10000, Loss: 0.7507, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 965/10000, Loss: 0.7506, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 966/10000, Loss: 0.7506, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 967/10000, Loss: 0.7505, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 968/10000, Loss: 0.7505, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 969/10000, Loss: 0.7504, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 970/10000, Loss: 0.7504, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 971/10000, Loss: 0.7503, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 972/10000, Loss: 0.7503, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 973/10000, Loss: 0.7502, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 974/10000, Loss: 0.7502, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 975/10000, Loss: 0.7501, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 976/10000, Loss: 0.7501, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 977/10000, Loss: 0.7500, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 978/10000, Loss: 0.7500, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 979/10000, Loss: 0.7499, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 980/10000, Loss: 0.7499, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 981/10000, Loss: 0.7498, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 982/10000, Loss: 0.7498, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 983/10000, Loss: 0.7497, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 984/10000, Loss: 0.7497, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 985/10000, Loss: 0.7496, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 986/10000, Loss: 0.7496, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 987/10000, Loss: 0.7495, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 988/10000, Loss: 0.7495, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 989/10000, Loss: 0.7494, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 990/10000, Loss: 0.7494, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 991/10000, Loss: 0.7493, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 992/10000, Loss: 0.7493, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 993/10000, Loss: 0.7492, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 994/10000, Loss: 0.7492, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 995/10000, Loss: 0.7491, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 996/10000, Loss: 0.7491, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 997/10000, Loss: 0.7490, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 998/10000, Loss: 0.7490, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 999/10000, Loss: 0.7489, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1000/10000, Loss: 0.7489, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1001/10000, Loss: 0.7488, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1002/10000, Loss: 0.7488, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1003/10000, Loss: 0.7487, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1004/10000, Loss: 0.7487, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1005/10000, Loss: 0.7486, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1006/10000, Loss: 0.7486, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1007/10000, Loss: 0.7485, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1008/10000, Loss: 0.7485, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1009/10000, Loss: 0.7484, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1010/10000, Loss: 0.7484, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1011/10000, Loss: 0.7483, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1012/10000, Loss: 0.7483, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1013/10000, Loss: 0.7482, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1014/10000, Loss: 0.7482, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1015/10000, Loss: 0.7481, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1016/10000, Loss: 0.7481, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1017/10000, Loss: 0.7480, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1018/10000, Loss: 0.7480, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1019/10000, Loss: 0.7479, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1020/10000, Loss: 0.7479, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1021/10000, Loss: 0.7478, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1022/10000, Loss: 0.7478, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1023/10000, Loss: 0.7477, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1024/10000, Loss: 0.7477, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1025/10000, Loss: 0.7476, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1026/10000, Loss: 0.7476, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1027/10000, Loss: 0.7475, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1028/10000, Loss: 0.7475, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1029/10000, Loss: 0.7474, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1030/10000, Loss: 0.7474, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1031/10000, Loss: 0.7473, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1032/10000, Loss: 0.7473, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1033/10000, Loss: 0.7472, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1034/10000, Loss: 0.7472, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1035/10000, Loss: 0.7471, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1036/10000, Loss: 0.7471, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1037/10000, Loss: 0.7471, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1038/10000, Loss: 0.7470, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1039/10000, Loss: 0.7470, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1040/10000, Loss: 0.7469, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1041/10000, Loss: 0.7469, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1042/10000, Loss: 0.7468, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1043/10000, Loss: 0.7468, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1044/10000, Loss: 0.7467, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1045/10000, Loss: 0.7467, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1046/10000, Loss: 0.7466, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1047/10000, Loss: 0.7466, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1048/10000, Loss: 0.7465, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1049/10000, Loss: 0.7465, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1050/10000, Loss: 0.7464, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1051/10000, Loss: 0.7464, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1052/10000, Loss: 0.7463, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1053/10000, Loss: 0.7463, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1054/10000, Loss: 0.7462, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1055/10000, Loss: 0.7462, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1056/10000, Loss: 0.7461, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1057/10000, Loss: 0.7461, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1058/10000, Loss: 0.7460, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1059/10000, Loss: 0.7460, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1060/10000, Loss: 0.7459, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1061/10000, Loss: 0.7459, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1062/10000, Loss: 0.7458, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1063/10000, Loss: 0.7458, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1064/10000, Loss: 0.7457, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1065/10000, Loss: 0.7457, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1066/10000, Loss: 0.7457, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1067/10000, Loss: 0.7456, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1068/10000, Loss: 0.7456, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1069/10000, Loss: 0.7455, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1070/10000, Loss: 0.7455, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1071/10000, Loss: 0.7454, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1072/10000, Loss: 0.7454, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1073/10000, Loss: 0.7453, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1074/10000, Loss: 0.7453, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1075/10000, Loss: 0.7452, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1076/10000, Loss: 0.7452, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1077/10000, Loss: 0.7451, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1078/10000, Loss: 0.7451, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1079/10000, Loss: 0.7450, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1080/10000, Loss: 0.7450, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1081/10000, Loss: 0.7449, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1082/10000, Loss: 0.7449, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1083/10000, Loss: 0.7448, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1084/10000, Loss: 0.7448, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1085/10000, Loss: 0.7447, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1086/10000, Loss: 0.7447, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1087/10000, Loss: 0.7447, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1088/10000, Loss: 0.7446, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1089/10000, Loss: 0.7446, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1090/10000, Loss: 0.7445, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1091/10000, Loss: 0.7445, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1092/10000, Loss: 0.7444, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1093/10000, Loss: 0.7444, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1094/10000, Loss: 0.7443, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1095/10000, Loss: 0.7443, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1096/10000, Loss: 0.7442, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1097/10000, Loss: 0.7442, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1098/10000, Loss: 0.7441, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1099/10000, Loss: 0.7441, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1100/10000, Loss: 0.7440, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1101/10000, Loss: 0.7440, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1102/10000, Loss: 0.7439, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1103/10000, Loss: 0.7439, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1104/10000, Loss: 0.7439, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1105/10000, Loss: 0.7438, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1106/10000, Loss: 0.7438, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1107/10000, Loss: 0.7437, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1108/10000, Loss: 0.7437, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1109/10000, Loss: 0.7436, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1110/10000, Loss: 0.7436, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1111/10000, Loss: 0.7435, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1112/10000, Loss: 0.7435, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1113/10000, Loss: 0.7434, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1114/10000, Loss: 0.7434, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1115/10000, Loss: 0.7433, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1116/10000, Loss: 0.7433, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1117/10000, Loss: 0.7433, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1118/10000, Loss: 0.7432, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1119/10000, Loss: 0.7432, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1120/10000, Loss: 0.7431, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1121/10000, Loss: 0.7431, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1122/10000, Loss: 0.7430, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1123/10000, Loss: 0.7430, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1124/10000, Loss: 0.7429, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1125/10000, Loss: 0.7429, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1126/10000, Loss: 0.7428, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1127/10000, Loss: 0.7428, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1128/10000, Loss: 0.7427, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1129/10000, Loss: 0.7427, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1130/10000, Loss: 0.7427, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1131/10000, Loss: 0.7426, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1132/10000, Loss: 0.7426, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1133/10000, Loss: 0.7425, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1134/10000, Loss: 0.7425, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1135/10000, Loss: 0.7424, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1136/10000, Loss: 0.7424, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1137/10000, Loss: 0.7423, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1138/10000, Loss: 0.7423, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1139/10000, Loss: 0.7422, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1140/10000, Loss: 0.7422, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1141/10000, Loss: 0.7421, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1142/10000, Loss: 0.7421, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1143/10000, Loss: 0.7421, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1144/10000, Loss: 0.7420, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1145/10000, Loss: 0.7420, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1146/10000, Loss: 0.7419, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1147/10000, Loss: 0.7419, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1148/10000, Loss: 0.7418, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1149/10000, Loss: 0.7418, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1150/10000, Loss: 0.7417, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1151/10000, Loss: 0.7417, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1152/10000, Loss: 0.7416, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1153/10000, Loss: 0.7416, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1154/10000, Loss: 0.7416, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1155/10000, Loss: 0.7415, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1156/10000, Loss: 0.7415, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1157/10000, Loss: 0.7414, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1158/10000, Loss: 0.7414, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1159/10000, Loss: 0.7413, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1160/10000, Loss: 0.7413, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1161/10000, Loss: 0.7412, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1162/10000, Loss: 0.7412, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1163/10000, Loss: 0.7411, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1164/10000, Loss: 0.7411, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1165/10000, Loss: 0.7411, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1166/10000, Loss: 0.7410, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1167/10000, Loss: 0.7410, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1168/10000, Loss: 0.7409, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1169/10000, Loss: 0.7409, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1170/10000, Loss: 0.7408, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1171/10000, Loss: 0.7408, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1172/10000, Loss: 0.7407, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1173/10000, Loss: 0.7407, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1174/10000, Loss: 0.7406, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1175/10000, Loss: 0.7406, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1176/10000, Loss: 0.7406, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1177/10000, Loss: 0.7405, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1178/10000, Loss: 0.7405, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1179/10000, Loss: 0.7404, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1180/10000, Loss: 0.7404, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1181/10000, Loss: 0.7403, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1182/10000, Loss: 0.7403, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1183/10000, Loss: 0.7402, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1184/10000, Loss: 0.7402, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1185/10000, Loss: 0.7402, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1186/10000, Loss: 0.7401, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1187/10000, Loss: 0.7401, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1188/10000, Loss: 0.7400, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1189/10000, Loss: 0.7400, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1190/10000, Loss: 0.7399, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1191/10000, Loss: 0.7399, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1192/10000, Loss: 0.7398, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1193/10000, Loss: 0.7398, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1194/10000, Loss: 0.7398, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1195/10000, Loss: 0.7397, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1196/10000, Loss: 0.7397, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1197/10000, Loss: 0.7396, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1198/10000, Loss: 0.7396, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1199/10000, Loss: 0.7395, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1200/10000, Loss: 0.7395, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1201/10000, Loss: 0.7394, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1202/10000, Loss: 0.7394, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1203/10000, Loss: 0.7394, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1204/10000, Loss: 0.7393, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1205/10000, Loss: 0.7393, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1206/10000, Loss: 0.7392, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1207/10000, Loss: 0.7392, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1208/10000, Loss: 0.7391, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1209/10000, Loss: 0.7391, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1210/10000, Loss: 0.7390, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1211/10000, Loss: 0.7390, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1212/10000, Loss: 0.7390, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1213/10000, Loss: 0.7389, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1214/10000, Loss: 0.7389, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1215/10000, Loss: 0.7388, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1216/10000, Loss: 0.7388, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1217/10000, Loss: 0.7387, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1218/10000, Loss: 0.7387, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1219/10000, Loss: 0.7387, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1220/10000, Loss: 0.7386, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1221/10000, Loss: 0.7386, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1222/10000, Loss: 0.7385, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1223/10000, Loss: 0.7385, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1224/10000, Loss: 0.7384, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1225/10000, Loss: 0.7384, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1226/10000, Loss: 0.7383, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1227/10000, Loss: 0.7383, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1228/10000, Loss: 0.7383, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1229/10000, Loss: 0.7382, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1230/10000, Loss: 0.7382, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1231/10000, Loss: 0.7381, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1232/10000, Loss: 0.7381, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1233/10000, Loss: 0.7380, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1234/10000, Loss: 0.7380, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1235/10000, Loss: 0.7380, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1236/10000, Loss: 0.7379, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1237/10000, Loss: 0.7379, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1238/10000, Loss: 0.7378, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1239/10000, Loss: 0.7378, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1240/10000, Loss: 0.7377, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1241/10000, Loss: 0.7377, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1242/10000, Loss: 0.7376, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1243/10000, Loss: 0.7376, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1244/10000, Loss: 0.7376, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1245/10000, Loss: 0.7375, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1246/10000, Loss: 0.7375, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1247/10000, Loss: 0.7374, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1248/10000, Loss: 0.7374, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1249/10000, Loss: 0.7373, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1250/10000, Loss: 0.7373, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1251/10000, Loss: 0.7373, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1252/10000, Loss: 0.7372, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1253/10000, Loss: 0.7372, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1254/10000, Loss: 0.7371, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1255/10000, Loss: 0.7371, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1256/10000, Loss: 0.7370, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1257/10000, Loss: 0.7370, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1258/10000, Loss: 0.7370, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1259/10000, Loss: 0.7369, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1260/10000, Loss: 0.7369, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1261/10000, Loss: 0.7368, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1262/10000, Loss: 0.7368, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1263/10000, Loss: 0.7367, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1264/10000, Loss: 0.7367, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1265/10000, Loss: 0.7367, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1266/10000, Loss: 0.7366, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1267/10000, Loss: 0.7366, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1268/10000, Loss: 0.7365, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1269/10000, Loss: 0.7365, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1270/10000, Loss: 0.7364, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1271/10000, Loss: 0.7364, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1272/10000, Loss: 0.7364, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1273/10000, Loss: 0.7363, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1274/10000, Loss: 0.7363, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1275/10000, Loss: 0.7362, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1276/10000, Loss: 0.7362, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1277/10000, Loss: 0.7361, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1278/10000, Loss: 0.7361, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1279/10000, Loss: 0.7361, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1280/10000, Loss: 0.7360, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1281/10000, Loss: 0.7360, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1282/10000, Loss: 0.7359, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1283/10000, Loss: 0.7359, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1284/10000, Loss: 0.7358, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1285/10000, Loss: 0.7358, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1286/10000, Loss: 0.7358, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1287/10000, Loss: 0.7357, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1288/10000, Loss: 0.7357, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1289/10000, Loss: 0.7356, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1290/10000, Loss: 0.7356, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1291/10000, Loss: 0.7356, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1292/10000, Loss: 0.7355, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1293/10000, Loss: 0.7355, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1294/10000, Loss: 0.7354, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1295/10000, Loss: 0.7354, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1296/10000, Loss: 0.7353, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1297/10000, Loss: 0.7353, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1298/10000, Loss: 0.7353, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1299/10000, Loss: 0.7352, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1300/10000, Loss: 0.7352, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1301/10000, Loss: 0.7351, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1302/10000, Loss: 0.7351, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1303/10000, Loss: 0.7350, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1304/10000, Loss: 0.7350, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1305/10000, Loss: 0.7350, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1306/10000, Loss: 0.7349, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1307/10000, Loss: 0.7349, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1308/10000, Loss: 0.7348, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1309/10000, Loss: 0.7348, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1310/10000, Loss: 0.7348, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1311/10000, Loss: 0.7347, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1312/10000, Loss: 0.7347, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1313/10000, Loss: 0.7346, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1314/10000, Loss: 0.7346, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1315/10000, Loss: 0.7345, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1316/10000, Loss: 0.7345, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1317/10000, Loss: 0.7345, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1318/10000, Loss: 0.7344, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1319/10000, Loss: 0.7344, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1320/10000, Loss: 0.7343, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1321/10000, Loss: 0.7343, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1322/10000, Loss: 0.7342, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1323/10000, Loss: 0.7342, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1324/10000, Loss: 0.7342, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1325/10000, Loss: 0.7341, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1326/10000, Loss: 0.7341, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1327/10000, Loss: 0.7340, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1328/10000, Loss: 0.7340, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1329/10000, Loss: 0.7340, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1330/10000, Loss: 0.7339, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1331/10000, Loss: 0.7339, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1332/10000, Loss: 0.7338, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1333/10000, Loss: 0.7338, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1334/10000, Loss: 0.7338, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1335/10000, Loss: 0.7337, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1336/10000, Loss: 0.7337, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1337/10000, Loss: 0.7336, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1338/10000, Loss: 0.7336, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1339/10000, Loss: 0.7335, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1340/10000, Loss: 0.7335, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1341/10000, Loss: 0.7335, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1342/10000, Loss: 0.7334, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1343/10000, Loss: 0.7334, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1344/10000, Loss: 0.7333, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1345/10000, Loss: 0.7333, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1346/10000, Loss: 0.7333, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1347/10000, Loss: 0.7332, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1348/10000, Loss: 0.7332, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1349/10000, Loss: 0.7331, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1350/10000, Loss: 0.7331, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1351/10000, Loss: 0.7331, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1352/10000, Loss: 0.7330, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1353/10000, Loss: 0.7330, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1354/10000, Loss: 0.7329, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1355/10000, Loss: 0.7329, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1356/10000, Loss: 0.7328, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1357/10000, Loss: 0.7328, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1358/10000, Loss: 0.7328, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1359/10000, Loss: 0.7327, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1360/10000, Loss: 0.7327, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1361/10000, Loss: 0.7326, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1362/10000, Loss: 0.7326, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1363/10000, Loss: 0.7326, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1364/10000, Loss: 0.7325, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1365/10000, Loss: 0.7325, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1366/10000, Loss: 0.7324, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1367/10000, Loss: 0.7324, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1368/10000, Loss: 0.7324, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1369/10000, Loss: 0.7323, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1370/10000, Loss: 0.7323, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1371/10000, Loss: 0.7322, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1372/10000, Loss: 0.7322, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1373/10000, Loss: 0.7322, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1374/10000, Loss: 0.7321, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1375/10000, Loss: 0.7321, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1376/10000, Loss: 0.7320, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1377/10000, Loss: 0.7320, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1378/10000, Loss: 0.7319, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1379/10000, Loss: 0.7319, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1380/10000, Loss: 0.7319, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1381/10000, Loss: 0.7318, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1382/10000, Loss: 0.7318, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1383/10000, Loss: 0.7317, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1384/10000, Loss: 0.7317, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1385/10000, Loss: 0.7317, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1386/10000, Loss: 0.7316, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1387/10000, Loss: 0.7316, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1388/10000, Loss: 0.7315, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1389/10000, Loss: 0.7315, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1390/10000, Loss: 0.7315, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1391/10000, Loss: 0.7314, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1392/10000, Loss: 0.7314, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1393/10000, Loss: 0.7313, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1394/10000, Loss: 0.7313, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1395/10000, Loss: 0.7313, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1396/10000, Loss: 0.7312, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1397/10000, Loss: 0.7312, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1398/10000, Loss: 0.7311, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1399/10000, Loss: 0.7311, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1400/10000, Loss: 0.7311, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1401/10000, Loss: 0.7310, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1402/10000, Loss: 0.7310, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1403/10000, Loss: 0.7309, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1404/10000, Loss: 0.7309, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1405/10000, Loss: 0.7309, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1406/10000, Loss: 0.7308, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1407/10000, Loss: 0.7308, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1408/10000, Loss: 0.7307, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1409/10000, Loss: 0.7307, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1410/10000, Loss: 0.7307, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1411/10000, Loss: 0.7306, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1412/10000, Loss: 0.7306, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1413/10000, Loss: 0.7305, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1414/10000, Loss: 0.7305, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1415/10000, Loss: 0.7305, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1416/10000, Loss: 0.7304, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1417/10000, Loss: 0.7304, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1418/10000, Loss: 0.7303, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1419/10000, Loss: 0.7303, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1420/10000, Loss: 0.7303, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1421/10000, Loss: 0.7302, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1422/10000, Loss: 0.7302, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1423/10000, Loss: 0.7301, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1424/10000, Loss: 0.7301, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1425/10000, Loss: 0.7301, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1426/10000, Loss: 0.7300, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1427/10000, Loss: 0.7300, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1428/10000, Loss: 0.7299, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1429/10000, Loss: 0.7299, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1430/10000, Loss: 0.7299, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1431/10000, Loss: 0.7298, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1432/10000, Loss: 0.7298, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1433/10000, Loss: 0.7297, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1434/10000, Loss: 0.7297, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1435/10000, Loss: 0.7297, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1436/10000, Loss: 0.7296, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1437/10000, Loss: 0.7296, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1438/10000, Loss: 0.7296, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1439/10000, Loss: 0.7295, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1440/10000, Loss: 0.7295, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1441/10000, Loss: 0.7294, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1442/10000, Loss: 0.7294, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1443/10000, Loss: 0.7294, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1444/10000, Loss: 0.7293, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1445/10000, Loss: 0.7293, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1446/10000, Loss: 0.7292, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1447/10000, Loss: 0.7292, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1448/10000, Loss: 0.7292, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1449/10000, Loss: 0.7291, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1450/10000, Loss: 0.7291, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1451/10000, Loss: 0.7290, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1452/10000, Loss: 0.7290, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1453/10000, Loss: 0.7290, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1454/10000, Loss: 0.7289, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1455/10000, Loss: 0.7289, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1456/10000, Loss: 0.7288, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1457/10000, Loss: 0.7288, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1458/10000, Loss: 0.7288, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1459/10000, Loss: 0.7287, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1460/10000, Loss: 0.7287, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1461/10000, Loss: 0.7286, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1462/10000, Loss: 0.7286, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1463/10000, Loss: 0.7286, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1464/10000, Loss: 0.7285, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1465/10000, Loss: 0.7285, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1466/10000, Loss: 0.7285, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1467/10000, Loss: 0.7284, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1468/10000, Loss: 0.7284, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1469/10000, Loss: 0.7283, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1470/10000, Loss: 0.7283, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1471/10000, Loss: 0.7283, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1472/10000, Loss: 0.7282, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1473/10000, Loss: 0.7282, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1474/10000, Loss: 0.7281, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1475/10000, Loss: 0.7281, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1476/10000, Loss: 0.7281, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1477/10000, Loss: 0.7280, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1478/10000, Loss: 0.7280, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1479/10000, Loss: 0.7279, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1480/10000, Loss: 0.7279, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1481/10000, Loss: 0.7279, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1482/10000, Loss: 0.7278, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1483/10000, Loss: 0.7278, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1484/10000, Loss: 0.7278, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1485/10000, Loss: 0.7277, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1486/10000, Loss: 0.7277, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1487/10000, Loss: 0.7276, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1488/10000, Loss: 0.7276, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1489/10000, Loss: 0.7276, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1490/10000, Loss: 0.7275, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1491/10000, Loss: 0.7275, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1492/10000, Loss: 0.7274, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1493/10000, Loss: 0.7274, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1494/10000, Loss: 0.7274, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1495/10000, Loss: 0.7273, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1496/10000, Loss: 0.7273, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1497/10000, Loss: 0.7273, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1498/10000, Loss: 0.7272, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1499/10000, Loss: 0.7272, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1500/10000, Loss: 0.7271, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1501/10000, Loss: 0.7271, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1502/10000, Loss: 0.7271, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1503/10000, Loss: 0.7270, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1504/10000, Loss: 0.7270, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1505/10000, Loss: 0.7269, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1506/10000, Loss: 0.7269, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1507/10000, Loss: 0.7269, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1508/10000, Loss: 0.7268, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1509/10000, Loss: 0.7268, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1510/10000, Loss: 0.7268, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1511/10000, Loss: 0.7267, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1512/10000, Loss: 0.7267, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1513/10000, Loss: 0.7266, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1514/10000, Loss: 0.7266, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1515/10000, Loss: 0.7266, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1516/10000, Loss: 0.7265, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1517/10000, Loss: 0.7265, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1518/10000, Loss: 0.7265, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1519/10000, Loss: 0.7264, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1520/10000, Loss: 0.7264, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1521/10000, Loss: 0.7263, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1522/10000, Loss: 0.7263, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1523/10000, Loss: 0.7263, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1524/10000, Loss: 0.7262, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1525/10000, Loss: 0.7262, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1526/10000, Loss: 0.7261, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1527/10000, Loss: 0.7261, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1528/10000, Loss: 0.7261, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1529/10000, Loss: 0.7260, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1530/10000, Loss: 0.7260, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1531/10000, Loss: 0.7260, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1532/10000, Loss: 0.7259, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1533/10000, Loss: 0.7259, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1534/10000, Loss: 0.7258, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1535/10000, Loss: 0.7258, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1536/10000, Loss: 0.7258, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1537/10000, Loss: 0.7257, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1538/10000, Loss: 0.7257, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1539/10000, Loss: 0.7257, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1540/10000, Loss: 0.7256, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1541/10000, Loss: 0.7256, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1542/10000, Loss: 0.7255, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1543/10000, Loss: 0.7255, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1544/10000, Loss: 0.7255, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1545/10000, Loss: 0.7254, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1546/10000, Loss: 0.7254, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1547/10000, Loss: 0.7254, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1548/10000, Loss: 0.7253, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1549/10000, Loss: 0.7253, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1550/10000, Loss: 0.7252, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1551/10000, Loss: 0.7252, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1552/10000, Loss: 0.7252, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1553/10000, Loss: 0.7251, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1554/10000, Loss: 0.7251, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1555/10000, Loss: 0.7251, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1556/10000, Loss: 0.7250, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1557/10000, Loss: 0.7250, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1558/10000, Loss: 0.7249, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1559/10000, Loss: 0.7249, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1560/10000, Loss: 0.7249, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1561/10000, Loss: 0.7248, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1562/10000, Loss: 0.7248, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1563/10000, Loss: 0.7248, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1564/10000, Loss: 0.7247, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1565/10000, Loss: 0.7247, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1566/10000, Loss: 0.7246, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1567/10000, Loss: 0.7246, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1568/10000, Loss: 0.7246, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1569/10000, Loss: 0.7245, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1570/10000, Loss: 0.7245, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1571/10000, Loss: 0.7245, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1572/10000, Loss: 0.7244, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1573/10000, Loss: 0.7244, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1574/10000, Loss: 0.7243, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1575/10000, Loss: 0.7243, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1576/10000, Loss: 0.7243, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1577/10000, Loss: 0.7242, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1578/10000, Loss: 0.7242, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1579/10000, Loss: 0.7242, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1580/10000, Loss: 0.7241, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1581/10000, Loss: 0.7241, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1582/10000, Loss: 0.7240, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1583/10000, Loss: 0.7240, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1584/10000, Loss: 0.7240, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1585/10000, Loss: 0.7239, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1586/10000, Loss: 0.7239, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1587/10000, Loss: 0.7239, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1588/10000, Loss: 0.7238, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1589/10000, Loss: 0.7238, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1590/10000, Loss: 0.7238, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1591/10000, Loss: 0.7237, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1592/10000, Loss: 0.7237, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1593/10000, Loss: 0.7236, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1594/10000, Loss: 0.7236, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1595/10000, Loss: 0.7236, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1596/10000, Loss: 0.7235, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1597/10000, Loss: 0.7235, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1598/10000, Loss: 0.7235, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1599/10000, Loss: 0.7234, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1600/10000, Loss: 0.7234, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1601/10000, Loss: 0.7233, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1602/10000, Loss: 0.7233, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1603/10000, Loss: 0.7233, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1604/10000, Loss: 0.7232, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1605/10000, Loss: 0.7232, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1606/10000, Loss: 0.7232, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1607/10000, Loss: 0.7231, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1608/10000, Loss: 0.7231, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1609/10000, Loss: 0.7231, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1610/10000, Loss: 0.7230, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1611/10000, Loss: 0.7230, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1612/10000, Loss: 0.7229, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1613/10000, Loss: 0.7229, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1614/10000, Loss: 0.7229, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1615/10000, Loss: 0.7228, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1616/10000, Loss: 0.7228, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1617/10000, Loss: 0.7228, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1618/10000, Loss: 0.7227, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1619/10000, Loss: 0.7227, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1620/10000, Loss: 0.7227, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1621/10000, Loss: 0.7226, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1622/10000, Loss: 0.7226, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1623/10000, Loss: 0.7225, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1624/10000, Loss: 0.7225, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1625/10000, Loss: 0.7225, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1626/10000, Loss: 0.7224, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1627/10000, Loss: 0.7224, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1628/10000, Loss: 0.7224, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1629/10000, Loss: 0.7223, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1630/10000, Loss: 0.7223, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1631/10000, Loss: 0.7223, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1632/10000, Loss: 0.7222, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1633/10000, Loss: 0.7222, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1634/10000, Loss: 0.7221, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1635/10000, Loss: 0.7221, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1636/10000, Loss: 0.7221, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1637/10000, Loss: 0.7220, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1638/10000, Loss: 0.7220, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1639/10000, Loss: 0.7220, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1640/10000, Loss: 0.7219, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1641/10000, Loss: 0.7219, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1642/10000, Loss: 0.7219, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1643/10000, Loss: 0.7218, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1644/10000, Loss: 0.7218, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1645/10000, Loss: 0.7217, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1646/10000, Loss: 0.7217, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1647/10000, Loss: 0.7217, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1648/10000, Loss: 0.7216, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1649/10000, Loss: 0.7216, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1650/10000, Loss: 0.7216, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1651/10000, Loss: 0.7215, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1652/10000, Loss: 0.7215, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1653/10000, Loss: 0.7215, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1654/10000, Loss: 0.7214, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1655/10000, Loss: 0.7214, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1656/10000, Loss: 0.7213, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1657/10000, Loss: 0.7213, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1658/10000, Loss: 0.7213, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1659/10000, Loss: 0.7212, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1660/10000, Loss: 0.7212, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1661/10000, Loss: 0.7212, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1662/10000, Loss: 0.7211, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1663/10000, Loss: 0.7211, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1664/10000, Loss: 0.7211, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1665/10000, Loss: 0.7210, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1666/10000, Loss: 0.7210, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1667/10000, Loss: 0.7210, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1668/10000, Loss: 0.7209, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1669/10000, Loss: 0.7209, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1670/10000, Loss: 0.7208, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1671/10000, Loss: 0.7208, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1672/10000, Loss: 0.7208, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1673/10000, Loss: 0.7207, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1674/10000, Loss: 0.7207, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1675/10000, Loss: 0.7207, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1676/10000, Loss: 0.7206, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1677/10000, Loss: 0.7206, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1678/10000, Loss: 0.7206, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1679/10000, Loss: 0.7205, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1680/10000, Loss: 0.7205, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1681/10000, Loss: 0.7205, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1682/10000, Loss: 0.7204, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1683/10000, Loss: 0.7204, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1684/10000, Loss: 0.7203, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1685/10000, Loss: 0.7203, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1686/10000, Loss: 0.7203, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1687/10000, Loss: 0.7202, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1688/10000, Loss: 0.7202, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1689/10000, Loss: 0.7202, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1690/10000, Loss: 0.7201, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1691/10000, Loss: 0.7201, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1692/10000, Loss: 0.7201, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1693/10000, Loss: 0.7200, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1694/10000, Loss: 0.7200, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1695/10000, Loss: 0.7200, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1696/10000, Loss: 0.7199, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1697/10000, Loss: 0.7199, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1698/10000, Loss: 0.7199, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1699/10000, Loss: 0.7198, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1700/10000, Loss: 0.7198, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1701/10000, Loss: 0.7197, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1702/10000, Loss: 0.7197, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1703/10000, Loss: 0.7197, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1704/10000, Loss: 0.7196, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1705/10000, Loss: 0.7196, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1706/10000, Loss: 0.7196, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1707/10000, Loss: 0.7195, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1708/10000, Loss: 0.7195, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1709/10000, Loss: 0.7195, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1710/10000, Loss: 0.7194, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1711/10000, Loss: 0.7194, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1712/10000, Loss: 0.7194, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1713/10000, Loss: 0.7193, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1714/10000, Loss: 0.7193, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1715/10000, Loss: 0.7193, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1716/10000, Loss: 0.7192, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1717/10000, Loss: 0.7192, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1718/10000, Loss: 0.7191, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1719/10000, Loss: 0.7191, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1720/10000, Loss: 0.7191, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1721/10000, Loss: 0.7190, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1722/10000, Loss: 0.7190, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1723/10000, Loss: 0.7190, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1724/10000, Loss: 0.7189, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1725/10000, Loss: 0.7189, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1726/10000, Loss: 0.7189, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1727/10000, Loss: 0.7188, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1728/10000, Loss: 0.7188, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1729/10000, Loss: 0.7188, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1730/10000, Loss: 0.7187, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1731/10000, Loss: 0.7187, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1732/10000, Loss: 0.7187, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1733/10000, Loss: 0.7186, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1734/10000, Loss: 0.7186, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1735/10000, Loss: 0.7186, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1736/10000, Loss: 0.7185, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1737/10000, Loss: 0.7185, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1738/10000, Loss: 0.7184, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1739/10000, Loss: 0.7184, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1740/10000, Loss: 0.7184, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1741/10000, Loss: 0.7183, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1742/10000, Loss: 0.7183, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1743/10000, Loss: 0.7183, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1744/10000, Loss: 0.7182, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1745/10000, Loss: 0.7182, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1746/10000, Loss: 0.7182, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1747/10000, Loss: 0.7181, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1748/10000, Loss: 0.7181, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1749/10000, Loss: 0.7181, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1750/10000, Loss: 0.7180, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1751/10000, Loss: 0.7180, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1752/10000, Loss: 0.7180, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1753/10000, Loss: 0.7179, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1754/10000, Loss: 0.7179, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1755/10000, Loss: 0.7179, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1756/10000, Loss: 0.7178, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1757/10000, Loss: 0.7178, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1758/10000, Loss: 0.7178, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1759/10000, Loss: 0.7177, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1760/10000, Loss: 0.7177, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1761/10000, Loss: 0.7177, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1762/10000, Loss: 0.7176, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1763/10000, Loss: 0.7176, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1764/10000, Loss: 0.7175, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1765/10000, Loss: 0.7175, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1766/10000, Loss: 0.7175, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1767/10000, Loss: 0.7174, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1768/10000, Loss: 0.7174, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1769/10000, Loss: 0.7174, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1770/10000, Loss: 0.7173, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1771/10000, Loss: 0.7173, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1772/10000, Loss: 0.7173, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1773/10000, Loss: 0.7172, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1774/10000, Loss: 0.7172, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1775/10000, Loss: 0.7172, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1776/10000, Loss: 0.7171, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1777/10000, Loss: 0.7171, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1778/10000, Loss: 0.7171, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1779/10000, Loss: 0.7170, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1780/10000, Loss: 0.7170, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1781/10000, Loss: 0.7170, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1782/10000, Loss: 0.7169, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1783/10000, Loss: 0.7169, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1784/10000, Loss: 0.7169, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1785/10000, Loss: 0.7168, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1786/10000, Loss: 0.7168, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1787/10000, Loss: 0.7168, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1788/10000, Loss: 0.7167, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1789/10000, Loss: 0.7167, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1790/10000, Loss: 0.7167, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1791/10000, Loss: 0.7166, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1792/10000, Loss: 0.7166, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1793/10000, Loss: 0.7166, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1794/10000, Loss: 0.7165, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1795/10000, Loss: 0.7165, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1796/10000, Loss: 0.7164, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1797/10000, Loss: 0.7164, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1798/10000, Loss: 0.7164, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1799/10000, Loss: 0.7163, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1800/10000, Loss: 0.7163, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1801/10000, Loss: 0.7163, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1802/10000, Loss: 0.7162, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1803/10000, Loss: 0.7162, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1804/10000, Loss: 0.7162, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1805/10000, Loss: 0.7161, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1806/10000, Loss: 0.7161, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1807/10000, Loss: 0.7161, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1808/10000, Loss: 0.7160, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1809/10000, Loss: 0.7160, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1810/10000, Loss: 0.7160, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1811/10000, Loss: 0.7159, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1812/10000, Loss: 0.7159, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1813/10000, Loss: 0.7159, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1814/10000, Loss: 0.7158, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1815/10000, Loss: 0.7158, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1816/10000, Loss: 0.7158, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1817/10000, Loss: 0.7157, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1818/10000, Loss: 0.7157, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1819/10000, Loss: 0.7157, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1820/10000, Loss: 0.7156, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1821/10000, Loss: 0.7156, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1822/10000, Loss: 0.7156, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1823/10000, Loss: 0.7155, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1824/10000, Loss: 0.7155, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1825/10000, Loss: 0.7155, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1826/10000, Loss: 0.7154, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1827/10000, Loss: 0.7154, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1828/10000, Loss: 0.7154, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1829/10000, Loss: 0.7153, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1830/10000, Loss: 0.7153, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1831/10000, Loss: 0.7153, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1832/10000, Loss: 0.7152, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1833/10000, Loss: 0.7152, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1834/10000, Loss: 0.7152, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1835/10000, Loss: 0.7151, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1836/10000, Loss: 0.7151, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1837/10000, Loss: 0.7151, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1838/10000, Loss: 0.7150, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1839/10000, Loss: 0.7150, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1840/10000, Loss: 0.7150, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1841/10000, Loss: 0.7149, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1842/10000, Loss: 0.7149, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1843/10000, Loss: 0.7149, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1844/10000, Loss: 0.7148, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1845/10000, Loss: 0.7148, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1846/10000, Loss: 0.7148, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1847/10000, Loss: 0.7147, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1848/10000, Loss: 0.7147, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1849/10000, Loss: 0.7147, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1850/10000, Loss: 0.7146, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1851/10000, Loss: 0.7146, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1852/10000, Loss: 0.7146, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1853/10000, Loss: 0.7145, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1854/10000, Loss: 0.7145, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1855/10000, Loss: 0.7145, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1856/10000, Loss: 0.7144, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1857/10000, Loss: 0.7144, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1858/10000, Loss: 0.7144, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1859/10000, Loss: 0.7143, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1860/10000, Loss: 0.7143, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1861/10000, Loss: 0.7143, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1862/10000, Loss: 0.7142, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1863/10000, Loss: 0.7142, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1864/10000, Loss: 0.7142, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1865/10000, Loss: 0.7141, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1866/10000, Loss: 0.7141, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1867/10000, Loss: 0.7141, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1868/10000, Loss: 0.7140, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1869/10000, Loss: 0.7140, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1870/10000, Loss: 0.7140, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1871/10000, Loss: 0.7139, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1872/10000, Loss: 0.7139, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1873/10000, Loss: 0.7139, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1874/10000, Loss: 0.7138, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1875/10000, Loss: 0.7138, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1876/10000, Loss: 0.7138, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1877/10000, Loss: 0.7137, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1878/10000, Loss: 0.7137, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1879/10000, Loss: 0.7137, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1880/10000, Loss: 0.7136, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1881/10000, Loss: 0.7136, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1882/10000, Loss: 0.7136, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1883/10000, Loss: 0.7135, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1884/10000, Loss: 0.7135, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1885/10000, Loss: 0.7135, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1886/10000, Loss: 0.7134, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1887/10000, Loss: 0.7134, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1888/10000, Loss: 0.7134, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1889/10000, Loss: 0.7133, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1890/10000, Loss: 0.7133, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1891/10000, Loss: 0.7133, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1892/10000, Loss: 0.7132, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1893/10000, Loss: 0.7132, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1894/10000, Loss: 0.7132, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1895/10000, Loss: 0.7131, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1896/10000, Loss: 0.7131, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1897/10000, Loss: 0.7131, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1898/10000, Loss: 0.7130, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1899/10000, Loss: 0.7130, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1900/10000, Loss: 0.7130, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1901/10000, Loss: 0.7129, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1902/10000, Loss: 0.7129, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1903/10000, Loss: 0.7129, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1904/10000, Loss: 0.7128, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1905/10000, Loss: 0.7128, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1906/10000, Loss: 0.7128, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1907/10000, Loss: 0.7127, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1908/10000, Loss: 0.7127, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1909/10000, Loss: 0.7127, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1910/10000, Loss: 0.7126, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1911/10000, Loss: 0.7126, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1912/10000, Loss: 0.7126, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1913/10000, Loss: 0.7125, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1914/10000, Loss: 0.7125, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1915/10000, Loss: 0.7125, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1916/10000, Loss: 0.7124, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1917/10000, Loss: 0.7124, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1918/10000, Loss: 0.7124, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1919/10000, Loss: 0.7124, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1920/10000, Loss: 0.7123, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1921/10000, Loss: 0.7123, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1922/10000, Loss: 0.7123, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1923/10000, Loss: 0.7122, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1924/10000, Loss: 0.7122, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1925/10000, Loss: 0.7122, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1926/10000, Loss: 0.7121, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1927/10000, Loss: 0.7121, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1928/10000, Loss: 0.7121, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1929/10000, Loss: 0.7120, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1930/10000, Loss: 0.7120, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1931/10000, Loss: 0.7120, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1932/10000, Loss: 0.7119, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1933/10000, Loss: 0.7119, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1934/10000, Loss: 0.7119, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1935/10000, Loss: 0.7118, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1936/10000, Loss: 0.7118, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1937/10000, Loss: 0.7118, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1938/10000, Loss: 0.7117, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1939/10000, Loss: 0.7117, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1940/10000, Loss: 0.7117, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1941/10000, Loss: 0.7116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1942/10000, Loss: 0.7116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1943/10000, Loss: 0.7116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1944/10000, Loss: 0.7115, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1945/10000, Loss: 0.7115, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1946/10000, Loss: 0.7115, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1947/10000, Loss: 0.7114, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1948/10000, Loss: 0.7114, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1949/10000, Loss: 0.7114, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1950/10000, Loss: 0.7113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1951/10000, Loss: 0.7113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1952/10000, Loss: 0.7113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1953/10000, Loss: 0.7112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1954/10000, Loss: 0.7112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1955/10000, Loss: 0.7112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1956/10000, Loss: 0.7112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1957/10000, Loss: 0.7111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1958/10000, Loss: 0.7111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1959/10000, Loss: 0.7111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1960/10000, Loss: 0.7110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1961/10000, Loss: 0.7110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1962/10000, Loss: 0.7110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1963/10000, Loss: 0.7109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1964/10000, Loss: 0.7109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1965/10000, Loss: 0.7109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1966/10000, Loss: 0.7108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1967/10000, Loss: 0.7108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1968/10000, Loss: 0.7108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1969/10000, Loss: 0.7107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1970/10000, Loss: 0.7107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1971/10000, Loss: 0.7107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1972/10000, Loss: 0.7106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1973/10000, Loss: 0.7106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1974/10000, Loss: 0.7106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1975/10000, Loss: 0.7105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1976/10000, Loss: 0.7105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1977/10000, Loss: 0.7105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1978/10000, Loss: 0.7104, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1979/10000, Loss: 0.7104, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1980/10000, Loss: 0.7104, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1981/10000, Loss: 0.7104, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1982/10000, Loss: 0.7103, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1983/10000, Loss: 0.7103, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1984/10000, Loss: 0.7103, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1985/10000, Loss: 0.7102, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1986/10000, Loss: 0.7102, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1987/10000, Loss: 0.7102, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1988/10000, Loss: 0.7101, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1989/10000, Loss: 0.7101, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1990/10000, Loss: 0.7101, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1991/10000, Loss: 0.7100, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1992/10000, Loss: 0.7100, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1993/10000, Loss: 0.7100, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1994/10000, Loss: 0.7099, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1995/10000, Loss: 0.7099, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1996/10000, Loss: 0.7099, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1997/10000, Loss: 0.7098, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1998/10000, Loss: 0.7098, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1999/10000, Loss: 0.7098, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2000/10000, Loss: 0.7097, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2001/10000, Loss: 0.7097, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2002/10000, Loss: 0.7097, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2003/10000, Loss: 0.7097, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2004/10000, Loss: 0.7096, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2005/10000, Loss: 0.7096, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2006/10000, Loss: 0.7096, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2007/10000, Loss: 0.7095, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2008/10000, Loss: 0.7095, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2009/10000, Loss: 0.7095, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2010/10000, Loss: 0.7094, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2011/10000, Loss: 0.7094, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2012/10000, Loss: 0.7094, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2013/10000, Loss: 0.7093, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2014/10000, Loss: 0.7093, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2015/10000, Loss: 0.7093, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2016/10000, Loss: 0.7092, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2017/10000, Loss: 0.7092, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2018/10000, Loss: 0.7092, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2019/10000, Loss: 0.7091, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2020/10000, Loss: 0.7091, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2021/10000, Loss: 0.7091, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2022/10000, Loss: 0.7091, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2023/10000, Loss: 0.7090, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2024/10000, Loss: 0.7090, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2025/10000, Loss: 0.7090, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2026/10000, Loss: 0.7089, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2027/10000, Loss: 0.7089, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2028/10000, Loss: 0.7089, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2029/10000, Loss: 0.7088, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2030/10000, Loss: 0.7088, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2031/10000, Loss: 0.7088, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2032/10000, Loss: 0.7087, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2033/10000, Loss: 0.7087, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2034/10000, Loss: 0.7087, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2035/10000, Loss: 0.7086, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2036/10000, Loss: 0.7086, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2037/10000, Loss: 0.7086, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2038/10000, Loss: 0.7086, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2039/10000, Loss: 0.7085, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2040/10000, Loss: 0.7085, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2041/10000, Loss: 0.7085, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2042/10000, Loss: 0.7084, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2043/10000, Loss: 0.7084, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2044/10000, Loss: 0.7084, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2045/10000, Loss: 0.7083, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2046/10000, Loss: 0.7083, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2047/10000, Loss: 0.7083, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2048/10000, Loss: 0.7082, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2049/10000, Loss: 0.7082, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2050/10000, Loss: 0.7082, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2051/10000, Loss: 0.7081, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2052/10000, Loss: 0.7081, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2053/10000, Loss: 0.7081, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2054/10000, Loss: 0.7081, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2055/10000, Loss: 0.7080, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2056/10000, Loss: 0.7080, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2057/10000, Loss: 0.7080, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2058/10000, Loss: 0.7079, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2059/10000, Loss: 0.7079, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2060/10000, Loss: 0.7079, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2061/10000, Loss: 0.7078, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2062/10000, Loss: 0.7078, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2063/10000, Loss: 0.7078, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2064/10000, Loss: 0.7077, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2065/10000, Loss: 0.7077, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2066/10000, Loss: 0.7077, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2067/10000, Loss: 0.7076, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2068/10000, Loss: 0.7076, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2069/10000, Loss: 0.7076, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2070/10000, Loss: 0.7076, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2071/10000, Loss: 0.7075, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2072/10000, Loss: 0.7075, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2073/10000, Loss: 0.7075, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2074/10000, Loss: 0.7074, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2075/10000, Loss: 0.7074, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2076/10000, Loss: 0.7074, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2077/10000, Loss: 0.7073, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2078/10000, Loss: 0.7073, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2079/10000, Loss: 0.7073, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2080/10000, Loss: 0.7072, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2081/10000, Loss: 0.7072, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2082/10000, Loss: 0.7072, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2083/10000, Loss: 0.7072, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2084/10000, Loss: 0.7071, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2085/10000, Loss: 0.7071, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2086/10000, Loss: 0.7071, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2087/10000, Loss: 0.7070, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2088/10000, Loss: 0.7070, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2089/10000, Loss: 0.7070, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2090/10000, Loss: 0.7069, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2091/10000, Loss: 0.7069, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2092/10000, Loss: 0.7069, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2093/10000, Loss: 0.7068, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2094/10000, Loss: 0.7068, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2095/10000, Loss: 0.7068, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2096/10000, Loss: 0.7068, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2097/10000, Loss: 0.7067, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2098/10000, Loss: 0.7067, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2099/10000, Loss: 0.7067, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2100/10000, Loss: 0.7066, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2101/10000, Loss: 0.7066, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2102/10000, Loss: 0.7066, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2103/10000, Loss: 0.7065, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2104/10000, Loss: 0.7065, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2105/10000, Loss: 0.7065, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2106/10000, Loss: 0.7064, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2107/10000, Loss: 0.7064, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2108/10000, Loss: 0.7064, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2109/10000, Loss: 0.7064, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2110/10000, Loss: 0.7063, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2111/10000, Loss: 0.7063, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2112/10000, Loss: 0.7063, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2113/10000, Loss: 0.7062, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2114/10000, Loss: 0.7062, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2115/10000, Loss: 0.7062, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2116/10000, Loss: 0.7061, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2117/10000, Loss: 0.7061, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2118/10000, Loss: 0.7061, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2119/10000, Loss: 0.7060, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2120/10000, Loss: 0.7060, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2121/10000, Loss: 0.7060, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2122/10000, Loss: 0.7060, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2123/10000, Loss: 0.7059, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2124/10000, Loss: 0.7059, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2125/10000, Loss: 0.7059, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2126/10000, Loss: 0.7058, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2127/10000, Loss: 0.7058, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2128/10000, Loss: 0.7058, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2129/10000, Loss: 0.7057, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2130/10000, Loss: 0.7057, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2131/10000, Loss: 0.7057, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2132/10000, Loss: 0.7057, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2133/10000, Loss: 0.7056, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2134/10000, Loss: 0.7056, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2135/10000, Loss: 0.7056, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2136/10000, Loss: 0.7055, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2137/10000, Loss: 0.7055, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2138/10000, Loss: 0.7055, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2139/10000, Loss: 0.7054, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2140/10000, Loss: 0.7054, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2141/10000, Loss: 0.7054, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2142/10000, Loss: 0.7054, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2143/10000, Loss: 0.7053, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2144/10000, Loss: 0.7053, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2145/10000, Loss: 0.7053, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2146/10000, Loss: 0.7052, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2147/10000, Loss: 0.7052, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2148/10000, Loss: 0.7052, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2149/10000, Loss: 0.7051, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2150/10000, Loss: 0.7051, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2151/10000, Loss: 0.7051, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2152/10000, Loss: 0.7050, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2153/10000, Loss: 0.7050, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2154/10000, Loss: 0.7050, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2155/10000, Loss: 0.7050, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2156/10000, Loss: 0.7049, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2157/10000, Loss: 0.7049, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2158/10000, Loss: 0.7049, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2159/10000, Loss: 0.7048, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2160/10000, Loss: 0.7048, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2161/10000, Loss: 0.7048, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2162/10000, Loss: 0.7047, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2163/10000, Loss: 0.7047, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2164/10000, Loss: 0.7047, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2165/10000, Loss: 0.7047, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2166/10000, Loss: 0.7046, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2167/10000, Loss: 0.7046, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2168/10000, Loss: 0.7046, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2169/10000, Loss: 0.7045, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2170/10000, Loss: 0.7045, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2171/10000, Loss: 0.7045, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2172/10000, Loss: 0.7044, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2173/10000, Loss: 0.7044, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2174/10000, Loss: 0.7044, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2175/10000, Loss: 0.7044, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2176/10000, Loss: 0.7043, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2177/10000, Loss: 0.7043, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2178/10000, Loss: 0.7043, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2179/10000, Loss: 0.7042, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2180/10000, Loss: 0.7042, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2181/10000, Loss: 0.7042, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2182/10000, Loss: 0.7041, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2183/10000, Loss: 0.7041, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2184/10000, Loss: 0.7041, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2185/10000, Loss: 0.7041, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2186/10000, Loss: 0.7040, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2187/10000, Loss: 0.7040, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2188/10000, Loss: 0.7040, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2189/10000, Loss: 0.7039, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2190/10000, Loss: 0.7039, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2191/10000, Loss: 0.7039, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2192/10000, Loss: 0.7039, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2193/10000, Loss: 0.7038, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2194/10000, Loss: 0.7038, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2195/10000, Loss: 0.7038, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2196/10000, Loss: 0.7037, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2197/10000, Loss: 0.7037, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2198/10000, Loss: 0.7037, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2199/10000, Loss: 0.7036, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2200/10000, Loss: 0.7036, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2201/10000, Loss: 0.7036, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2202/10000, Loss: 0.7036, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2203/10000, Loss: 0.7035, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2204/10000, Loss: 0.7035, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2205/10000, Loss: 0.7035, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2206/10000, Loss: 0.7034, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2207/10000, Loss: 0.7034, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2208/10000, Loss: 0.7034, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2209/10000, Loss: 0.7033, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2210/10000, Loss: 0.7033, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2211/10000, Loss: 0.7033, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2212/10000, Loss: 0.7033, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2213/10000, Loss: 0.7032, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2214/10000, Loss: 0.7032, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2215/10000, Loss: 0.7032, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2216/10000, Loss: 0.7031, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2217/10000, Loss: 0.7031, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2218/10000, Loss: 0.7031, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2219/10000, Loss: 0.7031, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2220/10000, Loss: 0.7030, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2221/10000, Loss: 0.7030, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2222/10000, Loss: 0.7030, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2223/10000, Loss: 0.7029, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2224/10000, Loss: 0.7029, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2225/10000, Loss: 0.7029, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2226/10000, Loss: 0.7028, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2227/10000, Loss: 0.7028, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2228/10000, Loss: 0.7028, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2229/10000, Loss: 0.7028, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2230/10000, Loss: 0.7027, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2231/10000, Loss: 0.7027, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2232/10000, Loss: 0.7027, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2233/10000, Loss: 0.7026, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2234/10000, Loss: 0.7026, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2235/10000, Loss: 0.7026, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2236/10000, Loss: 0.7025, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2237/10000, Loss: 0.7025, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2238/10000, Loss: 0.7025, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2239/10000, Loss: 0.7025, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2240/10000, Loss: 0.7024, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2241/10000, Loss: 0.7024, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2242/10000, Loss: 0.7024, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2243/10000, Loss: 0.7023, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2244/10000, Loss: 0.7023, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2245/10000, Loss: 0.7023, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2246/10000, Loss: 0.7023, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2247/10000, Loss: 0.7022, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2248/10000, Loss: 0.7022, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2249/10000, Loss: 0.7022, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2250/10000, Loss: 0.7021, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2251/10000, Loss: 0.7021, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2252/10000, Loss: 0.7021, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2253/10000, Loss: 0.7021, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2254/10000, Loss: 0.7020, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2255/10000, Loss: 0.7020, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2256/10000, Loss: 0.7020, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2257/10000, Loss: 0.7019, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2258/10000, Loss: 0.7019, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2259/10000, Loss: 0.7019, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2260/10000, Loss: 0.7018, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2261/10000, Loss: 0.7018, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2262/10000, Loss: 0.7018, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2263/10000, Loss: 0.7018, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2264/10000, Loss: 0.7017, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2265/10000, Loss: 0.7017, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2266/10000, Loss: 0.7017, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2267/10000, Loss: 0.7016, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2268/10000, Loss: 0.7016, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2269/10000, Loss: 0.7016, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2270/10000, Loss: 0.7016, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2271/10000, Loss: 0.7015, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2272/10000, Loss: 0.7015, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2273/10000, Loss: 0.7015, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2274/10000, Loss: 0.7014, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2275/10000, Loss: 0.7014, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2276/10000, Loss: 0.7014, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2277/10000, Loss: 0.7014, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2278/10000, Loss: 0.7013, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2279/10000, Loss: 0.7013, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2280/10000, Loss: 0.7013, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2281/10000, Loss: 0.7012, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2282/10000, Loss: 0.7012, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2283/10000, Loss: 0.7012, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2284/10000, Loss: 0.7012, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2285/10000, Loss: 0.7011, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2286/10000, Loss: 0.7011, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2287/10000, Loss: 0.7011, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2288/10000, Loss: 0.7010, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2289/10000, Loss: 0.7010, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2290/10000, Loss: 0.7010, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2291/10000, Loss: 0.7009, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2292/10000, Loss: 0.7009, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2293/10000, Loss: 0.7009, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2294/10000, Loss: 0.7009, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2295/10000, Loss: 0.7008, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2296/10000, Loss: 0.7008, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2297/10000, Loss: 0.7008, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2298/10000, Loss: 0.7007, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2299/10000, Loss: 0.7007, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2300/10000, Loss: 0.7007, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2301/10000, Loss: 0.7007, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2302/10000, Loss: 0.7006, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2303/10000, Loss: 0.7006, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2304/10000, Loss: 0.7006, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2305/10000, Loss: 0.7005, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2306/10000, Loss: 0.7005, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2307/10000, Loss: 0.7005, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2308/10000, Loss: 0.7005, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2309/10000, Loss: 0.7004, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2310/10000, Loss: 0.7004, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2311/10000, Loss: 0.7004, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2312/10000, Loss: 0.7003, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2313/10000, Loss: 0.7003, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2314/10000, Loss: 0.7003, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2315/10000, Loss: 0.7003, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2316/10000, Loss: 0.7002, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2317/10000, Loss: 0.7002, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2318/10000, Loss: 0.7002, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2319/10000, Loss: 0.7001, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2320/10000, Loss: 0.7001, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2321/10000, Loss: 0.7001, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2322/10000, Loss: 0.7001, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2323/10000, Loss: 0.7000, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2324/10000, Loss: 0.7000, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2325/10000, Loss: 0.7000, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2326/10000, Loss: 0.6999, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2327/10000, Loss: 0.6999, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2328/10000, Loss: 0.6999, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2329/10000, Loss: 0.6999, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2330/10000, Loss: 0.6998, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2331/10000, Loss: 0.6998, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2332/10000, Loss: 0.6998, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2333/10000, Loss: 0.6997, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2334/10000, Loss: 0.6997, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2335/10000, Loss: 0.6997, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2336/10000, Loss: 0.6997, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2337/10000, Loss: 0.6996, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2338/10000, Loss: 0.6996, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2339/10000, Loss: 0.6996, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2340/10000, Loss: 0.6995, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2341/10000, Loss: 0.6995, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2342/10000, Loss: 0.6995, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2343/10000, Loss: 0.6995, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2344/10000, Loss: 0.6994, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2345/10000, Loss: 0.6994, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2346/10000, Loss: 0.6994, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2347/10000, Loss: 0.6993, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2348/10000, Loss: 0.6993, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2349/10000, Loss: 0.6993, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2350/10000, Loss: 0.6993, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2351/10000, Loss: 0.6992, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2352/10000, Loss: 0.6992, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2353/10000, Loss: 0.6992, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2354/10000, Loss: 0.6991, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2355/10000, Loss: 0.6991, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2356/10000, Loss: 0.6991, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2357/10000, Loss: 0.6991, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2358/10000, Loss: 0.6990, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2359/10000, Loss: 0.6990, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2360/10000, Loss: 0.6990, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2361/10000, Loss: 0.6989, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2362/10000, Loss: 0.6989, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2363/10000, Loss: 0.6989, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2364/10000, Loss: 0.6989, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2365/10000, Loss: 0.6988, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2366/10000, Loss: 0.6988, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2367/10000, Loss: 0.6988, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2368/10000, Loss: 0.6988, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2369/10000, Loss: 0.6987, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2370/10000, Loss: 0.6987, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2371/10000, Loss: 0.6987, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2372/10000, Loss: 0.6986, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2373/10000, Loss: 0.6986, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2374/10000, Loss: 0.6986, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2375/10000, Loss: 0.6986, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2376/10000, Loss: 0.6985, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2377/10000, Loss: 0.6985, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2378/10000, Loss: 0.6985, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2379/10000, Loss: 0.6984, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2380/10000, Loss: 0.6984, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2381/10000, Loss: 0.6984, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2382/10000, Loss: 0.6984, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2383/10000, Loss: 0.6983, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2384/10000, Loss: 0.6983, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2385/10000, Loss: 0.6983, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2386/10000, Loss: 0.6982, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2387/10000, Loss: 0.6982, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2388/10000, Loss: 0.6982, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2389/10000, Loss: 0.6982, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2390/10000, Loss: 0.6981, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2391/10000, Loss: 0.6981, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2392/10000, Loss: 0.6981, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2393/10000, Loss: 0.6981, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2394/10000, Loss: 0.6980, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2395/10000, Loss: 0.6980, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2396/10000, Loss: 0.6980, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2397/10000, Loss: 0.6979, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2398/10000, Loss: 0.6979, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2399/10000, Loss: 0.6979, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2400/10000, Loss: 0.6979, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2401/10000, Loss: 0.6978, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2402/10000, Loss: 0.6978, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2403/10000, Loss: 0.6978, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2404/10000, Loss: 0.6977, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2405/10000, Loss: 0.6977, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2406/10000, Loss: 0.6977, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2407/10000, Loss: 0.6977, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2408/10000, Loss: 0.6976, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2409/10000, Loss: 0.6976, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2410/10000, Loss: 0.6976, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2411/10000, Loss: 0.6975, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2412/10000, Loss: 0.6975, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2413/10000, Loss: 0.6975, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2414/10000, Loss: 0.6975, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2415/10000, Loss: 0.6974, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2416/10000, Loss: 0.6974, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2417/10000, Loss: 0.6974, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2418/10000, Loss: 0.6974, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2419/10000, Loss: 0.6973, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2420/10000, Loss: 0.6973, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2421/10000, Loss: 0.6973, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2422/10000, Loss: 0.6972, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2423/10000, Loss: 0.6972, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2424/10000, Loss: 0.6972, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2425/10000, Loss: 0.6972, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2426/10000, Loss: 0.6971, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2427/10000, Loss: 0.6971, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2428/10000, Loss: 0.6971, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2429/10000, Loss: 0.6970, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2430/10000, Loss: 0.6970, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2431/10000, Loss: 0.6970, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2432/10000, Loss: 0.6970, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2433/10000, Loss: 0.6969, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2434/10000, Loss: 0.6969, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2435/10000, Loss: 0.6969, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2436/10000, Loss: 0.6969, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2437/10000, Loss: 0.6968, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2438/10000, Loss: 0.6968, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2439/10000, Loss: 0.6968, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2440/10000, Loss: 0.6967, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2441/10000, Loss: 0.6967, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2442/10000, Loss: 0.6967, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2443/10000, Loss: 0.6967, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2444/10000, Loss: 0.6966, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2445/10000, Loss: 0.6966, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2446/10000, Loss: 0.6966, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2447/10000, Loss: 0.6966, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2448/10000, Loss: 0.6965, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2449/10000, Loss: 0.6965, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2450/10000, Loss: 0.6965, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2451/10000, Loss: 0.6964, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2452/10000, Loss: 0.6964, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2453/10000, Loss: 0.6964, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2454/10000, Loss: 0.6964, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2455/10000, Loss: 0.6963, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2456/10000, Loss: 0.6963, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2457/10000, Loss: 0.6963, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2458/10000, Loss: 0.6962, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2459/10000, Loss: 0.6962, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2460/10000, Loss: 0.6962, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2461/10000, Loss: 0.6962, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2462/10000, Loss: 0.6961, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2463/10000, Loss: 0.6961, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2464/10000, Loss: 0.6961, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2465/10000, Loss: 0.6961, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2466/10000, Loss: 0.6960, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2467/10000, Loss: 0.6960, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2468/10000, Loss: 0.6960, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2469/10000, Loss: 0.6959, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2470/10000, Loss: 0.6959, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2471/10000, Loss: 0.6959, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2472/10000, Loss: 0.6959, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2473/10000, Loss: 0.6958, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2474/10000, Loss: 0.6958, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2475/10000, Loss: 0.6958, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2476/10000, Loss: 0.6958, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2477/10000, Loss: 0.6957, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2478/10000, Loss: 0.6957, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2479/10000, Loss: 0.6957, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2480/10000, Loss: 0.6956, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2481/10000, Loss: 0.6956, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2482/10000, Loss: 0.6956, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2483/10000, Loss: 0.6956, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2484/10000, Loss: 0.6955, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2485/10000, Loss: 0.6955, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2486/10000, Loss: 0.6955, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2487/10000, Loss: 0.6955, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2488/10000, Loss: 0.6954, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2489/10000, Loss: 0.6954, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2490/10000, Loss: 0.6954, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2491/10000, Loss: 0.6953, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2492/10000, Loss: 0.6953, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2493/10000, Loss: 0.6953, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2494/10000, Loss: 0.6953, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2495/10000, Loss: 0.6952, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2496/10000, Loss: 0.6952, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2497/10000, Loss: 0.6952, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2498/10000, Loss: 0.6952, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2499/10000, Loss: 0.6951, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2500/10000, Loss: 0.6951, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2501/10000, Loss: 0.6951, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2502/10000, Loss: 0.6950, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2503/10000, Loss: 0.6950, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2504/10000, Loss: 0.6950, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2505/10000, Loss: 0.6950, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2506/10000, Loss: 0.6949, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2507/10000, Loss: 0.6949, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2508/10000, Loss: 0.6949, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2509/10000, Loss: 0.6949, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2510/10000, Loss: 0.6948, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2511/10000, Loss: 0.6948, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2512/10000, Loss: 0.6948, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2513/10000, Loss: 0.6948, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2514/10000, Loss: 0.6947, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2515/10000, Loss: 0.6947, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2516/10000, Loss: 0.6947, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2517/10000, Loss: 0.6946, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2518/10000, Loss: 0.6946, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2519/10000, Loss: 0.6946, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2520/10000, Loss: 0.6946, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2521/10000, Loss: 0.6945, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2522/10000, Loss: 0.6945, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2523/10000, Loss: 0.6945, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2524/10000, Loss: 0.6945, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2525/10000, Loss: 0.6944, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2526/10000, Loss: 0.6944, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2527/10000, Loss: 0.6944, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2528/10000, Loss: 0.6943, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2529/10000, Loss: 0.6943, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2530/10000, Loss: 0.6943, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2531/10000, Loss: 0.6943, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2532/10000, Loss: 0.6942, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2533/10000, Loss: 0.6942, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2534/10000, Loss: 0.6942, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2535/10000, Loss: 0.6942, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2536/10000, Loss: 0.6941, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2537/10000, Loss: 0.6941, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2538/10000, Loss: 0.6941, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2539/10000, Loss: 0.6941, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2540/10000, Loss: 0.6940, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2541/10000, Loss: 0.6940, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2542/10000, Loss: 0.6940, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2543/10000, Loss: 0.6939, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2544/10000, Loss: 0.6939, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2545/10000, Loss: 0.6939, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2546/10000, Loss: 0.6939, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2547/10000, Loss: 0.6938, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2548/10000, Loss: 0.6938, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2549/10000, Loss: 0.6938, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2550/10000, Loss: 0.6938, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2551/10000, Loss: 0.6937, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2552/10000, Loss: 0.6937, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2553/10000, Loss: 0.6937, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2554/10000, Loss: 0.6936, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2555/10000, Loss: 0.6936, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2556/10000, Loss: 0.6936, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2557/10000, Loss: 0.6936, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2558/10000, Loss: 0.6935, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2559/10000, Loss: 0.6935, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2560/10000, Loss: 0.6935, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2561/10000, Loss: 0.6935, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2562/10000, Loss: 0.6934, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2563/10000, Loss: 0.6934, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2564/10000, Loss: 0.6934, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2565/10000, Loss: 0.6934, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2566/10000, Loss: 0.6933, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2567/10000, Loss: 0.6933, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2568/10000, Loss: 0.6933, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2569/10000, Loss: 0.6933, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2570/10000, Loss: 0.6932, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2571/10000, Loss: 0.6932, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2572/10000, Loss: 0.6932, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2573/10000, Loss: 0.6931, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2574/10000, Loss: 0.6931, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2575/10000, Loss: 0.6931, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2576/10000, Loss: 0.6931, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2577/10000, Loss: 0.6930, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2578/10000, Loss: 0.6930, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2579/10000, Loss: 0.6930, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2580/10000, Loss: 0.6930, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2581/10000, Loss: 0.6929, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2582/10000, Loss: 0.6929, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2583/10000, Loss: 0.6929, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2584/10000, Loss: 0.6929, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2585/10000, Loss: 0.6928, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2586/10000, Loss: 0.6928, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2587/10000, Loss: 0.6928, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2588/10000, Loss: 0.6927, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2589/10000, Loss: 0.6927, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2590/10000, Loss: 0.6927, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2591/10000, Loss: 0.6927, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2592/10000, Loss: 0.6926, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2593/10000, Loss: 0.6926, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2594/10000, Loss: 0.6926, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2595/10000, Loss: 0.6926, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2596/10000, Loss: 0.6925, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2597/10000, Loss: 0.6925, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2598/10000, Loss: 0.6925, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2599/10000, Loss: 0.6925, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2600/10000, Loss: 0.6924, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2601/10000, Loss: 0.6924, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2602/10000, Loss: 0.6924, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2603/10000, Loss: 0.6924, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2604/10000, Loss: 0.6923, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2605/10000, Loss: 0.6923, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2606/10000, Loss: 0.6923, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2607/10000, Loss: 0.6922, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2608/10000, Loss: 0.6922, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2609/10000, Loss: 0.6922, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2610/10000, Loss: 0.6922, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2611/10000, Loss: 0.6921, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2612/10000, Loss: 0.6921, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2613/10000, Loss: 0.6921, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2614/10000, Loss: 0.6921, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2615/10000, Loss: 0.6920, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2616/10000, Loss: 0.6920, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2617/10000, Loss: 0.6920, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2618/10000, Loss: 0.6920, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2619/10000, Loss: 0.6919, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2620/10000, Loss: 0.6919, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2621/10000, Loss: 0.6919, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2622/10000, Loss: 0.6919, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2623/10000, Loss: 0.6918, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2624/10000, Loss: 0.6918, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2625/10000, Loss: 0.6918, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2626/10000, Loss: 0.6917, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2627/10000, Loss: 0.6917, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2628/10000, Loss: 0.6917, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2629/10000, Loss: 0.6917, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2630/10000, Loss: 0.6916, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2631/10000, Loss: 0.6916, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2632/10000, Loss: 0.6916, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2633/10000, Loss: 0.6916, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2634/10000, Loss: 0.6915, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2635/10000, Loss: 0.6915, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2636/10000, Loss: 0.6915, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2637/10000, Loss: 0.6915, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2638/10000, Loss: 0.6914, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2639/10000, Loss: 0.6914, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2640/10000, Loss: 0.6914, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2641/10000, Loss: 0.6914, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2642/10000, Loss: 0.6913, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2643/10000, Loss: 0.6913, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2644/10000, Loss: 0.6913, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2645/10000, Loss: 0.6913, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2646/10000, Loss: 0.6912, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2647/10000, Loss: 0.6912, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2648/10000, Loss: 0.6912, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2649/10000, Loss: 0.6911, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2650/10000, Loss: 0.6911, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2651/10000, Loss: 0.6911, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2652/10000, Loss: 0.6911, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2653/10000, Loss: 0.6910, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2654/10000, Loss: 0.6910, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2655/10000, Loss: 0.6910, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2656/10000, Loss: 0.6910, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2657/10000, Loss: 0.6909, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2658/10000, Loss: 0.6909, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2659/10000, Loss: 0.6909, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2660/10000, Loss: 0.6909, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2661/10000, Loss: 0.6908, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2662/10000, Loss: 0.6908, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2663/10000, Loss: 0.6908, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2664/10000, Loss: 0.6908, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2665/10000, Loss: 0.6907, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2666/10000, Loss: 0.6907, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2667/10000, Loss: 0.6907, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2668/10000, Loss: 0.6907, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2669/10000, Loss: 0.6906, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2670/10000, Loss: 0.6906, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2671/10000, Loss: 0.6906, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2672/10000, Loss: 0.6906, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2673/10000, Loss: 0.6905, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2674/10000, Loss: 0.6905, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2675/10000, Loss: 0.6905, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2676/10000, Loss: 0.6904, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2677/10000, Loss: 0.6904, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2678/10000, Loss: 0.6904, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2679/10000, Loss: 0.6904, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2680/10000, Loss: 0.6903, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2681/10000, Loss: 0.6903, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2682/10000, Loss: 0.6903, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2683/10000, Loss: 0.6903, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2684/10000, Loss: 0.6902, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2685/10000, Loss: 0.6902, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2686/10000, Loss: 0.6902, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2687/10000, Loss: 0.6902, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2688/10000, Loss: 0.6901, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2689/10000, Loss: 0.6901, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2690/10000, Loss: 0.6901, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2691/10000, Loss: 0.6901, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2692/10000, Loss: 0.6900, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2693/10000, Loss: 0.6900, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2694/10000, Loss: 0.6900, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2695/10000, Loss: 0.6900, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2696/10000, Loss: 0.6899, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2697/10000, Loss: 0.6899, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2698/10000, Loss: 0.6899, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2699/10000, Loss: 0.6899, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2700/10000, Loss: 0.6898, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2701/10000, Loss: 0.6898, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2702/10000, Loss: 0.6898, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2703/10000, Loss: 0.6898, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2704/10000, Loss: 0.6897, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2705/10000, Loss: 0.6897, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2706/10000, Loss: 0.6897, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2707/10000, Loss: 0.6897, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2708/10000, Loss: 0.6896, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2709/10000, Loss: 0.6896, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2710/10000, Loss: 0.6896, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2711/10000, Loss: 0.6896, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2712/10000, Loss: 0.6895, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2713/10000, Loss: 0.6895, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2714/10000, Loss: 0.6895, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2715/10000, Loss: 0.6894, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2716/10000, Loss: 0.6894, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2717/10000, Loss: 0.6894, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2718/10000, Loss: 0.6894, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2719/10000, Loss: 0.6893, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2720/10000, Loss: 0.6893, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2721/10000, Loss: 0.6893, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2722/10000, Loss: 0.6893, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2723/10000, Loss: 0.6892, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2724/10000, Loss: 0.6892, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2725/10000, Loss: 0.6892, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2726/10000, Loss: 0.6892, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2727/10000, Loss: 0.6891, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2728/10000, Loss: 0.6891, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2729/10000, Loss: 0.6891, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2730/10000, Loss: 0.6891, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2731/10000, Loss: 0.6890, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2732/10000, Loss: 0.6890, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2733/10000, Loss: 0.6890, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2734/10000, Loss: 0.6890, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2735/10000, Loss: 0.6889, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2736/10000, Loss: 0.6889, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2737/10000, Loss: 0.6889, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2738/10000, Loss: 0.6889, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2739/10000, Loss: 0.6888, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2740/10000, Loss: 0.6888, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2741/10000, Loss: 0.6888, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2742/10000, Loss: 0.6888, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2743/10000, Loss: 0.6887, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2744/10000, Loss: 0.6887, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2745/10000, Loss: 0.6887, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2746/10000, Loss: 0.6887, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2747/10000, Loss: 0.6886, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2748/10000, Loss: 0.6886, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2749/10000, Loss: 0.6886, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2750/10000, Loss: 0.6886, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2751/10000, Loss: 0.6885, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2752/10000, Loss: 0.6885, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2753/10000, Loss: 0.6885, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2754/10000, Loss: 0.6885, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2755/10000, Loss: 0.6884, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2756/10000, Loss: 0.6884, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2757/10000, Loss: 0.6884, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2758/10000, Loss: 0.6884, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2759/10000, Loss: 0.6883, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2760/10000, Loss: 0.6883, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2761/10000, Loss: 0.6883, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2762/10000, Loss: 0.6883, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2763/10000, Loss: 0.6882, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2764/10000, Loss: 0.6882, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2765/10000, Loss: 0.6882, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2766/10000, Loss: 0.6882, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2767/10000, Loss: 0.6881, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2768/10000, Loss: 0.6881, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2769/10000, Loss: 0.6881, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2770/10000, Loss: 0.6881, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2771/10000, Loss: 0.6880, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2772/10000, Loss: 0.6880, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2773/10000, Loss: 0.6880, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2774/10000, Loss: 0.6880, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2775/10000, Loss: 0.6879, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2776/10000, Loss: 0.6879, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2777/10000, Loss: 0.6879, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2778/10000, Loss: 0.6879, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2779/10000, Loss: 0.6878, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2780/10000, Loss: 0.6878, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2781/10000, Loss: 0.6878, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2782/10000, Loss: 0.6878, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2783/10000, Loss: 0.6877, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2784/10000, Loss: 0.6877, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2785/10000, Loss: 0.6877, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2786/10000, Loss: 0.6877, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2787/10000, Loss: 0.6876, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2788/10000, Loss: 0.6876, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2789/10000, Loss: 0.6876, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2790/10000, Loss: 0.6876, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2791/10000, Loss: 0.6875, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2792/10000, Loss: 0.6875, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2793/10000, Loss: 0.6875, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2794/10000, Loss: 0.6875, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2795/10000, Loss: 0.6874, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2796/10000, Loss: 0.6874, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2797/10000, Loss: 0.6874, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2798/10000, Loss: 0.6874, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2799/10000, Loss: 0.6873, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2800/10000, Loss: 0.6873, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2801/10000, Loss: 0.6873, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2802/10000, Loss: 0.6873, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2803/10000, Loss: 0.6872, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2804/10000, Loss: 0.6872, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2805/10000, Loss: 0.6872, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2806/10000, Loss: 0.6872, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2807/10000, Loss: 0.6871, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2808/10000, Loss: 0.6871, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2809/10000, Loss: 0.6871, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2810/10000, Loss: 0.6871, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2811/10000, Loss: 0.6870, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2812/10000, Loss: 0.6870, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2813/10000, Loss: 0.6870, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2814/10000, Loss: 0.6870, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2815/10000, Loss: 0.6869, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2816/10000, Loss: 0.6869, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2817/10000, Loss: 0.6869, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2818/10000, Loss: 0.6869, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2819/10000, Loss: 0.6868, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2820/10000, Loss: 0.6868, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2821/10000, Loss: 0.6868, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2822/10000, Loss: 0.6868, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2823/10000, Loss: 0.6867, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2824/10000, Loss: 0.6867, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2825/10000, Loss: 0.6867, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2826/10000, Loss: 0.6867, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2827/10000, Loss: 0.6866, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2828/10000, Loss: 0.6866, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2829/10000, Loss: 0.6866, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2830/10000, Loss: 0.6866, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2831/10000, Loss: 0.6865, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2832/10000, Loss: 0.6865, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2833/10000, Loss: 0.6865, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2834/10000, Loss: 0.6865, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2835/10000, Loss: 0.6864, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2836/10000, Loss: 0.6864, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2837/10000, Loss: 0.6864, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2838/10000, Loss: 0.6864, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2839/10000, Loss: 0.6863, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2840/10000, Loss: 0.6863, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2841/10000, Loss: 0.6863, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2842/10000, Loss: 0.6863, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2843/10000, Loss: 0.6862, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2844/10000, Loss: 0.6862, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2845/10000, Loss: 0.6862, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2846/10000, Loss: 0.6862, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2847/10000, Loss: 0.6861, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2848/10000, Loss: 0.6861, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2849/10000, Loss: 0.6861, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2850/10000, Loss: 0.6861, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2851/10000, Loss: 0.6860, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2852/10000, Loss: 0.6860, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2853/10000, Loss: 0.6860, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2854/10000, Loss: 0.6860, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2855/10000, Loss: 0.6859, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2856/10000, Loss: 0.6859, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2857/10000, Loss: 0.6859, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2858/10000, Loss: 0.6859, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2859/10000, Loss: 0.6858, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2860/10000, Loss: 0.6858, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2861/10000, Loss: 0.6858, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2862/10000, Loss: 0.6858, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2863/10000, Loss: 0.6857, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2864/10000, Loss: 0.6857, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2865/10000, Loss: 0.6857, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2866/10000, Loss: 0.6857, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2867/10000, Loss: 0.6857, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2868/10000, Loss: 0.6856, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2869/10000, Loss: 0.6856, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2870/10000, Loss: 0.6856, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2871/10000, Loss: 0.6856, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2872/10000, Loss: 0.6855, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2873/10000, Loss: 0.6855, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2874/10000, Loss: 0.6855, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2875/10000, Loss: 0.6855, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2876/10000, Loss: 0.6854, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2877/10000, Loss: 0.6854, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2878/10000, Loss: 0.6854, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2879/10000, Loss: 0.6854, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2880/10000, Loss: 0.6853, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2881/10000, Loss: 0.6853, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2882/10000, Loss: 0.6853, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2883/10000, Loss: 0.6853, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2884/10000, Loss: 0.6852, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2885/10000, Loss: 0.6852, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2886/10000, Loss: 0.6852, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2887/10000, Loss: 0.6852, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2888/10000, Loss: 0.6851, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2889/10000, Loss: 0.6851, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2890/10000, Loss: 0.6851, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2891/10000, Loss: 0.6851, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2892/10000, Loss: 0.6850, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2893/10000, Loss: 0.6850, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2894/10000, Loss: 0.6850, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2895/10000, Loss: 0.6850, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2896/10000, Loss: 0.6849, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2897/10000, Loss: 0.6849, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2898/10000, Loss: 0.6849, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2899/10000, Loss: 0.6849, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2900/10000, Loss: 0.6848, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2901/10000, Loss: 0.6848, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2902/10000, Loss: 0.6848, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2903/10000, Loss: 0.6848, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2904/10000, Loss: 0.6847, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2905/10000, Loss: 0.6847, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2906/10000, Loss: 0.6847, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2907/10000, Loss: 0.6847, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2908/10000, Loss: 0.6847, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2909/10000, Loss: 0.6846, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2910/10000, Loss: 0.6846, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2911/10000, Loss: 0.6846, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2912/10000, Loss: 0.6846, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2913/10000, Loss: 0.6845, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2914/10000, Loss: 0.6845, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2915/10000, Loss: 0.6845, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2916/10000, Loss: 0.6845, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2917/10000, Loss: 0.6844, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2918/10000, Loss: 0.6844, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2919/10000, Loss: 0.6844, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2920/10000, Loss: 0.6844, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2921/10000, Loss: 0.6843, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2922/10000, Loss: 0.6843, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2923/10000, Loss: 0.6843, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2924/10000, Loss: 0.6843, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2925/10000, Loss: 0.6842, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2926/10000, Loss: 0.6842, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2927/10000, Loss: 0.6842, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2928/10000, Loss: 0.6842, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2929/10000, Loss: 0.6841, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2930/10000, Loss: 0.6841, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2931/10000, Loss: 0.6841, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2932/10000, Loss: 0.6841, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2933/10000, Loss: 0.6840, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2934/10000, Loss: 0.6840, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2935/10000, Loss: 0.6840, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2936/10000, Loss: 0.6840, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2937/10000, Loss: 0.6840, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2938/10000, Loss: 0.6839, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2939/10000, Loss: 0.6839, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2940/10000, Loss: 0.6839, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2941/10000, Loss: 0.6839, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2942/10000, Loss: 0.6838, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2943/10000, Loss: 0.6838, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2944/10000, Loss: 0.6838, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2945/10000, Loss: 0.6838, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2946/10000, Loss: 0.6837, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2947/10000, Loss: 0.6837, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2948/10000, Loss: 0.6837, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2949/10000, Loss: 0.6837, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2950/10000, Loss: 0.6836, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2951/10000, Loss: 0.6836, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2952/10000, Loss: 0.6836, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2953/10000, Loss: 0.6836, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2954/10000, Loss: 0.6835, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2955/10000, Loss: 0.6835, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2956/10000, Loss: 0.6835, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2957/10000, Loss: 0.6835, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2958/10000, Loss: 0.6835, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2959/10000, Loss: 0.6834, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2960/10000, Loss: 0.6834, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2961/10000, Loss: 0.6834, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2962/10000, Loss: 0.6834, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2963/10000, Loss: 0.6833, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2964/10000, Loss: 0.6833, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2965/10000, Loss: 0.6833, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2966/10000, Loss: 0.6833, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2967/10000, Loss: 0.6832, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2968/10000, Loss: 0.6832, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2969/10000, Loss: 0.6832, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2970/10000, Loss: 0.6832, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2971/10000, Loss: 0.6831, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2972/10000, Loss: 0.6831, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2973/10000, Loss: 0.6831, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2974/10000, Loss: 0.6831, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2975/10000, Loss: 0.6830, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2976/10000, Loss: 0.6830, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2977/10000, Loss: 0.6830, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2978/10000, Loss: 0.6830, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2979/10000, Loss: 0.6830, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2980/10000, Loss: 0.6829, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2981/10000, Loss: 0.6829, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2982/10000, Loss: 0.6829, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2983/10000, Loss: 0.6829, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2984/10000, Loss: 0.6828, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2985/10000, Loss: 0.6828, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2986/10000, Loss: 0.6828, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2987/10000, Loss: 0.6828, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2988/10000, Loss: 0.6827, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2989/10000, Loss: 0.6827, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2990/10000, Loss: 0.6827, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2991/10000, Loss: 0.6827, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2992/10000, Loss: 0.6826, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2993/10000, Loss: 0.6826, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2994/10000, Loss: 0.6826, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2995/10000, Loss: 0.6826, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2996/10000, Loss: 0.6825, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2997/10000, Loss: 0.6825, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2998/10000, Loss: 0.6825, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2999/10000, Loss: 0.6825, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3000/10000, Loss: 0.6825, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3001/10000, Loss: 0.6824, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3002/10000, Loss: 0.6824, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3003/10000, Loss: 0.6824, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3004/10000, Loss: 0.6824, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3005/10000, Loss: 0.6823, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3006/10000, Loss: 0.6823, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3007/10000, Loss: 0.6823, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3008/10000, Loss: 0.6823, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3009/10000, Loss: 0.6822, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3010/10000, Loss: 0.6822, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3011/10000, Loss: 0.6822, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3012/10000, Loss: 0.6822, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3013/10000, Loss: 0.6821, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3014/10000, Loss: 0.6821, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3015/10000, Loss: 0.6821, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3016/10000, Loss: 0.6821, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3017/10000, Loss: 0.6821, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3018/10000, Loss: 0.6820, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3019/10000, Loss: 0.6820, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3020/10000, Loss: 0.6820, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3021/10000, Loss: 0.6820, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3022/10000, Loss: 0.6819, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3023/10000, Loss: 0.6819, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3024/10000, Loss: 0.6819, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3025/10000, Loss: 0.6819, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3026/10000, Loss: 0.6818, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3027/10000, Loss: 0.6818, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3028/10000, Loss: 0.6818, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3029/10000, Loss: 0.6818, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3030/10000, Loss: 0.6817, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3031/10000, Loss: 0.6817, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3032/10000, Loss: 0.6817, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3033/10000, Loss: 0.6817, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3034/10000, Loss: 0.6817, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3035/10000, Loss: 0.6816, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3036/10000, Loss: 0.6816, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3037/10000, Loss: 0.6816, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3038/10000, Loss: 0.6816, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3039/10000, Loss: 0.6815, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3040/10000, Loss: 0.6815, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3041/10000, Loss: 0.6815, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3042/10000, Loss: 0.6815, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3043/10000, Loss: 0.6814, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3044/10000, Loss: 0.6814, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3045/10000, Loss: 0.6814, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3046/10000, Loss: 0.6814, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3047/10000, Loss: 0.6814, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3048/10000, Loss: 0.6813, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3049/10000, Loss: 0.6813, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3050/10000, Loss: 0.6813, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3051/10000, Loss: 0.6813, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3052/10000, Loss: 0.6812, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3053/10000, Loss: 0.6812, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3054/10000, Loss: 0.6812, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3055/10000, Loss: 0.6812, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3056/10000, Loss: 0.6811, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3057/10000, Loss: 0.6811, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3058/10000, Loss: 0.6811, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3059/10000, Loss: 0.6811, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3060/10000, Loss: 0.6810, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3061/10000, Loss: 0.6810, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3062/10000, Loss: 0.6810, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3063/10000, Loss: 0.6810, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3064/10000, Loss: 0.6810, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3065/10000, Loss: 0.6809, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3066/10000, Loss: 0.6809, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3067/10000, Loss: 0.6809, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3068/10000, Loss: 0.6809, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3069/10000, Loss: 0.6808, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3070/10000, Loss: 0.6808, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3071/10000, Loss: 0.6808, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3072/10000, Loss: 0.6808, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3073/10000, Loss: 0.6807, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3074/10000, Loss: 0.6807, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3075/10000, Loss: 0.6807, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3076/10000, Loss: 0.6807, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3077/10000, Loss: 0.6807, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3078/10000, Loss: 0.6806, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3079/10000, Loss: 0.6806, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3080/10000, Loss: 0.6806, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3081/10000, Loss: 0.6806, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3082/10000, Loss: 0.6805, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3083/10000, Loss: 0.6805, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3084/10000, Loss: 0.6805, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3085/10000, Loss: 0.6805, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3086/10000, Loss: 0.6804, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3087/10000, Loss: 0.6804, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3088/10000, Loss: 0.6804, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3089/10000, Loss: 0.6804, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3090/10000, Loss: 0.6804, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3091/10000, Loss: 0.6803, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3092/10000, Loss: 0.6803, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3093/10000, Loss: 0.6803, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3094/10000, Loss: 0.6803, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3095/10000, Loss: 0.6802, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3096/10000, Loss: 0.6802, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3097/10000, Loss: 0.6802, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3098/10000, Loss: 0.6802, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3099/10000, Loss: 0.6801, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3100/10000, Loss: 0.6801, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3101/10000, Loss: 0.6801, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3102/10000, Loss: 0.6801, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3103/10000, Loss: 0.6801, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3104/10000, Loss: 0.6800, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3105/10000, Loss: 0.6800, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3106/10000, Loss: 0.6800, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3107/10000, Loss: 0.6800, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3108/10000, Loss: 0.6799, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3109/10000, Loss: 0.6799, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3110/10000, Loss: 0.6799, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3111/10000, Loss: 0.6799, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3112/10000, Loss: 0.6798, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3113/10000, Loss: 0.6798, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3114/10000, Loss: 0.6798, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3115/10000, Loss: 0.6798, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3116/10000, Loss: 0.6798, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3117/10000, Loss: 0.6797, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3118/10000, Loss: 0.6797, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3119/10000, Loss: 0.6797, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3120/10000, Loss: 0.6797, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3121/10000, Loss: 0.6796, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3122/10000, Loss: 0.6796, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3123/10000, Loss: 0.6796, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3124/10000, Loss: 0.6796, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3125/10000, Loss: 0.6796, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3126/10000, Loss: 0.6795, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3127/10000, Loss: 0.6795, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3128/10000, Loss: 0.6795, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3129/10000, Loss: 0.6795, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3130/10000, Loss: 0.6794, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3131/10000, Loss: 0.6794, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3132/10000, Loss: 0.6794, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3133/10000, Loss: 0.6794, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3134/10000, Loss: 0.6793, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3135/10000, Loss: 0.6793, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3136/10000, Loss: 0.6793, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3137/10000, Loss: 0.6793, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3138/10000, Loss: 0.6793, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3139/10000, Loss: 0.6792, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3140/10000, Loss: 0.6792, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3141/10000, Loss: 0.6792, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3142/10000, Loss: 0.6792, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3143/10000, Loss: 0.6791, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3144/10000, Loss: 0.6791, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3145/10000, Loss: 0.6791, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3146/10000, Loss: 0.6791, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3147/10000, Loss: 0.6790, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3148/10000, Loss: 0.6790, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3149/10000, Loss: 0.6790, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3150/10000, Loss: 0.6790, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3151/10000, Loss: 0.6790, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3152/10000, Loss: 0.6789, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3153/10000, Loss: 0.6789, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3154/10000, Loss: 0.6789, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3155/10000, Loss: 0.6789, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3156/10000, Loss: 0.6788, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3157/10000, Loss: 0.6788, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3158/10000, Loss: 0.6788, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3159/10000, Loss: 0.6788, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3160/10000, Loss: 0.6788, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3161/10000, Loss: 0.6787, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3162/10000, Loss: 0.6787, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3163/10000, Loss: 0.6787, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3164/10000, Loss: 0.6787, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3165/10000, Loss: 0.6786, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3166/10000, Loss: 0.6786, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3167/10000, Loss: 0.6786, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3168/10000, Loss: 0.6786, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3169/10000, Loss: 0.6786, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3170/10000, Loss: 0.6785, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3171/10000, Loss: 0.6785, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3172/10000, Loss: 0.6785, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3173/10000, Loss: 0.6785, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3174/10000, Loss: 0.6784, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3175/10000, Loss: 0.6784, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3176/10000, Loss: 0.6784, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3177/10000, Loss: 0.6784, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3178/10000, Loss: 0.6783, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3179/10000, Loss: 0.6783, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3180/10000, Loss: 0.6783, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3181/10000, Loss: 0.6783, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3182/10000, Loss: 0.6783, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3183/10000, Loss: 0.6782, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3184/10000, Loss: 0.6782, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3185/10000, Loss: 0.6782, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3186/10000, Loss: 0.6782, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3187/10000, Loss: 0.6781, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3188/10000, Loss: 0.6781, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3189/10000, Loss: 0.6781, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3190/10000, Loss: 0.6781, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3191/10000, Loss: 0.6781, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3192/10000, Loss: 0.6780, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3193/10000, Loss: 0.6780, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3194/10000, Loss: 0.6780, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3195/10000, Loss: 0.6780, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3196/10000, Loss: 0.6779, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3197/10000, Loss: 0.6779, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3198/10000, Loss: 0.6779, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3199/10000, Loss: 0.6779, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3200/10000, Loss: 0.6779, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3201/10000, Loss: 0.6778, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3202/10000, Loss: 0.6778, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3203/10000, Loss: 0.6778, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3204/10000, Loss: 0.6778, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3205/10000, Loss: 0.6777, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3206/10000, Loss: 0.6777, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3207/10000, Loss: 0.6777, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3208/10000, Loss: 0.6777, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3209/10000, Loss: 0.6777, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3210/10000, Loss: 0.6776, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3211/10000, Loss: 0.6776, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3212/10000, Loss: 0.6776, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3213/10000, Loss: 0.6776, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3214/10000, Loss: 0.6775, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3215/10000, Loss: 0.6775, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3216/10000, Loss: 0.6775, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3217/10000, Loss: 0.6775, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3218/10000, Loss: 0.6775, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3219/10000, Loss: 0.6774, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3220/10000, Loss: 0.6774, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3221/10000, Loss: 0.6774, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3222/10000, Loss: 0.6774, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3223/10000, Loss: 0.6773, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3224/10000, Loss: 0.6773, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3225/10000, Loss: 0.6773, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3226/10000, Loss: 0.6773, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3227/10000, Loss: 0.6773, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3228/10000, Loss: 0.6772, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3229/10000, Loss: 0.6772, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3230/10000, Loss: 0.6772, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3231/10000, Loss: 0.6772, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3232/10000, Loss: 0.6771, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3233/10000, Loss: 0.6771, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3234/10000, Loss: 0.6771, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3235/10000, Loss: 0.6771, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3236/10000, Loss: 0.6771, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3237/10000, Loss: 0.6770, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3238/10000, Loss: 0.6770, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3239/10000, Loss: 0.6770, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3240/10000, Loss: 0.6770, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3241/10000, Loss: 0.6769, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3242/10000, Loss: 0.6769, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3243/10000, Loss: 0.6769, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3244/10000, Loss: 0.6769, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3245/10000, Loss: 0.6769, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3246/10000, Loss: 0.6768, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3247/10000, Loss: 0.6768, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3248/10000, Loss: 0.6768, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3249/10000, Loss: 0.6768, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3250/10000, Loss: 0.6767, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3251/10000, Loss: 0.6767, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3252/10000, Loss: 0.6767, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3253/10000, Loss: 0.6767, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3254/10000, Loss: 0.6767, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3255/10000, Loss: 0.6766, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3256/10000, Loss: 0.6766, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3257/10000, Loss: 0.6766, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3258/10000, Loss: 0.6766, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3259/10000, Loss: 0.6765, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3260/10000, Loss: 0.6765, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3261/10000, Loss: 0.6765, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3262/10000, Loss: 0.6765, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3263/10000, Loss: 0.6765, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3264/10000, Loss: 0.6764, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3265/10000, Loss: 0.6764, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3266/10000, Loss: 0.6764, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3267/10000, Loss: 0.6764, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3268/10000, Loss: 0.6763, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3269/10000, Loss: 0.6763, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3270/10000, Loss: 0.6763, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3271/10000, Loss: 0.6763, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3272/10000, Loss: 0.6763, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3273/10000, Loss: 0.6762, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3274/10000, Loss: 0.6762, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3275/10000, Loss: 0.6762, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3276/10000, Loss: 0.6762, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3277/10000, Loss: 0.6761, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3278/10000, Loss: 0.6761, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3279/10000, Loss: 0.6761, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3280/10000, Loss: 0.6761, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3281/10000, Loss: 0.6761, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3282/10000, Loss: 0.6760, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3283/10000, Loss: 0.6760, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3284/10000, Loss: 0.6760, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3285/10000, Loss: 0.6760, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3286/10000, Loss: 0.6760, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3287/10000, Loss: 0.6759, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3288/10000, Loss: 0.6759, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3289/10000, Loss: 0.6759, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3290/10000, Loss: 0.6759, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3291/10000, Loss: 0.6758, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3292/10000, Loss: 0.6758, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3293/10000, Loss: 0.6758, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3294/10000, Loss: 0.6758, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3295/10000, Loss: 0.6758, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3296/10000, Loss: 0.6757, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3297/10000, Loss: 0.6757, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3298/10000, Loss: 0.6757, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3299/10000, Loss: 0.6757, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3300/10000, Loss: 0.6756, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3301/10000, Loss: 0.6756, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3302/10000, Loss: 0.6756, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3303/10000, Loss: 0.6756, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3304/10000, Loss: 0.6756, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3305/10000, Loss: 0.6755, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3306/10000, Loss: 0.6755, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3307/10000, Loss: 0.6755, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3308/10000, Loss: 0.6755, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3309/10000, Loss: 0.6754, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3310/10000, Loss: 0.6754, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3311/10000, Loss: 0.6754, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3312/10000, Loss: 0.6754, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3313/10000, Loss: 0.6754, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3314/10000, Loss: 0.6753, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3315/10000, Loss: 0.6753, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3316/10000, Loss: 0.6753, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3317/10000, Loss: 0.6753, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3318/10000, Loss: 0.6753, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3319/10000, Loss: 0.6752, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3320/10000, Loss: 0.6752, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3321/10000, Loss: 0.6752, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3322/10000, Loss: 0.6752, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3323/10000, Loss: 0.6751, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3324/10000, Loss: 0.6751, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3325/10000, Loss: 0.6751, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3326/10000, Loss: 0.6751, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3327/10000, Loss: 0.6751, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3328/10000, Loss: 0.6750, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3329/10000, Loss: 0.6750, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3330/10000, Loss: 0.6750, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3331/10000, Loss: 0.6750, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3332/10000, Loss: 0.6749, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3333/10000, Loss: 0.6749, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3334/10000, Loss: 0.6749, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3335/10000, Loss: 0.6749, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3336/10000, Loss: 0.6749, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3337/10000, Loss: 0.6748, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3338/10000, Loss: 0.6748, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3339/10000, Loss: 0.6748, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3340/10000, Loss: 0.6748, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3341/10000, Loss: 0.6748, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3342/10000, Loss: 0.6747, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3343/10000, Loss: 0.6747, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3344/10000, Loss: 0.6747, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3345/10000, Loss: 0.6747, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3346/10000, Loss: 0.6746, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3347/10000, Loss: 0.6746, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3348/10000, Loss: 0.6746, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3349/10000, Loss: 0.6746, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3350/10000, Loss: 0.6746, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3351/10000, Loss: 0.6745, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3352/10000, Loss: 0.6745, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3353/10000, Loss: 0.6745, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3354/10000, Loss: 0.6745, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3355/10000, Loss: 0.6745, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3356/10000, Loss: 0.6744, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3357/10000, Loss: 0.6744, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3358/10000, Loss: 0.6744, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3359/10000, Loss: 0.6744, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3360/10000, Loss: 0.6743, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3361/10000, Loss: 0.6743, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3362/10000, Loss: 0.6743, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3363/10000, Loss: 0.6743, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3364/10000, Loss: 0.6743, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3365/10000, Loss: 0.6742, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3366/10000, Loss: 0.6742, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3367/10000, Loss: 0.6742, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3368/10000, Loss: 0.6742, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3369/10000, Loss: 0.6742, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3370/10000, Loss: 0.6741, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3371/10000, Loss: 0.6741, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3372/10000, Loss: 0.6741, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3373/10000, Loss: 0.6741, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3374/10000, Loss: 0.6740, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3375/10000, Loss: 0.6740, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3376/10000, Loss: 0.6740, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3377/10000, Loss: 0.6740, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3378/10000, Loss: 0.6740, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3379/10000, Loss: 0.6739, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3380/10000, Loss: 0.6739, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3381/10000, Loss: 0.6739, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3382/10000, Loss: 0.6739, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3383/10000, Loss: 0.6739, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3384/10000, Loss: 0.6738, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3385/10000, Loss: 0.6738, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3386/10000, Loss: 0.6738, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3387/10000, Loss: 0.6738, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3388/10000, Loss: 0.6737, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3389/10000, Loss: 0.6737, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3390/10000, Loss: 0.6737, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3391/10000, Loss: 0.6737, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3392/10000, Loss: 0.6737, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3393/10000, Loss: 0.6736, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3394/10000, Loss: 0.6736, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3395/10000, Loss: 0.6736, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3396/10000, Loss: 0.6736, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3397/10000, Loss: 0.6736, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3398/10000, Loss: 0.6735, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3399/10000, Loss: 0.6735, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3400/10000, Loss: 0.6735, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3401/10000, Loss: 0.6735, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3402/10000, Loss: 0.6734, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3403/10000, Loss: 0.6734, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3404/10000, Loss: 0.6734, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3405/10000, Loss: 0.6734, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3406/10000, Loss: 0.6734, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3407/10000, Loss: 0.6733, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3408/10000, Loss: 0.6733, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3409/10000, Loss: 0.6733, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3410/10000, Loss: 0.6733, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3411/10000, Loss: 0.6733, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3412/10000, Loss: 0.6732, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3413/10000, Loss: 0.6732, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3414/10000, Loss: 0.6732, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3415/10000, Loss: 0.6732, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3416/10000, Loss: 0.6732, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3417/10000, Loss: 0.6731, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3418/10000, Loss: 0.6731, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3419/10000, Loss: 0.6731, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3420/10000, Loss: 0.6731, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3421/10000, Loss: 0.6730, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3422/10000, Loss: 0.6730, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3423/10000, Loss: 0.6730, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3424/10000, Loss: 0.6730, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3425/10000, Loss: 0.6730, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3426/10000, Loss: 0.6729, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3427/10000, Loss: 0.6729, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3428/10000, Loss: 0.6729, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3429/10000, Loss: 0.6729, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3430/10000, Loss: 0.6729, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3431/10000, Loss: 0.6728, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3432/10000, Loss: 0.6728, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3433/10000, Loss: 0.6728, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3434/10000, Loss: 0.6728, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3435/10000, Loss: 0.6727, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3436/10000, Loss: 0.6727, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3437/10000, Loss: 0.6727, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3438/10000, Loss: 0.6727, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3439/10000, Loss: 0.6727, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3440/10000, Loss: 0.6726, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3441/10000, Loss: 0.6726, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3442/10000, Loss: 0.6726, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3443/10000, Loss: 0.6726, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3444/10000, Loss: 0.6726, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3445/10000, Loss: 0.6725, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3446/10000, Loss: 0.6725, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3447/10000, Loss: 0.6725, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3448/10000, Loss: 0.6725, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3449/10000, Loss: 0.6725, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3450/10000, Loss: 0.6724, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3451/10000, Loss: 0.6724, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3452/10000, Loss: 0.6724, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3453/10000, Loss: 0.6724, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3454/10000, Loss: 0.6723, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3455/10000, Loss: 0.6723, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3456/10000, Loss: 0.6723, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3457/10000, Loss: 0.6723, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3458/10000, Loss: 0.6723, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3459/10000, Loss: 0.6722, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3460/10000, Loss: 0.6722, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3461/10000, Loss: 0.6722, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3462/10000, Loss: 0.6722, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3463/10000, Loss: 0.6722, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3464/10000, Loss: 0.6721, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3465/10000, Loss: 0.6721, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3466/10000, Loss: 0.6721, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3467/10000, Loss: 0.6721, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3468/10000, Loss: 0.6721, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3469/10000, Loss: 0.6720, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3470/10000, Loss: 0.6720, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3471/10000, Loss: 0.6720, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3472/10000, Loss: 0.6720, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3473/10000, Loss: 0.6720, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3474/10000, Loss: 0.6719, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3475/10000, Loss: 0.6719, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3476/10000, Loss: 0.6719, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3477/10000, Loss: 0.6719, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3478/10000, Loss: 0.6718, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3479/10000, Loss: 0.6718, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3480/10000, Loss: 0.6718, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3481/10000, Loss: 0.6718, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3482/10000, Loss: 0.6718, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3483/10000, Loss: 0.6717, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3484/10000, Loss: 0.6717, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3485/10000, Loss: 0.6717, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3486/10000, Loss: 0.6717, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3487/10000, Loss: 0.6717, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3488/10000, Loss: 0.6716, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3489/10000, Loss: 0.6716, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3490/10000, Loss: 0.6716, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3491/10000, Loss: 0.6716, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3492/10000, Loss: 0.6716, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3493/10000, Loss: 0.6715, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3494/10000, Loss: 0.6715, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3495/10000, Loss: 0.6715, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3496/10000, Loss: 0.6715, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3497/10000, Loss: 0.6715, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3498/10000, Loss: 0.6714, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3499/10000, Loss: 0.6714, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3500/10000, Loss: 0.6714, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3501/10000, Loss: 0.6714, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3502/10000, Loss: 0.6713, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3503/10000, Loss: 0.6713, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3504/10000, Loss: 0.6713, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3505/10000, Loss: 0.6713, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3506/10000, Loss: 0.6713, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3507/10000, Loss: 0.6712, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3508/10000, Loss: 0.6712, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3509/10000, Loss: 0.6712, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3510/10000, Loss: 0.6712, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3511/10000, Loss: 0.6712, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3512/10000, Loss: 0.6711, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3513/10000, Loss: 0.6711, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3514/10000, Loss: 0.6711, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3515/10000, Loss: 0.6711, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3516/10000, Loss: 0.6711, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3517/10000, Loss: 0.6710, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3518/10000, Loss: 0.6710, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3519/10000, Loss: 0.6710, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3520/10000, Loss: 0.6710, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3521/10000, Loss: 0.6710, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3522/10000, Loss: 0.6709, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3523/10000, Loss: 0.6709, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3524/10000, Loss: 0.6709, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3525/10000, Loss: 0.6709, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3526/10000, Loss: 0.6709, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3527/10000, Loss: 0.6708, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3528/10000, Loss: 0.6708, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3529/10000, Loss: 0.6708, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3530/10000, Loss: 0.6708, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3531/10000, Loss: 0.6708, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3532/10000, Loss: 0.6707, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3533/10000, Loss: 0.6707, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3534/10000, Loss: 0.6707, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3535/10000, Loss: 0.6707, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3536/10000, Loss: 0.6706, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3537/10000, Loss: 0.6706, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3538/10000, Loss: 0.6706, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3539/10000, Loss: 0.6706, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3540/10000, Loss: 0.6706, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3541/10000, Loss: 0.6705, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3542/10000, Loss: 0.6705, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3543/10000, Loss: 0.6705, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3544/10000, Loss: 0.6705, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3545/10000, Loss: 0.6705, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3546/10000, Loss: 0.6704, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3547/10000, Loss: 0.6704, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3548/10000, Loss: 0.6704, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3549/10000, Loss: 0.6704, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3550/10000, Loss: 0.6704, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3551/10000, Loss: 0.6703, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3552/10000, Loss: 0.6703, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3553/10000, Loss: 0.6703, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3554/10000, Loss: 0.6703, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3555/10000, Loss: 0.6703, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3556/10000, Loss: 0.6702, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3557/10000, Loss: 0.6702, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3558/10000, Loss: 0.6702, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3559/10000, Loss: 0.6702, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3560/10000, Loss: 0.6702, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3561/10000, Loss: 0.6701, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3562/10000, Loss: 0.6701, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3563/10000, Loss: 0.6701, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3564/10000, Loss: 0.6701, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3565/10000, Loss: 0.6701, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3566/10000, Loss: 0.6700, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3567/10000, Loss: 0.6700, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3568/10000, Loss: 0.6700, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3569/10000, Loss: 0.6700, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3570/10000, Loss: 0.6700, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3571/10000, Loss: 0.6699, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3572/10000, Loss: 0.6699, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3573/10000, Loss: 0.6699, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3574/10000, Loss: 0.6699, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3575/10000, Loss: 0.6699, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3576/10000, Loss: 0.6698, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3577/10000, Loss: 0.6698, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3578/10000, Loss: 0.6698, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3579/10000, Loss: 0.6698, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3580/10000, Loss: 0.6697, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3581/10000, Loss: 0.6697, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3582/10000, Loss: 0.6697, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3583/10000, Loss: 0.6697, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3584/10000, Loss: 0.6697, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3585/10000, Loss: 0.6696, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3586/10000, Loss: 0.6696, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3587/10000, Loss: 0.6696, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3588/10000, Loss: 0.6696, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3589/10000, Loss: 0.6696, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3590/10000, Loss: 0.6695, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3591/10000, Loss: 0.6695, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3592/10000, Loss: 0.6695, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3593/10000, Loss: 0.6695, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3594/10000, Loss: 0.6695, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3595/10000, Loss: 0.6694, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3596/10000, Loss: 0.6694, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3597/10000, Loss: 0.6694, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3598/10000, Loss: 0.6694, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3599/10000, Loss: 0.6694, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3600/10000, Loss: 0.6693, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3601/10000, Loss: 0.6693, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3602/10000, Loss: 0.6693, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3603/10000, Loss: 0.6693, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3604/10000, Loss: 0.6693, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3605/10000, Loss: 0.6692, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3606/10000, Loss: 0.6692, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3607/10000, Loss: 0.6692, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3608/10000, Loss: 0.6692, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3609/10000, Loss: 0.6692, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3610/10000, Loss: 0.6691, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3611/10000, Loss: 0.6691, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3612/10000, Loss: 0.6691, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3613/10000, Loss: 0.6691, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3614/10000, Loss: 0.6691, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3615/10000, Loss: 0.6690, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3616/10000, Loss: 0.6690, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3617/10000, Loss: 0.6690, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3618/10000, Loss: 0.6690, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3619/10000, Loss: 0.6690, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3620/10000, Loss: 0.6689, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3621/10000, Loss: 0.6689, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3622/10000, Loss: 0.6689, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3623/10000, Loss: 0.6689, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3624/10000, Loss: 0.6689, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3625/10000, Loss: 0.6688, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3626/10000, Loss: 0.6688, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3627/10000, Loss: 0.6688, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3628/10000, Loss: 0.6688, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3629/10000, Loss: 0.6688, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3630/10000, Loss: 0.6687, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3631/10000, Loss: 0.6687, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3632/10000, Loss: 0.6687, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3633/10000, Loss: 0.6687, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3634/10000, Loss: 0.6687, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3635/10000, Loss: 0.6686, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3636/10000, Loss: 0.6686, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3637/10000, Loss: 0.6686, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3638/10000, Loss: 0.6686, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3639/10000, Loss: 0.6686, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3640/10000, Loss: 0.6685, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3641/10000, Loss: 0.6685, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3642/10000, Loss: 0.6685, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3643/10000, Loss: 0.6685, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3644/10000, Loss: 0.6685, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3645/10000, Loss: 0.6684, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3646/10000, Loss: 0.6684, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3647/10000, Loss: 0.6684, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3648/10000, Loss: 0.6684, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3649/10000, Loss: 0.6684, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3650/10000, Loss: 0.6683, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3651/10000, Loss: 0.6683, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3652/10000, Loss: 0.6683, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3653/10000, Loss: 0.6683, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3654/10000, Loss: 0.6683, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3655/10000, Loss: 0.6682, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3656/10000, Loss: 0.6682, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3657/10000, Loss: 0.6682, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3658/10000, Loss: 0.6682, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3659/10000, Loss: 0.6682, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3660/10000, Loss: 0.6681, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3661/10000, Loss: 0.6681, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3662/10000, Loss: 0.6681, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3663/10000, Loss: 0.6681, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3664/10000, Loss: 0.6681, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3665/10000, Loss: 0.6680, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3666/10000, Loss: 0.6680, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3667/10000, Loss: 0.6680, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3668/10000, Loss: 0.6680, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3669/10000, Loss: 0.6680, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3670/10000, Loss: 0.6679, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3671/10000, Loss: 0.6679, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3672/10000, Loss: 0.6679, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3673/10000, Loss: 0.6679, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3674/10000, Loss: 0.6679, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3675/10000, Loss: 0.6678, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3676/10000, Loss: 0.6678, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3677/10000, Loss: 0.6678, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3678/10000, Loss: 0.6678, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3679/10000, Loss: 0.6678, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3680/10000, Loss: 0.6677, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3681/10000, Loss: 0.6677, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3682/10000, Loss: 0.6677, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3683/10000, Loss: 0.6677, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3684/10000, Loss: 0.6677, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3685/10000, Loss: 0.6676, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3686/10000, Loss: 0.6676, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3687/10000, Loss: 0.6676, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3688/10000, Loss: 0.6676, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3689/10000, Loss: 0.6676, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3690/10000, Loss: 0.6675, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3691/10000, Loss: 0.6675, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3692/10000, Loss: 0.6675, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3693/10000, Loss: 0.6675, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3694/10000, Loss: 0.6675, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3695/10000, Loss: 0.6674, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3696/10000, Loss: 0.6674, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3697/10000, Loss: 0.6674, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3698/10000, Loss: 0.6674, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3699/10000, Loss: 0.6674, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3700/10000, Loss: 0.6674, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3701/10000, Loss: 0.6673, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3702/10000, Loss: 0.6673, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3703/10000, Loss: 0.6673, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3704/10000, Loss: 0.6673, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3705/10000, Loss: 0.6673, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3706/10000, Loss: 0.6672, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3707/10000, Loss: 0.6672, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3708/10000, Loss: 0.6672, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3709/10000, Loss: 0.6672, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3710/10000, Loss: 0.6672, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3711/10000, Loss: 0.6671, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3712/10000, Loss: 0.6671, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3713/10000, Loss: 0.6671, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3714/10000, Loss: 0.6671, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3715/10000, Loss: 0.6671, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3716/10000, Loss: 0.6670, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3717/10000, Loss: 0.6670, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3718/10000, Loss: 0.6670, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3719/10000, Loss: 0.6670, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3720/10000, Loss: 0.6670, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3721/10000, Loss: 0.6669, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3722/10000, Loss: 0.6669, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3723/10000, Loss: 0.6669, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3724/10000, Loss: 0.6669, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3725/10000, Loss: 0.6669, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3726/10000, Loss: 0.6668, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3727/10000, Loss: 0.6668, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3728/10000, Loss: 0.6668, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3729/10000, Loss: 0.6668, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3730/10000, Loss: 0.6668, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3731/10000, Loss: 0.6667, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3732/10000, Loss: 0.6667, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3733/10000, Loss: 0.6667, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3734/10000, Loss: 0.6667, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3735/10000, Loss: 0.6667, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3736/10000, Loss: 0.6666, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3737/10000, Loss: 0.6666, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3738/10000, Loss: 0.6666, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3739/10000, Loss: 0.6666, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3740/10000, Loss: 0.6666, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3741/10000, Loss: 0.6665, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3742/10000, Loss: 0.6665, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3743/10000, Loss: 0.6665, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3744/10000, Loss: 0.6665, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3745/10000, Loss: 0.6665, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3746/10000, Loss: 0.6664, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3747/10000, Loss: 0.6664, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3748/10000, Loss: 0.6664, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3749/10000, Loss: 0.6664, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3750/10000, Loss: 0.6664, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3751/10000, Loss: 0.6664, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3752/10000, Loss: 0.6663, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3753/10000, Loss: 0.6663, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3754/10000, Loss: 0.6663, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3755/10000, Loss: 0.6663, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3756/10000, Loss: 0.6663, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3757/10000, Loss: 0.6662, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3758/10000, Loss: 0.6662, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3759/10000, Loss: 0.6662, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3760/10000, Loss: 0.6662, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3761/10000, Loss: 0.6662, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3762/10000, Loss: 0.6661, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3763/10000, Loss: 0.6661, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3764/10000, Loss: 0.6661, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3765/10000, Loss: 0.6661, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3766/10000, Loss: 0.6661, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3767/10000, Loss: 0.6660, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3768/10000, Loss: 0.6660, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3769/10000, Loss: 0.6660, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3770/10000, Loss: 0.6660, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3771/10000, Loss: 0.6660, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3772/10000, Loss: 0.6659, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3773/10000, Loss: 0.6659, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3774/10000, Loss: 0.6659, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3775/10000, Loss: 0.6659, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3776/10000, Loss: 0.6659, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3777/10000, Loss: 0.6658, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3778/10000, Loss: 0.6658, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3779/10000, Loss: 0.6658, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3780/10000, Loss: 0.6658, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3781/10000, Loss: 0.6658, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3782/10000, Loss: 0.6658, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3783/10000, Loss: 0.6657, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3784/10000, Loss: 0.6657, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3785/10000, Loss: 0.6657, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3786/10000, Loss: 0.6657, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3787/10000, Loss: 0.6657, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3788/10000, Loss: 0.6656, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3789/10000, Loss: 0.6656, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3790/10000, Loss: 0.6656, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3791/10000, Loss: 0.6656, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3792/10000, Loss: 0.6656, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3793/10000, Loss: 0.6655, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3794/10000, Loss: 0.6655, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3795/10000, Loss: 0.6655, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3796/10000, Loss: 0.6655, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3797/10000, Loss: 0.6655, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3798/10000, Loss: 0.6654, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3799/10000, Loss: 0.6654, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3800/10000, Loss: 0.6654, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3801/10000, Loss: 0.6654, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3802/10000, Loss: 0.6654, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3803/10000, Loss: 0.6653, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3804/10000, Loss: 0.6653, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3805/10000, Loss: 0.6653, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3806/10000, Loss: 0.6653, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3807/10000, Loss: 0.6653, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3808/10000, Loss: 0.6653, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3809/10000, Loss: 0.6652, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3810/10000, Loss: 0.6652, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3811/10000, Loss: 0.6652, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3812/10000, Loss: 0.6652, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3813/10000, Loss: 0.6652, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3814/10000, Loss: 0.6651, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3815/10000, Loss: 0.6651, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3816/10000, Loss: 0.6651, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3817/10000, Loss: 0.6651, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3818/10000, Loss: 0.6651, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3819/10000, Loss: 0.6650, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3820/10000, Loss: 0.6650, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3821/10000, Loss: 0.6650, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3822/10000, Loss: 0.6650, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3823/10000, Loss: 0.6650, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3824/10000, Loss: 0.6649, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3825/10000, Loss: 0.6649, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3826/10000, Loss: 0.6649, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3827/10000, Loss: 0.6649, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3828/10000, Loss: 0.6649, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3829/10000, Loss: 0.6649, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3830/10000, Loss: 0.6648, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3831/10000, Loss: 0.6648, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3832/10000, Loss: 0.6648, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3833/10000, Loss: 0.6648, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3834/10000, Loss: 0.6648, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3835/10000, Loss: 0.6647, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3836/10000, Loss: 0.6647, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3837/10000, Loss: 0.6647, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3838/10000, Loss: 0.6647, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3839/10000, Loss: 0.6647, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3840/10000, Loss: 0.6646, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3841/10000, Loss: 0.6646, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3842/10000, Loss: 0.6646, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3843/10000, Loss: 0.6646, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3844/10000, Loss: 0.6646, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3845/10000, Loss: 0.6645, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3846/10000, Loss: 0.6645, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3847/10000, Loss: 0.6645, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3848/10000, Loss: 0.6645, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3849/10000, Loss: 0.6645, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3850/10000, Loss: 0.6645, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3851/10000, Loss: 0.6644, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3852/10000, Loss: 0.6644, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3853/10000, Loss: 0.6644, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3854/10000, Loss: 0.6644, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3855/10000, Loss: 0.6644, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3856/10000, Loss: 0.6643, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3857/10000, Loss: 0.6643, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3858/10000, Loss: 0.6643, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3859/10000, Loss: 0.6643, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3860/10000, Loss: 0.6643, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3861/10000, Loss: 0.6642, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3862/10000, Loss: 0.6642, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3863/10000, Loss: 0.6642, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3864/10000, Loss: 0.6642, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3865/10000, Loss: 0.6642, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3866/10000, Loss: 0.6642, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3867/10000, Loss: 0.6641, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3868/10000, Loss: 0.6641, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3869/10000, Loss: 0.6641, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3870/10000, Loss: 0.6641, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3871/10000, Loss: 0.6641, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3872/10000, Loss: 0.6640, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3873/10000, Loss: 0.6640, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3874/10000, Loss: 0.6640, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3875/10000, Loss: 0.6640, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3876/10000, Loss: 0.6640, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3877/10000, Loss: 0.6639, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3878/10000, Loss: 0.6639, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3879/10000, Loss: 0.6639, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3880/10000, Loss: 0.6639, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3881/10000, Loss: 0.6639, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3882/10000, Loss: 0.6638, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3883/10000, Loss: 0.6638, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3884/10000, Loss: 0.6638, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3885/10000, Loss: 0.6638, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3886/10000, Loss: 0.6638, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3887/10000, Loss: 0.6638, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3888/10000, Loss: 0.6637, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3889/10000, Loss: 0.6637, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3890/10000, Loss: 0.6637, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3891/10000, Loss: 0.6637, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3892/10000, Loss: 0.6637, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3893/10000, Loss: 0.6636, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3894/10000, Loss: 0.6636, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3895/10000, Loss: 0.6636, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3896/10000, Loss: 0.6636, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3897/10000, Loss: 0.6636, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3898/10000, Loss: 0.6635, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3899/10000, Loss: 0.6635, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3900/10000, Loss: 0.6635, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3901/10000, Loss: 0.6635, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3902/10000, Loss: 0.6635, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3903/10000, Loss: 0.6635, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3904/10000, Loss: 0.6634, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3905/10000, Loss: 0.6634, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3906/10000, Loss: 0.6634, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3907/10000, Loss: 0.6634, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3908/10000, Loss: 0.6634, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3909/10000, Loss: 0.6633, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3910/10000, Loss: 0.6633, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3911/10000, Loss: 0.6633, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3912/10000, Loss: 0.6633, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3913/10000, Loss: 0.6633, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3914/10000, Loss: 0.6632, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3915/10000, Loss: 0.6632, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3916/10000, Loss: 0.6632, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3917/10000, Loss: 0.6632, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3918/10000, Loss: 0.6632, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3919/10000, Loss: 0.6632, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3920/10000, Loss: 0.6631, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3921/10000, Loss: 0.6631, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3922/10000, Loss: 0.6631, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3923/10000, Loss: 0.6631, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3924/10000, Loss: 0.6631, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3925/10000, Loss: 0.6630, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3926/10000, Loss: 0.6630, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3927/10000, Loss: 0.6630, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3928/10000, Loss: 0.6630, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3929/10000, Loss: 0.6630, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3930/10000, Loss: 0.6630, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3931/10000, Loss: 0.6629, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3932/10000, Loss: 0.6629, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3933/10000, Loss: 0.6629, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3934/10000, Loss: 0.6629, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3935/10000, Loss: 0.6629, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3936/10000, Loss: 0.6628, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3937/10000, Loss: 0.6628, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3938/10000, Loss: 0.6628, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3939/10000, Loss: 0.6628, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3940/10000, Loss: 0.6628, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3941/10000, Loss: 0.6627, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3942/10000, Loss: 0.6627, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3943/10000, Loss: 0.6627, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3944/10000, Loss: 0.6627, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3945/10000, Loss: 0.6627, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3946/10000, Loss: 0.6627, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3947/10000, Loss: 0.6626, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3948/10000, Loss: 0.6626, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3949/10000, Loss: 0.6626, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3950/10000, Loss: 0.6626, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3951/10000, Loss: 0.6626, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3952/10000, Loss: 0.6625, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3953/10000, Loss: 0.6625, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3954/10000, Loss: 0.6625, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3955/10000, Loss: 0.6625, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3956/10000, Loss: 0.6625, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3957/10000, Loss: 0.6625, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3958/10000, Loss: 0.6624, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3959/10000, Loss: 0.6624, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3960/10000, Loss: 0.6624, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3961/10000, Loss: 0.6624, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3962/10000, Loss: 0.6624, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3963/10000, Loss: 0.6623, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3964/10000, Loss: 0.6623, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3965/10000, Loss: 0.6623, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3966/10000, Loss: 0.6623, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3967/10000, Loss: 0.6623, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3968/10000, Loss: 0.6623, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3969/10000, Loss: 0.6622, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3970/10000, Loss: 0.6622, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3971/10000, Loss: 0.6622, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3972/10000, Loss: 0.6622, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3973/10000, Loss: 0.6622, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3974/10000, Loss: 0.6621, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3975/10000, Loss: 0.6621, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3976/10000, Loss: 0.6621, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3977/10000, Loss: 0.6621, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3978/10000, Loss: 0.6621, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3979/10000, Loss: 0.6620, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3980/10000, Loss: 0.6620, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3981/10000, Loss: 0.6620, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3982/10000, Loss: 0.6620, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3983/10000, Loss: 0.6620, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3984/10000, Loss: 0.6620, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3985/10000, Loss: 0.6619, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3986/10000, Loss: 0.6619, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3987/10000, Loss: 0.6619, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3988/10000, Loss: 0.6619, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3989/10000, Loss: 0.6619, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3990/10000, Loss: 0.6618, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3991/10000, Loss: 0.6618, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3992/10000, Loss: 0.6618, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3993/10000, Loss: 0.6618, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3994/10000, Loss: 0.6618, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3995/10000, Loss: 0.6618, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3996/10000, Loss: 0.6617, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3997/10000, Loss: 0.6617, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3998/10000, Loss: 0.6617, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3999/10000, Loss: 0.6617, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4000/10000, Loss: 0.6617, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4001/10000, Loss: 0.6616, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4002/10000, Loss: 0.6616, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4003/10000, Loss: 0.6616, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4004/10000, Loss: 0.6616, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4005/10000, Loss: 0.6616, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4006/10000, Loss: 0.6616, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4007/10000, Loss: 0.6615, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4008/10000, Loss: 0.6615, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4009/10000, Loss: 0.6615, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4010/10000, Loss: 0.6615, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4011/10000, Loss: 0.6615, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4012/10000, Loss: 0.6614, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4013/10000, Loss: 0.6614, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4014/10000, Loss: 0.6614, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4015/10000, Loss: 0.6614, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4016/10000, Loss: 0.6614, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4017/10000, Loss: 0.6614, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4018/10000, Loss: 0.6613, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4019/10000, Loss: 0.6613, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4020/10000, Loss: 0.6613, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4021/10000, Loss: 0.6613, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4022/10000, Loss: 0.6613, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4023/10000, Loss: 0.6612, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4024/10000, Loss: 0.6612, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4025/10000, Loss: 0.6612, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4026/10000, Loss: 0.6612, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4027/10000, Loss: 0.6612, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4028/10000, Loss: 0.6612, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4029/10000, Loss: 0.6611, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4030/10000, Loss: 0.6611, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4031/10000, Loss: 0.6611, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4032/10000, Loss: 0.6611, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4033/10000, Loss: 0.6611, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4034/10000, Loss: 0.6610, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4035/10000, Loss: 0.6610, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4036/10000, Loss: 0.6610, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4037/10000, Loss: 0.6610, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4038/10000, Loss: 0.6610, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4039/10000, Loss: 0.6610, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4040/10000, Loss: 0.6609, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4041/10000, Loss: 0.6609, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4042/10000, Loss: 0.6609, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4043/10000, Loss: 0.6609, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4044/10000, Loss: 0.6609, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4045/10000, Loss: 0.6608, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4046/10000, Loss: 0.6608, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4047/10000, Loss: 0.6608, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4048/10000, Loss: 0.6608, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4049/10000, Loss: 0.6608, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4050/10000, Loss: 0.6608, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4051/10000, Loss: 0.6607, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4052/10000, Loss: 0.6607, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4053/10000, Loss: 0.6607, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4054/10000, Loss: 0.6607, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4055/10000, Loss: 0.6607, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4056/10000, Loss: 0.6607, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4057/10000, Loss: 0.6606, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4058/10000, Loss: 0.6606, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4059/10000, Loss: 0.6606, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4060/10000, Loss: 0.6606, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4061/10000, Loss: 0.6606, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4062/10000, Loss: 0.6605, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4063/10000, Loss: 0.6605, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4064/10000, Loss: 0.6605, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4065/10000, Loss: 0.6605, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4066/10000, Loss: 0.6605, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4067/10000, Loss: 0.6605, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4068/10000, Loss: 0.6604, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4069/10000, Loss: 0.6604, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4070/10000, Loss: 0.6604, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4071/10000, Loss: 0.6604, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4072/10000, Loss: 0.6604, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4073/10000, Loss: 0.6603, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4074/10000, Loss: 0.6603, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4075/10000, Loss: 0.6603, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4076/10000, Loss: 0.6603, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4077/10000, Loss: 0.6603, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4078/10000, Loss: 0.6603, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4079/10000, Loss: 0.6602, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4080/10000, Loss: 0.6602, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4081/10000, Loss: 0.6602, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4082/10000, Loss: 0.6602, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4083/10000, Loss: 0.6602, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4084/10000, Loss: 0.6601, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4085/10000, Loss: 0.6601, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4086/10000, Loss: 0.6601, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4087/10000, Loss: 0.6601, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4088/10000, Loss: 0.6601, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4089/10000, Loss: 0.6601, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4090/10000, Loss: 0.6600, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4091/10000, Loss: 0.6600, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4092/10000, Loss: 0.6600, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4093/10000, Loss: 0.6600, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4094/10000, Loss: 0.6600, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4095/10000, Loss: 0.6600, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4096/10000, Loss: 0.6599, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4097/10000, Loss: 0.6599, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4098/10000, Loss: 0.6599, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4099/10000, Loss: 0.6599, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4100/10000, Loss: 0.6599, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4101/10000, Loss: 0.6598, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4102/10000, Loss: 0.6598, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4103/10000, Loss: 0.6598, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4104/10000, Loss: 0.6598, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4105/10000, Loss: 0.6598, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4106/10000, Loss: 0.6598, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4107/10000, Loss: 0.6597, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4108/10000, Loss: 0.6597, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4109/10000, Loss: 0.6597, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4110/10000, Loss: 0.6597, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4111/10000, Loss: 0.6597, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4112/10000, Loss: 0.6597, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4113/10000, Loss: 0.6596, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4114/10000, Loss: 0.6596, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4115/10000, Loss: 0.6596, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4116/10000, Loss: 0.6596, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4117/10000, Loss: 0.6596, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4118/10000, Loss: 0.6595, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4119/10000, Loss: 0.6595, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4120/10000, Loss: 0.6595, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4121/10000, Loss: 0.6595, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4122/10000, Loss: 0.6595, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4123/10000, Loss: 0.6595, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4124/10000, Loss: 0.6594, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4125/10000, Loss: 0.6594, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4126/10000, Loss: 0.6594, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4127/10000, Loss: 0.6594, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4128/10000, Loss: 0.6594, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4129/10000, Loss: 0.6594, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4130/10000, Loss: 0.6593, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4131/10000, Loss: 0.6593, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4132/10000, Loss: 0.6593, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4133/10000, Loss: 0.6593, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4134/10000, Loss: 0.6593, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4135/10000, Loss: 0.6592, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4136/10000, Loss: 0.6592, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4137/10000, Loss: 0.6592, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4138/10000, Loss: 0.6592, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4139/10000, Loss: 0.6592, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4140/10000, Loss: 0.6592, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4141/10000, Loss: 0.6591, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4142/10000, Loss: 0.6591, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4143/10000, Loss: 0.6591, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4144/10000, Loss: 0.6591, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4145/10000, Loss: 0.6591, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4146/10000, Loss: 0.6591, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4147/10000, Loss: 0.6590, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4148/10000, Loss: 0.6590, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4149/10000, Loss: 0.6590, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4150/10000, Loss: 0.6590, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4151/10000, Loss: 0.6590, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4152/10000, Loss: 0.6589, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4153/10000, Loss: 0.6589, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4154/10000, Loss: 0.6589, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4155/10000, Loss: 0.6589, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4156/10000, Loss: 0.6589, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4157/10000, Loss: 0.6589, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4158/10000, Loss: 0.6588, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4159/10000, Loss: 0.6588, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4160/10000, Loss: 0.6588, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4161/10000, Loss: 0.6588, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4162/10000, Loss: 0.6588, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4163/10000, Loss: 0.6588, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4164/10000, Loss: 0.6587, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4165/10000, Loss: 0.6587, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4166/10000, Loss: 0.6587, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4167/10000, Loss: 0.6587, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4168/10000, Loss: 0.6587, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4169/10000, Loss: 0.6586, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4170/10000, Loss: 0.6586, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4171/10000, Loss: 0.6586, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4172/10000, Loss: 0.6586, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4173/10000, Loss: 0.6586, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4174/10000, Loss: 0.6586, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4175/10000, Loss: 0.6585, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4176/10000, Loss: 0.6585, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4177/10000, Loss: 0.6585, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4178/10000, Loss: 0.6585, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4179/10000, Loss: 0.6585, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4180/10000, Loss: 0.6585, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4181/10000, Loss: 0.6584, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4182/10000, Loss: 0.6584, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4183/10000, Loss: 0.6584, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4184/10000, Loss: 0.6584, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4185/10000, Loss: 0.6584, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4186/10000, Loss: 0.6584, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4187/10000, Loss: 0.6583, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4188/10000, Loss: 0.6583, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4189/10000, Loss: 0.6583, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4190/10000, Loss: 0.6583, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4191/10000, Loss: 0.6583, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4192/10000, Loss: 0.6582, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4193/10000, Loss: 0.6582, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4194/10000, Loss: 0.6582, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4195/10000, Loss: 0.6582, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4196/10000, Loss: 0.6582, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4197/10000, Loss: 0.6582, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4198/10000, Loss: 0.6581, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4199/10000, Loss: 0.6581, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4200/10000, Loss: 0.6581, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4201/10000, Loss: 0.6581, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4202/10000, Loss: 0.6581, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4203/10000, Loss: 0.6581, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4204/10000, Loss: 0.6580, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4205/10000, Loss: 0.6580, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4206/10000, Loss: 0.6580, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4207/10000, Loss: 0.6580, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4208/10000, Loss: 0.6580, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4209/10000, Loss: 0.6580, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4210/10000, Loss: 0.6579, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4211/10000, Loss: 0.6579, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4212/10000, Loss: 0.6579, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4213/10000, Loss: 0.6579, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4214/10000, Loss: 0.6579, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4215/10000, Loss: 0.6578, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4216/10000, Loss: 0.6578, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4217/10000, Loss: 0.6578, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4218/10000, Loss: 0.6578, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4219/10000, Loss: 0.6578, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4220/10000, Loss: 0.6578, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4221/10000, Loss: 0.6577, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4222/10000, Loss: 0.6577, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4223/10000, Loss: 0.6577, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4224/10000, Loss: 0.6577, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4225/10000, Loss: 0.6577, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4226/10000, Loss: 0.6577, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4227/10000, Loss: 0.6576, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4228/10000, Loss: 0.6576, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4229/10000, Loss: 0.6576, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4230/10000, Loss: 0.6576, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4231/10000, Loss: 0.6576, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4232/10000, Loss: 0.6576, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4233/10000, Loss: 0.6575, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4234/10000, Loss: 0.6575, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4235/10000, Loss: 0.6575, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4236/10000, Loss: 0.6575, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4237/10000, Loss: 0.6575, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4238/10000, Loss: 0.6575, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4239/10000, Loss: 0.6574, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4240/10000, Loss: 0.6574, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4241/10000, Loss: 0.6574, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4242/10000, Loss: 0.6574, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4243/10000, Loss: 0.6574, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4244/10000, Loss: 0.6574, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4245/10000, Loss: 0.6573, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4246/10000, Loss: 0.6573, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4247/10000, Loss: 0.6573, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4248/10000, Loss: 0.6573, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4249/10000, Loss: 0.6573, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4250/10000, Loss: 0.6572, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4251/10000, Loss: 0.6572, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4252/10000, Loss: 0.6572, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4253/10000, Loss: 0.6572, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4254/10000, Loss: 0.6572, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4255/10000, Loss: 0.6572, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4256/10000, Loss: 0.6571, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4257/10000, Loss: 0.6571, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4258/10000, Loss: 0.6571, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4259/10000, Loss: 0.6571, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4260/10000, Loss: 0.6571, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4261/10000, Loss: 0.6571, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4262/10000, Loss: 0.6570, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4263/10000, Loss: 0.6570, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4264/10000, Loss: 0.6570, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4265/10000, Loss: 0.6570, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4266/10000, Loss: 0.6570, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4267/10000, Loss: 0.6570, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4268/10000, Loss: 0.6569, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4269/10000, Loss: 0.6569, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4270/10000, Loss: 0.6569, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4271/10000, Loss: 0.6569, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4272/10000, Loss: 0.6569, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4273/10000, Loss: 0.6569, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4274/10000, Loss: 0.6568, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4275/10000, Loss: 0.6568, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4276/10000, Loss: 0.6568, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4277/10000, Loss: 0.6568, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4278/10000, Loss: 0.6568, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4279/10000, Loss: 0.6568, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4280/10000, Loss: 0.6567, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4281/10000, Loss: 0.6567, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4282/10000, Loss: 0.6567, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4283/10000, Loss: 0.6567, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4284/10000, Loss: 0.6567, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4285/10000, Loss: 0.6567, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4286/10000, Loss: 0.6566, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4287/10000, Loss: 0.6566, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4288/10000, Loss: 0.6566, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4289/10000, Loss: 0.6566, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4290/10000, Loss: 0.6566, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4291/10000, Loss: 0.6566, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4292/10000, Loss: 0.6565, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4293/10000, Loss: 0.6565, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4294/10000, Loss: 0.6565, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4295/10000, Loss: 0.6565, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4296/10000, Loss: 0.6565, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4297/10000, Loss: 0.6564, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4298/10000, Loss: 0.6564, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4299/10000, Loss: 0.6564, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4300/10000, Loss: 0.6564, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4301/10000, Loss: 0.6564, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4302/10000, Loss: 0.6564, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4303/10000, Loss: 0.6563, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4304/10000, Loss: 0.6563, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4305/10000, Loss: 0.6563, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4306/10000, Loss: 0.6563, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4307/10000, Loss: 0.6563, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4308/10000, Loss: 0.6563, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4309/10000, Loss: 0.6562, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4310/10000, Loss: 0.6562, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4311/10000, Loss: 0.6562, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4312/10000, Loss: 0.6562, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4313/10000, Loss: 0.6562, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4314/10000, Loss: 0.6562, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4315/10000, Loss: 0.6561, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4316/10000, Loss: 0.6561, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4317/10000, Loss: 0.6561, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4318/10000, Loss: 0.6561, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4319/10000, Loss: 0.6561, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4320/10000, Loss: 0.6561, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4321/10000, Loss: 0.6560, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4322/10000, Loss: 0.6560, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4323/10000, Loss: 0.6560, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4324/10000, Loss: 0.6560, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4325/10000, Loss: 0.6560, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4326/10000, Loss: 0.6560, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4327/10000, Loss: 0.6559, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4328/10000, Loss: 0.6559, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4329/10000, Loss: 0.6559, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4330/10000, Loss: 0.6559, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4331/10000, Loss: 0.6559, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4332/10000, Loss: 0.6559, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4333/10000, Loss: 0.6558, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4334/10000, Loss: 0.6558, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4335/10000, Loss: 0.6558, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4336/10000, Loss: 0.6558, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4337/10000, Loss: 0.6558, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4338/10000, Loss: 0.6558, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4339/10000, Loss: 0.6557, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4340/10000, Loss: 0.6557, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4341/10000, Loss: 0.6557, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4342/10000, Loss: 0.6557, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4343/10000, Loss: 0.6557, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4344/10000, Loss: 0.6557, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4345/10000, Loss: 0.6556, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4346/10000, Loss: 0.6556, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4347/10000, Loss: 0.6556, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4348/10000, Loss: 0.6556, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4349/10000, Loss: 0.6556, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4350/10000, Loss: 0.6556, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4351/10000, Loss: 0.6555, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4352/10000, Loss: 0.6555, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4353/10000, Loss: 0.6555, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4354/10000, Loss: 0.6555, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4355/10000, Loss: 0.6555, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4356/10000, Loss: 0.6555, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4357/10000, Loss: 0.6554, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4358/10000, Loss: 0.6554, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4359/10000, Loss: 0.6554, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4360/10000, Loss: 0.6554, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4361/10000, Loss: 0.6554, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4362/10000, Loss: 0.6554, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4363/10000, Loss: 0.6553, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4364/10000, Loss: 0.6553, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4365/10000, Loss: 0.6553, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4366/10000, Loss: 0.6553, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4367/10000, Loss: 0.6553, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4368/10000, Loss: 0.6553, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4369/10000, Loss: 0.6552, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4370/10000, Loss: 0.6552, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4371/10000, Loss: 0.6552, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4372/10000, Loss: 0.6552, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4373/10000, Loss: 0.6552, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4374/10000, Loss: 0.6552, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4375/10000, Loss: 0.6551, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4376/10000, Loss: 0.6551, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4377/10000, Loss: 0.6551, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4378/10000, Loss: 0.6551, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4379/10000, Loss: 0.6551, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4380/10000, Loss: 0.6551, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4381/10000, Loss: 0.6550, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4382/10000, Loss: 0.6550, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4383/10000, Loss: 0.6550, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4384/10000, Loss: 0.6550, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4385/10000, Loss: 0.6550, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4386/10000, Loss: 0.6550, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4387/10000, Loss: 0.6549, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4388/10000, Loss: 0.6549, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4389/10000, Loss: 0.6549, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4390/10000, Loss: 0.6549, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4391/10000, Loss: 0.6549, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4392/10000, Loss: 0.6549, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4393/10000, Loss: 0.6548, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4394/10000, Loss: 0.6548, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4395/10000, Loss: 0.6548, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4396/10000, Loss: 0.6548, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4397/10000, Loss: 0.6548, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4398/10000, Loss: 0.6548, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4399/10000, Loss: 0.6547, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4400/10000, Loss: 0.6547, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4401/10000, Loss: 0.6547, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4402/10000, Loss: 0.6547, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4403/10000, Loss: 0.6547, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4404/10000, Loss: 0.6547, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4405/10000, Loss: 0.6546, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4406/10000, Loss: 0.6546, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4407/10000, Loss: 0.6546, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4408/10000, Loss: 0.6546, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4409/10000, Loss: 0.6546, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4410/10000, Loss: 0.6546, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4411/10000, Loss: 0.6546, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4412/10000, Loss: 0.6545, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4413/10000, Loss: 0.6545, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4414/10000, Loss: 0.6545, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4415/10000, Loss: 0.6545, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4416/10000, Loss: 0.6545, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4417/10000, Loss: 0.6545, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4418/10000, Loss: 0.6544, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4419/10000, Loss: 0.6544, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4420/10000, Loss: 0.6544, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4421/10000, Loss: 0.6544, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4422/10000, Loss: 0.6544, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4423/10000, Loss: 0.6544, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4424/10000, Loss: 0.6543, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4425/10000, Loss: 0.6543, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4426/10000, Loss: 0.6543, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4427/10000, Loss: 0.6543, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4428/10000, Loss: 0.6543, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4429/10000, Loss: 0.6543, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4430/10000, Loss: 0.6542, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4431/10000, Loss: 0.6542, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4432/10000, Loss: 0.6542, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4433/10000, Loss: 0.6542, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4434/10000, Loss: 0.6542, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4435/10000, Loss: 0.6542, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4436/10000, Loss: 0.6541, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4437/10000, Loss: 0.6541, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4438/10000, Loss: 0.6541, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4439/10000, Loss: 0.6541, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4440/10000, Loss: 0.6541, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4441/10000, Loss: 0.6541, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4442/10000, Loss: 0.6540, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4443/10000, Loss: 0.6540, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4444/10000, Loss: 0.6540, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4445/10000, Loss: 0.6540, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4446/10000, Loss: 0.6540, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4447/10000, Loss: 0.6540, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4448/10000, Loss: 0.6539, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4449/10000, Loss: 0.6539, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4450/10000, Loss: 0.6539, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4451/10000, Loss: 0.6539, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4452/10000, Loss: 0.6539, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4453/10000, Loss: 0.6539, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4454/10000, Loss: 0.6538, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4455/10000, Loss: 0.6538, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4456/10000, Loss: 0.6538, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4457/10000, Loss: 0.6538, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4458/10000, Loss: 0.6538, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4459/10000, Loss: 0.6538, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4460/10000, Loss: 0.6538, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4461/10000, Loss: 0.6537, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4462/10000, Loss: 0.6537, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4463/10000, Loss: 0.6537, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4464/10000, Loss: 0.6537, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4465/10000, Loss: 0.6537, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4466/10000, Loss: 0.6537, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4467/10000, Loss: 0.6536, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4468/10000, Loss: 0.6536, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4469/10000, Loss: 0.6536, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4470/10000, Loss: 0.6536, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4471/10000, Loss: 0.6536, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4472/10000, Loss: 0.6536, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4473/10000, Loss: 0.6535, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4474/10000, Loss: 0.6535, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4475/10000, Loss: 0.6535, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4476/10000, Loss: 0.6535, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4477/10000, Loss: 0.6535, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4478/10000, Loss: 0.6535, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4479/10000, Loss: 0.6534, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4480/10000, Loss: 0.6534, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4481/10000, Loss: 0.6534, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4482/10000, Loss: 0.6534, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4483/10000, Loss: 0.6534, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4484/10000, Loss: 0.6534, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4485/10000, Loss: 0.6533, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4486/10000, Loss: 0.6533, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4487/10000, Loss: 0.6533, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4488/10000, Loss: 0.6533, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4489/10000, Loss: 0.6533, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4490/10000, Loss: 0.6533, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4491/10000, Loss: 0.6533, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4492/10000, Loss: 0.6532, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4493/10000, Loss: 0.6532, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4494/10000, Loss: 0.6532, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4495/10000, Loss: 0.6532, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4496/10000, Loss: 0.6532, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4497/10000, Loss: 0.6532, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4498/10000, Loss: 0.6531, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4499/10000, Loss: 0.6531, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4500/10000, Loss: 0.6531, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4501/10000, Loss: 0.6531, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4502/10000, Loss: 0.6531, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4503/10000, Loss: 0.6531, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4504/10000, Loss: 0.6530, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4505/10000, Loss: 0.6530, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4506/10000, Loss: 0.6530, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4507/10000, Loss: 0.6530, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4508/10000, Loss: 0.6530, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4509/10000, Loss: 0.6530, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4510/10000, Loss: 0.6529, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4511/10000, Loss: 0.6529, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4512/10000, Loss: 0.6529, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4513/10000, Loss: 0.6529, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4514/10000, Loss: 0.6529, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4515/10000, Loss: 0.6529, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4516/10000, Loss: 0.6529, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4517/10000, Loss: 0.6528, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4518/10000, Loss: 0.6528, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4519/10000, Loss: 0.6528, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4520/10000, Loss: 0.6528, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4521/10000, Loss: 0.6528, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4522/10000, Loss: 0.6528, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4523/10000, Loss: 0.6527, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4524/10000, Loss: 0.6527, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4525/10000, Loss: 0.6527, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4526/10000, Loss: 0.6527, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4527/10000, Loss: 0.6527, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4528/10000, Loss: 0.6527, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4529/10000, Loss: 0.6526, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4530/10000, Loss: 0.6526, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4531/10000, Loss: 0.6526, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4532/10000, Loss: 0.6526, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4533/10000, Loss: 0.6526, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4534/10000, Loss: 0.6526, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4535/10000, Loss: 0.6525, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4536/10000, Loss: 0.6525, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4537/10000, Loss: 0.6525, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4538/10000, Loss: 0.6525, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4539/10000, Loss: 0.6525, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4540/10000, Loss: 0.6525, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4541/10000, Loss: 0.6525, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4542/10000, Loss: 0.6524, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4543/10000, Loss: 0.6524, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4544/10000, Loss: 0.6524, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4545/10000, Loss: 0.6524, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4546/10000, Loss: 0.6524, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4547/10000, Loss: 0.6524, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4548/10000, Loss: 0.6523, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4549/10000, Loss: 0.6523, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4550/10000, Loss: 0.6523, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4551/10000, Loss: 0.6523, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4552/10000, Loss: 0.6523, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4553/10000, Loss: 0.6523, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4554/10000, Loss: 0.6522, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4555/10000, Loss: 0.6522, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4556/10000, Loss: 0.6522, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4557/10000, Loss: 0.6522, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4558/10000, Loss: 0.6522, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4559/10000, Loss: 0.6522, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4560/10000, Loss: 0.6522, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4561/10000, Loss: 0.6521, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4562/10000, Loss: 0.6521, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4563/10000, Loss: 0.6521, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4564/10000, Loss: 0.6521, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4565/10000, Loss: 0.6521, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4566/10000, Loss: 0.6521, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4567/10000, Loss: 0.6520, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4568/10000, Loss: 0.6520, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4569/10000, Loss: 0.6520, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4570/10000, Loss: 0.6520, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4571/10000, Loss: 0.6520, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4572/10000, Loss: 0.6520, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4573/10000, Loss: 0.6519, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4574/10000, Loss: 0.6519, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4575/10000, Loss: 0.6519, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4576/10000, Loss: 0.6519, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4577/10000, Loss: 0.6519, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4578/10000, Loss: 0.6519, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4579/10000, Loss: 0.6519, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4580/10000, Loss: 0.6518, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4581/10000, Loss: 0.6518, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4582/10000, Loss: 0.6518, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4583/10000, Loss: 0.6518, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4584/10000, Loss: 0.6518, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4585/10000, Loss: 0.6518, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4586/10000, Loss: 0.6517, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4587/10000, Loss: 0.6517, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4588/10000, Loss: 0.6517, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4589/10000, Loss: 0.6517, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4590/10000, Loss: 0.6517, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4591/10000, Loss: 0.6517, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4592/10000, Loss: 0.6516, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4593/10000, Loss: 0.6516, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4594/10000, Loss: 0.6516, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4595/10000, Loss: 0.6516, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4596/10000, Loss: 0.6516, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4597/10000, Loss: 0.6516, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4598/10000, Loss: 0.6516, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4599/10000, Loss: 0.6515, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4600/10000, Loss: 0.6515, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4601/10000, Loss: 0.6515, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4602/10000, Loss: 0.6515, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4603/10000, Loss: 0.6515, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4604/10000, Loss: 0.6515, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4605/10000, Loss: 0.6514, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4606/10000, Loss: 0.6514, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4607/10000, Loss: 0.6514, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4608/10000, Loss: 0.6514, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4609/10000, Loss: 0.6514, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4610/10000, Loss: 0.6514, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4611/10000, Loss: 0.6514, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4612/10000, Loss: 0.6513, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4613/10000, Loss: 0.6513, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4614/10000, Loss: 0.6513, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4615/10000, Loss: 0.6513, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4616/10000, Loss: 0.6513, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4617/10000, Loss: 0.6513, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4618/10000, Loss: 0.6512, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4619/10000, Loss: 0.6512, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4620/10000, Loss: 0.6512, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4621/10000, Loss: 0.6512, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4622/10000, Loss: 0.6512, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4623/10000, Loss: 0.6512, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4624/10000, Loss: 0.6511, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4625/10000, Loss: 0.6511, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4626/10000, Loss: 0.6511, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4627/10000, Loss: 0.6511, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4628/10000, Loss: 0.6511, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4629/10000, Loss: 0.6511, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4630/10000, Loss: 0.6511, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4631/10000, Loss: 0.6510, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4632/10000, Loss: 0.6510, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4633/10000, Loss: 0.6510, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4634/10000, Loss: 0.6510, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4635/10000, Loss: 0.6510, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4636/10000, Loss: 0.6510, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4637/10000, Loss: 0.6509, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4638/10000, Loss: 0.6509, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4639/10000, Loss: 0.6509, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4640/10000, Loss: 0.6509, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4641/10000, Loss: 0.6509, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4642/10000, Loss: 0.6509, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4643/10000, Loss: 0.6509, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4644/10000, Loss: 0.6508, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4645/10000, Loss: 0.6508, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4646/10000, Loss: 0.6508, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4647/10000, Loss: 0.6508, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4648/10000, Loss: 0.6508, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4649/10000, Loss: 0.6508, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4650/10000, Loss: 0.6507, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4651/10000, Loss: 0.6507, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4652/10000, Loss: 0.6507, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4653/10000, Loss: 0.6507, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4654/10000, Loss: 0.6507, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4655/10000, Loss: 0.6507, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4656/10000, Loss: 0.6507, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4657/10000, Loss: 0.6506, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4658/10000, Loss: 0.6506, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4659/10000, Loss: 0.6506, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4660/10000, Loss: 0.6506, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4661/10000, Loss: 0.6506, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4662/10000, Loss: 0.6506, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4663/10000, Loss: 0.6505, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4664/10000, Loss: 0.6505, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4665/10000, Loss: 0.6505, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4666/10000, Loss: 0.6505, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4667/10000, Loss: 0.6505, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4668/10000, Loss: 0.6505, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4669/10000, Loss: 0.6505, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4670/10000, Loss: 0.6504, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4671/10000, Loss: 0.6504, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4672/10000, Loss: 0.6504, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4673/10000, Loss: 0.6504, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4674/10000, Loss: 0.6504, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4675/10000, Loss: 0.6504, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4676/10000, Loss: 0.6503, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4677/10000, Loss: 0.6503, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4678/10000, Loss: 0.6503, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4679/10000, Loss: 0.6503, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4680/10000, Loss: 0.6503, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4681/10000, Loss: 0.6503, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4682/10000, Loss: 0.6503, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4683/10000, Loss: 0.6502, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4684/10000, Loss: 0.6502, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4685/10000, Loss: 0.6502, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4686/10000, Loss: 0.6502, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4687/10000, Loss: 0.6502, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4688/10000, Loss: 0.6502, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4689/10000, Loss: 0.6501, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4690/10000, Loss: 0.6501, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4691/10000, Loss: 0.6501, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4692/10000, Loss: 0.6501, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4693/10000, Loss: 0.6501, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4694/10000, Loss: 0.6501, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4695/10000, Loss: 0.6501, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4696/10000, Loss: 0.6500, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4697/10000, Loss: 0.6500, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4698/10000, Loss: 0.6500, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4699/10000, Loss: 0.6500, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4700/10000, Loss: 0.6500, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4701/10000, Loss: 0.6500, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4702/10000, Loss: 0.6500, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4703/10000, Loss: 0.6499, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4704/10000, Loss: 0.6499, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4705/10000, Loss: 0.6499, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4706/10000, Loss: 0.6499, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4707/10000, Loss: 0.6499, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4708/10000, Loss: 0.6499, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4709/10000, Loss: 0.6498, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4710/10000, Loss: 0.6498, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4711/10000, Loss: 0.6498, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4712/10000, Loss: 0.6498, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4713/10000, Loss: 0.6498, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4714/10000, Loss: 0.6498, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4715/10000, Loss: 0.6498, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4716/10000, Loss: 0.6497, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4717/10000, Loss: 0.6497, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4718/10000, Loss: 0.6497, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4719/10000, Loss: 0.6497, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4720/10000, Loss: 0.6497, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4721/10000, Loss: 0.6497, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4722/10000, Loss: 0.6496, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4723/10000, Loss: 0.6496, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4724/10000, Loss: 0.6496, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4725/10000, Loss: 0.6496, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4726/10000, Loss: 0.6496, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4727/10000, Loss: 0.6496, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4728/10000, Loss: 0.6496, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4729/10000, Loss: 0.6495, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4730/10000, Loss: 0.6495, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4731/10000, Loss: 0.6495, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4732/10000, Loss: 0.6495, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4733/10000, Loss: 0.6495, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4734/10000, Loss: 0.6495, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4735/10000, Loss: 0.6495, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4736/10000, Loss: 0.6494, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4737/10000, Loss: 0.6494, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4738/10000, Loss: 0.6494, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4739/10000, Loss: 0.6494, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4740/10000, Loss: 0.6494, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4741/10000, Loss: 0.6494, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4742/10000, Loss: 0.6493, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4743/10000, Loss: 0.6493, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4744/10000, Loss: 0.6493, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4745/10000, Loss: 0.6493, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4746/10000, Loss: 0.6493, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4747/10000, Loss: 0.6493, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4748/10000, Loss: 0.6493, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4749/10000, Loss: 0.6492, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4750/10000, Loss: 0.6492, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4751/10000, Loss: 0.6492, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4752/10000, Loss: 0.6492, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4753/10000, Loss: 0.6492, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4754/10000, Loss: 0.6492, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4755/10000, Loss: 0.6491, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4756/10000, Loss: 0.6491, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4757/10000, Loss: 0.6491, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4758/10000, Loss: 0.6491, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4759/10000, Loss: 0.6491, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4760/10000, Loss: 0.6491, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4761/10000, Loss: 0.6491, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4762/10000, Loss: 0.6490, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4763/10000, Loss: 0.6490, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4764/10000, Loss: 0.6490, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4765/10000, Loss: 0.6490, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4766/10000, Loss: 0.6490, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4767/10000, Loss: 0.6490, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4768/10000, Loss: 0.6490, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4769/10000, Loss: 0.6489, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4770/10000, Loss: 0.6489, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4771/10000, Loss: 0.6489, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4772/10000, Loss: 0.6489, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4773/10000, Loss: 0.6489, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4774/10000, Loss: 0.6489, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4775/10000, Loss: 0.6488, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4776/10000, Loss: 0.6488, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4777/10000, Loss: 0.6488, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4778/10000, Loss: 0.6488, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4779/10000, Loss: 0.6488, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4780/10000, Loss: 0.6488, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4781/10000, Loss: 0.6488, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4782/10000, Loss: 0.6487, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4783/10000, Loss: 0.6487, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4784/10000, Loss: 0.6487, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4785/10000, Loss: 0.6487, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4786/10000, Loss: 0.6487, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4787/10000, Loss: 0.6487, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4788/10000, Loss: 0.6487, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4789/10000, Loss: 0.6486, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4790/10000, Loss: 0.6486, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4791/10000, Loss: 0.6486, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4792/10000, Loss: 0.6486, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4793/10000, Loss: 0.6486, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4794/10000, Loss: 0.6486, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4795/10000, Loss: 0.6486, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4796/10000, Loss: 0.6485, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4797/10000, Loss: 0.6485, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4798/10000, Loss: 0.6485, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4799/10000, Loss: 0.6485, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4800/10000, Loss: 0.6485, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4801/10000, Loss: 0.6485, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4802/10000, Loss: 0.6484, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4803/10000, Loss: 0.6484, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4804/10000, Loss: 0.6484, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4805/10000, Loss: 0.6484, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4806/10000, Loss: 0.6484, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4807/10000, Loss: 0.6484, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4808/10000, Loss: 0.6484, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4809/10000, Loss: 0.6483, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4810/10000, Loss: 0.6483, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4811/10000, Loss: 0.6483, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4812/10000, Loss: 0.6483, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4813/10000, Loss: 0.6483, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4814/10000, Loss: 0.6483, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4815/10000, Loss: 0.6483, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4816/10000, Loss: 0.6482, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4817/10000, Loss: 0.6482, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4818/10000, Loss: 0.6482, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4819/10000, Loss: 0.6482, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4820/10000, Loss: 0.6482, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4821/10000, Loss: 0.6482, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4822/10000, Loss: 0.6482, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4823/10000, Loss: 0.6481, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4824/10000, Loss: 0.6481, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4825/10000, Loss: 0.6481, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4826/10000, Loss: 0.6481, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4827/10000, Loss: 0.6481, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4828/10000, Loss: 0.6481, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4829/10000, Loss: 0.6480, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4830/10000, Loss: 0.6480, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4831/10000, Loss: 0.6480, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4832/10000, Loss: 0.6480, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4833/10000, Loss: 0.6480, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4834/10000, Loss: 0.6480, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4835/10000, Loss: 0.6480, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4836/10000, Loss: 0.6479, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4837/10000, Loss: 0.6479, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4838/10000, Loss: 0.6479, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4839/10000, Loss: 0.6479, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4840/10000, Loss: 0.6479, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4841/10000, Loss: 0.6479, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4842/10000, Loss: 0.6479, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4843/10000, Loss: 0.6478, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4844/10000, Loss: 0.6478, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4845/10000, Loss: 0.6478, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4846/10000, Loss: 0.6478, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4847/10000, Loss: 0.6478, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4848/10000, Loss: 0.6478, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4849/10000, Loss: 0.6478, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4850/10000, Loss: 0.6477, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4851/10000, Loss: 0.6477, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4852/10000, Loss: 0.6477, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4853/10000, Loss: 0.6477, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4854/10000, Loss: 0.6477, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4855/10000, Loss: 0.6477, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4856/10000, Loss: 0.6477, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4857/10000, Loss: 0.6476, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4858/10000, Loss: 0.6476, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4859/10000, Loss: 0.6476, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4860/10000, Loss: 0.6476, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4861/10000, Loss: 0.6476, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4862/10000, Loss: 0.6476, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4863/10000, Loss: 0.6476, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4864/10000, Loss: 0.6475, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4865/10000, Loss: 0.6475, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4866/10000, Loss: 0.6475, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4867/10000, Loss: 0.6475, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4868/10000, Loss: 0.6475, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4869/10000, Loss: 0.6475, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4870/10000, Loss: 0.6474, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4871/10000, Loss: 0.6474, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4872/10000, Loss: 0.6474, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4873/10000, Loss: 0.6474, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4874/10000, Loss: 0.6474, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4875/10000, Loss: 0.6474, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4876/10000, Loss: 0.6474, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4877/10000, Loss: 0.6473, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4878/10000, Loss: 0.6473, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4879/10000, Loss: 0.6473, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4880/10000, Loss: 0.6473, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4881/10000, Loss: 0.6473, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4882/10000, Loss: 0.6473, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4883/10000, Loss: 0.6473, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4884/10000, Loss: 0.6472, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4885/10000, Loss: 0.6472, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4886/10000, Loss: 0.6472, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4887/10000, Loss: 0.6472, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4888/10000, Loss: 0.6472, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4889/10000, Loss: 0.6472, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4890/10000, Loss: 0.6472, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4891/10000, Loss: 0.6471, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4892/10000, Loss: 0.6471, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4893/10000, Loss: 0.6471, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4894/10000, Loss: 0.6471, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4895/10000, Loss: 0.6471, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4896/10000, Loss: 0.6471, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4897/10000, Loss: 0.6471, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4898/10000, Loss: 0.6470, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4899/10000, Loss: 0.6470, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4900/10000, Loss: 0.6470, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4901/10000, Loss: 0.6470, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4902/10000, Loss: 0.6470, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4903/10000, Loss: 0.6470, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4904/10000, Loss: 0.6470, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4905/10000, Loss: 0.6469, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4906/10000, Loss: 0.6469, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4907/10000, Loss: 0.6469, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4908/10000, Loss: 0.6469, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4909/10000, Loss: 0.6469, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4910/10000, Loss: 0.6469, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4911/10000, Loss: 0.6469, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4912/10000, Loss: 0.6468, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4913/10000, Loss: 0.6468, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4914/10000, Loss: 0.6468, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4915/10000, Loss: 0.6468, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4916/10000, Loss: 0.6468, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4917/10000, Loss: 0.6468, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4918/10000, Loss: 0.6468, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4919/10000, Loss: 0.6467, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4920/10000, Loss: 0.6467, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4921/10000, Loss: 0.6467, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4922/10000, Loss: 0.6467, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4923/10000, Loss: 0.6467, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4924/10000, Loss: 0.6467, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4925/10000, Loss: 0.6467, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4926/10000, Loss: 0.6466, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4927/10000, Loss: 0.6466, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4928/10000, Loss: 0.6466, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4929/10000, Loss: 0.6466, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4930/10000, Loss: 0.6466, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4931/10000, Loss: 0.6466, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4932/10000, Loss: 0.6466, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4933/10000, Loss: 0.6465, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4934/10000, Loss: 0.6465, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4935/10000, Loss: 0.6465, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4936/10000, Loss: 0.6465, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4937/10000, Loss: 0.6465, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4938/10000, Loss: 0.6465, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4939/10000, Loss: 0.6465, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4940/10000, Loss: 0.6464, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4941/10000, Loss: 0.6464, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4942/10000, Loss: 0.6464, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4943/10000, Loss: 0.6464, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4944/10000, Loss: 0.6464, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4945/10000, Loss: 0.6464, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4946/10000, Loss: 0.6464, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4947/10000, Loss: 0.6463, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4948/10000, Loss: 0.6463, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4949/10000, Loss: 0.6463, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4950/10000, Loss: 0.6463, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4951/10000, Loss: 0.6463, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4952/10000, Loss: 0.6463, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4953/10000, Loss: 0.6463, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4954/10000, Loss: 0.6462, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4955/10000, Loss: 0.6462, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4956/10000, Loss: 0.6462, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4957/10000, Loss: 0.6462, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4958/10000, Loss: 0.6462, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4959/10000, Loss: 0.6462, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4960/10000, Loss: 0.6462, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4961/10000, Loss: 0.6461, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4962/10000, Loss: 0.6461, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4963/10000, Loss: 0.6461, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4964/10000, Loss: 0.6461, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4965/10000, Loss: 0.6461, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4966/10000, Loss: 0.6461, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4967/10000, Loss: 0.6461, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4968/10000, Loss: 0.6460, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4969/10000, Loss: 0.6460, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4970/10000, Loss: 0.6460, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4971/10000, Loss: 0.6460, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4972/10000, Loss: 0.6460, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4973/10000, Loss: 0.6460, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4974/10000, Loss: 0.6460, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4975/10000, Loss: 0.6459, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4976/10000, Loss: 0.6459, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4977/10000, Loss: 0.6459, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4978/10000, Loss: 0.6459, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4979/10000, Loss: 0.6459, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4980/10000, Loss: 0.6459, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4981/10000, Loss: 0.6459, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4982/10000, Loss: 0.6458, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4983/10000, Loss: 0.6458, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4984/10000, Loss: 0.6458, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4985/10000, Loss: 0.6458, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4986/10000, Loss: 0.6458, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4987/10000, Loss: 0.6458, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4988/10000, Loss: 0.6458, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4989/10000, Loss: 0.6457, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4990/10000, Loss: 0.6457, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4991/10000, Loss: 0.6457, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4992/10000, Loss: 0.6457, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4993/10000, Loss: 0.6457, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4994/10000, Loss: 0.6457, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4995/10000, Loss: 0.6457, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4996/10000, Loss: 0.6456, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4997/10000, Loss: 0.6456, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4998/10000, Loss: 0.6456, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4999/10000, Loss: 0.6456, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5000/10000, Loss: 0.6456, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5001/10000, Loss: 0.6456, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5002/10000, Loss: 0.6456, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5003/10000, Loss: 0.6455, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5004/10000, Loss: 0.6455, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5005/10000, Loss: 0.6455, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5006/10000, Loss: 0.6455, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5007/10000, Loss: 0.6455, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5008/10000, Loss: 0.6455, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5009/10000, Loss: 0.6455, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5010/10000, Loss: 0.6454, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5011/10000, Loss: 0.6454, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5012/10000, Loss: 0.6454, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5013/10000, Loss: 0.6454, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5014/10000, Loss: 0.6454, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5015/10000, Loss: 0.6454, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5016/10000, Loss: 0.6454, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5017/10000, Loss: 0.6453, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5018/10000, Loss: 0.6453, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5019/10000, Loss: 0.6453, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5020/10000, Loss: 0.6453, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5021/10000, Loss: 0.6453, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5022/10000, Loss: 0.6453, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5023/10000, Loss: 0.6453, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5024/10000, Loss: 0.6453, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5025/10000, Loss: 0.6452, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5026/10000, Loss: 0.6452, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5027/10000, Loss: 0.6452, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5028/10000, Loss: 0.6452, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5029/10000, Loss: 0.6452, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5030/10000, Loss: 0.6452, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5031/10000, Loss: 0.6452, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5032/10000, Loss: 0.6451, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5033/10000, Loss: 0.6451, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5034/10000, Loss: 0.6451, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5035/10000, Loss: 0.6451, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5036/10000, Loss: 0.6451, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5037/10000, Loss: 0.6451, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5038/10000, Loss: 0.6451, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5039/10000, Loss: 0.6450, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5040/10000, Loss: 0.6450, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5041/10000, Loss: 0.6450, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5042/10000, Loss: 0.6450, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5043/10000, Loss: 0.6450, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5044/10000, Loss: 0.6450, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5045/10000, Loss: 0.6450, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5046/10000, Loss: 0.6449, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5047/10000, Loss: 0.6449, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5048/10000, Loss: 0.6449, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5049/10000, Loss: 0.6449, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5050/10000, Loss: 0.6449, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5051/10000, Loss: 0.6449, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5052/10000, Loss: 0.6449, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5053/10000, Loss: 0.6448, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5054/10000, Loss: 0.6448, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5055/10000, Loss: 0.6448, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5056/10000, Loss: 0.6448, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5057/10000, Loss: 0.6448, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5058/10000, Loss: 0.6448, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5059/10000, Loss: 0.6448, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5060/10000, Loss: 0.6448, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5061/10000, Loss: 0.6447, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5062/10000, Loss: 0.6447, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5063/10000, Loss: 0.6447, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5064/10000, Loss: 0.6447, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5065/10000, Loss: 0.6447, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5066/10000, Loss: 0.6447, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5067/10000, Loss: 0.6447, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5068/10000, Loss: 0.6446, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5069/10000, Loss: 0.6446, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5070/10000, Loss: 0.6446, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5071/10000, Loss: 0.6446, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5072/10000, Loss: 0.6446, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5073/10000, Loss: 0.6446, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5074/10000, Loss: 0.6446, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5075/10000, Loss: 0.6445, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5076/10000, Loss: 0.6445, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5077/10000, Loss: 0.6445, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5078/10000, Loss: 0.6445, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5079/10000, Loss: 0.6445, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5080/10000, Loss: 0.6445, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5081/10000, Loss: 0.6445, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5082/10000, Loss: 0.6444, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5083/10000, Loss: 0.6444, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5084/10000, Loss: 0.6444, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5085/10000, Loss: 0.6444, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5086/10000, Loss: 0.6444, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5087/10000, Loss: 0.6444, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5088/10000, Loss: 0.6444, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5089/10000, Loss: 0.6444, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5090/10000, Loss: 0.6443, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5091/10000, Loss: 0.6443, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5092/10000, Loss: 0.6443, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5093/10000, Loss: 0.6443, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5094/10000, Loss: 0.6443, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5095/10000, Loss: 0.6443, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5096/10000, Loss: 0.6443, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5097/10000, Loss: 0.6442, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5098/10000, Loss: 0.6442, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5099/10000, Loss: 0.6442, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5100/10000, Loss: 0.6442, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5101/10000, Loss: 0.6442, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5102/10000, Loss: 0.6442, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5103/10000, Loss: 0.6442, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5104/10000, Loss: 0.6441, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5105/10000, Loss: 0.6441, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5106/10000, Loss: 0.6441, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5107/10000, Loss: 0.6441, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5108/10000, Loss: 0.6441, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5109/10000, Loss: 0.6441, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5110/10000, Loss: 0.6441, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5111/10000, Loss: 0.6440, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5112/10000, Loss: 0.6440, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5113/10000, Loss: 0.6440, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5114/10000, Loss: 0.6440, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5115/10000, Loss: 0.6440, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5116/10000, Loss: 0.6440, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5117/10000, Loss: 0.6440, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5118/10000, Loss: 0.6440, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5119/10000, Loss: 0.6439, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5120/10000, Loss: 0.6439, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5121/10000, Loss: 0.6439, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5122/10000, Loss: 0.6439, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5123/10000, Loss: 0.6439, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5124/10000, Loss: 0.6439, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5125/10000, Loss: 0.6439, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5126/10000, Loss: 0.6438, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5127/10000, Loss: 0.6438, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5128/10000, Loss: 0.6438, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5129/10000, Loss: 0.6438, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5130/10000, Loss: 0.6438, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5131/10000, Loss: 0.6438, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5132/10000, Loss: 0.6438, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5133/10000, Loss: 0.6438, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5134/10000, Loss: 0.6437, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5135/10000, Loss: 0.6437, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5136/10000, Loss: 0.6437, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5137/10000, Loss: 0.6437, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5138/10000, Loss: 0.6437, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5139/10000, Loss: 0.6437, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5140/10000, Loss: 0.6437, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5141/10000, Loss: 0.6436, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5142/10000, Loss: 0.6436, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5143/10000, Loss: 0.6436, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5144/10000, Loss: 0.6436, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5145/10000, Loss: 0.6436, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5146/10000, Loss: 0.6436, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5147/10000, Loss: 0.6436, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5148/10000, Loss: 0.6435, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5149/10000, Loss: 0.6435, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5150/10000, Loss: 0.6435, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5151/10000, Loss: 0.6435, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5152/10000, Loss: 0.6435, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5153/10000, Loss: 0.6435, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5154/10000, Loss: 0.6435, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5155/10000, Loss: 0.6435, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5156/10000, Loss: 0.6434, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5157/10000, Loss: 0.6434, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5158/10000, Loss: 0.6434, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5159/10000, Loss: 0.6434, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5160/10000, Loss: 0.6434, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5161/10000, Loss: 0.6434, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5162/10000, Loss: 0.6434, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5163/10000, Loss: 0.6433, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5164/10000, Loss: 0.6433, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5165/10000, Loss: 0.6433, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5166/10000, Loss: 0.6433, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5167/10000, Loss: 0.6433, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5168/10000, Loss: 0.6433, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5169/10000, Loss: 0.6433, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5170/10000, Loss: 0.6433, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5171/10000, Loss: 0.6432, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5172/10000, Loss: 0.6432, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5173/10000, Loss: 0.6432, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5174/10000, Loss: 0.6432, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5175/10000, Loss: 0.6432, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5176/10000, Loss: 0.6432, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5177/10000, Loss: 0.6432, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5178/10000, Loss: 0.6431, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5179/10000, Loss: 0.6431, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5180/10000, Loss: 0.6431, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5181/10000, Loss: 0.6431, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5182/10000, Loss: 0.6431, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5183/10000, Loss: 0.6431, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5184/10000, Loss: 0.6431, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5185/10000, Loss: 0.6430, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5186/10000, Loss: 0.6430, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5187/10000, Loss: 0.6430, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5188/10000, Loss: 0.6430, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5189/10000, Loss: 0.6430, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5190/10000, Loss: 0.6430, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5191/10000, Loss: 0.6430, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5192/10000, Loss: 0.6430, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5193/10000, Loss: 0.6429, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5194/10000, Loss: 0.6429, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5195/10000, Loss: 0.6429, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5196/10000, Loss: 0.6429, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5197/10000, Loss: 0.6429, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5198/10000, Loss: 0.6429, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5199/10000, Loss: 0.6429, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5200/10000, Loss: 0.6428, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5201/10000, Loss: 0.6428, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5202/10000, Loss: 0.6428, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5203/10000, Loss: 0.6428, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5204/10000, Loss: 0.6428, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5205/10000, Loss: 0.6428, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5206/10000, Loss: 0.6428, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5207/10000, Loss: 0.6428, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5208/10000, Loss: 0.6427, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5209/10000, Loss: 0.6427, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5210/10000, Loss: 0.6427, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5211/10000, Loss: 0.6427, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5212/10000, Loss: 0.6427, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5213/10000, Loss: 0.6427, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5214/10000, Loss: 0.6427, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5215/10000, Loss: 0.6426, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5216/10000, Loss: 0.6426, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5217/10000, Loss: 0.6426, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5218/10000, Loss: 0.6426, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5219/10000, Loss: 0.6426, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5220/10000, Loss: 0.6426, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5221/10000, Loss: 0.6426, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5222/10000, Loss: 0.6426, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5223/10000, Loss: 0.6425, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5224/10000, Loss: 0.6425, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5225/10000, Loss: 0.6425, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5226/10000, Loss: 0.6425, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5227/10000, Loss: 0.6425, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5228/10000, Loss: 0.6425, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5229/10000, Loss: 0.6425, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5230/10000, Loss: 0.6424, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5231/10000, Loss: 0.6424, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5232/10000, Loss: 0.6424, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5233/10000, Loss: 0.6424, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5234/10000, Loss: 0.6424, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5235/10000, Loss: 0.6424, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5236/10000, Loss: 0.6424, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5237/10000, Loss: 0.6424, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5238/10000, Loss: 0.6423, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5239/10000, Loss: 0.6423, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5240/10000, Loss: 0.6423, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5241/10000, Loss: 0.6423, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5242/10000, Loss: 0.6423, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5243/10000, Loss: 0.6423, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5244/10000, Loss: 0.6423, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5245/10000, Loss: 0.6423, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5246/10000, Loss: 0.6422, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5247/10000, Loss: 0.6422, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5248/10000, Loss: 0.6422, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5249/10000, Loss: 0.6422, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5250/10000, Loss: 0.6422, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5251/10000, Loss: 0.6422, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5252/10000, Loss: 0.6422, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5253/10000, Loss: 0.6421, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5254/10000, Loss: 0.6421, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5255/10000, Loss: 0.6421, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5256/10000, Loss: 0.6421, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5257/10000, Loss: 0.6421, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5258/10000, Loss: 0.6421, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5259/10000, Loss: 0.6421, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5260/10000, Loss: 0.6421, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5261/10000, Loss: 0.6420, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5262/10000, Loss: 0.6420, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5263/10000, Loss: 0.6420, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5264/10000, Loss: 0.6420, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5265/10000, Loss: 0.6420, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5266/10000, Loss: 0.6420, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5267/10000, Loss: 0.6420, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5268/10000, Loss: 0.6419, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5269/10000, Loss: 0.6419, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5270/10000, Loss: 0.6419, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5271/10000, Loss: 0.6419, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5272/10000, Loss: 0.6419, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5273/10000, Loss: 0.6419, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5274/10000, Loss: 0.6419, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5275/10000, Loss: 0.6419, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5276/10000, Loss: 0.6418, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5277/10000, Loss: 0.6418, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5278/10000, Loss: 0.6418, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5279/10000, Loss: 0.6418, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5280/10000, Loss: 0.6418, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5281/10000, Loss: 0.6418, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5282/10000, Loss: 0.6418, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5283/10000, Loss: 0.6418, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5284/10000, Loss: 0.6417, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5285/10000, Loss: 0.6417, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5286/10000, Loss: 0.6417, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5287/10000, Loss: 0.6417, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5288/10000, Loss: 0.6417, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5289/10000, Loss: 0.6417, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5290/10000, Loss: 0.6417, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5291/10000, Loss: 0.6416, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5292/10000, Loss: 0.6416, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5293/10000, Loss: 0.6416, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5294/10000, Loss: 0.6416, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5295/10000, Loss: 0.6416, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5296/10000, Loss: 0.6416, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5297/10000, Loss: 0.6416, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5298/10000, Loss: 0.6416, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5299/10000, Loss: 0.6415, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5300/10000, Loss: 0.6415, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5301/10000, Loss: 0.6415, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5302/10000, Loss: 0.6415, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5303/10000, Loss: 0.6415, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5304/10000, Loss: 0.6415, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5305/10000, Loss: 0.6415, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5306/10000, Loss: 0.6415, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5307/10000, Loss: 0.6414, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5308/10000, Loss: 0.6414, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5309/10000, Loss: 0.6414, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5310/10000, Loss: 0.6414, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5311/10000, Loss: 0.6414, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5312/10000, Loss: 0.6414, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5313/10000, Loss: 0.6414, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5314/10000, Loss: 0.6414, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5315/10000, Loss: 0.6413, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5316/10000, Loss: 0.6413, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5317/10000, Loss: 0.6413, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5318/10000, Loss: 0.6413, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5319/10000, Loss: 0.6413, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5320/10000, Loss: 0.6413, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5321/10000, Loss: 0.6413, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5322/10000, Loss: 0.6412, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5323/10000, Loss: 0.6412, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5324/10000, Loss: 0.6412, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5325/10000, Loss: 0.6412, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5326/10000, Loss: 0.6412, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5327/10000, Loss: 0.6412, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5328/10000, Loss: 0.6412, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5329/10000, Loss: 0.6412, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5330/10000, Loss: 0.6411, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5331/10000, Loss: 0.6411, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5332/10000, Loss: 0.6411, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5333/10000, Loss: 0.6411, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5334/10000, Loss: 0.6411, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5335/10000, Loss: 0.6411, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5336/10000, Loss: 0.6411, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5337/10000, Loss: 0.6411, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5338/10000, Loss: 0.6410, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5339/10000, Loss: 0.6410, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5340/10000, Loss: 0.6410, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5341/10000, Loss: 0.6410, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5342/10000, Loss: 0.6410, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5343/10000, Loss: 0.6410, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5344/10000, Loss: 0.6410, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5345/10000, Loss: 0.6410, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5346/10000, Loss: 0.6409, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5347/10000, Loss: 0.6409, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5348/10000, Loss: 0.6409, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5349/10000, Loss: 0.6409, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5350/10000, Loss: 0.6409, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5351/10000, Loss: 0.6409, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5352/10000, Loss: 0.6409, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5353/10000, Loss: 0.6408, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5354/10000, Loss: 0.6408, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5355/10000, Loss: 0.6408, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5356/10000, Loss: 0.6408, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5357/10000, Loss: 0.6408, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5358/10000, Loss: 0.6408, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5359/10000, Loss: 0.6408, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5360/10000, Loss: 0.6408, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5361/10000, Loss: 0.6407, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5362/10000, Loss: 0.6407, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5363/10000, Loss: 0.6407, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5364/10000, Loss: 0.6407, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5365/10000, Loss: 0.6407, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5366/10000, Loss: 0.6407, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5367/10000, Loss: 0.6407, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5368/10000, Loss: 0.6407, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5369/10000, Loss: 0.6406, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5370/10000, Loss: 0.6406, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5371/10000, Loss: 0.6406, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5372/10000, Loss: 0.6406, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5373/10000, Loss: 0.6406, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5374/10000, Loss: 0.6406, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5375/10000, Loss: 0.6406, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5376/10000, Loss: 0.6406, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5377/10000, Loss: 0.6405, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5378/10000, Loss: 0.6405, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5379/10000, Loss: 0.6405, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5380/10000, Loss: 0.6405, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5381/10000, Loss: 0.6405, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5382/10000, Loss: 0.6405, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5383/10000, Loss: 0.6405, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5384/10000, Loss: 0.6405, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5385/10000, Loss: 0.6404, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5386/10000, Loss: 0.6404, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5387/10000, Loss: 0.6404, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5388/10000, Loss: 0.6404, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5389/10000, Loss: 0.6404, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5390/10000, Loss: 0.6404, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5391/10000, Loss: 0.6404, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5392/10000, Loss: 0.6404, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5393/10000, Loss: 0.6403, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5394/10000, Loss: 0.6403, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5395/10000, Loss: 0.6403, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5396/10000, Loss: 0.6403, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5397/10000, Loss: 0.6403, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5398/10000, Loss: 0.6403, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5399/10000, Loss: 0.6403, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5400/10000, Loss: 0.6403, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5401/10000, Loss: 0.6402, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5402/10000, Loss: 0.6402, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5403/10000, Loss: 0.6402, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5404/10000, Loss: 0.6402, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5405/10000, Loss: 0.6402, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5406/10000, Loss: 0.6402, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5407/10000, Loss: 0.6402, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5408/10000, Loss: 0.6402, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5409/10000, Loss: 0.6401, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5410/10000, Loss: 0.6401, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5411/10000, Loss: 0.6401, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5412/10000, Loss: 0.6401, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5413/10000, Loss: 0.6401, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5414/10000, Loss: 0.6401, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5415/10000, Loss: 0.6401, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5416/10000, Loss: 0.6400, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5417/10000, Loss: 0.6400, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5418/10000, Loss: 0.6400, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5419/10000, Loss: 0.6400, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5420/10000, Loss: 0.6400, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5421/10000, Loss: 0.6400, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5422/10000, Loss: 0.6400, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5423/10000, Loss: 0.6400, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5424/10000, Loss: 0.6399, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5425/10000, Loss: 0.6399, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5426/10000, Loss: 0.6399, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5427/10000, Loss: 0.6399, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5428/10000, Loss: 0.6399, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5429/10000, Loss: 0.6399, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5430/10000, Loss: 0.6399, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5431/10000, Loss: 0.6399, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5432/10000, Loss: 0.6398, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5433/10000, Loss: 0.6398, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5434/10000, Loss: 0.6398, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5435/10000, Loss: 0.6398, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5436/10000, Loss: 0.6398, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5437/10000, Loss: 0.6398, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5438/10000, Loss: 0.6398, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5439/10000, Loss: 0.6398, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5440/10000, Loss: 0.6397, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5441/10000, Loss: 0.6397, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5442/10000, Loss: 0.6397, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5443/10000, Loss: 0.6397, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5444/10000, Loss: 0.6397, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5445/10000, Loss: 0.6397, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5446/10000, Loss: 0.6397, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5447/10000, Loss: 0.6397, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5448/10000, Loss: 0.6396, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5449/10000, Loss: 0.6396, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5450/10000, Loss: 0.6396, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5451/10000, Loss: 0.6396, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5452/10000, Loss: 0.6396, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5453/10000, Loss: 0.6396, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5454/10000, Loss: 0.6396, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5455/10000, Loss: 0.6396, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5456/10000, Loss: 0.6395, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5457/10000, Loss: 0.6395, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5458/10000, Loss: 0.6395, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5459/10000, Loss: 0.6395, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5460/10000, Loss: 0.6395, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5461/10000, Loss: 0.6395, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5462/10000, Loss: 0.6395, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5463/10000, Loss: 0.6395, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5464/10000, Loss: 0.6394, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5465/10000, Loss: 0.6394, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5466/10000, Loss: 0.6394, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5467/10000, Loss: 0.6394, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5468/10000, Loss: 0.6394, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5469/10000, Loss: 0.6394, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5470/10000, Loss: 0.6394, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5471/10000, Loss: 0.6394, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5472/10000, Loss: 0.6394, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5473/10000, Loss: 0.6393, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5474/10000, Loss: 0.6393, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5475/10000, Loss: 0.6393, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5476/10000, Loss: 0.6393, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5477/10000, Loss: 0.6393, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5478/10000, Loss: 0.6393, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5479/10000, Loss: 0.6393, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5480/10000, Loss: 0.6393, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5481/10000, Loss: 0.6392, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5482/10000, Loss: 0.6392, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5483/10000, Loss: 0.6392, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5484/10000, Loss: 0.6392, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5485/10000, Loss: 0.6392, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5486/10000, Loss: 0.6392, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5487/10000, Loss: 0.6392, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5488/10000, Loss: 0.6392, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5489/10000, Loss: 0.6391, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5490/10000, Loss: 0.6391, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5491/10000, Loss: 0.6391, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5492/10000, Loss: 0.6391, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5493/10000, Loss: 0.6391, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5494/10000, Loss: 0.6391, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5495/10000, Loss: 0.6391, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5496/10000, Loss: 0.6391, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5497/10000, Loss: 0.6390, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5498/10000, Loss: 0.6390, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5499/10000, Loss: 0.6390, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5500/10000, Loss: 0.6390, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5501/10000, Loss: 0.6390, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5502/10000, Loss: 0.6390, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5503/10000, Loss: 0.6390, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5504/10000, Loss: 0.6390, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5505/10000, Loss: 0.6389, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5506/10000, Loss: 0.6389, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5507/10000, Loss: 0.6389, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5508/10000, Loss: 0.6389, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5509/10000, Loss: 0.6389, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5510/10000, Loss: 0.6389, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5511/10000, Loss: 0.6389, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5512/10000, Loss: 0.6389, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5513/10000, Loss: 0.6388, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5514/10000, Loss: 0.6388, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5515/10000, Loss: 0.6388, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5516/10000, Loss: 0.6388, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5517/10000, Loss: 0.6388, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5518/10000, Loss: 0.6388, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5519/10000, Loss: 0.6388, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5520/10000, Loss: 0.6388, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5521/10000, Loss: 0.6387, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5522/10000, Loss: 0.6387, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5523/10000, Loss: 0.6387, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5524/10000, Loss: 0.6387, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5525/10000, Loss: 0.6387, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5526/10000, Loss: 0.6387, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5527/10000, Loss: 0.6387, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5528/10000, Loss: 0.6387, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5529/10000, Loss: 0.6386, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5530/10000, Loss: 0.6386, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5531/10000, Loss: 0.6386, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5532/10000, Loss: 0.6386, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5533/10000, Loss: 0.6386, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5534/10000, Loss: 0.6386, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5535/10000, Loss: 0.6386, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5536/10000, Loss: 0.6386, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5537/10000, Loss: 0.6386, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5538/10000, Loss: 0.6385, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5539/10000, Loss: 0.6385, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5540/10000, Loss: 0.6385, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5541/10000, Loss: 0.6385, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5542/10000, Loss: 0.6385, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5543/10000, Loss: 0.6385, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5544/10000, Loss: 0.6385, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5545/10000, Loss: 0.6385, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5546/10000, Loss: 0.6384, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5547/10000, Loss: 0.6384, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5548/10000, Loss: 0.6384, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5549/10000, Loss: 0.6384, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5550/10000, Loss: 0.6384, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5551/10000, Loss: 0.6384, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5552/10000, Loss: 0.6384, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5553/10000, Loss: 0.6384, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5554/10000, Loss: 0.6383, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5555/10000, Loss: 0.6383, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5556/10000, Loss: 0.6383, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5557/10000, Loss: 0.6383, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5558/10000, Loss: 0.6383, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5559/10000, Loss: 0.6383, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5560/10000, Loss: 0.6383, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5561/10000, Loss: 0.6383, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5562/10000, Loss: 0.6382, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5563/10000, Loss: 0.6382, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5564/10000, Loss: 0.6382, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5565/10000, Loss: 0.6382, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5566/10000, Loss: 0.6382, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5567/10000, Loss: 0.6382, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5568/10000, Loss: 0.6382, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5569/10000, Loss: 0.6382, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5570/10000, Loss: 0.6382, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5571/10000, Loss: 0.6381, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5572/10000, Loss: 0.6381, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5573/10000, Loss: 0.6381, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5574/10000, Loss: 0.6381, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5575/10000, Loss: 0.6381, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5576/10000, Loss: 0.6381, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5577/10000, Loss: 0.6381, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5578/10000, Loss: 0.6381, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5579/10000, Loss: 0.6380, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5580/10000, Loss: 0.6380, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5581/10000, Loss: 0.6380, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5582/10000, Loss: 0.6380, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5583/10000, Loss: 0.6380, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5584/10000, Loss: 0.6380, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5585/10000, Loss: 0.6380, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5586/10000, Loss: 0.6380, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5587/10000, Loss: 0.6379, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5588/10000, Loss: 0.6379, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5589/10000, Loss: 0.6379, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5590/10000, Loss: 0.6379, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5591/10000, Loss: 0.6379, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5592/10000, Loss: 0.6379, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5593/10000, Loss: 0.6379, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5594/10000, Loss: 0.6379, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5595/10000, Loss: 0.6379, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5596/10000, Loss: 0.6378, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5597/10000, Loss: 0.6378, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5598/10000, Loss: 0.6378, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5599/10000, Loss: 0.6378, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5600/10000, Loss: 0.6378, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5601/10000, Loss: 0.6378, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5602/10000, Loss: 0.6378, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5603/10000, Loss: 0.6378, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5604/10000, Loss: 0.6377, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5605/10000, Loss: 0.6377, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5606/10000, Loss: 0.6377, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5607/10000, Loss: 0.6377, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5608/10000, Loss: 0.6377, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5609/10000, Loss: 0.6377, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5610/10000, Loss: 0.6377, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5611/10000, Loss: 0.6377, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5612/10000, Loss: 0.6376, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5613/10000, Loss: 0.6376, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5614/10000, Loss: 0.6376, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5615/10000, Loss: 0.6376, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5616/10000, Loss: 0.6376, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5617/10000, Loss: 0.6376, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5618/10000, Loss: 0.6376, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5619/10000, Loss: 0.6376, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5620/10000, Loss: 0.6376, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5621/10000, Loss: 0.6375, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5622/10000, Loss: 0.6375, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5623/10000, Loss: 0.6375, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5624/10000, Loss: 0.6375, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5625/10000, Loss: 0.6375, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5626/10000, Loss: 0.6375, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5627/10000, Loss: 0.6375, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5628/10000, Loss: 0.6375, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5629/10000, Loss: 0.6374, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5630/10000, Loss: 0.6374, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5631/10000, Loss: 0.6374, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5632/10000, Loss: 0.6374, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5633/10000, Loss: 0.6374, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5634/10000, Loss: 0.6374, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5635/10000, Loss: 0.6374, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5636/10000, Loss: 0.6374, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5637/10000, Loss: 0.6374, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5638/10000, Loss: 0.6373, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5639/10000, Loss: 0.6373, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5640/10000, Loss: 0.6373, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5641/10000, Loss: 0.6373, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5642/10000, Loss: 0.6373, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5643/10000, Loss: 0.6373, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5644/10000, Loss: 0.6373, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5645/10000, Loss: 0.6373, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5646/10000, Loss: 0.6372, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5647/10000, Loss: 0.6372, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5648/10000, Loss: 0.6372, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5649/10000, Loss: 0.6372, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5650/10000, Loss: 0.6372, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5651/10000, Loss: 0.6372, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5652/10000, Loss: 0.6372, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5653/10000, Loss: 0.6372, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5654/10000, Loss: 0.6371, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5655/10000, Loss: 0.6371, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5656/10000, Loss: 0.6371, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5657/10000, Loss: 0.6371, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5658/10000, Loss: 0.6371, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5659/10000, Loss: 0.6371, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5660/10000, Loss: 0.6371, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5661/10000, Loss: 0.6371, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5662/10000, Loss: 0.6371, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5663/10000, Loss: 0.6370, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5664/10000, Loss: 0.6370, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5665/10000, Loss: 0.6370, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5666/10000, Loss: 0.6370, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5667/10000, Loss: 0.6370, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5668/10000, Loss: 0.6370, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5669/10000, Loss: 0.6370, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5670/10000, Loss: 0.6370, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5671/10000, Loss: 0.6369, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5672/10000, Loss: 0.6369, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5673/10000, Loss: 0.6369, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5674/10000, Loss: 0.6369, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5675/10000, Loss: 0.6369, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5676/10000, Loss: 0.6369, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5677/10000, Loss: 0.6369, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5678/10000, Loss: 0.6369, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5679/10000, Loss: 0.6369, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5680/10000, Loss: 0.6368, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5681/10000, Loss: 0.6368, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5682/10000, Loss: 0.6368, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5683/10000, Loss: 0.6368, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5684/10000, Loss: 0.6368, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5685/10000, Loss: 0.6368, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5686/10000, Loss: 0.6368, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5687/10000, Loss: 0.6368, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5688/10000, Loss: 0.6368, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5689/10000, Loss: 0.6367, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5690/10000, Loss: 0.6367, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5691/10000, Loss: 0.6367, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5692/10000, Loss: 0.6367, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5693/10000, Loss: 0.6367, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5694/10000, Loss: 0.6367, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5695/10000, Loss: 0.6367, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5696/10000, Loss: 0.6367, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5697/10000, Loss: 0.6366, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5698/10000, Loss: 0.6366, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5699/10000, Loss: 0.6366, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5700/10000, Loss: 0.6366, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5701/10000, Loss: 0.6366, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5702/10000, Loss: 0.6366, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5703/10000, Loss: 0.6366, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5704/10000, Loss: 0.6366, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5705/10000, Loss: 0.6366, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5706/10000, Loss: 0.6365, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5707/10000, Loss: 0.6365, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5708/10000, Loss: 0.6365, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5709/10000, Loss: 0.6365, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5710/10000, Loss: 0.6365, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5711/10000, Loss: 0.6365, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5712/10000, Loss: 0.6365, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5713/10000, Loss: 0.6365, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5714/10000, Loss: 0.6364, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5715/10000, Loss: 0.6364, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5716/10000, Loss: 0.6364, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5717/10000, Loss: 0.6364, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5718/10000, Loss: 0.6364, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5719/10000, Loss: 0.6364, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5720/10000, Loss: 0.6364, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5721/10000, Loss: 0.6364, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5722/10000, Loss: 0.6364, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5723/10000, Loss: 0.6363, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5724/10000, Loss: 0.6363, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5725/10000, Loss: 0.6363, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5726/10000, Loss: 0.6363, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5727/10000, Loss: 0.6363, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5728/10000, Loss: 0.6363, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5729/10000, Loss: 0.6363, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5730/10000, Loss: 0.6363, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5731/10000, Loss: 0.6363, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5732/10000, Loss: 0.6362, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5733/10000, Loss: 0.6362, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5734/10000, Loss: 0.6362, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5735/10000, Loss: 0.6362, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5736/10000, Loss: 0.6362, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5737/10000, Loss: 0.6362, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5738/10000, Loss: 0.6362, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5739/10000, Loss: 0.6362, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5740/10000, Loss: 0.6361, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5741/10000, Loss: 0.6361, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5742/10000, Loss: 0.6361, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5743/10000, Loss: 0.6361, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5744/10000, Loss: 0.6361, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5745/10000, Loss: 0.6361, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5746/10000, Loss: 0.6361, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5747/10000, Loss: 0.6361, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5748/10000, Loss: 0.6361, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5749/10000, Loss: 0.6360, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5750/10000, Loss: 0.6360, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5751/10000, Loss: 0.6360, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5752/10000, Loss: 0.6360, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5753/10000, Loss: 0.6360, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5754/10000, Loss: 0.6360, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5755/10000, Loss: 0.6360, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5756/10000, Loss: 0.6360, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5757/10000, Loss: 0.6360, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5758/10000, Loss: 0.6359, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5759/10000, Loss: 0.6359, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5760/10000, Loss: 0.6359, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5761/10000, Loss: 0.6359, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5762/10000, Loss: 0.6359, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5763/10000, Loss: 0.6359, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5764/10000, Loss: 0.6359, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5765/10000, Loss: 0.6359, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5766/10000, Loss: 0.6358, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5767/10000, Loss: 0.6358, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5768/10000, Loss: 0.6358, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5769/10000, Loss: 0.6358, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5770/10000, Loss: 0.6358, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5771/10000, Loss: 0.6358, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5772/10000, Loss: 0.6358, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5773/10000, Loss: 0.6358, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5774/10000, Loss: 0.6358, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5775/10000, Loss: 0.6357, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5776/10000, Loss: 0.6357, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5777/10000, Loss: 0.6357, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5778/10000, Loss: 0.6357, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5779/10000, Loss: 0.6357, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5780/10000, Loss: 0.6357, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5781/10000, Loss: 0.6357, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5782/10000, Loss: 0.6357, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5783/10000, Loss: 0.6357, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5784/10000, Loss: 0.6356, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5785/10000, Loss: 0.6356, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5786/10000, Loss: 0.6356, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5787/10000, Loss: 0.6356, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5788/10000, Loss: 0.6356, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5789/10000, Loss: 0.6356, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5790/10000, Loss: 0.6356, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5791/10000, Loss: 0.6356, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5792/10000, Loss: 0.6356, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5793/10000, Loss: 0.6355, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5794/10000, Loss: 0.6355, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5795/10000, Loss: 0.6355, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5796/10000, Loss: 0.6355, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5797/10000, Loss: 0.6355, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5798/10000, Loss: 0.6355, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5799/10000, Loss: 0.6355, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5800/10000, Loss: 0.6355, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5801/10000, Loss: 0.6355, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5802/10000, Loss: 0.6354, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5803/10000, Loss: 0.6354, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5804/10000, Loss: 0.6354, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5805/10000, Loss: 0.6354, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5806/10000, Loss: 0.6354, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5807/10000, Loss: 0.6354, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5808/10000, Loss: 0.6354, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5809/10000, Loss: 0.6354, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5810/10000, Loss: 0.6353, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5811/10000, Loss: 0.6353, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5812/10000, Loss: 0.6353, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5813/10000, Loss: 0.6353, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5814/10000, Loss: 0.6353, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5815/10000, Loss: 0.6353, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5816/10000, Loss: 0.6353, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5817/10000, Loss: 0.6353, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5818/10000, Loss: 0.6353, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5819/10000, Loss: 0.6352, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5820/10000, Loss: 0.6352, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5821/10000, Loss: 0.6352, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5822/10000, Loss: 0.6352, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5823/10000, Loss: 0.6352, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5824/10000, Loss: 0.6352, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5825/10000, Loss: 0.6352, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5826/10000, Loss: 0.6352, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5827/10000, Loss: 0.6352, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5828/10000, Loss: 0.6351, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5829/10000, Loss: 0.6351, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5830/10000, Loss: 0.6351, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5831/10000, Loss: 0.6351, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5832/10000, Loss: 0.6351, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5833/10000, Loss: 0.6351, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5834/10000, Loss: 0.6351, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5835/10000, Loss: 0.6351, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5836/10000, Loss: 0.6351, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5837/10000, Loss: 0.6350, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5838/10000, Loss: 0.6350, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5839/10000, Loss: 0.6350, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5840/10000, Loss: 0.6350, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5841/10000, Loss: 0.6350, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5842/10000, Loss: 0.6350, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5843/10000, Loss: 0.6350, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5844/10000, Loss: 0.6350, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5845/10000, Loss: 0.6350, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5846/10000, Loss: 0.6349, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5847/10000, Loss: 0.6349, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5848/10000, Loss: 0.6349, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5849/10000, Loss: 0.6349, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5850/10000, Loss: 0.6349, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5851/10000, Loss: 0.6349, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5852/10000, Loss: 0.6349, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5853/10000, Loss: 0.6349, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5854/10000, Loss: 0.6349, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5855/10000, Loss: 0.6348, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5856/10000, Loss: 0.6348, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5857/10000, Loss: 0.6348, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5858/10000, Loss: 0.6348, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5859/10000, Loss: 0.6348, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5860/10000, Loss: 0.6348, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5861/10000, Loss: 0.6348, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5862/10000, Loss: 0.6348, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5863/10000, Loss: 0.6348, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5864/10000, Loss: 0.6347, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5865/10000, Loss: 0.6347, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5866/10000, Loss: 0.6347, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5867/10000, Loss: 0.6347, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5868/10000, Loss: 0.6347, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5869/10000, Loss: 0.6347, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5870/10000, Loss: 0.6347, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5871/10000, Loss: 0.6347, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5872/10000, Loss: 0.6347, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5873/10000, Loss: 0.6346, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5874/10000, Loss: 0.6346, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5875/10000, Loss: 0.6346, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5876/10000, Loss: 0.6346, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5877/10000, Loss: 0.6346, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5878/10000, Loss: 0.6346, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5879/10000, Loss: 0.6346, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5880/10000, Loss: 0.6346, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5881/10000, Loss: 0.6346, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5882/10000, Loss: 0.6345, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5883/10000, Loss: 0.6345, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5884/10000, Loss: 0.6345, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5885/10000, Loss: 0.6345, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5886/10000, Loss: 0.6345, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5887/10000, Loss: 0.6345, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5888/10000, Loss: 0.6345, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5889/10000, Loss: 0.6345, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5890/10000, Loss: 0.6345, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5891/10000, Loss: 0.6344, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5892/10000, Loss: 0.6344, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5893/10000, Loss: 0.6344, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5894/10000, Loss: 0.6344, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5895/10000, Loss: 0.6344, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5896/10000, Loss: 0.6344, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5897/10000, Loss: 0.6344, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5898/10000, Loss: 0.6344, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5899/10000, Loss: 0.6344, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5900/10000, Loss: 0.6343, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5901/10000, Loss: 0.6343, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5902/10000, Loss: 0.6343, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5903/10000, Loss: 0.6343, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5904/10000, Loss: 0.6343, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5905/10000, Loss: 0.6343, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5906/10000, Loss: 0.6343, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5907/10000, Loss: 0.6343, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5908/10000, Loss: 0.6343, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5909/10000, Loss: 0.6342, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5910/10000, Loss: 0.6342, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5911/10000, Loss: 0.6342, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5912/10000, Loss: 0.6342, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5913/10000, Loss: 0.6342, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5914/10000, Loss: 0.6342, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5915/10000, Loss: 0.6342, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5916/10000, Loss: 0.6342, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5917/10000, Loss: 0.6342, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5918/10000, Loss: 0.6341, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5919/10000, Loss: 0.6341, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5920/10000, Loss: 0.6341, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5921/10000, Loss: 0.6341, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5922/10000, Loss: 0.6341, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5923/10000, Loss: 0.6341, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5924/10000, Loss: 0.6341, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5925/10000, Loss: 0.6341, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5926/10000, Loss: 0.6341, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5927/10000, Loss: 0.6340, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5928/10000, Loss: 0.6340, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5929/10000, Loss: 0.6340, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5930/10000, Loss: 0.6340, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5931/10000, Loss: 0.6340, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5932/10000, Loss: 0.6340, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5933/10000, Loss: 0.6340, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5934/10000, Loss: 0.6340, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5935/10000, Loss: 0.6340, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5936/10000, Loss: 0.6339, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5937/10000, Loss: 0.6339, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5938/10000, Loss: 0.6339, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5939/10000, Loss: 0.6339, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5940/10000, Loss: 0.6339, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5941/10000, Loss: 0.6339, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5942/10000, Loss: 0.6339, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5943/10000, Loss: 0.6339, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5944/10000, Loss: 0.6339, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5945/10000, Loss: 0.6339, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5946/10000, Loss: 0.6338, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5947/10000, Loss: 0.6338, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5948/10000, Loss: 0.6338, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5949/10000, Loss: 0.6338, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5950/10000, Loss: 0.6338, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5951/10000, Loss: 0.6338, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5952/10000, Loss: 0.6338, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5953/10000, Loss: 0.6338, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5954/10000, Loss: 0.6338, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5955/10000, Loss: 0.6337, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5956/10000, Loss: 0.6337, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5957/10000, Loss: 0.6337, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5958/10000, Loss: 0.6337, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5959/10000, Loss: 0.6337, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5960/10000, Loss: 0.6337, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5961/10000, Loss: 0.6337, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5962/10000, Loss: 0.6337, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5963/10000, Loss: 0.6337, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5964/10000, Loss: 0.6336, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5965/10000, Loss: 0.6336, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5966/10000, Loss: 0.6336, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5967/10000, Loss: 0.6336, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5968/10000, Loss: 0.6336, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5969/10000, Loss: 0.6336, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5970/10000, Loss: 0.6336, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5971/10000, Loss: 0.6336, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5972/10000, Loss: 0.6336, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5973/10000, Loss: 0.6335, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5974/10000, Loss: 0.6335, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5975/10000, Loss: 0.6335, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5976/10000, Loss: 0.6335, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5977/10000, Loss: 0.6335, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5978/10000, Loss: 0.6335, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5979/10000, Loss: 0.6335, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5980/10000, Loss: 0.6335, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5981/10000, Loss: 0.6335, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5982/10000, Loss: 0.6335, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5983/10000, Loss: 0.6334, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5984/10000, Loss: 0.6334, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5985/10000, Loss: 0.6334, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5986/10000, Loss: 0.6334, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5987/10000, Loss: 0.6334, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5988/10000, Loss: 0.6334, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5989/10000, Loss: 0.6334, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5990/10000, Loss: 0.6334, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5991/10000, Loss: 0.6334, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5992/10000, Loss: 0.6333, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5993/10000, Loss: 0.6333, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5994/10000, Loss: 0.6333, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5995/10000, Loss: 0.6333, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5996/10000, Loss: 0.6333, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5997/10000, Loss: 0.6333, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5998/10000, Loss: 0.6333, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 5999/10000, Loss: 0.6333, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6000/10000, Loss: 0.6333, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6001/10000, Loss: 0.6332, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6002/10000, Loss: 0.6332, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6003/10000, Loss: 0.6332, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6004/10000, Loss: 0.6332, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6005/10000, Loss: 0.6332, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6006/10000, Loss: 0.6332, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6007/10000, Loss: 0.6332, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6008/10000, Loss: 0.6332, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6009/10000, Loss: 0.6332, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6010/10000, Loss: 0.6332, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6011/10000, Loss: 0.6331, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6012/10000, Loss: 0.6331, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6013/10000, Loss: 0.6331, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6014/10000, Loss: 0.6331, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6015/10000, Loss: 0.6331, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6016/10000, Loss: 0.6331, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6017/10000, Loss: 0.6331, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6018/10000, Loss: 0.6331, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6019/10000, Loss: 0.6331, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6020/10000, Loss: 0.6330, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6021/10000, Loss: 0.6330, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6022/10000, Loss: 0.6330, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6023/10000, Loss: 0.6330, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6024/10000, Loss: 0.6330, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6025/10000, Loss: 0.6330, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6026/10000, Loss: 0.6330, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6027/10000, Loss: 0.6330, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6028/10000, Loss: 0.6330, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6029/10000, Loss: 0.6329, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6030/10000, Loss: 0.6329, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6031/10000, Loss: 0.6329, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6032/10000, Loss: 0.6329, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6033/10000, Loss: 0.6329, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6034/10000, Loss: 0.6329, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6035/10000, Loss: 0.6329, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6036/10000, Loss: 0.6329, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6037/10000, Loss: 0.6329, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6038/10000, Loss: 0.6329, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6039/10000, Loss: 0.6328, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6040/10000, Loss: 0.6328, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6041/10000, Loss: 0.6328, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6042/10000, Loss: 0.6328, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6043/10000, Loss: 0.6328, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6044/10000, Loss: 0.6328, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6045/10000, Loss: 0.6328, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6046/10000, Loss: 0.6328, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6047/10000, Loss: 0.6328, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6048/10000, Loss: 0.6327, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6049/10000, Loss: 0.6327, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6050/10000, Loss: 0.6327, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6051/10000, Loss: 0.6327, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6052/10000, Loss: 0.6327, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6053/10000, Loss: 0.6327, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6054/10000, Loss: 0.6327, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6055/10000, Loss: 0.6327, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6056/10000, Loss: 0.6327, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6057/10000, Loss: 0.6327, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6058/10000, Loss: 0.6326, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6059/10000, Loss: 0.6326, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6060/10000, Loss: 0.6326, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6061/10000, Loss: 0.6326, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6062/10000, Loss: 0.6326, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6063/10000, Loss: 0.6326, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6064/10000, Loss: 0.6326, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6065/10000, Loss: 0.6326, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6066/10000, Loss: 0.6326, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6067/10000, Loss: 0.6325, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6068/10000, Loss: 0.6325, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6069/10000, Loss: 0.6325, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6070/10000, Loss: 0.6325, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6071/10000, Loss: 0.6325, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6072/10000, Loss: 0.6325, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6073/10000, Loss: 0.6325, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6074/10000, Loss: 0.6325, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6075/10000, Loss: 0.6325, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6076/10000, Loss: 0.6325, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6077/10000, Loss: 0.6324, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6078/10000, Loss: 0.6324, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6079/10000, Loss: 0.6324, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6080/10000, Loss: 0.6324, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6081/10000, Loss: 0.6324, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6082/10000, Loss: 0.6324, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6083/10000, Loss: 0.6324, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6084/10000, Loss: 0.6324, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6085/10000, Loss: 0.6324, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6086/10000, Loss: 0.6323, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6087/10000, Loss: 0.6323, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6088/10000, Loss: 0.6323, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6089/10000, Loss: 0.6323, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6090/10000, Loss: 0.6323, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6091/10000, Loss: 0.6323, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6092/10000, Loss: 0.6323, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6093/10000, Loss: 0.6323, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6094/10000, Loss: 0.6323, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6095/10000, Loss: 0.6323, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6096/10000, Loss: 0.6322, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6097/10000, Loss: 0.6322, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6098/10000, Loss: 0.6322, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6099/10000, Loss: 0.6322, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6100/10000, Loss: 0.6322, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6101/10000, Loss: 0.6322, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6102/10000, Loss: 0.6322, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6103/10000, Loss: 0.6322, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6104/10000, Loss: 0.6322, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6105/10000, Loss: 0.6321, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6106/10000, Loss: 0.6321, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6107/10000, Loss: 0.6321, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6108/10000, Loss: 0.6321, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6109/10000, Loss: 0.6321, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6110/10000, Loss: 0.6321, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6111/10000, Loss: 0.6321, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6112/10000, Loss: 0.6321, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6113/10000, Loss: 0.6321, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6114/10000, Loss: 0.6321, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6115/10000, Loss: 0.6320, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6116/10000, Loss: 0.6320, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6117/10000, Loss: 0.6320, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6118/10000, Loss: 0.6320, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6119/10000, Loss: 0.6320, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6120/10000, Loss: 0.6320, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6121/10000, Loss: 0.6320, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6122/10000, Loss: 0.6320, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6123/10000, Loss: 0.6320, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6124/10000, Loss: 0.6320, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6125/10000, Loss: 0.6319, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6126/10000, Loss: 0.6319, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6127/10000, Loss: 0.6319, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6128/10000, Loss: 0.6319, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6129/10000, Loss: 0.6319, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6130/10000, Loss: 0.6319, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6131/10000, Loss: 0.6319, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6132/10000, Loss: 0.6319, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6133/10000, Loss: 0.6319, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6134/10000, Loss: 0.6318, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6135/10000, Loss: 0.6318, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6136/10000, Loss: 0.6318, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6137/10000, Loss: 0.6318, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6138/10000, Loss: 0.6318, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6139/10000, Loss: 0.6318, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6140/10000, Loss: 0.6318, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6141/10000, Loss: 0.6318, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6142/10000, Loss: 0.6318, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6143/10000, Loss: 0.6318, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6144/10000, Loss: 0.6317, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6145/10000, Loss: 0.6317, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6146/10000, Loss: 0.6317, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6147/10000, Loss: 0.6317, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6148/10000, Loss: 0.6317, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6149/10000, Loss: 0.6317, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6150/10000, Loss: 0.6317, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6151/10000, Loss: 0.6317, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6152/10000, Loss: 0.6317, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6153/10000, Loss: 0.6317, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6154/10000, Loss: 0.6316, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6155/10000, Loss: 0.6316, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6156/10000, Loss: 0.6316, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6157/10000, Loss: 0.6316, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6158/10000, Loss: 0.6316, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6159/10000, Loss: 0.6316, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6160/10000, Loss: 0.6316, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6161/10000, Loss: 0.6316, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6162/10000, Loss: 0.6316, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6163/10000, Loss: 0.6316, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6164/10000, Loss: 0.6315, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6165/10000, Loss: 0.6315, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6166/10000, Loss: 0.6315, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6167/10000, Loss: 0.6315, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6168/10000, Loss: 0.6315, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6169/10000, Loss: 0.6315, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6170/10000, Loss: 0.6315, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6171/10000, Loss: 0.6315, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6172/10000, Loss: 0.6315, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6173/10000, Loss: 0.6314, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6174/10000, Loss: 0.6314, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6175/10000, Loss: 0.6314, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6176/10000, Loss: 0.6314, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6177/10000, Loss: 0.6314, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6178/10000, Loss: 0.6314, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6179/10000, Loss: 0.6314, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6180/10000, Loss: 0.6314, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6181/10000, Loss: 0.6314, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6182/10000, Loss: 0.6314, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6183/10000, Loss: 0.6313, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6184/10000, Loss: 0.6313, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6185/10000, Loss: 0.6313, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6186/10000, Loss: 0.6313, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6187/10000, Loss: 0.6313, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6188/10000, Loss: 0.6313, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6189/10000, Loss: 0.6313, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6190/10000, Loss: 0.6313, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6191/10000, Loss: 0.6313, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6192/10000, Loss: 0.6313, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6193/10000, Loss: 0.6312, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6194/10000, Loss: 0.6312, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6195/10000, Loss: 0.6312, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6196/10000, Loss: 0.6312, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6197/10000, Loss: 0.6312, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6198/10000, Loss: 0.6312, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6199/10000, Loss: 0.6312, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6200/10000, Loss: 0.6312, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6201/10000, Loss: 0.6312, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6202/10000, Loss: 0.6312, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6203/10000, Loss: 0.6311, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6204/10000, Loss: 0.6311, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6205/10000, Loss: 0.6311, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6206/10000, Loss: 0.6311, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6207/10000, Loss: 0.6311, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6208/10000, Loss: 0.6311, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6209/10000, Loss: 0.6311, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6210/10000, Loss: 0.6311, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6211/10000, Loss: 0.6311, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6212/10000, Loss: 0.6311, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6213/10000, Loss: 0.6310, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6214/10000, Loss: 0.6310, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6215/10000, Loss: 0.6310, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6216/10000, Loss: 0.6310, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6217/10000, Loss: 0.6310, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6218/10000, Loss: 0.6310, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6219/10000, Loss: 0.6310, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6220/10000, Loss: 0.6310, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6221/10000, Loss: 0.6310, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6222/10000, Loss: 0.6310, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6223/10000, Loss: 0.6309, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6224/10000, Loss: 0.6309, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6225/10000, Loss: 0.6309, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6226/10000, Loss: 0.6309, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6227/10000, Loss: 0.6309, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6228/10000, Loss: 0.6309, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6229/10000, Loss: 0.6309, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6230/10000, Loss: 0.6309, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6231/10000, Loss: 0.6309, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6232/10000, Loss: 0.6309, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6233/10000, Loss: 0.6308, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6234/10000, Loss: 0.6308, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6235/10000, Loss: 0.6308, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6236/10000, Loss: 0.6308, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6237/10000, Loss: 0.6308, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6238/10000, Loss: 0.6308, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6239/10000, Loss: 0.6308, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6240/10000, Loss: 0.6308, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6241/10000, Loss: 0.6308, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6242/10000, Loss: 0.6308, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6243/10000, Loss: 0.6307, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6244/10000, Loss: 0.6307, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6245/10000, Loss: 0.6307, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6246/10000, Loss: 0.6307, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6247/10000, Loss: 0.6307, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6248/10000, Loss: 0.6307, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6249/10000, Loss: 0.6307, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6250/10000, Loss: 0.6307, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6251/10000, Loss: 0.6307, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6252/10000, Loss: 0.6307, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6253/10000, Loss: 0.6306, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6254/10000, Loss: 0.6306, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6255/10000, Loss: 0.6306, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6256/10000, Loss: 0.6306, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6257/10000, Loss: 0.6306, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6258/10000, Loss: 0.6306, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6259/10000, Loss: 0.6306, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6260/10000, Loss: 0.6306, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6261/10000, Loss: 0.6306, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6262/10000, Loss: 0.6306, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6263/10000, Loss: 0.6305, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6264/10000, Loss: 0.6305, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6265/10000, Loss: 0.6305, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6266/10000, Loss: 0.6305, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6267/10000, Loss: 0.6305, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6268/10000, Loss: 0.6305, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6269/10000, Loss: 0.6305, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6270/10000, Loss: 0.6305, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6271/10000, Loss: 0.6305, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6272/10000, Loss: 0.6305, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6273/10000, Loss: 0.6304, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6274/10000, Loss: 0.6304, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6275/10000, Loss: 0.6304, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6276/10000, Loss: 0.6304, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6277/10000, Loss: 0.6304, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6278/10000, Loss: 0.6304, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6279/10000, Loss: 0.6304, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6280/10000, Loss: 0.6304, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6281/10000, Loss: 0.6304, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6282/10000, Loss: 0.6304, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6283/10000, Loss: 0.6303, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6284/10000, Loss: 0.6303, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6285/10000, Loss: 0.6303, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6286/10000, Loss: 0.6303, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6287/10000, Loss: 0.6303, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6288/10000, Loss: 0.6303, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6289/10000, Loss: 0.6303, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6290/10000, Loss: 0.6303, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6291/10000, Loss: 0.6303, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6292/10000, Loss: 0.6303, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6293/10000, Loss: 0.6302, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6294/10000, Loss: 0.6302, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6295/10000, Loss: 0.6302, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6296/10000, Loss: 0.6302, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6297/10000, Loss: 0.6302, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6298/10000, Loss: 0.6302, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6299/10000, Loss: 0.6302, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6300/10000, Loss: 0.6302, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6301/10000, Loss: 0.6302, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6302/10000, Loss: 0.6302, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6303/10000, Loss: 0.6301, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6304/10000, Loss: 0.6301, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6305/10000, Loss: 0.6301, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6306/10000, Loss: 0.6301, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6307/10000, Loss: 0.6301, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6308/10000, Loss: 0.6301, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6309/10000, Loss: 0.6301, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6310/10000, Loss: 0.6301, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6311/10000, Loss: 0.6301, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6312/10000, Loss: 0.6301, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6313/10000, Loss: 0.6300, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6314/10000, Loss: 0.6300, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6315/10000, Loss: 0.6300, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6316/10000, Loss: 0.6300, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6317/10000, Loss: 0.6300, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6318/10000, Loss: 0.6300, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6319/10000, Loss: 0.6300, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6320/10000, Loss: 0.6300, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6321/10000, Loss: 0.6300, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6322/10000, Loss: 0.6300, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6323/10000, Loss: 0.6299, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6324/10000, Loss: 0.6299, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6325/10000, Loss: 0.6299, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6326/10000, Loss: 0.6299, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6327/10000, Loss: 0.6299, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6328/10000, Loss: 0.6299, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6329/10000, Loss: 0.6299, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6330/10000, Loss: 0.6299, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6331/10000, Loss: 0.6299, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6332/10000, Loss: 0.6299, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6333/10000, Loss: 0.6299, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6334/10000, Loss: 0.6298, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6335/10000, Loss: 0.6298, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6336/10000, Loss: 0.6298, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6337/10000, Loss: 0.6298, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6338/10000, Loss: 0.6298, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6339/10000, Loss: 0.6298, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6340/10000, Loss: 0.6298, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6341/10000, Loss: 0.6298, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6342/10000, Loss: 0.6298, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6343/10000, Loss: 0.6298, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6344/10000, Loss: 0.6297, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6345/10000, Loss: 0.6297, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6346/10000, Loss: 0.6297, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6347/10000, Loss: 0.6297, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6348/10000, Loss: 0.6297, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6349/10000, Loss: 0.6297, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6350/10000, Loss: 0.6297, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6351/10000, Loss: 0.6297, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6352/10000, Loss: 0.6297, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6353/10000, Loss: 0.6297, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6354/10000, Loss: 0.6296, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6355/10000, Loss: 0.6296, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6356/10000, Loss: 0.6296, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6357/10000, Loss: 0.6296, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6358/10000, Loss: 0.6296, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6359/10000, Loss: 0.6296, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6360/10000, Loss: 0.6296, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6361/10000, Loss: 0.6296, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6362/10000, Loss: 0.6296, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6363/10000, Loss: 0.6296, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6364/10000, Loss: 0.6296, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6365/10000, Loss: 0.6295, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6366/10000, Loss: 0.6295, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6367/10000, Loss: 0.6295, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6368/10000, Loss: 0.6295, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6369/10000, Loss: 0.6295, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6370/10000, Loss: 0.6295, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6371/10000, Loss: 0.6295, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6372/10000, Loss: 0.6295, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6373/10000, Loss: 0.6295, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6374/10000, Loss: 0.6295, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6375/10000, Loss: 0.6294, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6376/10000, Loss: 0.6294, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6377/10000, Loss: 0.6294, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6378/10000, Loss: 0.6294, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6379/10000, Loss: 0.6294, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6380/10000, Loss: 0.6294, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6381/10000, Loss: 0.6294, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6382/10000, Loss: 0.6294, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6383/10000, Loss: 0.6294, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6384/10000, Loss: 0.6294, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6385/10000, Loss: 0.6293, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6386/10000, Loss: 0.6293, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6387/10000, Loss: 0.6293, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6388/10000, Loss: 0.6293, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6389/10000, Loss: 0.6293, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6390/10000, Loss: 0.6293, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6391/10000, Loss: 0.6293, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6392/10000, Loss: 0.6293, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6393/10000, Loss: 0.6293, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6394/10000, Loss: 0.6293, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6395/10000, Loss: 0.6293, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6396/10000, Loss: 0.6292, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6397/10000, Loss: 0.6292, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6398/10000, Loss: 0.6292, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6399/10000, Loss: 0.6292, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6400/10000, Loss: 0.6292, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6401/10000, Loss: 0.6292, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6402/10000, Loss: 0.6292, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6403/10000, Loss: 0.6292, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6404/10000, Loss: 0.6292, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6405/10000, Loss: 0.6292, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6406/10000, Loss: 0.6291, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6407/10000, Loss: 0.6291, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6408/10000, Loss: 0.6291, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6409/10000, Loss: 0.6291, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6410/10000, Loss: 0.6291, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6411/10000, Loss: 0.6291, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6412/10000, Loss: 0.6291, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6413/10000, Loss: 0.6291, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6414/10000, Loss: 0.6291, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6415/10000, Loss: 0.6291, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6416/10000, Loss: 0.6291, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6417/10000, Loss: 0.6290, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6418/10000, Loss: 0.6290, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6419/10000, Loss: 0.6290, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6420/10000, Loss: 0.6290, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6421/10000, Loss: 0.6290, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6422/10000, Loss: 0.6290, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6423/10000, Loss: 0.6290, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6424/10000, Loss: 0.6290, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6425/10000, Loss: 0.6290, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6426/10000, Loss: 0.6290, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6427/10000, Loss: 0.6289, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6428/10000, Loss: 0.6289, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6429/10000, Loss: 0.6289, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6430/10000, Loss: 0.6289, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6431/10000, Loss: 0.6289, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6432/10000, Loss: 0.6289, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6433/10000, Loss: 0.6289, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6434/10000, Loss: 0.6289, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6435/10000, Loss: 0.6289, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6436/10000, Loss: 0.6289, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6437/10000, Loss: 0.6289, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6438/10000, Loss: 0.6288, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6439/10000, Loss: 0.6288, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6440/10000, Loss: 0.6288, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6441/10000, Loss: 0.6288, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6442/10000, Loss: 0.6288, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6443/10000, Loss: 0.6288, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6444/10000, Loss: 0.6288, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6445/10000, Loss: 0.6288, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6446/10000, Loss: 0.6288, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6447/10000, Loss: 0.6288, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6448/10000, Loss: 0.6287, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6449/10000, Loss: 0.6287, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6450/10000, Loss: 0.6287, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6451/10000, Loss: 0.6287, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6452/10000, Loss: 0.6287, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6453/10000, Loss: 0.6287, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6454/10000, Loss: 0.6287, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6455/10000, Loss: 0.6287, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6456/10000, Loss: 0.6287, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6457/10000, Loss: 0.6287, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6458/10000, Loss: 0.6287, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6459/10000, Loss: 0.6286, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6460/10000, Loss: 0.6286, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6461/10000, Loss: 0.6286, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6462/10000, Loss: 0.6286, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6463/10000, Loss: 0.6286, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6464/10000, Loss: 0.6286, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6465/10000, Loss: 0.6286, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6466/10000, Loss: 0.6286, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6467/10000, Loss: 0.6286, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6468/10000, Loss: 0.6286, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6469/10000, Loss: 0.6286, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6470/10000, Loss: 0.6285, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6471/10000, Loss: 0.6285, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6472/10000, Loss: 0.6285, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6473/10000, Loss: 0.6285, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6474/10000, Loss: 0.6285, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6475/10000, Loss: 0.6285, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6476/10000, Loss: 0.6285, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6477/10000, Loss: 0.6285, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6478/10000, Loss: 0.6285, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6479/10000, Loss: 0.6285, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6480/10000, Loss: 0.6284, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6481/10000, Loss: 0.6284, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6482/10000, Loss: 0.6284, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6483/10000, Loss: 0.6284, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6484/10000, Loss: 0.6284, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6485/10000, Loss: 0.6284, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6486/10000, Loss: 0.6284, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6487/10000, Loss: 0.6284, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6488/10000, Loss: 0.6284, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6489/10000, Loss: 0.6284, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6490/10000, Loss: 0.6284, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6491/10000, Loss: 0.6283, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6492/10000, Loss: 0.6283, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6493/10000, Loss: 0.6283, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6494/10000, Loss: 0.6283, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6495/10000, Loss: 0.6283, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6496/10000, Loss: 0.6283, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6497/10000, Loss: 0.6283, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6498/10000, Loss: 0.6283, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6499/10000, Loss: 0.6283, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6500/10000, Loss: 0.6283, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6501/10000, Loss: 0.6283, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6502/10000, Loss: 0.6282, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6503/10000, Loss: 0.6282, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6504/10000, Loss: 0.6282, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6505/10000, Loss: 0.6282, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6506/10000, Loss: 0.6282, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6507/10000, Loss: 0.6282, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6508/10000, Loss: 0.6282, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6509/10000, Loss: 0.6282, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6510/10000, Loss: 0.6282, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6511/10000, Loss: 0.6282, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6512/10000, Loss: 0.6281, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6513/10000, Loss: 0.6281, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6514/10000, Loss: 0.6281, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6515/10000, Loss: 0.6281, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6516/10000, Loss: 0.6281, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6517/10000, Loss: 0.6281, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6518/10000, Loss: 0.6281, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6519/10000, Loss: 0.6281, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6520/10000, Loss: 0.6281, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6521/10000, Loss: 0.6281, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6522/10000, Loss: 0.6281, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6523/10000, Loss: 0.6280, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6524/10000, Loss: 0.6280, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6525/10000, Loss: 0.6280, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6526/10000, Loss: 0.6280, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6527/10000, Loss: 0.6280, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6528/10000, Loss: 0.6280, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6529/10000, Loss: 0.6280, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6530/10000, Loss: 0.6280, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6531/10000, Loss: 0.6280, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6532/10000, Loss: 0.6280, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6533/10000, Loss: 0.6280, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6534/10000, Loss: 0.6279, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6535/10000, Loss: 0.6279, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6536/10000, Loss: 0.6279, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6537/10000, Loss: 0.6279, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6538/10000, Loss: 0.6279, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6539/10000, Loss: 0.6279, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6540/10000, Loss: 0.6279, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6541/10000, Loss: 0.6279, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6542/10000, Loss: 0.6279, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6543/10000, Loss: 0.6279, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6544/10000, Loss: 0.6279, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6545/10000, Loss: 0.6278, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6546/10000, Loss: 0.6278, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6547/10000, Loss: 0.6278, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6548/10000, Loss: 0.6278, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6549/10000, Loss: 0.6278, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6550/10000, Loss: 0.6278, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6551/10000, Loss: 0.6278, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6552/10000, Loss: 0.6278, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6553/10000, Loss: 0.6278, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6554/10000, Loss: 0.6278, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6555/10000, Loss: 0.6278, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6556/10000, Loss: 0.6277, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6557/10000, Loss: 0.6277, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6558/10000, Loss: 0.6277, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6559/10000, Loss: 0.6277, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6560/10000, Loss: 0.6277, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6561/10000, Loss: 0.6277, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6562/10000, Loss: 0.6277, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6563/10000, Loss: 0.6277, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6564/10000, Loss: 0.6277, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6565/10000, Loss: 0.6277, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6566/10000, Loss: 0.6277, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6567/10000, Loss: 0.6276, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6568/10000, Loss: 0.6276, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6569/10000, Loss: 0.6276, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6570/10000, Loss: 0.6276, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6571/10000, Loss: 0.6276, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6572/10000, Loss: 0.6276, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6573/10000, Loss: 0.6276, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6574/10000, Loss: 0.6276, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6575/10000, Loss: 0.6276, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6576/10000, Loss: 0.6276, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6577/10000, Loss: 0.6276, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6578/10000, Loss: 0.6275, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6579/10000, Loss: 0.6275, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6580/10000, Loss: 0.6275, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6581/10000, Loss: 0.6275, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6582/10000, Loss: 0.6275, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6583/10000, Loss: 0.6275, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6584/10000, Loss: 0.6275, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6585/10000, Loss: 0.6275, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6586/10000, Loss: 0.6275, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6587/10000, Loss: 0.6275, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6588/10000, Loss: 0.6275, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6589/10000, Loss: 0.6274, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6590/10000, Loss: 0.6274, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6591/10000, Loss: 0.6274, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6592/10000, Loss: 0.6274, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6593/10000, Loss: 0.6274, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6594/10000, Loss: 0.6274, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6595/10000, Loss: 0.6274, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6596/10000, Loss: 0.6274, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6597/10000, Loss: 0.6274, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6598/10000, Loss: 0.6274, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6599/10000, Loss: 0.6274, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6600/10000, Loss: 0.6273, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6601/10000, Loss: 0.6273, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6602/10000, Loss: 0.6273, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6603/10000, Loss: 0.6273, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6604/10000, Loss: 0.6273, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6605/10000, Loss: 0.6273, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6606/10000, Loss: 0.6273, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6607/10000, Loss: 0.6273, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6608/10000, Loss: 0.6273, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6609/10000, Loss: 0.6273, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6610/10000, Loss: 0.6273, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6611/10000, Loss: 0.6272, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6612/10000, Loss: 0.6272, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6613/10000, Loss: 0.6272, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6614/10000, Loss: 0.6272, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6615/10000, Loss: 0.6272, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6616/10000, Loss: 0.6272, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6617/10000, Loss: 0.6272, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6618/10000, Loss: 0.6272, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6619/10000, Loss: 0.6272, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6620/10000, Loss: 0.6272, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6621/10000, Loss: 0.6272, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6622/10000, Loss: 0.6271, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6623/10000, Loss: 0.6271, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6624/10000, Loss: 0.6271, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6625/10000, Loss: 0.6271, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6626/10000, Loss: 0.6271, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6627/10000, Loss: 0.6271, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6628/10000, Loss: 0.6271, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6629/10000, Loss: 0.6271, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6630/10000, Loss: 0.6271, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6631/10000, Loss: 0.6271, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6632/10000, Loss: 0.6271, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6633/10000, Loss: 0.6270, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6634/10000, Loss: 0.6270, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6635/10000, Loss: 0.6270, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6636/10000, Loss: 0.6270, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6637/10000, Loss: 0.6270, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6638/10000, Loss: 0.6270, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6639/10000, Loss: 0.6270, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6640/10000, Loss: 0.6270, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6641/10000, Loss: 0.6270, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6642/10000, Loss: 0.6270, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6643/10000, Loss: 0.6270, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6644/10000, Loss: 0.6269, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6645/10000, Loss: 0.6269, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6646/10000, Loss: 0.6269, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6647/10000, Loss: 0.6269, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6648/10000, Loss: 0.6269, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6649/10000, Loss: 0.6269, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6650/10000, Loss: 0.6269, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6651/10000, Loss: 0.6269, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6652/10000, Loss: 0.6269, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6653/10000, Loss: 0.6269, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6654/10000, Loss: 0.6269, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6655/10000, Loss: 0.6269, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6656/10000, Loss: 0.6268, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6657/10000, Loss: 0.6268, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6658/10000, Loss: 0.6268, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6659/10000, Loss: 0.6268, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6660/10000, Loss: 0.6268, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6661/10000, Loss: 0.6268, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6662/10000, Loss: 0.6268, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6663/10000, Loss: 0.6268, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6664/10000, Loss: 0.6268, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6665/10000, Loss: 0.6268, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6666/10000, Loss: 0.6268, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6667/10000, Loss: 0.6267, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6668/10000, Loss: 0.6267, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6669/10000, Loss: 0.6267, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6670/10000, Loss: 0.6267, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6671/10000, Loss: 0.6267, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6672/10000, Loss: 0.6267, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6673/10000, Loss: 0.6267, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6674/10000, Loss: 0.6267, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6675/10000, Loss: 0.6267, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6676/10000, Loss: 0.6267, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6677/10000, Loss: 0.6267, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6678/10000, Loss: 0.6266, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6679/10000, Loss: 0.6266, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6680/10000, Loss: 0.6266, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6681/10000, Loss: 0.6266, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6682/10000, Loss: 0.6266, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6683/10000, Loss: 0.6266, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6684/10000, Loss: 0.6266, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6685/10000, Loss: 0.6266, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6686/10000, Loss: 0.6266, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6687/10000, Loss: 0.6266, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6688/10000, Loss: 0.6266, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6689/10000, Loss: 0.6265, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6690/10000, Loss: 0.6265, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6691/10000, Loss: 0.6265, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6692/10000, Loss: 0.6265, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6693/10000, Loss: 0.6265, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6694/10000, Loss: 0.6265, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6695/10000, Loss: 0.6265, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6696/10000, Loss: 0.6265, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6697/10000, Loss: 0.6265, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6698/10000, Loss: 0.6265, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6699/10000, Loss: 0.6265, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6700/10000, Loss: 0.6265, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6701/10000, Loss: 0.6264, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6702/10000, Loss: 0.6264, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6703/10000, Loss: 0.6264, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6704/10000, Loss: 0.6264, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6705/10000, Loss: 0.6264, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6706/10000, Loss: 0.6264, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6707/10000, Loss: 0.6264, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6708/10000, Loss: 0.6264, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6709/10000, Loss: 0.6264, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6710/10000, Loss: 0.6264, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6711/10000, Loss: 0.6264, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6712/10000, Loss: 0.6263, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6713/10000, Loss: 0.6263, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6714/10000, Loss: 0.6263, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6715/10000, Loss: 0.6263, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6716/10000, Loss: 0.6263, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6717/10000, Loss: 0.6263, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6718/10000, Loss: 0.6263, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6719/10000, Loss: 0.6263, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6720/10000, Loss: 0.6263, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6721/10000, Loss: 0.6263, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6722/10000, Loss: 0.6263, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6723/10000, Loss: 0.6263, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6724/10000, Loss: 0.6262, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6725/10000, Loss: 0.6262, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6726/10000, Loss: 0.6262, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6727/10000, Loss: 0.6262, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6728/10000, Loss: 0.6262, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6729/10000, Loss: 0.6262, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6730/10000, Loss: 0.6262, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6731/10000, Loss: 0.6262, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6732/10000, Loss: 0.6262, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6733/10000, Loss: 0.6262, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6734/10000, Loss: 0.6262, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6735/10000, Loss: 0.6261, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6736/10000, Loss: 0.6261, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6737/10000, Loss: 0.6261, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6738/10000, Loss: 0.6261, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6739/10000, Loss: 0.6261, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6740/10000, Loss: 0.6261, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6741/10000, Loss: 0.6261, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6742/10000, Loss: 0.6261, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6743/10000, Loss: 0.6261, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6744/10000, Loss: 0.6261, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6745/10000, Loss: 0.6261, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6746/10000, Loss: 0.6261, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6747/10000, Loss: 0.6260, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6748/10000, Loss: 0.6260, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6749/10000, Loss: 0.6260, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6750/10000, Loss: 0.6260, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6751/10000, Loss: 0.6260, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6752/10000, Loss: 0.6260, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6753/10000, Loss: 0.6260, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6754/10000, Loss: 0.6260, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6755/10000, Loss: 0.6260, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6756/10000, Loss: 0.6260, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6757/10000, Loss: 0.6260, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6758/10000, Loss: 0.6259, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6759/10000, Loss: 0.6259, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6760/10000, Loss: 0.6259, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6761/10000, Loss: 0.6259, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6762/10000, Loss: 0.6259, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6763/10000, Loss: 0.6259, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6764/10000, Loss: 0.6259, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6765/10000, Loss: 0.6259, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6766/10000, Loss: 0.6259, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6767/10000, Loss: 0.6259, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6768/10000, Loss: 0.6259, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6769/10000, Loss: 0.6259, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6770/10000, Loss: 0.6258, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6771/10000, Loss: 0.6258, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6772/10000, Loss: 0.6258, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6773/10000, Loss: 0.6258, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6774/10000, Loss: 0.6258, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6775/10000, Loss: 0.6258, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6776/10000, Loss: 0.6258, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6777/10000, Loss: 0.6258, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6778/10000, Loss: 0.6258, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6779/10000, Loss: 0.6258, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6780/10000, Loss: 0.6258, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6781/10000, Loss: 0.6257, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6782/10000, Loss: 0.6257, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6783/10000, Loss: 0.6257, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6784/10000, Loss: 0.6257, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6785/10000, Loss: 0.6257, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6786/10000, Loss: 0.6257, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6787/10000, Loss: 0.6257, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6788/10000, Loss: 0.6257, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6789/10000, Loss: 0.6257, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6790/10000, Loss: 0.6257, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6791/10000, Loss: 0.6257, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6792/10000, Loss: 0.6257, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6793/10000, Loss: 0.6256, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6794/10000, Loss: 0.6256, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6795/10000, Loss: 0.6256, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6796/10000, Loss: 0.6256, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6797/10000, Loss: 0.6256, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6798/10000, Loss: 0.6256, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6799/10000, Loss: 0.6256, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6800/10000, Loss: 0.6256, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6801/10000, Loss: 0.6256, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6802/10000, Loss: 0.6256, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6803/10000, Loss: 0.6256, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6804/10000, Loss: 0.6256, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6805/10000, Loss: 0.6255, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6806/10000, Loss: 0.6255, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6807/10000, Loss: 0.6255, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6808/10000, Loss: 0.6255, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6809/10000, Loss: 0.6255, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6810/10000, Loss: 0.6255, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6811/10000, Loss: 0.6255, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6812/10000, Loss: 0.6255, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6813/10000, Loss: 0.6255, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6814/10000, Loss: 0.6255, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6815/10000, Loss: 0.6255, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6816/10000, Loss: 0.6255, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6817/10000, Loss: 0.6254, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6818/10000, Loss: 0.6254, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6819/10000, Loss: 0.6254, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6820/10000, Loss: 0.6254, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6821/10000, Loss: 0.6254, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6822/10000, Loss: 0.6254, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6823/10000, Loss: 0.6254, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6824/10000, Loss: 0.6254, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6825/10000, Loss: 0.6254, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6826/10000, Loss: 0.6254, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6827/10000, Loss: 0.6254, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6828/10000, Loss: 0.6253, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6829/10000, Loss: 0.6253, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6830/10000, Loss: 0.6253, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6831/10000, Loss: 0.6253, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6832/10000, Loss: 0.6253, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6833/10000, Loss: 0.6253, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6834/10000, Loss: 0.6253, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6835/10000, Loss: 0.6253, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6836/10000, Loss: 0.6253, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6837/10000, Loss: 0.6253, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6838/10000, Loss: 0.6253, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6839/10000, Loss: 0.6253, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6840/10000, Loss: 0.6252, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6841/10000, Loss: 0.6252, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6842/10000, Loss: 0.6252, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6843/10000, Loss: 0.6252, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6844/10000, Loss: 0.6252, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6845/10000, Loss: 0.6252, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6846/10000, Loss: 0.6252, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6847/10000, Loss: 0.6252, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6848/10000, Loss: 0.6252, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6849/10000, Loss: 0.6252, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6850/10000, Loss: 0.6252, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6851/10000, Loss: 0.6252, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6852/10000, Loss: 0.6251, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6853/10000, Loss: 0.6251, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6854/10000, Loss: 0.6251, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6855/10000, Loss: 0.6251, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6856/10000, Loss: 0.6251, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6857/10000, Loss: 0.6251, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6858/10000, Loss: 0.6251, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6859/10000, Loss: 0.6251, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6860/10000, Loss: 0.6251, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6861/10000, Loss: 0.6251, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6862/10000, Loss: 0.6251, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6863/10000, Loss: 0.6251, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6864/10000, Loss: 0.6250, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6865/10000, Loss: 0.6250, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6866/10000, Loss: 0.6250, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6867/10000, Loss: 0.6250, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6868/10000, Loss: 0.6250, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6869/10000, Loss: 0.6250, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6870/10000, Loss: 0.6250, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6871/10000, Loss: 0.6250, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6872/10000, Loss: 0.6250, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6873/10000, Loss: 0.6250, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6874/10000, Loss: 0.6250, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6875/10000, Loss: 0.6250, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6876/10000, Loss: 0.6249, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6877/10000, Loss: 0.6249, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6878/10000, Loss: 0.6249, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6879/10000, Loss: 0.6249, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6880/10000, Loss: 0.6249, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6881/10000, Loss: 0.6249, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6882/10000, Loss: 0.6249, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6883/10000, Loss: 0.6249, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6884/10000, Loss: 0.6249, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6885/10000, Loss: 0.6249, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6886/10000, Loss: 0.6249, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6887/10000, Loss: 0.6249, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6888/10000, Loss: 0.6248, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6889/10000, Loss: 0.6248, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6890/10000, Loss: 0.6248, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6891/10000, Loss: 0.6248, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6892/10000, Loss: 0.6248, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6893/10000, Loss: 0.6248, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6894/10000, Loss: 0.6248, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6895/10000, Loss: 0.6248, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6896/10000, Loss: 0.6248, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6897/10000, Loss: 0.6248, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6898/10000, Loss: 0.6248, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6899/10000, Loss: 0.6248, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6900/10000, Loss: 0.6247, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6901/10000, Loss: 0.6247, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6902/10000, Loss: 0.6247, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6903/10000, Loss: 0.6247, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6904/10000, Loss: 0.6247, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6905/10000, Loss: 0.6247, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6906/10000, Loss: 0.6247, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6907/10000, Loss: 0.6247, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6908/10000, Loss: 0.6247, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6909/10000, Loss: 0.6247, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6910/10000, Loss: 0.6247, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6911/10000, Loss: 0.6247, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6912/10000, Loss: 0.6246, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6913/10000, Loss: 0.6246, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6914/10000, Loss: 0.6246, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6915/10000, Loss: 0.6246, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6916/10000, Loss: 0.6246, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6917/10000, Loss: 0.6246, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6918/10000, Loss: 0.6246, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6919/10000, Loss: 0.6246, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6920/10000, Loss: 0.6246, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6921/10000, Loss: 0.6246, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6922/10000, Loss: 0.6246, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6923/10000, Loss: 0.6246, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6924/10000, Loss: 0.6245, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6925/10000, Loss: 0.6245, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6926/10000, Loss: 0.6245, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6927/10000, Loss: 0.6245, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6928/10000, Loss: 0.6245, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6929/10000, Loss: 0.6245, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6930/10000, Loss: 0.6245, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6931/10000, Loss: 0.6245, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6932/10000, Loss: 0.6245, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6933/10000, Loss: 0.6245, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6934/10000, Loss: 0.6245, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6935/10000, Loss: 0.6245, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6936/10000, Loss: 0.6245, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6937/10000, Loss: 0.6244, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6938/10000, Loss: 0.6244, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6939/10000, Loss: 0.6244, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6940/10000, Loss: 0.6244, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6941/10000, Loss: 0.6244, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6942/10000, Loss: 0.6244, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6943/10000, Loss: 0.6244, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6944/10000, Loss: 0.6244, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6945/10000, Loss: 0.6244, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6946/10000, Loss: 0.6244, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6947/10000, Loss: 0.6244, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6948/10000, Loss: 0.6244, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6949/10000, Loss: 0.6243, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6950/10000, Loss: 0.6243, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6951/10000, Loss: 0.6243, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6952/10000, Loss: 0.6243, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6953/10000, Loss: 0.6243, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6954/10000, Loss: 0.6243, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6955/10000, Loss: 0.6243, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6956/10000, Loss: 0.6243, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6957/10000, Loss: 0.6243, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6958/10000, Loss: 0.6243, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6959/10000, Loss: 0.6243, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6960/10000, Loss: 0.6243, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6961/10000, Loss: 0.6242, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6962/10000, Loss: 0.6242, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6963/10000, Loss: 0.6242, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6964/10000, Loss: 0.6242, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6965/10000, Loss: 0.6242, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6966/10000, Loss: 0.6242, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6967/10000, Loss: 0.6242, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6968/10000, Loss: 0.6242, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6969/10000, Loss: 0.6242, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6970/10000, Loss: 0.6242, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6971/10000, Loss: 0.6242, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6972/10000, Loss: 0.6242, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6973/10000, Loss: 0.6241, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6974/10000, Loss: 0.6241, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6975/10000, Loss: 0.6241, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6976/10000, Loss: 0.6241, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6977/10000, Loss: 0.6241, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6978/10000, Loss: 0.6241, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6979/10000, Loss: 0.6241, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6980/10000, Loss: 0.6241, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6981/10000, Loss: 0.6241, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6982/10000, Loss: 0.6241, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6983/10000, Loss: 0.6241, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6984/10000, Loss: 0.6241, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6985/10000, Loss: 0.6241, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6986/10000, Loss: 0.6240, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6987/10000, Loss: 0.6240, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6988/10000, Loss: 0.6240, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6989/10000, Loss: 0.6240, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6990/10000, Loss: 0.6240, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6991/10000, Loss: 0.6240, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6992/10000, Loss: 0.6240, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6993/10000, Loss: 0.6240, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6994/10000, Loss: 0.6240, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6995/10000, Loss: 0.6240, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6996/10000, Loss: 0.6240, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6997/10000, Loss: 0.6240, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6998/10000, Loss: 0.6239, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6999/10000, Loss: 0.6239, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7000/10000, Loss: 0.6239, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7001/10000, Loss: 0.6239, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7002/10000, Loss: 0.6239, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7003/10000, Loss: 0.6239, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7004/10000, Loss: 0.6239, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7005/10000, Loss: 0.6239, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7006/10000, Loss: 0.6239, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7007/10000, Loss: 0.6239, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7008/10000, Loss: 0.6239, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7009/10000, Loss: 0.6239, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7010/10000, Loss: 0.6238, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7011/10000, Loss: 0.6238, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7012/10000, Loss: 0.6238, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7013/10000, Loss: 0.6238, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7014/10000, Loss: 0.6238, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7015/10000, Loss: 0.6238, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7016/10000, Loss: 0.6238, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7017/10000, Loss: 0.6238, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7018/10000, Loss: 0.6238, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7019/10000, Loss: 0.6238, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7020/10000, Loss: 0.6238, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7021/10000, Loss: 0.6238, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7022/10000, Loss: 0.6238, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7023/10000, Loss: 0.6237, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7024/10000, Loss: 0.6237, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7025/10000, Loss: 0.6237, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7026/10000, Loss: 0.6237, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7027/10000, Loss: 0.6237, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7028/10000, Loss: 0.6237, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7029/10000, Loss: 0.6237, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7030/10000, Loss: 0.6237, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7031/10000, Loss: 0.6237, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7032/10000, Loss: 0.6237, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7033/10000, Loss: 0.6237, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7034/10000, Loss: 0.6237, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7035/10000, Loss: 0.6237, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7036/10000, Loss: 0.6236, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7037/10000, Loss: 0.6236, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7038/10000, Loss: 0.6236, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7039/10000, Loss: 0.6236, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7040/10000, Loss: 0.6236, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7041/10000, Loss: 0.6236, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7042/10000, Loss: 0.6236, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7043/10000, Loss: 0.6236, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7044/10000, Loss: 0.6236, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7045/10000, Loss: 0.6236, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7046/10000, Loss: 0.6236, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7047/10000, Loss: 0.6236, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7048/10000, Loss: 0.6235, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7049/10000, Loss: 0.6235, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7050/10000, Loss: 0.6235, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7051/10000, Loss: 0.6235, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7052/10000, Loss: 0.6235, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7053/10000, Loss: 0.6235, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7054/10000, Loss: 0.6235, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7055/10000, Loss: 0.6235, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7056/10000, Loss: 0.6235, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7057/10000, Loss: 0.6235, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7058/10000, Loss: 0.6235, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7059/10000, Loss: 0.6235, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7060/10000, Loss: 0.6235, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7061/10000, Loss: 0.6234, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7062/10000, Loss: 0.6234, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7063/10000, Loss: 0.6234, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7064/10000, Loss: 0.6234, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7065/10000, Loss: 0.6234, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7066/10000, Loss: 0.6234, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7067/10000, Loss: 0.6234, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7068/10000, Loss: 0.6234, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7069/10000, Loss: 0.6234, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7070/10000, Loss: 0.6234, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7071/10000, Loss: 0.6234, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7072/10000, Loss: 0.6234, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7073/10000, Loss: 0.6233, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7074/10000, Loss: 0.6233, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7075/10000, Loss: 0.6233, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7076/10000, Loss: 0.6233, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7077/10000, Loss: 0.6233, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7078/10000, Loss: 0.6233, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7079/10000, Loss: 0.6233, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7080/10000, Loss: 0.6233, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7081/10000, Loss: 0.6233, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7082/10000, Loss: 0.6233, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7083/10000, Loss: 0.6233, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7084/10000, Loss: 0.6233, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7085/10000, Loss: 0.6233, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7086/10000, Loss: 0.6232, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7087/10000, Loss: 0.6232, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7088/10000, Loss: 0.6232, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7089/10000, Loss: 0.6232, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7090/10000, Loss: 0.6232, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7091/10000, Loss: 0.6232, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7092/10000, Loss: 0.6232, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7093/10000, Loss: 0.6232, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7094/10000, Loss: 0.6232, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7095/10000, Loss: 0.6232, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7096/10000, Loss: 0.6232, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7097/10000, Loss: 0.6232, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7098/10000, Loss: 0.6232, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7099/10000, Loss: 0.6231, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7100/10000, Loss: 0.6231, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7101/10000, Loss: 0.6231, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7102/10000, Loss: 0.6231, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7103/10000, Loss: 0.6231, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7104/10000, Loss: 0.6231, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7105/10000, Loss: 0.6231, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7106/10000, Loss: 0.6231, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7107/10000, Loss: 0.6231, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7108/10000, Loss: 0.6231, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7109/10000, Loss: 0.6231, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7110/10000, Loss: 0.6231, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7111/10000, Loss: 0.6231, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7112/10000, Loss: 0.6230, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7113/10000, Loss: 0.6230, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7114/10000, Loss: 0.6230, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7115/10000, Loss: 0.6230, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7116/10000, Loss: 0.6230, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7117/10000, Loss: 0.6230, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7118/10000, Loss: 0.6230, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7119/10000, Loss: 0.6230, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7120/10000, Loss: 0.6230, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7121/10000, Loss: 0.6230, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7122/10000, Loss: 0.6230, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7123/10000, Loss: 0.6230, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7124/10000, Loss: 0.6230, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7125/10000, Loss: 0.6229, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7126/10000, Loss: 0.6229, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7127/10000, Loss: 0.6229, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7128/10000, Loss: 0.6229, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7129/10000, Loss: 0.6229, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7130/10000, Loss: 0.6229, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7131/10000, Loss: 0.6229, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7132/10000, Loss: 0.6229, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7133/10000, Loss: 0.6229, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7134/10000, Loss: 0.6229, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7135/10000, Loss: 0.6229, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7136/10000, Loss: 0.6229, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7137/10000, Loss: 0.6228, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7138/10000, Loss: 0.6228, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7139/10000, Loss: 0.6228, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7140/10000, Loss: 0.6228, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7141/10000, Loss: 0.6228, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7142/10000, Loss: 0.6228, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7143/10000, Loss: 0.6228, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7144/10000, Loss: 0.6228, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7145/10000, Loss: 0.6228, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7146/10000, Loss: 0.6228, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7147/10000, Loss: 0.6228, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7148/10000, Loss: 0.6228, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7149/10000, Loss: 0.6228, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7150/10000, Loss: 0.6227, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7151/10000, Loss: 0.6227, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7152/10000, Loss: 0.6227, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7153/10000, Loss: 0.6227, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7154/10000, Loss: 0.6227, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7155/10000, Loss: 0.6227, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7156/10000, Loss: 0.6227, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7157/10000, Loss: 0.6227, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7158/10000, Loss: 0.6227, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7159/10000, Loss: 0.6227, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7160/10000, Loss: 0.6227, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7161/10000, Loss: 0.6227, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7162/10000, Loss: 0.6227, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7163/10000, Loss: 0.6226, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7164/10000, Loss: 0.6226, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7165/10000, Loss: 0.6226, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7166/10000, Loss: 0.6226, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7167/10000, Loss: 0.6226, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7168/10000, Loss: 0.6226, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7169/10000, Loss: 0.6226, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7170/10000, Loss: 0.6226, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7171/10000, Loss: 0.6226, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7172/10000, Loss: 0.6226, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7173/10000, Loss: 0.6226, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7174/10000, Loss: 0.6226, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7175/10000, Loss: 0.6226, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7176/10000, Loss: 0.6226, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7177/10000, Loss: 0.6225, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7178/10000, Loss: 0.6225, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7179/10000, Loss: 0.6225, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7180/10000, Loss: 0.6225, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7181/10000, Loss: 0.6225, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7182/10000, Loss: 0.6225, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7183/10000, Loss: 0.6225, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7184/10000, Loss: 0.6225, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7185/10000, Loss: 0.6225, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7186/10000, Loss: 0.6225, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7187/10000, Loss: 0.6225, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7188/10000, Loss: 0.6225, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7189/10000, Loss: 0.6225, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7190/10000, Loss: 0.6224, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7191/10000, Loss: 0.6224, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7192/10000, Loss: 0.6224, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7193/10000, Loss: 0.6224, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7194/10000, Loss: 0.6224, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7195/10000, Loss: 0.6224, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7196/10000, Loss: 0.6224, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7197/10000, Loss: 0.6224, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7198/10000, Loss: 0.6224, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7199/10000, Loss: 0.6224, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7200/10000, Loss: 0.6224, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7201/10000, Loss: 0.6224, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7202/10000, Loss: 0.6224, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7203/10000, Loss: 0.6223, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7204/10000, Loss: 0.6223, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7205/10000, Loss: 0.6223, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7206/10000, Loss: 0.6223, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7207/10000, Loss: 0.6223, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7208/10000, Loss: 0.6223, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7209/10000, Loss: 0.6223, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7210/10000, Loss: 0.6223, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7211/10000, Loss: 0.6223, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7212/10000, Loss: 0.6223, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7213/10000, Loss: 0.6223, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7214/10000, Loss: 0.6223, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7215/10000, Loss: 0.6223, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7216/10000, Loss: 0.6222, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7217/10000, Loss: 0.6222, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7218/10000, Loss: 0.6222, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7219/10000, Loss: 0.6222, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7220/10000, Loss: 0.6222, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7221/10000, Loss: 0.6222, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7222/10000, Loss: 0.6222, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7223/10000, Loss: 0.6222, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7224/10000, Loss: 0.6222, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7225/10000, Loss: 0.6222, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7226/10000, Loss: 0.6222, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7227/10000, Loss: 0.6222, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7228/10000, Loss: 0.6222, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7229/10000, Loss: 0.6221, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7230/10000, Loss: 0.6221, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7231/10000, Loss: 0.6221, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7232/10000, Loss: 0.6221, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7233/10000, Loss: 0.6221, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7234/10000, Loss: 0.6221, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7235/10000, Loss: 0.6221, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7236/10000, Loss: 0.6221, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7237/10000, Loss: 0.6221, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7238/10000, Loss: 0.6221, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7239/10000, Loss: 0.6221, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7240/10000, Loss: 0.6221, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7241/10000, Loss: 0.6221, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7242/10000, Loss: 0.6221, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7243/10000, Loss: 0.6220, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7244/10000, Loss: 0.6220, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7245/10000, Loss: 0.6220, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7246/10000, Loss: 0.6220, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7247/10000, Loss: 0.6220, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7248/10000, Loss: 0.6220, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7249/10000, Loss: 0.6220, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7250/10000, Loss: 0.6220, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7251/10000, Loss: 0.6220, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7252/10000, Loss: 0.6220, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7253/10000, Loss: 0.6220, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7254/10000, Loss: 0.6220, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7255/10000, Loss: 0.6220, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7256/10000, Loss: 0.6219, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7257/10000, Loss: 0.6219, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7258/10000, Loss: 0.6219, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7259/10000, Loss: 0.6219, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7260/10000, Loss: 0.6219, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7261/10000, Loss: 0.6219, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7262/10000, Loss: 0.6219, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7263/10000, Loss: 0.6219, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7264/10000, Loss: 0.6219, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7265/10000, Loss: 0.6219, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7266/10000, Loss: 0.6219, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7267/10000, Loss: 0.6219, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7268/10000, Loss: 0.6219, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7269/10000, Loss: 0.6218, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7270/10000, Loss: 0.6218, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7271/10000, Loss: 0.6218, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7272/10000, Loss: 0.6218, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7273/10000, Loss: 0.6218, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7274/10000, Loss: 0.6218, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7275/10000, Loss: 0.6218, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7276/10000, Loss: 0.6218, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7277/10000, Loss: 0.6218, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7278/10000, Loss: 0.6218, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7279/10000, Loss: 0.6218, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7280/10000, Loss: 0.6218, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7281/10000, Loss: 0.6218, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7282/10000, Loss: 0.6218, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7283/10000, Loss: 0.6217, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7284/10000, Loss: 0.6217, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7285/10000, Loss: 0.6217, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7286/10000, Loss: 0.6217, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7287/10000, Loss: 0.6217, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7288/10000, Loss: 0.6217, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7289/10000, Loss: 0.6217, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7290/10000, Loss: 0.6217, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7291/10000, Loss: 0.6217, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7292/10000, Loss: 0.6217, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7293/10000, Loss: 0.6217, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7294/10000, Loss: 0.6217, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7295/10000, Loss: 0.6217, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7296/10000, Loss: 0.6216, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7297/10000, Loss: 0.6216, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7298/10000, Loss: 0.6216, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7299/10000, Loss: 0.6216, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7300/10000, Loss: 0.6216, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7301/10000, Loss: 0.6216, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7302/10000, Loss: 0.6216, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7303/10000, Loss: 0.6216, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7304/10000, Loss: 0.6216, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7305/10000, Loss: 0.6216, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7306/10000, Loss: 0.6216, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7307/10000, Loss: 0.6216, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7308/10000, Loss: 0.6216, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7309/10000, Loss: 0.6216, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7310/10000, Loss: 0.6215, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7311/10000, Loss: 0.6215, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7312/10000, Loss: 0.6215, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7313/10000, Loss: 0.6215, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7314/10000, Loss: 0.6215, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7315/10000, Loss: 0.6215, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7316/10000, Loss: 0.6215, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7317/10000, Loss: 0.6215, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7318/10000, Loss: 0.6215, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7319/10000, Loss: 0.6215, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7320/10000, Loss: 0.6215, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7321/10000, Loss: 0.6215, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7322/10000, Loss: 0.6215, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7323/10000, Loss: 0.6215, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7324/10000, Loss: 0.6214, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7325/10000, Loss: 0.6214, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7326/10000, Loss: 0.6214, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7327/10000, Loss: 0.6214, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7328/10000, Loss: 0.6214, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7329/10000, Loss: 0.6214, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7330/10000, Loss: 0.6214, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7331/10000, Loss: 0.6214, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7332/10000, Loss: 0.6214, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7333/10000, Loss: 0.6214, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7334/10000, Loss: 0.6214, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7335/10000, Loss: 0.6214, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7336/10000, Loss: 0.6214, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7337/10000, Loss: 0.6213, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7338/10000, Loss: 0.6213, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7339/10000, Loss: 0.6213, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7340/10000, Loss: 0.6213, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7341/10000, Loss: 0.6213, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7342/10000, Loss: 0.6213, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7343/10000, Loss: 0.6213, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7344/10000, Loss: 0.6213, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7345/10000, Loss: 0.6213, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7346/10000, Loss: 0.6213, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7347/10000, Loss: 0.6213, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7348/10000, Loss: 0.6213, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7349/10000, Loss: 0.6213, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7350/10000, Loss: 0.6213, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7351/10000, Loss: 0.6212, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7352/10000, Loss: 0.6212, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7353/10000, Loss: 0.6212, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7354/10000, Loss: 0.6212, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7355/10000, Loss: 0.6212, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7356/10000, Loss: 0.6212, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7357/10000, Loss: 0.6212, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7358/10000, Loss: 0.6212, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7359/10000, Loss: 0.6212, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7360/10000, Loss: 0.6212, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7361/10000, Loss: 0.6212, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7362/10000, Loss: 0.6212, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7363/10000, Loss: 0.6212, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7364/10000, Loss: 0.6212, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7365/10000, Loss: 0.6211, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7366/10000, Loss: 0.6211, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7367/10000, Loss: 0.6211, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7368/10000, Loss: 0.6211, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7369/10000, Loss: 0.6211, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7370/10000, Loss: 0.6211, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7371/10000, Loss: 0.6211, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7372/10000, Loss: 0.6211, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7373/10000, Loss: 0.6211, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7374/10000, Loss: 0.6211, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7375/10000, Loss: 0.6211, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7376/10000, Loss: 0.6211, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7377/10000, Loss: 0.6211, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7378/10000, Loss: 0.6211, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7379/10000, Loss: 0.6210, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7380/10000, Loss: 0.6210, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7381/10000, Loss: 0.6210, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7382/10000, Loss: 0.6210, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7383/10000, Loss: 0.6210, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7384/10000, Loss: 0.6210, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7385/10000, Loss: 0.6210, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7386/10000, Loss: 0.6210, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7387/10000, Loss: 0.6210, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7388/10000, Loss: 0.6210, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7389/10000, Loss: 0.6210, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7390/10000, Loss: 0.6210, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7391/10000, Loss: 0.6210, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7392/10000, Loss: 0.6210, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7393/10000, Loss: 0.6209, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7394/10000, Loss: 0.6209, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7395/10000, Loss: 0.6209, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7396/10000, Loss: 0.6209, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7397/10000, Loss: 0.6209, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7398/10000, Loss: 0.6209, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7399/10000, Loss: 0.6209, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7400/10000, Loss: 0.6209, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7401/10000, Loss: 0.6209, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7402/10000, Loss: 0.6209, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7403/10000, Loss: 0.6209, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7404/10000, Loss: 0.6209, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7405/10000, Loss: 0.6209, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7406/10000, Loss: 0.6209, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7407/10000, Loss: 0.6208, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7408/10000, Loss: 0.6208, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7409/10000, Loss: 0.6208, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7410/10000, Loss: 0.6208, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7411/10000, Loss: 0.6208, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7412/10000, Loss: 0.6208, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7413/10000, Loss: 0.6208, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7414/10000, Loss: 0.6208, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7415/10000, Loss: 0.6208, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7416/10000, Loss: 0.6208, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7417/10000, Loss: 0.6208, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7418/10000, Loss: 0.6208, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7419/10000, Loss: 0.6208, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7420/10000, Loss: 0.6208, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7421/10000, Loss: 0.6207, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7422/10000, Loss: 0.6207, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7423/10000, Loss: 0.6207, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7424/10000, Loss: 0.6207, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7425/10000, Loss: 0.6207, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7426/10000, Loss: 0.6207, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7427/10000, Loss: 0.6207, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7428/10000, Loss: 0.6207, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7429/10000, Loss: 0.6207, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7430/10000, Loss: 0.6207, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7431/10000, Loss: 0.6207, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7432/10000, Loss: 0.6207, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7433/10000, Loss: 0.6207, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7434/10000, Loss: 0.6207, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7435/10000, Loss: 0.6206, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7436/10000, Loss: 0.6206, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7437/10000, Loss: 0.6206, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7438/10000, Loss: 0.6206, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7439/10000, Loss: 0.6206, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7440/10000, Loss: 0.6206, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7441/10000, Loss: 0.6206, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7442/10000, Loss: 0.6206, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7443/10000, Loss: 0.6206, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7444/10000, Loss: 0.6206, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7445/10000, Loss: 0.6206, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7446/10000, Loss: 0.6206, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7447/10000, Loss: 0.6206, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7448/10000, Loss: 0.6206, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7449/10000, Loss: 0.6205, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7450/10000, Loss: 0.6205, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7451/10000, Loss: 0.6205, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7452/10000, Loss: 0.6205, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7453/10000, Loss: 0.6205, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7454/10000, Loss: 0.6205, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7455/10000, Loss: 0.6205, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7456/10000, Loss: 0.6205, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7457/10000, Loss: 0.6205, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7458/10000, Loss: 0.6205, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7459/10000, Loss: 0.6205, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7460/10000, Loss: 0.6205, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7461/10000, Loss: 0.6205, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7462/10000, Loss: 0.6205, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7463/10000, Loss: 0.6204, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7464/10000, Loss: 0.6204, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7465/10000, Loss: 0.6204, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7466/10000, Loss: 0.6204, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7467/10000, Loss: 0.6204, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7468/10000, Loss: 0.6204, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7469/10000, Loss: 0.6204, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7470/10000, Loss: 0.6204, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7471/10000, Loss: 0.6204, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7472/10000, Loss: 0.6204, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7473/10000, Loss: 0.6204, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7474/10000, Loss: 0.6204, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7475/10000, Loss: 0.6204, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7476/10000, Loss: 0.6204, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7477/10000, Loss: 0.6203, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7478/10000, Loss: 0.6203, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7479/10000, Loss: 0.6203, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7480/10000, Loss: 0.6203, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7481/10000, Loss: 0.6203, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7482/10000, Loss: 0.6203, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7483/10000, Loss: 0.6203, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7484/10000, Loss: 0.6203, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7485/10000, Loss: 0.6203, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7486/10000, Loss: 0.6203, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7487/10000, Loss: 0.6203, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7488/10000, Loss: 0.6203, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7489/10000, Loss: 0.6203, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7490/10000, Loss: 0.6203, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7491/10000, Loss: 0.6203, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7492/10000, Loss: 0.6202, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7493/10000, Loss: 0.6202, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7494/10000, Loss: 0.6202, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7495/10000, Loss: 0.6202, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7496/10000, Loss: 0.6202, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7497/10000, Loss: 0.6202, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7498/10000, Loss: 0.6202, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7499/10000, Loss: 0.6202, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7500/10000, Loss: 0.6202, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7501/10000, Loss: 0.6202, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7502/10000, Loss: 0.6202, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7503/10000, Loss: 0.6202, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7504/10000, Loss: 0.6202, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7505/10000, Loss: 0.6202, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7506/10000, Loss: 0.6201, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7507/10000, Loss: 0.6201, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7508/10000, Loss: 0.6201, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7509/10000, Loss: 0.6201, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7510/10000, Loss: 0.6201, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7511/10000, Loss: 0.6201, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7512/10000, Loss: 0.6201, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7513/10000, Loss: 0.6201, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7514/10000, Loss: 0.6201, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7515/10000, Loss: 0.6201, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7516/10000, Loss: 0.6201, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7517/10000, Loss: 0.6201, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7518/10000, Loss: 0.6201, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7519/10000, Loss: 0.6201, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7520/10000, Loss: 0.6201, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7521/10000, Loss: 0.6200, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7522/10000, Loss: 0.6200, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7523/10000, Loss: 0.6200, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7524/10000, Loss: 0.6200, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7525/10000, Loss: 0.6200, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7526/10000, Loss: 0.6200, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7527/10000, Loss: 0.6200, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7528/10000, Loss: 0.6200, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7529/10000, Loss: 0.6200, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7530/10000, Loss: 0.6200, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7531/10000, Loss: 0.6200, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7532/10000, Loss: 0.6200, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7533/10000, Loss: 0.6200, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7534/10000, Loss: 0.6200, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7535/10000, Loss: 0.6199, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7536/10000, Loss: 0.6199, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7537/10000, Loss: 0.6199, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7538/10000, Loss: 0.6199, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7539/10000, Loss: 0.6199, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7540/10000, Loss: 0.6199, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7541/10000, Loss: 0.6199, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7542/10000, Loss: 0.6199, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7543/10000, Loss: 0.6199, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7544/10000, Loss: 0.6199, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7545/10000, Loss: 0.6199, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7546/10000, Loss: 0.6199, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7547/10000, Loss: 0.6199, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7548/10000, Loss: 0.6199, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7549/10000, Loss: 0.6199, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7550/10000, Loss: 0.6198, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7551/10000, Loss: 0.6198, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7552/10000, Loss: 0.6198, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7553/10000, Loss: 0.6198, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7554/10000, Loss: 0.6198, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7555/10000, Loss: 0.6198, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7556/10000, Loss: 0.6198, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7557/10000, Loss: 0.6198, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7558/10000, Loss: 0.6198, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7559/10000, Loss: 0.6198, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7560/10000, Loss: 0.6198, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7561/10000, Loss: 0.6198, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7562/10000, Loss: 0.6198, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7563/10000, Loss: 0.6198, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7564/10000, Loss: 0.6197, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7565/10000, Loss: 0.6197, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7566/10000, Loss: 0.6197, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7567/10000, Loss: 0.6197, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7568/10000, Loss: 0.6197, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7569/10000, Loss: 0.6197, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7570/10000, Loss: 0.6197, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7571/10000, Loss: 0.6197, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7572/10000, Loss: 0.6197, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7573/10000, Loss: 0.6197, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7574/10000, Loss: 0.6197, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7575/10000, Loss: 0.6197, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7576/10000, Loss: 0.6197, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7577/10000, Loss: 0.6197, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7578/10000, Loss: 0.6197, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7579/10000, Loss: 0.6196, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7580/10000, Loss: 0.6196, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7581/10000, Loss: 0.6196, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7582/10000, Loss: 0.6196, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7583/10000, Loss: 0.6196, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7584/10000, Loss: 0.6196, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7585/10000, Loss: 0.6196, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7586/10000, Loss: 0.6196, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7587/10000, Loss: 0.6196, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7588/10000, Loss: 0.6196, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7589/10000, Loss: 0.6196, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7590/10000, Loss: 0.6196, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7591/10000, Loss: 0.6196, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7592/10000, Loss: 0.6196, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7593/10000, Loss: 0.6196, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7594/10000, Loss: 0.6195, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7595/10000, Loss: 0.6195, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7596/10000, Loss: 0.6195, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7597/10000, Loss: 0.6195, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7598/10000, Loss: 0.6195, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7599/10000, Loss: 0.6195, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7600/10000, Loss: 0.6195, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7601/10000, Loss: 0.6195, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7602/10000, Loss: 0.6195, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7603/10000, Loss: 0.6195, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7604/10000, Loss: 0.6195, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7605/10000, Loss: 0.6195, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7606/10000, Loss: 0.6195, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7607/10000, Loss: 0.6195, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7608/10000, Loss: 0.6195, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7609/10000, Loss: 0.6194, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7610/10000, Loss: 0.6194, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7611/10000, Loss: 0.6194, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7612/10000, Loss: 0.6194, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7613/10000, Loss: 0.6194, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7614/10000, Loss: 0.6194, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7615/10000, Loss: 0.6194, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7616/10000, Loss: 0.6194, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7617/10000, Loss: 0.6194, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7618/10000, Loss: 0.6194, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7619/10000, Loss: 0.6194, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7620/10000, Loss: 0.6194, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7621/10000, Loss: 0.6194, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7622/10000, Loss: 0.6194, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7623/10000, Loss: 0.6194, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7624/10000, Loss: 0.6193, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7625/10000, Loss: 0.6193, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7626/10000, Loss: 0.6193, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7627/10000, Loss: 0.6193, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7628/10000, Loss: 0.6193, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7629/10000, Loss: 0.6193, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7630/10000, Loss: 0.6193, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7631/10000, Loss: 0.6193, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7632/10000, Loss: 0.6193, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7633/10000, Loss: 0.6193, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7634/10000, Loss: 0.6193, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7635/10000, Loss: 0.6193, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7636/10000, Loss: 0.6193, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7637/10000, Loss: 0.6193, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7638/10000, Loss: 0.6193, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7639/10000, Loss: 0.6192, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7640/10000, Loss: 0.6192, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7641/10000, Loss: 0.6192, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7642/10000, Loss: 0.6192, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7643/10000, Loss: 0.6192, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7644/10000, Loss: 0.6192, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7645/10000, Loss: 0.6192, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7646/10000, Loss: 0.6192, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7647/10000, Loss: 0.6192, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7648/10000, Loss: 0.6192, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7649/10000, Loss: 0.6192, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7650/10000, Loss: 0.6192, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7651/10000, Loss: 0.6192, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7652/10000, Loss: 0.6192, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7653/10000, Loss: 0.6192, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7654/10000, Loss: 0.6191, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7655/10000, Loss: 0.6191, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7656/10000, Loss: 0.6191, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7657/10000, Loss: 0.6191, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7658/10000, Loss: 0.6191, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7659/10000, Loss: 0.6191, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7660/10000, Loss: 0.6191, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7661/10000, Loss: 0.6191, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7662/10000, Loss: 0.6191, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7663/10000, Loss: 0.6191, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7664/10000, Loss: 0.6191, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7665/10000, Loss: 0.6191, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7666/10000, Loss: 0.6191, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7667/10000, Loss: 0.6191, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7668/10000, Loss: 0.6191, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7669/10000, Loss: 0.6190, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7670/10000, Loss: 0.6190, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7671/10000, Loss: 0.6190, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7672/10000, Loss: 0.6190, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7673/10000, Loss: 0.6190, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7674/10000, Loss: 0.6190, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7675/10000, Loss: 0.6190, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7676/10000, Loss: 0.6190, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7677/10000, Loss: 0.6190, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7678/10000, Loss: 0.6190, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7679/10000, Loss: 0.6190, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7680/10000, Loss: 0.6190, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7681/10000, Loss: 0.6190, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7682/10000, Loss: 0.6190, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7683/10000, Loss: 0.6190, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7684/10000, Loss: 0.6189, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7685/10000, Loss: 0.6189, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7686/10000, Loss: 0.6189, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7687/10000, Loss: 0.6189, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7688/10000, Loss: 0.6189, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7689/10000, Loss: 0.6189, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7690/10000, Loss: 0.6189, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7691/10000, Loss: 0.6189, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7692/10000, Loss: 0.6189, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7693/10000, Loss: 0.6189, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7694/10000, Loss: 0.6189, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7695/10000, Loss: 0.6189, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7696/10000, Loss: 0.6189, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7697/10000, Loss: 0.6189, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7698/10000, Loss: 0.6189, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7699/10000, Loss: 0.6188, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7700/10000, Loss: 0.6188, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7701/10000, Loss: 0.6188, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7702/10000, Loss: 0.6188, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7703/10000, Loss: 0.6188, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7704/10000, Loss: 0.6188, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7705/10000, Loss: 0.6188, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7706/10000, Loss: 0.6188, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7707/10000, Loss: 0.6188, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7708/10000, Loss: 0.6188, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7709/10000, Loss: 0.6188, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7710/10000, Loss: 0.6188, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7711/10000, Loss: 0.6188, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7712/10000, Loss: 0.6188, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7713/10000, Loss: 0.6188, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7714/10000, Loss: 0.6188, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7715/10000, Loss: 0.6187, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7716/10000, Loss: 0.6187, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7717/10000, Loss: 0.6187, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7718/10000, Loss: 0.6187, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7719/10000, Loss: 0.6187, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7720/10000, Loss: 0.6187, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7721/10000, Loss: 0.6187, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7722/10000, Loss: 0.6187, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7723/10000, Loss: 0.6187, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7724/10000, Loss: 0.6187, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7725/10000, Loss: 0.6187, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7726/10000, Loss: 0.6187, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7727/10000, Loss: 0.6187, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7728/10000, Loss: 0.6187, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7729/10000, Loss: 0.6187, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7730/10000, Loss: 0.6186, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7731/10000, Loss: 0.6186, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7732/10000, Loss: 0.6186, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7733/10000, Loss: 0.6186, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7734/10000, Loss: 0.6186, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7735/10000, Loss: 0.6186, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7736/10000, Loss: 0.6186, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7737/10000, Loss: 0.6186, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7738/10000, Loss: 0.6186, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7739/10000, Loss: 0.6186, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7740/10000, Loss: 0.6186, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7741/10000, Loss: 0.6186, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7742/10000, Loss: 0.6186, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7743/10000, Loss: 0.6186, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7744/10000, Loss: 0.6186, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7745/10000, Loss: 0.6186, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7746/10000, Loss: 0.6185, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7747/10000, Loss: 0.6185, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7748/10000, Loss: 0.6185, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7749/10000, Loss: 0.6185, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7750/10000, Loss: 0.6185, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7751/10000, Loss: 0.6185, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7752/10000, Loss: 0.6185, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7753/10000, Loss: 0.6185, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7754/10000, Loss: 0.6185, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7755/10000, Loss: 0.6185, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7756/10000, Loss: 0.6185, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7757/10000, Loss: 0.6185, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7758/10000, Loss: 0.6185, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7759/10000, Loss: 0.6185, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7760/10000, Loss: 0.6185, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7761/10000, Loss: 0.6184, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7762/10000, Loss: 0.6184, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7763/10000, Loss: 0.6184, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7764/10000, Loss: 0.6184, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7765/10000, Loss: 0.6184, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7766/10000, Loss: 0.6184, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7767/10000, Loss: 0.6184, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7768/10000, Loss: 0.6184, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7769/10000, Loss: 0.6184, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7770/10000, Loss: 0.6184, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7771/10000, Loss: 0.6184, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7772/10000, Loss: 0.6184, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7773/10000, Loss: 0.6184, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7774/10000, Loss: 0.6184, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7775/10000, Loss: 0.6184, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7776/10000, Loss: 0.6184, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7777/10000, Loss: 0.6183, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7778/10000, Loss: 0.6183, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7779/10000, Loss: 0.6183, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7780/10000, Loss: 0.6183, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7781/10000, Loss: 0.6183, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7782/10000, Loss: 0.6183, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7783/10000, Loss: 0.6183, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7784/10000, Loss: 0.6183, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7785/10000, Loss: 0.6183, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7786/10000, Loss: 0.6183, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7787/10000, Loss: 0.6183, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7788/10000, Loss: 0.6183, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7789/10000, Loss: 0.6183, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7790/10000, Loss: 0.6183, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7791/10000, Loss: 0.6183, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7792/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7793/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7794/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7795/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7796/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7797/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7798/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7799/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7800/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7801/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7802/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7803/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7804/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7805/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7806/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7807/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7808/10000, Loss: 0.6181, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7809/10000, Loss: 0.6181, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7810/10000, Loss: 0.6181, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7811/10000, Loss: 0.6181, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7812/10000, Loss: 0.6181, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7813/10000, Loss: 0.6181, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7814/10000, Loss: 0.6181, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7815/10000, Loss: 0.6181, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7816/10000, Loss: 0.6181, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7817/10000, Loss: 0.6181, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7818/10000, Loss: 0.6181, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7819/10000, Loss: 0.6181, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7820/10000, Loss: 0.6181, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7821/10000, Loss: 0.6181, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7822/10000, Loss: 0.6181, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7823/10000, Loss: 0.6181, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7824/10000, Loss: 0.6180, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7825/10000, Loss: 0.6180, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7826/10000, Loss: 0.6180, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7827/10000, Loss: 0.6180, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7828/10000, Loss: 0.6180, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7829/10000, Loss: 0.6180, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7830/10000, Loss: 0.6180, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7831/10000, Loss: 0.6180, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7832/10000, Loss: 0.6180, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7833/10000, Loss: 0.6180, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7834/10000, Loss: 0.6180, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7835/10000, Loss: 0.6180, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7836/10000, Loss: 0.6180, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7837/10000, Loss: 0.6180, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7838/10000, Loss: 0.6180, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7839/10000, Loss: 0.6180, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7840/10000, Loss: 0.6179, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7841/10000, Loss: 0.6179, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7842/10000, Loss: 0.6179, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7843/10000, Loss: 0.6179, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7844/10000, Loss: 0.6179, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7845/10000, Loss: 0.6179, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7846/10000, Loss: 0.6179, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7847/10000, Loss: 0.6179, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7848/10000, Loss: 0.6179, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7849/10000, Loss: 0.6179, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7850/10000, Loss: 0.6179, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7851/10000, Loss: 0.6179, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7852/10000, Loss: 0.6179, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7853/10000, Loss: 0.6179, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7854/10000, Loss: 0.6179, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7855/10000, Loss: 0.6179, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7856/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7857/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7858/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7859/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7860/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7861/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7862/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7863/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7864/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7865/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7866/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7867/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7868/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7869/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7870/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7871/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7872/10000, Loss: 0.6177, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7873/10000, Loss: 0.6177, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7874/10000, Loss: 0.6177, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7875/10000, Loss: 0.6177, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7876/10000, Loss: 0.6177, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7877/10000, Loss: 0.6177, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7878/10000, Loss: 0.6177, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7879/10000, Loss: 0.6177, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7880/10000, Loss: 0.6177, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7881/10000, Loss: 0.6177, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7882/10000, Loss: 0.6177, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7883/10000, Loss: 0.6177, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7884/10000, Loss: 0.6177, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7885/10000, Loss: 0.6177, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7886/10000, Loss: 0.6177, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7887/10000, Loss: 0.6177, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7888/10000, Loss: 0.6176, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7889/10000, Loss: 0.6176, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7890/10000, Loss: 0.6176, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7891/10000, Loss: 0.6176, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7892/10000, Loss: 0.6176, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7893/10000, Loss: 0.6176, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7894/10000, Loss: 0.6176, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7895/10000, Loss: 0.6176, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7896/10000, Loss: 0.6176, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7897/10000, Loss: 0.6176, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7898/10000, Loss: 0.6176, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7899/10000, Loss: 0.6176, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7900/10000, Loss: 0.6176, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7901/10000, Loss: 0.6176, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7902/10000, Loss: 0.6176, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7903/10000, Loss: 0.6176, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7904/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7905/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7906/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7907/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7908/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7909/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7910/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7911/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7912/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7913/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7914/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7915/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7916/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7917/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7918/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7919/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7920/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7921/10000, Loss: 0.6174, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7922/10000, Loss: 0.6174, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7923/10000, Loss: 0.6174, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7924/10000, Loss: 0.6174, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7925/10000, Loss: 0.6174, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7926/10000, Loss: 0.6174, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7927/10000, Loss: 0.6174, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7928/10000, Loss: 0.6174, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7929/10000, Loss: 0.6174, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7930/10000, Loss: 0.6174, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7931/10000, Loss: 0.6174, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7932/10000, Loss: 0.6174, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7933/10000, Loss: 0.6174, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7934/10000, Loss: 0.6174, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7935/10000, Loss: 0.6174, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7936/10000, Loss: 0.6174, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7937/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7938/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7939/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7940/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7941/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7942/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7943/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7944/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7945/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7946/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7947/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7948/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7949/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7950/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7951/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7952/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7953/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7954/10000, Loss: 0.6172, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7955/10000, Loss: 0.6172, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7956/10000, Loss: 0.6172, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7957/10000, Loss: 0.6172, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7958/10000, Loss: 0.6172, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7959/10000, Loss: 0.6172, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7960/10000, Loss: 0.6172, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7961/10000, Loss: 0.6172, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7962/10000, Loss: 0.6172, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7963/10000, Loss: 0.6172, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7964/10000, Loss: 0.6172, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7965/10000, Loss: 0.6172, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7966/10000, Loss: 0.6172, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7967/10000, Loss: 0.6172, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7968/10000, Loss: 0.6172, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7969/10000, Loss: 0.6172, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7970/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7971/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7972/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7973/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7974/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7975/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7976/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7977/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7978/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7979/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7980/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7981/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7982/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7983/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7984/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7985/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7986/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7987/10000, Loss: 0.6170, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7988/10000, Loss: 0.6170, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7989/10000, Loss: 0.6170, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7990/10000, Loss: 0.6170, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7991/10000, Loss: 0.6170, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7992/10000, Loss: 0.6170, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7993/10000, Loss: 0.6170, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7994/10000, Loss: 0.6170, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7995/10000, Loss: 0.6170, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7996/10000, Loss: 0.6170, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7997/10000, Loss: 0.6170, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7998/10000, Loss: 0.6170, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 7999/10000, Loss: 0.6170, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 8000/10000, Loss: 0.6170, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 8001/10000, Loss: 0.6170, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 8002/10000, Loss: 0.6170, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 8003/10000, Loss: 0.6169, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 8004/10000, Loss: 0.6169, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 8005/10000, Loss: 0.6169, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 8006/10000, Loss: 0.6169, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 8007/10000, Loss: 0.6169, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 8008/10000, Loss: 0.6169, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 8009/10000, Loss: 0.6169, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 8010/10000, Loss: 0.6169, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 8011/10000, Loss: 0.6169, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 8012/10000, Loss: 0.6169, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8013/10000, Loss: 0.6169, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8014/10000, Loss: 0.6169, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8015/10000, Loss: 0.6169, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8016/10000, Loss: 0.6169, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8017/10000, Loss: 0.6169, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8018/10000, Loss: 0.6169, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8019/10000, Loss: 0.6169, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8020/10000, Loss: 0.6168, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8021/10000, Loss: 0.6168, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8022/10000, Loss: 0.6168, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8023/10000, Loss: 0.6168, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8024/10000, Loss: 0.6168, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8025/10000, Loss: 0.6168, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8026/10000, Loss: 0.6168, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8027/10000, Loss: 0.6168, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8028/10000, Loss: 0.6168, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8029/10000, Loss: 0.6168, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8030/10000, Loss: 0.6168, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8031/10000, Loss: 0.6168, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8032/10000, Loss: 0.6168, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8033/10000, Loss: 0.6168, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8034/10000, Loss: 0.6168, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8035/10000, Loss: 0.6168, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8036/10000, Loss: 0.6168, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8037/10000, Loss: 0.6167, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8038/10000, Loss: 0.6167, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8039/10000, Loss: 0.6167, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8040/10000, Loss: 0.6167, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8041/10000, Loss: 0.6167, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8042/10000, Loss: 0.6167, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8043/10000, Loss: 0.6167, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8044/10000, Loss: 0.6167, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8045/10000, Loss: 0.6167, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8046/10000, Loss: 0.6167, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8047/10000, Loss: 0.6167, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8048/10000, Loss: 0.6167, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8049/10000, Loss: 0.6167, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8050/10000, Loss: 0.6167, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8051/10000, Loss: 0.6167, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8052/10000, Loss: 0.6167, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8053/10000, Loss: 0.6167, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8054/10000, Loss: 0.6166, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8055/10000, Loss: 0.6166, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8056/10000, Loss: 0.6166, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8057/10000, Loss: 0.6166, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8058/10000, Loss: 0.6166, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8059/10000, Loss: 0.6166, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8060/10000, Loss: 0.6166, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8061/10000, Loss: 0.6166, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8062/10000, Loss: 0.6166, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8063/10000, Loss: 0.6166, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8064/10000, Loss: 0.6166, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8065/10000, Loss: 0.6166, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8066/10000, Loss: 0.6166, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8067/10000, Loss: 0.6166, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8068/10000, Loss: 0.6166, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8069/10000, Loss: 0.6166, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8070/10000, Loss: 0.6166, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8071/10000, Loss: 0.6165, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8072/10000, Loss: 0.6165, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8073/10000, Loss: 0.6165, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8074/10000, Loss: 0.6165, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8075/10000, Loss: 0.6165, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8076/10000, Loss: 0.6165, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8077/10000, Loss: 0.6165, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8078/10000, Loss: 0.6165, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8079/10000, Loss: 0.6165, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8080/10000, Loss: 0.6165, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8081/10000, Loss: 0.6165, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8082/10000, Loss: 0.6165, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8083/10000, Loss: 0.6165, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8084/10000, Loss: 0.6165, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8085/10000, Loss: 0.6165, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8086/10000, Loss: 0.6165, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8087/10000, Loss: 0.6165, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8088/10000, Loss: 0.6164, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8089/10000, Loss: 0.6164, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8090/10000, Loss: 0.6164, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8091/10000, Loss: 0.6164, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8092/10000, Loss: 0.6164, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8093/10000, Loss: 0.6164, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8094/10000, Loss: 0.6164, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8095/10000, Loss: 0.6164, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8096/10000, Loss: 0.6164, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8097/10000, Loss: 0.6164, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8098/10000, Loss: 0.6164, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8099/10000, Loss: 0.6164, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8100/10000, Loss: 0.6164, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8101/10000, Loss: 0.6164, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8102/10000, Loss: 0.6164, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8103/10000, Loss: 0.6164, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8104/10000, Loss: 0.6164, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8105/10000, Loss: 0.6164, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8106/10000, Loss: 0.6163, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8107/10000, Loss: 0.6163, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8108/10000, Loss: 0.6163, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8109/10000, Loss: 0.6163, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8110/10000, Loss: 0.6163, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8111/10000, Loss: 0.6163, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8112/10000, Loss: 0.6163, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8113/10000, Loss: 0.6163, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8114/10000, Loss: 0.6163, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8115/10000, Loss: 0.6163, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8116/10000, Loss: 0.6163, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8117/10000, Loss: 0.6163, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8118/10000, Loss: 0.6163, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8119/10000, Loss: 0.6163, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8120/10000, Loss: 0.6163, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8121/10000, Loss: 0.6163, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8122/10000, Loss: 0.6163, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8123/10000, Loss: 0.6162, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8124/10000, Loss: 0.6162, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8125/10000, Loss: 0.6162, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8126/10000, Loss: 0.6162, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8127/10000, Loss: 0.6162, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8128/10000, Loss: 0.6162, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8129/10000, Loss: 0.6162, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8130/10000, Loss: 0.6162, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8131/10000, Loss: 0.6162, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8132/10000, Loss: 0.6162, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8133/10000, Loss: 0.6162, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8134/10000, Loss: 0.6162, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8135/10000, Loss: 0.6162, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8136/10000, Loss: 0.6162, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8137/10000, Loss: 0.6162, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8138/10000, Loss: 0.6162, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8139/10000, Loss: 0.6162, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8140/10000, Loss: 0.6161, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8141/10000, Loss: 0.6161, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8142/10000, Loss: 0.6161, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8143/10000, Loss: 0.6161, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8144/10000, Loss: 0.6161, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8145/10000, Loss: 0.6161, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8146/10000, Loss: 0.6161, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8147/10000, Loss: 0.6161, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8148/10000, Loss: 0.6161, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8149/10000, Loss: 0.6161, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8150/10000, Loss: 0.6161, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8151/10000, Loss: 0.6161, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8152/10000, Loss: 0.6161, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8153/10000, Loss: 0.6161, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8154/10000, Loss: 0.6161, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8155/10000, Loss: 0.6161, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8156/10000, Loss: 0.6161, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8157/10000, Loss: 0.6161, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8158/10000, Loss: 0.6160, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8159/10000, Loss: 0.6160, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8160/10000, Loss: 0.6160, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8161/10000, Loss: 0.6160, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8162/10000, Loss: 0.6160, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8163/10000, Loss: 0.6160, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8164/10000, Loss: 0.6160, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8165/10000, Loss: 0.6160, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8166/10000, Loss: 0.6160, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8167/10000, Loss: 0.6160, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8168/10000, Loss: 0.6160, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8169/10000, Loss: 0.6160, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8170/10000, Loss: 0.6160, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8171/10000, Loss: 0.6160, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8172/10000, Loss: 0.6160, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8173/10000, Loss: 0.6160, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8174/10000, Loss: 0.6160, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8175/10000, Loss: 0.6160, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8176/10000, Loss: 0.6159, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8177/10000, Loss: 0.6159, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8178/10000, Loss: 0.6159, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8179/10000, Loss: 0.6159, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8180/10000, Loss: 0.6159, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8181/10000, Loss: 0.6159, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8182/10000, Loss: 0.6159, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8183/10000, Loss: 0.6159, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8184/10000, Loss: 0.6159, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8185/10000, Loss: 0.6159, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8186/10000, Loss: 0.6159, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8187/10000, Loss: 0.6159, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8188/10000, Loss: 0.6159, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8189/10000, Loss: 0.6159, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8190/10000, Loss: 0.6159, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8191/10000, Loss: 0.6159, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8192/10000, Loss: 0.6159, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8193/10000, Loss: 0.6158, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8194/10000, Loss: 0.6158, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8195/10000, Loss: 0.6158, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8196/10000, Loss: 0.6158, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8197/10000, Loss: 0.6158, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8198/10000, Loss: 0.6158, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8199/10000, Loss: 0.6158, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8200/10000, Loss: 0.6158, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8201/10000, Loss: 0.6158, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8202/10000, Loss: 0.6158, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8203/10000, Loss: 0.6158, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8204/10000, Loss: 0.6158, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8205/10000, Loss: 0.6158, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8206/10000, Loss: 0.6158, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8207/10000, Loss: 0.6158, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8208/10000, Loss: 0.6158, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8209/10000, Loss: 0.6158, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8210/10000, Loss: 0.6158, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8211/10000, Loss: 0.6157, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8212/10000, Loss: 0.6157, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8213/10000, Loss: 0.6157, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8214/10000, Loss: 0.6157, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8215/10000, Loss: 0.6157, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8216/10000, Loss: 0.6157, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8217/10000, Loss: 0.6157, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8218/10000, Loss: 0.6157, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8219/10000, Loss: 0.6157, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8220/10000, Loss: 0.6157, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8221/10000, Loss: 0.6157, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8222/10000, Loss: 0.6157, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8223/10000, Loss: 0.6157, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8224/10000, Loss: 0.6157, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8225/10000, Loss: 0.6157, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8226/10000, Loss: 0.6157, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8227/10000, Loss: 0.6157, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8228/10000, Loss: 0.6157, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8229/10000, Loss: 0.6156, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8230/10000, Loss: 0.6156, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8231/10000, Loss: 0.6156, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8232/10000, Loss: 0.6156, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8233/10000, Loss: 0.6156, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8234/10000, Loss: 0.6156, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8235/10000, Loss: 0.6156, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8236/10000, Loss: 0.6156, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8237/10000, Loss: 0.6156, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8238/10000, Loss: 0.6156, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8239/10000, Loss: 0.6156, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8240/10000, Loss: 0.6156, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8241/10000, Loss: 0.6156, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8242/10000, Loss: 0.6156, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8243/10000, Loss: 0.6156, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8244/10000, Loss: 0.6156, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8245/10000, Loss: 0.6156, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8246/10000, Loss: 0.6156, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8247/10000, Loss: 0.6155, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8248/10000, Loss: 0.6155, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8249/10000, Loss: 0.6155, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8250/10000, Loss: 0.6155, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8251/10000, Loss: 0.6155, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8252/10000, Loss: 0.6155, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8253/10000, Loss: 0.6155, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8254/10000, Loss: 0.6155, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8255/10000, Loss: 0.6155, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8256/10000, Loss: 0.6155, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8257/10000, Loss: 0.6155, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8258/10000, Loss: 0.6155, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8259/10000, Loss: 0.6155, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8260/10000, Loss: 0.6155, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8261/10000, Loss: 0.6155, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8262/10000, Loss: 0.6155, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8263/10000, Loss: 0.6155, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8264/10000, Loss: 0.6155, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8265/10000, Loss: 0.6154, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8266/10000, Loss: 0.6154, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8267/10000, Loss: 0.6154, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8268/10000, Loss: 0.6154, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8269/10000, Loss: 0.6154, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8270/10000, Loss: 0.6154, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8271/10000, Loss: 0.6154, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8272/10000, Loss: 0.6154, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8273/10000, Loss: 0.6154, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8274/10000, Loss: 0.6154, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8275/10000, Loss: 0.6154, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8276/10000, Loss: 0.6154, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8277/10000, Loss: 0.6154, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8278/10000, Loss: 0.6154, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8279/10000, Loss: 0.6154, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8280/10000, Loss: 0.6154, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8281/10000, Loss: 0.6154, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8282/10000, Loss: 0.6154, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8283/10000, Loss: 0.6153, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8284/10000, Loss: 0.6153, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8285/10000, Loss: 0.6153, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8286/10000, Loss: 0.6153, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8287/10000, Loss: 0.6153, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8288/10000, Loss: 0.6153, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8289/10000, Loss: 0.6153, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8290/10000, Loss: 0.6153, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8291/10000, Loss: 0.6153, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8292/10000, Loss: 0.6153, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8293/10000, Loss: 0.6153, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8294/10000, Loss: 0.6153, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8295/10000, Loss: 0.6153, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8296/10000, Loss: 0.6153, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8297/10000, Loss: 0.6153, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8298/10000, Loss: 0.6153, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8299/10000, Loss: 0.6153, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8300/10000, Loss: 0.6153, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8301/10000, Loss: 0.6153, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8302/10000, Loss: 0.6152, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8303/10000, Loss: 0.6152, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8304/10000, Loss: 0.6152, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8305/10000, Loss: 0.6152, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8306/10000, Loss: 0.6152, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8307/10000, Loss: 0.6152, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8308/10000, Loss: 0.6152, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8309/10000, Loss: 0.6152, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8310/10000, Loss: 0.6152, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8311/10000, Loss: 0.6152, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8312/10000, Loss: 0.6152, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8313/10000, Loss: 0.6152, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8314/10000, Loss: 0.6152, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8315/10000, Loss: 0.6152, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8316/10000, Loss: 0.6152, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8317/10000, Loss: 0.6152, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8318/10000, Loss: 0.6152, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8319/10000, Loss: 0.6152, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8320/10000, Loss: 0.6151, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8321/10000, Loss: 0.6151, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8322/10000, Loss: 0.6151, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8323/10000, Loss: 0.6151, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8324/10000, Loss: 0.6151, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8325/10000, Loss: 0.6151, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8326/10000, Loss: 0.6151, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8327/10000, Loss: 0.6151, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8328/10000, Loss: 0.6151, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8329/10000, Loss: 0.6151, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8330/10000, Loss: 0.6151, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8331/10000, Loss: 0.6151, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8332/10000, Loss: 0.6151, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8333/10000, Loss: 0.6151, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8334/10000, Loss: 0.6151, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8335/10000, Loss: 0.6151, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8336/10000, Loss: 0.6151, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8337/10000, Loss: 0.6151, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8338/10000, Loss: 0.6151, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8339/10000, Loss: 0.6150, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8340/10000, Loss: 0.6150, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8341/10000, Loss: 0.6150, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8342/10000, Loss: 0.6150, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8343/10000, Loss: 0.6150, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8344/10000, Loss: 0.6150, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8345/10000, Loss: 0.6150, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8346/10000, Loss: 0.6150, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8347/10000, Loss: 0.6150, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8348/10000, Loss: 0.6150, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8349/10000, Loss: 0.6150, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8350/10000, Loss: 0.6150, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8351/10000, Loss: 0.6150, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8352/10000, Loss: 0.6150, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8353/10000, Loss: 0.6150, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8354/10000, Loss: 0.6150, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8355/10000, Loss: 0.6150, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8356/10000, Loss: 0.6150, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8357/10000, Loss: 0.6149, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8358/10000, Loss: 0.6149, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8359/10000, Loss: 0.6149, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8360/10000, Loss: 0.6149, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8361/10000, Loss: 0.6149, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8362/10000, Loss: 0.6149, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8363/10000, Loss: 0.6149, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8364/10000, Loss: 0.6149, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8365/10000, Loss: 0.6149, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8366/10000, Loss: 0.6149, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8367/10000, Loss: 0.6149, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8368/10000, Loss: 0.6149, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8369/10000, Loss: 0.6149, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8370/10000, Loss: 0.6149, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8371/10000, Loss: 0.6149, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8372/10000, Loss: 0.6149, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8373/10000, Loss: 0.6149, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8374/10000, Loss: 0.6149, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8375/10000, Loss: 0.6149, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8376/10000, Loss: 0.6148, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8377/10000, Loss: 0.6148, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8378/10000, Loss: 0.6148, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8379/10000, Loss: 0.6148, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8380/10000, Loss: 0.6148, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8381/10000, Loss: 0.6148, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8382/10000, Loss: 0.6148, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8383/10000, Loss: 0.6148, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8384/10000, Loss: 0.6148, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8385/10000, Loss: 0.6148, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8386/10000, Loss: 0.6148, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8387/10000, Loss: 0.6148, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8388/10000, Loss: 0.6148, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8389/10000, Loss: 0.6148, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8390/10000, Loss: 0.6148, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8391/10000, Loss: 0.6148, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8392/10000, Loss: 0.6148, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8393/10000, Loss: 0.6148, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8394/10000, Loss: 0.6148, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8395/10000, Loss: 0.6147, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8396/10000, Loss: 0.6147, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8397/10000, Loss: 0.6147, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8398/10000, Loss: 0.6147, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8399/10000, Loss: 0.6147, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8400/10000, Loss: 0.6147, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8401/10000, Loss: 0.6147, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8402/10000, Loss: 0.6147, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8403/10000, Loss: 0.6147, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8404/10000, Loss: 0.6147, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8405/10000, Loss: 0.6147, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8406/10000, Loss: 0.6147, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8407/10000, Loss: 0.6147, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8408/10000, Loss: 0.6147, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8409/10000, Loss: 0.6147, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8410/10000, Loss: 0.6147, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8411/10000, Loss: 0.6147, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8412/10000, Loss: 0.6147, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8413/10000, Loss: 0.6147, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8414/10000, Loss: 0.6146, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8415/10000, Loss: 0.6146, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8416/10000, Loss: 0.6146, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8417/10000, Loss: 0.6146, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8418/10000, Loss: 0.6146, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8419/10000, Loss: 0.6146, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8420/10000, Loss: 0.6146, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8421/10000, Loss: 0.6146, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8422/10000, Loss: 0.6146, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8423/10000, Loss: 0.6146, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8424/10000, Loss: 0.6146, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8425/10000, Loss: 0.6146, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8426/10000, Loss: 0.6146, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8427/10000, Loss: 0.6146, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8428/10000, Loss: 0.6146, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8429/10000, Loss: 0.6146, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8430/10000, Loss: 0.6146, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8431/10000, Loss: 0.6146, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8432/10000, Loss: 0.6146, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8433/10000, Loss: 0.6145, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8434/10000, Loss: 0.6145, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8435/10000, Loss: 0.6145, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8436/10000, Loss: 0.6145, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8437/10000, Loss: 0.6145, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8438/10000, Loss: 0.6145, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8439/10000, Loss: 0.6145, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8440/10000, Loss: 0.6145, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8441/10000, Loss: 0.6145, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8442/10000, Loss: 0.6145, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8443/10000, Loss: 0.6145, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8444/10000, Loss: 0.6145, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8445/10000, Loss: 0.6145, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8446/10000, Loss: 0.6145, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8447/10000, Loss: 0.6145, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8448/10000, Loss: 0.6145, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8449/10000, Loss: 0.6145, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8450/10000, Loss: 0.6145, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8451/10000, Loss: 0.6145, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8452/10000, Loss: 0.6144, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8453/10000, Loss: 0.6144, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8454/10000, Loss: 0.6144, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8455/10000, Loss: 0.6144, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8456/10000, Loss: 0.6144, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8457/10000, Loss: 0.6144, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8458/10000, Loss: 0.6144, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8459/10000, Loss: 0.6144, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8460/10000, Loss: 0.6144, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8461/10000, Loss: 0.6144, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8462/10000, Loss: 0.6144, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8463/10000, Loss: 0.6144, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8464/10000, Loss: 0.6144, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8465/10000, Loss: 0.6144, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8466/10000, Loss: 0.6144, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8467/10000, Loss: 0.6144, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8468/10000, Loss: 0.6144, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8469/10000, Loss: 0.6144, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8470/10000, Loss: 0.6144, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8471/10000, Loss: 0.6143, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8472/10000, Loss: 0.6143, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8473/10000, Loss: 0.6143, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8474/10000, Loss: 0.6143, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8475/10000, Loss: 0.6143, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8476/10000, Loss: 0.6143, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8477/10000, Loss: 0.6143, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8478/10000, Loss: 0.6143, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8479/10000, Loss: 0.6143, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8480/10000, Loss: 0.6143, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8481/10000, Loss: 0.6143, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8482/10000, Loss: 0.6143, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8483/10000, Loss: 0.6143, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8484/10000, Loss: 0.6143, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8485/10000, Loss: 0.6143, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8486/10000, Loss: 0.6143, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8487/10000, Loss: 0.6143, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8488/10000, Loss: 0.6143, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8489/10000, Loss: 0.6143, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8490/10000, Loss: 0.6143, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8491/10000, Loss: 0.6142, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8492/10000, Loss: 0.6142, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8493/10000, Loss: 0.6142, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8494/10000, Loss: 0.6142, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8495/10000, Loss: 0.6142, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8496/10000, Loss: 0.6142, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8497/10000, Loss: 0.6142, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8498/10000, Loss: 0.6142, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8499/10000, Loss: 0.6142, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8500/10000, Loss: 0.6142, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8501/10000, Loss: 0.6142, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8502/10000, Loss: 0.6142, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8503/10000, Loss: 0.6142, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8504/10000, Loss: 0.6142, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8505/10000, Loss: 0.6142, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8506/10000, Loss: 0.6142, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8507/10000, Loss: 0.6142, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8508/10000, Loss: 0.6142, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8509/10000, Loss: 0.6142, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8510/10000, Loss: 0.6141, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8511/10000, Loss: 0.6141, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8512/10000, Loss: 0.6141, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8513/10000, Loss: 0.6141, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8514/10000, Loss: 0.6141, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8515/10000, Loss: 0.6141, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8516/10000, Loss: 0.6141, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8517/10000, Loss: 0.6141, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8518/10000, Loss: 0.6141, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8519/10000, Loss: 0.6141, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8520/10000, Loss: 0.6141, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8521/10000, Loss: 0.6141, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8522/10000, Loss: 0.6141, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8523/10000, Loss: 0.6141, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8524/10000, Loss: 0.6141, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8525/10000, Loss: 0.6141, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8526/10000, Loss: 0.6141, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8527/10000, Loss: 0.6141, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8528/10000, Loss: 0.6141, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8529/10000, Loss: 0.6141, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8530/10000, Loss: 0.6140, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8531/10000, Loss: 0.6140, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8532/10000, Loss: 0.6140, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8533/10000, Loss: 0.6140, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8534/10000, Loss: 0.6140, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8535/10000, Loss: 0.6140, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8536/10000, Loss: 0.6140, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8537/10000, Loss: 0.6140, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8538/10000, Loss: 0.6140, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8539/10000, Loss: 0.6140, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8540/10000, Loss: 0.6140, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8541/10000, Loss: 0.6140, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8542/10000, Loss: 0.6140, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8543/10000, Loss: 0.6140, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8544/10000, Loss: 0.6140, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8545/10000, Loss: 0.6140, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8546/10000, Loss: 0.6140, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8547/10000, Loss: 0.6140, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8548/10000, Loss: 0.6140, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8549/10000, Loss: 0.6139, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8550/10000, Loss: 0.6139, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8551/10000, Loss: 0.6139, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8552/10000, Loss: 0.6139, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8553/10000, Loss: 0.6139, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8554/10000, Loss: 0.6139, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8555/10000, Loss: 0.6139, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8556/10000, Loss: 0.6139, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8557/10000, Loss: 0.6139, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8558/10000, Loss: 0.6139, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8559/10000, Loss: 0.6139, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8560/10000, Loss: 0.6139, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8561/10000, Loss: 0.6139, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8562/10000, Loss: 0.6139, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8563/10000, Loss: 0.6139, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8564/10000, Loss: 0.6139, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8565/10000, Loss: 0.6139, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8566/10000, Loss: 0.6139, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8567/10000, Loss: 0.6139, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8568/10000, Loss: 0.6139, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8569/10000, Loss: 0.6138, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8570/10000, Loss: 0.6138, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8571/10000, Loss: 0.6138, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8572/10000, Loss: 0.6138, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8573/10000, Loss: 0.6138, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8574/10000, Loss: 0.6138, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8575/10000, Loss: 0.6138, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8576/10000, Loss: 0.6138, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8577/10000, Loss: 0.6138, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8578/10000, Loss: 0.6138, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8579/10000, Loss: 0.6138, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8580/10000, Loss: 0.6138, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8581/10000, Loss: 0.6138, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8582/10000, Loss: 0.6138, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8583/10000, Loss: 0.6138, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8584/10000, Loss: 0.6138, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8585/10000, Loss: 0.6138, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8586/10000, Loss: 0.6138, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8587/10000, Loss: 0.6138, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8588/10000, Loss: 0.6138, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8589/10000, Loss: 0.6137, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8590/10000, Loss: 0.6137, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8591/10000, Loss: 0.6137, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8592/10000, Loss: 0.6137, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8593/10000, Loss: 0.6137, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8594/10000, Loss: 0.6137, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8595/10000, Loss: 0.6137, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8596/10000, Loss: 0.6137, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8597/10000, Loss: 0.6137, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8598/10000, Loss: 0.6137, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8599/10000, Loss: 0.6137, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8600/10000, Loss: 0.6137, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8601/10000, Loss: 0.6137, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8602/10000, Loss: 0.6137, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8603/10000, Loss: 0.6137, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8604/10000, Loss: 0.6137, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8605/10000, Loss: 0.6137, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8606/10000, Loss: 0.6137, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8607/10000, Loss: 0.6137, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8608/10000, Loss: 0.6137, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8609/10000, Loss: 0.6136, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8610/10000, Loss: 0.6136, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8611/10000, Loss: 0.6136, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8612/10000, Loss: 0.6136, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8613/10000, Loss: 0.6136, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8614/10000, Loss: 0.6136, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8615/10000, Loss: 0.6136, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8616/10000, Loss: 0.6136, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8617/10000, Loss: 0.6136, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8618/10000, Loss: 0.6136, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8619/10000, Loss: 0.6136, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8620/10000, Loss: 0.6136, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8621/10000, Loss: 0.6136, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8622/10000, Loss: 0.6136, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8623/10000, Loss: 0.6136, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8624/10000, Loss: 0.6136, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8625/10000, Loss: 0.6136, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8626/10000, Loss: 0.6136, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8627/10000, Loss: 0.6136, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8628/10000, Loss: 0.6136, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8629/10000, Loss: 0.6136, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8630/10000, Loss: 0.6135, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8631/10000, Loss: 0.6135, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8632/10000, Loss: 0.6135, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8633/10000, Loss: 0.6135, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8634/10000, Loss: 0.6135, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8635/10000, Loss: 0.6135, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8636/10000, Loss: 0.6135, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8637/10000, Loss: 0.6135, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8638/10000, Loss: 0.6135, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8639/10000, Loss: 0.6135, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8640/10000, Loss: 0.6135, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8641/10000, Loss: 0.6135, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8642/10000, Loss: 0.6135, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8643/10000, Loss: 0.6135, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8644/10000, Loss: 0.6135, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8645/10000, Loss: 0.6135, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8646/10000, Loss: 0.6135, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8647/10000, Loss: 0.6135, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8648/10000, Loss: 0.6135, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8649/10000, Loss: 0.6135, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8650/10000, Loss: 0.6134, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8651/10000, Loss: 0.6134, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8652/10000, Loss: 0.6134, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8653/10000, Loss: 0.6134, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8654/10000, Loss: 0.6134, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8655/10000, Loss: 0.6134, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8656/10000, Loss: 0.6134, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8657/10000, Loss: 0.6134, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8658/10000, Loss: 0.6134, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8659/10000, Loss: 0.6134, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8660/10000, Loss: 0.6134, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8661/10000, Loss: 0.6134, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8662/10000, Loss: 0.6134, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8663/10000, Loss: 0.6134, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8664/10000, Loss: 0.6134, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8665/10000, Loss: 0.6134, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8666/10000, Loss: 0.6134, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8667/10000, Loss: 0.6134, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8668/10000, Loss: 0.6134, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8669/10000, Loss: 0.6134, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8670/10000, Loss: 0.6134, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8671/10000, Loss: 0.6133, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8672/10000, Loss: 0.6133, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8673/10000, Loss: 0.6133, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8674/10000, Loss: 0.6133, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8675/10000, Loss: 0.6133, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8676/10000, Loss: 0.6133, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8677/10000, Loss: 0.6133, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8678/10000, Loss: 0.6133, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8679/10000, Loss: 0.6133, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8680/10000, Loss: 0.6133, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8681/10000, Loss: 0.6133, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8682/10000, Loss: 0.6133, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8683/10000, Loss: 0.6133, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8684/10000, Loss: 0.6133, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8685/10000, Loss: 0.6133, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8686/10000, Loss: 0.6133, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8687/10000, Loss: 0.6133, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8688/10000, Loss: 0.6133, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8689/10000, Loss: 0.6133, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8690/10000, Loss: 0.6133, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8691/10000, Loss: 0.6132, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8692/10000, Loss: 0.6132, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8693/10000, Loss: 0.6132, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8694/10000, Loss: 0.6132, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8695/10000, Loss: 0.6132, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8696/10000, Loss: 0.6132, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8697/10000, Loss: 0.6132, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8698/10000, Loss: 0.6132, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8699/10000, Loss: 0.6132, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8700/10000, Loss: 0.6132, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8701/10000, Loss: 0.6132, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8702/10000, Loss: 0.6132, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8703/10000, Loss: 0.6132, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8704/10000, Loss: 0.6132, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8705/10000, Loss: 0.6132, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8706/10000, Loss: 0.6132, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8707/10000, Loss: 0.6132, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8708/10000, Loss: 0.6132, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8709/10000, Loss: 0.6132, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8710/10000, Loss: 0.6132, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8711/10000, Loss: 0.6132, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8712/10000, Loss: 0.6131, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8713/10000, Loss: 0.6131, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8714/10000, Loss: 0.6131, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8715/10000, Loss: 0.6131, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8716/10000, Loss: 0.6131, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8717/10000, Loss: 0.6131, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8718/10000, Loss: 0.6131, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8719/10000, Loss: 0.6131, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8720/10000, Loss: 0.6131, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8721/10000, Loss: 0.6131, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8722/10000, Loss: 0.6131, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8723/10000, Loss: 0.6131, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8724/10000, Loss: 0.6131, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8725/10000, Loss: 0.6131, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8726/10000, Loss: 0.6131, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8727/10000, Loss: 0.6131, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8728/10000, Loss: 0.6131, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8729/10000, Loss: 0.6131, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8730/10000, Loss: 0.6131, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8731/10000, Loss: 0.6131, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8732/10000, Loss: 0.6131, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8733/10000, Loss: 0.6130, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8734/10000, Loss: 0.6130, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8735/10000, Loss: 0.6130, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8736/10000, Loss: 0.6130, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8737/10000, Loss: 0.6130, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8738/10000, Loss: 0.6130, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8739/10000, Loss: 0.6130, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8740/10000, Loss: 0.6130, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8741/10000, Loss: 0.6130, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8742/10000, Loss: 0.6130, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8743/10000, Loss: 0.6130, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8744/10000, Loss: 0.6130, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8745/10000, Loss: 0.6130, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8746/10000, Loss: 0.6130, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8747/10000, Loss: 0.6130, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8748/10000, Loss: 0.6130, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8749/10000, Loss: 0.6130, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8750/10000, Loss: 0.6130, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8751/10000, Loss: 0.6130, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8752/10000, Loss: 0.6130, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8753/10000, Loss: 0.6130, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8754/10000, Loss: 0.6129, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8755/10000, Loss: 0.6129, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8756/10000, Loss: 0.6129, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8757/10000, Loss: 0.6129, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8758/10000, Loss: 0.6129, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8759/10000, Loss: 0.6129, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8760/10000, Loss: 0.6129, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8761/10000, Loss: 0.6129, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8762/10000, Loss: 0.6129, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8763/10000, Loss: 0.6129, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8764/10000, Loss: 0.6129, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8765/10000, Loss: 0.6129, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8766/10000, Loss: 0.6129, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8767/10000, Loss: 0.6129, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8768/10000, Loss: 0.6129, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8769/10000, Loss: 0.6129, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8770/10000, Loss: 0.6129, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8771/10000, Loss: 0.6129, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8772/10000, Loss: 0.6129, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8773/10000, Loss: 0.6129, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8774/10000, Loss: 0.6129, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8775/10000, Loss: 0.6128, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8776/10000, Loss: 0.6128, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8777/10000, Loss: 0.6128, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8778/10000, Loss: 0.6128, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8779/10000, Loss: 0.6128, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8780/10000, Loss: 0.6128, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8781/10000, Loss: 0.6128, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8782/10000, Loss: 0.6128, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8783/10000, Loss: 0.6128, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8784/10000, Loss: 0.6128, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8785/10000, Loss: 0.6128, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8786/10000, Loss: 0.6128, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8787/10000, Loss: 0.6128, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8788/10000, Loss: 0.6128, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8789/10000, Loss: 0.6128, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8790/10000, Loss: 0.6128, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8791/10000, Loss: 0.6128, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8792/10000, Loss: 0.6128, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8793/10000, Loss: 0.6128, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8794/10000, Loss: 0.6128, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8795/10000, Loss: 0.6128, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8796/10000, Loss: 0.6127, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8797/10000, Loss: 0.6127, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8798/10000, Loss: 0.6127, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8799/10000, Loss: 0.6127, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8800/10000, Loss: 0.6127, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8801/10000, Loss: 0.6127, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8802/10000, Loss: 0.6127, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8803/10000, Loss: 0.6127, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8804/10000, Loss: 0.6127, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8805/10000, Loss: 0.6127, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8806/10000, Loss: 0.6127, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8807/10000, Loss: 0.6127, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8808/10000, Loss: 0.6127, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8809/10000, Loss: 0.6127, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8810/10000, Loss: 0.6127, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8811/10000, Loss: 0.6127, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8812/10000, Loss: 0.6127, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8813/10000, Loss: 0.6127, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8814/10000, Loss: 0.6127, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8815/10000, Loss: 0.6127, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8816/10000, Loss: 0.6127, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8817/10000, Loss: 0.6127, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8818/10000, Loss: 0.6126, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8819/10000, Loss: 0.6126, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8820/10000, Loss: 0.6126, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8821/10000, Loss: 0.6126, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8822/10000, Loss: 0.6126, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8823/10000, Loss: 0.6126, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8824/10000, Loss: 0.6126, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8825/10000, Loss: 0.6126, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8826/10000, Loss: 0.6126, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8827/10000, Loss: 0.6126, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8828/10000, Loss: 0.6126, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8829/10000, Loss: 0.6126, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8830/10000, Loss: 0.6126, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8831/10000, Loss: 0.6126, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8832/10000, Loss: 0.6126, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8833/10000, Loss: 0.6126, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8834/10000, Loss: 0.6126, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8835/10000, Loss: 0.6126, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8836/10000, Loss: 0.6126, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8837/10000, Loss: 0.6126, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8838/10000, Loss: 0.6126, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8839/10000, Loss: 0.6125, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8840/10000, Loss: 0.6125, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8841/10000, Loss: 0.6125, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8842/10000, Loss: 0.6125, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8843/10000, Loss: 0.6125, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8844/10000, Loss: 0.6125, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8845/10000, Loss: 0.6125, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8846/10000, Loss: 0.6125, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8847/10000, Loss: 0.6125, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8848/10000, Loss: 0.6125, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8849/10000, Loss: 0.6125, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8850/10000, Loss: 0.6125, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8851/10000, Loss: 0.6125, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8852/10000, Loss: 0.6125, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8853/10000, Loss: 0.6125, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8854/10000, Loss: 0.6125, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8855/10000, Loss: 0.6125, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8856/10000, Loss: 0.6125, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8857/10000, Loss: 0.6125, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8858/10000, Loss: 0.6125, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8859/10000, Loss: 0.6125, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8860/10000, Loss: 0.6125, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8861/10000, Loss: 0.6124, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8862/10000, Loss: 0.6124, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8863/10000, Loss: 0.6124, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8864/10000, Loss: 0.6124, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8865/10000, Loss: 0.6124, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8866/10000, Loss: 0.6124, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8867/10000, Loss: 0.6124, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8868/10000, Loss: 0.6124, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8869/10000, Loss: 0.6124, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8870/10000, Loss: 0.6124, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8871/10000, Loss: 0.6124, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8872/10000, Loss: 0.6124, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8873/10000, Loss: 0.6124, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8874/10000, Loss: 0.6124, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8875/10000, Loss: 0.6124, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8876/10000, Loss: 0.6124, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8877/10000, Loss: 0.6124, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8878/10000, Loss: 0.6124, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8879/10000, Loss: 0.6124, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8880/10000, Loss: 0.6124, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8881/10000, Loss: 0.6124, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8882/10000, Loss: 0.6124, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8883/10000, Loss: 0.6123, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8884/10000, Loss: 0.6123, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8885/10000, Loss: 0.6123, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8886/10000, Loss: 0.6123, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8887/10000, Loss: 0.6123, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8888/10000, Loss: 0.6123, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8889/10000, Loss: 0.6123, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8890/10000, Loss: 0.6123, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8891/10000, Loss: 0.6123, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8892/10000, Loss: 0.6123, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8893/10000, Loss: 0.6123, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8894/10000, Loss: 0.6123, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8895/10000, Loss: 0.6123, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8896/10000, Loss: 0.6123, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8897/10000, Loss: 0.6123, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8898/10000, Loss: 0.6123, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8899/10000, Loss: 0.6123, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8900/10000, Loss: 0.6123, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8901/10000, Loss: 0.6123, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8902/10000, Loss: 0.6123, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8903/10000, Loss: 0.6123, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8904/10000, Loss: 0.6123, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8905/10000, Loss: 0.6122, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8906/10000, Loss: 0.6122, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8907/10000, Loss: 0.6122, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8908/10000, Loss: 0.6122, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8909/10000, Loss: 0.6122, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8910/10000, Loss: 0.6122, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8911/10000, Loss: 0.6122, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8912/10000, Loss: 0.6122, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8913/10000, Loss: 0.6122, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8914/10000, Loss: 0.6122, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8915/10000, Loss: 0.6122, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8916/10000, Loss: 0.6122, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8917/10000, Loss: 0.6122, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8918/10000, Loss: 0.6122, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8919/10000, Loss: 0.6122, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8920/10000, Loss: 0.6122, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8921/10000, Loss: 0.6122, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8922/10000, Loss: 0.6122, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8923/10000, Loss: 0.6122, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8924/10000, Loss: 0.6122, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8925/10000, Loss: 0.6122, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8926/10000, Loss: 0.6122, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8927/10000, Loss: 0.6121, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8928/10000, Loss: 0.6121, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8929/10000, Loss: 0.6121, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8930/10000, Loss: 0.6121, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8931/10000, Loss: 0.6121, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8932/10000, Loss: 0.6121, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8933/10000, Loss: 0.6121, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8934/10000, Loss: 0.6121, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8935/10000, Loss: 0.6121, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8936/10000, Loss: 0.6121, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8937/10000, Loss: 0.6121, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8938/10000, Loss: 0.6121, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8939/10000, Loss: 0.6121, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8940/10000, Loss: 0.6121, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8941/10000, Loss: 0.6121, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8942/10000, Loss: 0.6121, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8943/10000, Loss: 0.6121, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8944/10000, Loss: 0.6121, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8945/10000, Loss: 0.6121, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8946/10000, Loss: 0.6121, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8947/10000, Loss: 0.6121, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8948/10000, Loss: 0.6121, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8949/10000, Loss: 0.6121, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8950/10000, Loss: 0.6120, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8951/10000, Loss: 0.6120, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8952/10000, Loss: 0.6120, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8953/10000, Loss: 0.6120, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8954/10000, Loss: 0.6120, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8955/10000, Loss: 0.6120, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8956/10000, Loss: 0.6120, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8957/10000, Loss: 0.6120, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8958/10000, Loss: 0.6120, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8959/10000, Loss: 0.6120, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8960/10000, Loss: 0.6120, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8961/10000, Loss: 0.6120, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8962/10000, Loss: 0.6120, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8963/10000, Loss: 0.6120, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8964/10000, Loss: 0.6120, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8965/10000, Loss: 0.6120, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8966/10000, Loss: 0.6120, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8967/10000, Loss: 0.6120, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8968/10000, Loss: 0.6120, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8969/10000, Loss: 0.6120, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8970/10000, Loss: 0.6120, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8971/10000, Loss: 0.6120, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8972/10000, Loss: 0.6119, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8973/10000, Loss: 0.6119, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8974/10000, Loss: 0.6119, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8975/10000, Loss: 0.6119, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8976/10000, Loss: 0.6119, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8977/10000, Loss: 0.6119, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8978/10000, Loss: 0.6119, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8979/10000, Loss: 0.6119, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8980/10000, Loss: 0.6119, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8981/10000, Loss: 0.6119, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8982/10000, Loss: 0.6119, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8983/10000, Loss: 0.6119, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8984/10000, Loss: 0.6119, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8985/10000, Loss: 0.6119, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8986/10000, Loss: 0.6119, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8987/10000, Loss: 0.6119, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8988/10000, Loss: 0.6119, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8989/10000, Loss: 0.6119, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8990/10000, Loss: 0.6119, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8991/10000, Loss: 0.6119, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8992/10000, Loss: 0.6119, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8993/10000, Loss: 0.6119, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8994/10000, Loss: 0.6119, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8995/10000, Loss: 0.6118, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8996/10000, Loss: 0.6118, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8997/10000, Loss: 0.6118, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8998/10000, Loss: 0.6118, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 8999/10000, Loss: 0.6118, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9000/10000, Loss: 0.6118, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9001/10000, Loss: 0.6118, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9002/10000, Loss: 0.6118, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9003/10000, Loss: 0.6118, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9004/10000, Loss: 0.6118, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9005/10000, Loss: 0.6118, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9006/10000, Loss: 0.6118, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9007/10000, Loss: 0.6118, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9008/10000, Loss: 0.6118, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9009/10000, Loss: 0.6118, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9010/10000, Loss: 0.6118, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9011/10000, Loss: 0.6118, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9012/10000, Loss: 0.6118, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9013/10000, Loss: 0.6118, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9014/10000, Loss: 0.6118, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9015/10000, Loss: 0.6118, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9016/10000, Loss: 0.6118, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9017/10000, Loss: 0.6117, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9018/10000, Loss: 0.6117, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9019/10000, Loss: 0.6117, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9020/10000, Loss: 0.6117, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9021/10000, Loss: 0.6117, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9022/10000, Loss: 0.6117, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9023/10000, Loss: 0.6117, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9024/10000, Loss: 0.6117, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9025/10000, Loss: 0.6117, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9026/10000, Loss: 0.6117, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9027/10000, Loss: 0.6117, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9028/10000, Loss: 0.6117, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9029/10000, Loss: 0.6117, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9030/10000, Loss: 0.6117, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9031/10000, Loss: 0.6117, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9032/10000, Loss: 0.6117, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9033/10000, Loss: 0.6117, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9034/10000, Loss: 0.6117, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9035/10000, Loss: 0.6117, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9036/10000, Loss: 0.6117, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9037/10000, Loss: 0.6117, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9038/10000, Loss: 0.6117, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9039/10000, Loss: 0.6117, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9040/10000, Loss: 0.6116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9041/10000, Loss: 0.6116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9042/10000, Loss: 0.6116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9043/10000, Loss: 0.6116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9044/10000, Loss: 0.6116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9045/10000, Loss: 0.6116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9046/10000, Loss: 0.6116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9047/10000, Loss: 0.6116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9048/10000, Loss: 0.6116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9049/10000, Loss: 0.6116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9050/10000, Loss: 0.6116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9051/10000, Loss: 0.6116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9052/10000, Loss: 0.6116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9053/10000, Loss: 0.6116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9054/10000, Loss: 0.6116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9055/10000, Loss: 0.6116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9056/10000, Loss: 0.6116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9057/10000, Loss: 0.6116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9058/10000, Loss: 0.6116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9059/10000, Loss: 0.6116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9060/10000, Loss: 0.6116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9061/10000, Loss: 0.6116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9062/10000, Loss: 0.6116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9063/10000, Loss: 0.6116, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9064/10000, Loss: 0.6115, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9065/10000, Loss: 0.6115, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9066/10000, Loss: 0.6115, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9067/10000, Loss: 0.6115, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9068/10000, Loss: 0.6115, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9069/10000, Loss: 0.6115, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9070/10000, Loss: 0.6115, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9071/10000, Loss: 0.6115, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9072/10000, Loss: 0.6115, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9073/10000, Loss: 0.6115, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9074/10000, Loss: 0.6115, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9075/10000, Loss: 0.6115, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9076/10000, Loss: 0.6115, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9077/10000, Loss: 0.6115, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9078/10000, Loss: 0.6115, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9079/10000, Loss: 0.6115, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9080/10000, Loss: 0.6115, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9081/10000, Loss: 0.6115, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9082/10000, Loss: 0.6115, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9083/10000, Loss: 0.6115, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9084/10000, Loss: 0.6115, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9085/10000, Loss: 0.6115, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9086/10000, Loss: 0.6115, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9087/10000, Loss: 0.6114, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9088/10000, Loss: 0.6114, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9089/10000, Loss: 0.6114, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9090/10000, Loss: 0.6114, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9091/10000, Loss: 0.6114, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9092/10000, Loss: 0.6114, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9093/10000, Loss: 0.6114, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9094/10000, Loss: 0.6114, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9095/10000, Loss: 0.6114, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9096/10000, Loss: 0.6114, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9097/10000, Loss: 0.6114, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9098/10000, Loss: 0.6114, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9099/10000, Loss: 0.6114, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9100/10000, Loss: 0.6114, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9101/10000, Loss: 0.6114, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9102/10000, Loss: 0.6114, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9103/10000, Loss: 0.6114, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9104/10000, Loss: 0.6114, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9105/10000, Loss: 0.6114, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9106/10000, Loss: 0.6114, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9107/10000, Loss: 0.6114, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9108/10000, Loss: 0.6114, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9109/10000, Loss: 0.6114, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9110/10000, Loss: 0.6113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9111/10000, Loss: 0.6113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9112/10000, Loss: 0.6113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9113/10000, Loss: 0.6113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9114/10000, Loss: 0.6113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9115/10000, Loss: 0.6113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9116/10000, Loss: 0.6113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9117/10000, Loss: 0.6113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9118/10000, Loss: 0.6113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9119/10000, Loss: 0.6113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9120/10000, Loss: 0.6113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9121/10000, Loss: 0.6113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9122/10000, Loss: 0.6113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9123/10000, Loss: 0.6113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9124/10000, Loss: 0.6113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9125/10000, Loss: 0.6113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9126/10000, Loss: 0.6113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9127/10000, Loss: 0.6113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9128/10000, Loss: 0.6113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9129/10000, Loss: 0.6113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9130/10000, Loss: 0.6113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9131/10000, Loss: 0.6113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9132/10000, Loss: 0.6113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9133/10000, Loss: 0.6113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9134/10000, Loss: 0.6112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9135/10000, Loss: 0.6112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9136/10000, Loss: 0.6112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9137/10000, Loss: 0.6112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9138/10000, Loss: 0.6112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9139/10000, Loss: 0.6112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9140/10000, Loss: 0.6112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9141/10000, Loss: 0.6112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9142/10000, Loss: 0.6112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9143/10000, Loss: 0.6112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9144/10000, Loss: 0.6112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9145/10000, Loss: 0.6112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9146/10000, Loss: 0.6112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9147/10000, Loss: 0.6112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9148/10000, Loss: 0.6112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9149/10000, Loss: 0.6112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9150/10000, Loss: 0.6112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9151/10000, Loss: 0.6112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9152/10000, Loss: 0.6112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9153/10000, Loss: 0.6112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9154/10000, Loss: 0.6112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9155/10000, Loss: 0.6112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9156/10000, Loss: 0.6112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9157/10000, Loss: 0.6112, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9158/10000, Loss: 0.6111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9159/10000, Loss: 0.6111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9160/10000, Loss: 0.6111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9161/10000, Loss: 0.6111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9162/10000, Loss: 0.6111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9163/10000, Loss: 0.6111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9164/10000, Loss: 0.6111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9165/10000, Loss: 0.6111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9166/10000, Loss: 0.6111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9167/10000, Loss: 0.6111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9168/10000, Loss: 0.6111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9169/10000, Loss: 0.6111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9170/10000, Loss: 0.6111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9171/10000, Loss: 0.6111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9172/10000, Loss: 0.6111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9173/10000, Loss: 0.6111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9174/10000, Loss: 0.6111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9175/10000, Loss: 0.6111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9176/10000, Loss: 0.6111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9177/10000, Loss: 0.6111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9178/10000, Loss: 0.6111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9179/10000, Loss: 0.6111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9180/10000, Loss: 0.6111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9181/10000, Loss: 0.6111, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9182/10000, Loss: 0.6110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9183/10000, Loss: 0.6110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9184/10000, Loss: 0.6110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9185/10000, Loss: 0.6110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9186/10000, Loss: 0.6110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9187/10000, Loss: 0.6110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9188/10000, Loss: 0.6110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9189/10000, Loss: 0.6110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9190/10000, Loss: 0.6110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9191/10000, Loss: 0.6110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9192/10000, Loss: 0.6110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9193/10000, Loss: 0.6110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9194/10000, Loss: 0.6110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9195/10000, Loss: 0.6110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9196/10000, Loss: 0.6110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9197/10000, Loss: 0.6110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9198/10000, Loss: 0.6110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9199/10000, Loss: 0.6110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9200/10000, Loss: 0.6110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9201/10000, Loss: 0.6110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9202/10000, Loss: 0.6110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9203/10000, Loss: 0.6110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9204/10000, Loss: 0.6110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9205/10000, Loss: 0.6110, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9206/10000, Loss: 0.6109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9207/10000, Loss: 0.6109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9208/10000, Loss: 0.6109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9209/10000, Loss: 0.6109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9210/10000, Loss: 0.6109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9211/10000, Loss: 0.6109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9212/10000, Loss: 0.6109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9213/10000, Loss: 0.6109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9214/10000, Loss: 0.6109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9215/10000, Loss: 0.6109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9216/10000, Loss: 0.6109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9217/10000, Loss: 0.6109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9218/10000, Loss: 0.6109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9219/10000, Loss: 0.6109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9220/10000, Loss: 0.6109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9221/10000, Loss: 0.6109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9222/10000, Loss: 0.6109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9223/10000, Loss: 0.6109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9224/10000, Loss: 0.6109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9225/10000, Loss: 0.6109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9226/10000, Loss: 0.6109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9227/10000, Loss: 0.6109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9228/10000, Loss: 0.6109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9229/10000, Loss: 0.6109, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9230/10000, Loss: 0.6108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9231/10000, Loss: 0.6108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9232/10000, Loss: 0.6108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9233/10000, Loss: 0.6108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9234/10000, Loss: 0.6108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9235/10000, Loss: 0.6108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9236/10000, Loss: 0.6108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9237/10000, Loss: 0.6108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9238/10000, Loss: 0.6108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9239/10000, Loss: 0.6108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9240/10000, Loss: 0.6108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9241/10000, Loss: 0.6108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9242/10000, Loss: 0.6108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9243/10000, Loss: 0.6108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9244/10000, Loss: 0.6108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9245/10000, Loss: 0.6108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9246/10000, Loss: 0.6108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9247/10000, Loss: 0.6108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9248/10000, Loss: 0.6108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9249/10000, Loss: 0.6108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9250/10000, Loss: 0.6108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9251/10000, Loss: 0.6108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9252/10000, Loss: 0.6108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9253/10000, Loss: 0.6108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9254/10000, Loss: 0.6108, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9255/10000, Loss: 0.6107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9256/10000, Loss: 0.6107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9257/10000, Loss: 0.6107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9258/10000, Loss: 0.6107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9259/10000, Loss: 0.6107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9260/10000, Loss: 0.6107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9261/10000, Loss: 0.6107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9262/10000, Loss: 0.6107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9263/10000, Loss: 0.6107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9264/10000, Loss: 0.6107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9265/10000, Loss: 0.6107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9266/10000, Loss: 0.6107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9267/10000, Loss: 0.6107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9268/10000, Loss: 0.6107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9269/10000, Loss: 0.6107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9270/10000, Loss: 0.6107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9271/10000, Loss: 0.6107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9272/10000, Loss: 0.6107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9273/10000, Loss: 0.6107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9274/10000, Loss: 0.6107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9275/10000, Loss: 0.6107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9276/10000, Loss: 0.6107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9277/10000, Loss: 0.6107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9278/10000, Loss: 0.6107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9279/10000, Loss: 0.6107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9280/10000, Loss: 0.6106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9281/10000, Loss: 0.6106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9282/10000, Loss: 0.6106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9283/10000, Loss: 0.6106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9284/10000, Loss: 0.6106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9285/10000, Loss: 0.6106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9286/10000, Loss: 0.6106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9287/10000, Loss: 0.6106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9288/10000, Loss: 0.6106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9289/10000, Loss: 0.6106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9290/10000, Loss: 0.6106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9291/10000, Loss: 0.6106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9292/10000, Loss: 0.6106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9293/10000, Loss: 0.6106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9294/10000, Loss: 0.6106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9295/10000, Loss: 0.6106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9296/10000, Loss: 0.6106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9297/10000, Loss: 0.6106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9298/10000, Loss: 0.6106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9299/10000, Loss: 0.6106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9300/10000, Loss: 0.6106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9301/10000, Loss: 0.6106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9302/10000, Loss: 0.6106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9303/10000, Loss: 0.6106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9304/10000, Loss: 0.6106, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9305/10000, Loss: 0.6105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9306/10000, Loss: 0.6105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9307/10000, Loss: 0.6105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9308/10000, Loss: 0.6105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9309/10000, Loss: 0.6105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9310/10000, Loss: 0.6105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9311/10000, Loss: 0.6105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9312/10000, Loss: 0.6105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9313/10000, Loss: 0.6105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9314/10000, Loss: 0.6105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9315/10000, Loss: 0.6105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9316/10000, Loss: 0.6105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9317/10000, Loss: 0.6105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9318/10000, Loss: 0.6105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9319/10000, Loss: 0.6105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9320/10000, Loss: 0.6105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9321/10000, Loss: 0.6105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9322/10000, Loss: 0.6105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9323/10000, Loss: 0.6105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9324/10000, Loss: 0.6105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9325/10000, Loss: 0.6105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9326/10000, Loss: 0.6105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9327/10000, Loss: 0.6105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9328/10000, Loss: 0.6105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9329/10000, Loss: 0.6105, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9330/10000, Loss: 0.6104, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9331/10000, Loss: 0.6104, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9332/10000, Loss: 0.6104, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9333/10000, Loss: 0.6104, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9334/10000, Loss: 0.6104, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9335/10000, Loss: 0.6104, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9336/10000, Loss: 0.6104, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9337/10000, Loss: 0.6104, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9338/10000, Loss: 0.6104, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9339/10000, Loss: 0.6104, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9340/10000, Loss: 0.6104, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9341/10000, Loss: 0.6104, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9342/10000, Loss: 0.6104, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9343/10000, Loss: 0.6104, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9344/10000, Loss: 0.6104, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9345/10000, Loss: 0.6104, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9346/10000, Loss: 0.6104, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9347/10000, Loss: 0.6104, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9348/10000, Loss: 0.6104, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9349/10000, Loss: 0.6104, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9350/10000, Loss: 0.6104, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9351/10000, Loss: 0.6104, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9352/10000, Loss: 0.6104, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9353/10000, Loss: 0.6104, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9354/10000, Loss: 0.6104, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9355/10000, Loss: 0.6103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9356/10000, Loss: 0.6103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9357/10000, Loss: 0.6103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9358/10000, Loss: 0.6103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9359/10000, Loss: 0.6103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9360/10000, Loss: 0.6103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9361/10000, Loss: 0.6103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9362/10000, Loss: 0.6103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9363/10000, Loss: 0.6103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9364/10000, Loss: 0.6103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9365/10000, Loss: 0.6103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9366/10000, Loss: 0.6103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9367/10000, Loss: 0.6103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9368/10000, Loss: 0.6103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9369/10000, Loss: 0.6103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9370/10000, Loss: 0.6103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9371/10000, Loss: 0.6103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9372/10000, Loss: 0.6103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9373/10000, Loss: 0.6103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9374/10000, Loss: 0.6103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9375/10000, Loss: 0.6103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9376/10000, Loss: 0.6103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9377/10000, Loss: 0.6103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9378/10000, Loss: 0.6103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9379/10000, Loss: 0.6103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9380/10000, Loss: 0.6103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9381/10000, Loss: 0.6102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9382/10000, Loss: 0.6102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9383/10000, Loss: 0.6102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9384/10000, Loss: 0.6102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9385/10000, Loss: 0.6102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9386/10000, Loss: 0.6102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9387/10000, Loss: 0.6102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9388/10000, Loss: 0.6102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9389/10000, Loss: 0.6102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9390/10000, Loss: 0.6102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9391/10000, Loss: 0.6102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9392/10000, Loss: 0.6102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9393/10000, Loss: 0.6102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9394/10000, Loss: 0.6102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9395/10000, Loss: 0.6102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9396/10000, Loss: 0.6102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9397/10000, Loss: 0.6102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9398/10000, Loss: 0.6102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9399/10000, Loss: 0.6102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9400/10000, Loss: 0.6102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9401/10000, Loss: 0.6102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9402/10000, Loss: 0.6102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9403/10000, Loss: 0.6102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9404/10000, Loss: 0.6102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9405/10000, Loss: 0.6102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9406/10000, Loss: 0.6101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9407/10000, Loss: 0.6101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9408/10000, Loss: 0.6101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9409/10000, Loss: 0.6101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9410/10000, Loss: 0.6101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9411/10000, Loss: 0.6101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9412/10000, Loss: 0.6101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9413/10000, Loss: 0.6101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9414/10000, Loss: 0.6101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9415/10000, Loss: 0.6101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9416/10000, Loss: 0.6101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9417/10000, Loss: 0.6101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9418/10000, Loss: 0.6101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9419/10000, Loss: 0.6101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9420/10000, Loss: 0.6101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9421/10000, Loss: 0.6101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9422/10000, Loss: 0.6101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9423/10000, Loss: 0.6101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9424/10000, Loss: 0.6101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9425/10000, Loss: 0.6101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9426/10000, Loss: 0.6101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9427/10000, Loss: 0.6101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9428/10000, Loss: 0.6101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9429/10000, Loss: 0.6101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9430/10000, Loss: 0.6101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9431/10000, Loss: 0.6101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9432/10000, Loss: 0.6100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9433/10000, Loss: 0.6100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9434/10000, Loss: 0.6100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9435/10000, Loss: 0.6100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9436/10000, Loss: 0.6100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9437/10000, Loss: 0.6100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9438/10000, Loss: 0.6100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9439/10000, Loss: 0.6100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9440/10000, Loss: 0.6100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9441/10000, Loss: 0.6100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9442/10000, Loss: 0.6100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9443/10000, Loss: 0.6100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9444/10000, Loss: 0.6100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9445/10000, Loss: 0.6100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9446/10000, Loss: 0.6100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9447/10000, Loss: 0.6100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9448/10000, Loss: 0.6100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9449/10000, Loss: 0.6100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9450/10000, Loss: 0.6100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9451/10000, Loss: 0.6100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9452/10000, Loss: 0.6100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9453/10000, Loss: 0.6100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9454/10000, Loss: 0.6100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9455/10000, Loss: 0.6100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9456/10000, Loss: 0.6100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9457/10000, Loss: 0.6100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9458/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9459/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9460/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9461/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9462/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9463/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9464/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9465/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9466/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9467/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9468/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9469/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9470/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9471/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9472/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9473/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9474/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9475/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9476/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9477/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9478/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9479/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9480/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9481/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9482/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9483/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9484/10000, Loss: 0.6099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9485/10000, Loss: 0.6098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9486/10000, Loss: 0.6098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9487/10000, Loss: 0.6098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9488/10000, Loss: 0.6098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9489/10000, Loss: 0.6098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9490/10000, Loss: 0.6098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9491/10000, Loss: 0.6098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9492/10000, Loss: 0.6098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9493/10000, Loss: 0.6098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9494/10000, Loss: 0.6098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9495/10000, Loss: 0.6098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9496/10000, Loss: 0.6098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9497/10000, Loss: 0.6098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9498/10000, Loss: 0.6098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9499/10000, Loss: 0.6098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9500/10000, Loss: 0.6098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9501/10000, Loss: 0.6098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9502/10000, Loss: 0.6098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9503/10000, Loss: 0.6098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9504/10000, Loss: 0.6098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9505/10000, Loss: 0.6098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9506/10000, Loss: 0.6098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9507/10000, Loss: 0.6098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9508/10000, Loss: 0.6098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9509/10000, Loss: 0.6098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9510/10000, Loss: 0.6098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9511/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9512/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9513/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9514/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9515/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9516/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9517/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9518/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9519/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9520/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9521/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9522/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9523/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9524/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9525/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9526/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9527/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9528/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9529/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9530/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9531/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9532/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9533/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9534/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9535/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9536/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9537/10000, Loss: 0.6097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9538/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9539/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9540/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9541/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9542/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9543/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9544/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9545/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9546/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9547/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9548/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9549/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9550/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9551/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9552/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9553/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9554/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9555/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9556/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9557/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9558/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9559/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9560/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9561/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9562/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9563/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9564/10000, Loss: 0.6096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9565/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9566/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9567/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9568/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9569/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9570/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9571/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9572/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9573/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9574/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9575/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9576/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9577/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9578/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9579/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9580/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9581/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9582/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9583/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9584/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9585/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9586/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9587/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9588/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9589/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9590/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9591/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9592/10000, Loss: 0.6095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9593/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9594/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9595/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9596/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9597/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9598/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9599/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9600/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9601/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9602/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9603/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9604/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9605/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9606/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9607/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9608/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9609/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9610/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9611/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9612/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9613/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9614/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9615/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9616/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9617/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9618/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9619/10000, Loss: 0.6094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9620/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9621/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9622/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9623/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9624/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9625/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9626/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9627/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9628/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9629/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9630/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9631/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9632/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9633/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9634/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9635/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9636/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9637/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9638/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9639/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9640/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9641/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9642/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9643/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9644/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9645/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9646/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9647/10000, Loss: 0.6093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9648/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9649/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9650/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9651/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9652/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9653/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9654/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9655/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9656/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9657/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9658/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9659/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9660/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9661/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9662/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9663/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9664/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9665/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9666/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9667/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9668/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9669/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9670/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9671/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9672/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9673/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9674/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9675/10000, Loss: 0.6092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9676/10000, Loss: 0.6091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9677/10000, Loss: 0.6091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9678/10000, Loss: 0.6091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9679/10000, Loss: 0.6091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9680/10000, Loss: 0.6091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9681/10000, Loss: 0.6091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9682/10000, Loss: 0.6091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9683/10000, Loss: 0.6091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9684/10000, Loss: 0.6091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9685/10000, Loss: 0.6091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9686/10000, Loss: 0.6091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9687/10000, Loss: 0.6091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9688/10000, Loss: 0.6091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9689/10000, Loss: 0.6091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9690/10000, Loss: 0.6091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9691/10000, Loss: 0.6091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9692/10000, Loss: 0.6091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9693/10000, Loss: 0.6091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9694/10000, Loss: 0.6091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9695/10000, Loss: 0.6091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9696/10000, Loss: 0.6091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9697/10000, Loss: 0.6091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9698/10000, Loss: 0.6091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9699/10000, Loss: 0.6091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9700/10000, Loss: 0.6091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 9701/10000, Loss: 0.6091, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9702/10000, Loss: 0.6091, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9703/10000, Loss: 0.6091, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9704/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9705/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9706/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9707/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9708/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9709/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9710/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9711/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9712/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9713/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9714/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9715/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9716/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9717/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9718/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9719/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9720/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9721/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9722/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9723/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9724/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9725/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9726/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9727/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9728/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9729/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9730/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9731/10000, Loss: 0.6090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9732/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9733/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9734/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9735/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9736/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9737/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9738/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9739/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9740/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9741/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9742/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9743/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9744/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9745/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9746/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9747/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9748/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9749/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9750/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9751/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9752/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9753/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9754/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9755/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9756/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9757/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9758/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9759/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9760/10000, Loss: 0.6089, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9761/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9762/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9763/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9764/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9765/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9766/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9767/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9768/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9769/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9770/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9771/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9772/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9773/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9774/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9775/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9776/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9777/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9778/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9779/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9780/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9781/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9782/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9783/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9784/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9785/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9786/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9787/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9788/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9789/10000, Loss: 0.6088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9790/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9791/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9792/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9793/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9794/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9795/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9796/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9797/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9798/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9799/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9800/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9801/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9802/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9803/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9804/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9805/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9806/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9807/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9808/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9809/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9810/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9811/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9812/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9813/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9814/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9815/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9816/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9817/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9818/10000, Loss: 0.6087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9819/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9820/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9821/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9822/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9823/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9824/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9825/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9826/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9827/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9828/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9829/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9830/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9831/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9832/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9833/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9834/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9835/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9836/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9837/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9838/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9839/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9840/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9841/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9842/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9843/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9844/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9845/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9846/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9847/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9848/10000, Loss: 0.6086, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9849/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9850/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9851/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9852/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9853/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9854/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9855/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9856/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9857/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9858/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9859/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9860/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9861/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9862/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9863/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9864/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9865/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9866/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9867/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9868/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9869/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9870/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9871/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9872/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9873/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9874/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9875/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9876/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9877/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9878/10000, Loss: 0.6085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9879/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9880/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9881/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9882/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9883/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9884/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9885/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9886/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9887/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9888/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9889/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9890/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9891/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9892/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9893/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9894/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9895/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9896/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9897/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9898/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9899/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9900/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9901/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9902/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9903/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9904/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9905/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9906/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9907/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9908/10000, Loss: 0.6084, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9909/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9910/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9911/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9912/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9913/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9914/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9915/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9916/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9917/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9918/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9919/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9920/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9921/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9922/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9923/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9924/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9925/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9926/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9927/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9928/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9929/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9930/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9931/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9932/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9933/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9934/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9935/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9936/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9937/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9938/10000, Loss: 0.6083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9939/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9940/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9941/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9942/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9943/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9944/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9945/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9946/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9947/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9948/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9949/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9950/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9951/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9952/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9953/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9954/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9955/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9956/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9957/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9958/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9959/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9960/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9961/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9962/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9963/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9964/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9965/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9966/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9967/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9968/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9969/10000, Loss: 0.6082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9970/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9971/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9972/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9973/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9974/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9975/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9976/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9977/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9978/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9979/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9980/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9981/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9982/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9983/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9984/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9985/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9986/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9987/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9988/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9989/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9990/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9991/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9992/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9993/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9994/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9995/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9996/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9997/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9998/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9999/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 10000/10000, Loss: 0.6081, Accuracy: 0.6538, Learning Rate: 0.000100\n"
     ]
    }
   ],
   "source": [
    "# training on validation dataset\n",
    "lr.fit(val_x,val_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebee4146-929f-4f6c-b3d4-b45b2a1f8243",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#validation loss vs validation accuracy\n",
    "\n",
    "lr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f8b4c36-e793-4f03-b389-55cb15f38cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a3389a4-6de5-4827-9c57-70336282f213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[107.  82.]\n",
      " [108. 240.]]\n",
      "Precision:  0.49767441860465117\n",
      "Recall:  0.5661375661375662\n",
      "Accuracy:  0.6461824953445066\n",
      "F1 Score:  0.5297029702970296\n"
     ]
    }
   ],
   "source": [
    "#Finding confusion matrix precision,recall and F1 score for different learning rates\n",
    "\n",
    "def confusion_matrix(x,y):\n",
    "    cmat = np.zeros((2,2))\n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "        if(x[i] == 1 and y[i] ==1):\n",
    "            cmat[0,0]+=1\n",
    "        elif(y[i]==1 and x[i]==0):\n",
    "            cmat[0,1]+=1\n",
    "        elif(y[i]==0 and x[i]==1):\n",
    "            cmat[1,0]+=1\n",
    "        else:\n",
    "            cmat[1,1]+=1\n",
    "\n",
    "    return cmat\n",
    "\n",
    "def performance_print(cmat):\n",
    "    precision = cmat[0,0]/(cmat[0,0]+cmat[1,0])\n",
    "\n",
    "    recall = cmat[0,0]/(cmat[0,0]+cmat[0,1])\n",
    "    \n",
    "    accuracy = (cmat[0,0]+cmat[1,1])/(cmat[0,0] + cmat[0,1] + cmat[1,0] + cmat[1,1])\n",
    "    \n",
    "    f1 = 2*(precision*recall)/(precision+recall)\n",
    "    \n",
    "    \n",
    "    print(\"Confusion matrix:\\n\",cmat)\n",
    "    print(\"Precision: \",precision)\n",
    "    print(\"Recall: \",recall)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print(\"F1 Score: \",f1)\n",
    "    \n",
    "\n",
    "train_pred = lr.predict(train_x)\n",
    "\n",
    "performance_print(confusion_matrix(train_pred,train_y))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66da3956-2b67-451a-8da0-a83fdd4e79b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression with regularization\n",
    "\n",
    "class LogisticRegression:\n",
    "\n",
    "    def __init__(self, learning_rate, epochs,reg,reg_param):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.b = 0.01\n",
    "        self.epochs = epochs\n",
    "        self.reg = reg\n",
    "        self.reg_param = reg_param\n",
    "        self.w = np.ones(x.shape[1])\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return np.where(z >= 0, 1 / (1 + np.exp(-z)), np.exp(z) / (1 + np.exp(z)))\n",
    "\n",
    "    def forward_pass(self, x):\n",
    "        z = np.dot(x, self.w) + self.b\n",
    "        predictions = self.sigmoid(z)\n",
    "        return predictions\n",
    "\n",
    "    def binary_cross_entropy(self, pred):\n",
    "        loss = -(self.y * np.log(pred + 1e-9) + (1 - self.y) * np.log(1 - pred + 1e-9))\n",
    "        return np.mean(loss)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.n = x.shape[0]\n",
    "        self.loss = []\n",
    "        self.accuracy = []  # Array to store accuracy values\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            predictions = self.forward_pass(x)\n",
    "            dw = db = 0\n",
    "            if(self.reg=='l1'):\n",
    "                dw = (1 / self.n) * np.dot(self.x.T, (predictions - self.y)) + self.reg_param*np.sum(np.abs(self.w))\n",
    "                db = (1 / self.n) * np.sum(predictions - self.y) + self.reg_param*np.sum(np.abs(self.w))\n",
    "            elif(self.reg=='l2'):\n",
    "                dw = (1 / self.n) * np.dot(self.x.T, (predictions - self.y)) + self.reg_param*np.sum(np.abs(self.w))\n",
    "                db = (1 / self.n) * np.sum(predictions - self.y) + self.reg_param*np.sum(np.abs(self.w))\n",
    "\n",
    "            self.w -= self.learning_rate * dw\n",
    "            self.b -= self.learning_rate * db\n",
    "\n",
    "            \n",
    "            l = self.binary_cross_entropy(predictions)\n",
    "\n",
    "            self.loss.append(l)\n",
    "\n",
    "            accuracy = self.compute_accuracy(predictions, y)\n",
    "            self.accuracy.append(accuracy)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{self.epochs}, Loss: {l:.4f}, Accuracy: {accuracy:.4f}, Learning Rate: {self.learning_rate:.6f}\")\n",
    "\n",
    "    def compute_accuracy(self, predictions, y):\n",
    "        predicted_labels = np.where(predictions >= 0.5, 1, 0)\n",
    "        correct_predictions = np.sum(predicted_labels == y)\n",
    "        accuracy = correct_predictions / len(y)\n",
    "        return accuracy\n",
    "\n",
    "    def plot(self):\n",
    "        plt.subplot(2,1,1)\n",
    "        plt.plot(lr.loss)\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Loss vs. Iteration')\n",
    "        \n",
    "        \n",
    "        plt.subplot(2,1,2)\n",
    "        plt.plot(lr.accuracy)\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.title('Accuracy vs. Iteration')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def predict(self, data):\n",
    "        z = np.dot(data, self.w) + self.b\n",
    "        predictions = self.sigmoid(z)\n",
    "        return np.where(predictions >= 0.5, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d07ecff-b322-4d3d-b3fb-c33d75d5f317",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5705/2119091274.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return np.where(z >= 0, 1 / (1 + np.exp(-z)), np.exp(z) / (1 + np.exp(z)))\n",
      "/tmp/ipykernel_5705/2119091274.py:14: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.where(z >= 0, 1 / (1 + np.exp(-z)), np.exp(z) / (1 + np.exp(z)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 2/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 3/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 4/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 5/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 6/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 7/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 8/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 9/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 10/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 11/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 12/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 13/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 14/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 15/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 16/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 17/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 18/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 19/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 20/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 21/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 22/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 23/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 24/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 25/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 26/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 27/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 28/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 29/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 30/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 31/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 32/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 33/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 34/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 35/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 36/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 37/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 38/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 39/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 40/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 41/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 42/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 43/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 44/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 45/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 46/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 47/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 48/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 49/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 50/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 51/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 52/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 53/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 54/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 55/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 56/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 57/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 58/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 59/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 60/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 61/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 62/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 63/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 64/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 65/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 66/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 67/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 68/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 69/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 70/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 71/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 72/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 73/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 74/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 75/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 76/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 77/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 78/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 79/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 80/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 81/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 82/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 83/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 84/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 85/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 86/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 87/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 88/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 89/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 90/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 91/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 92/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 93/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 94/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 95/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 96/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 97/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 98/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 99/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 100/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 101/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 102/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 103/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 104/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 105/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 106/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 107/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 108/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 109/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 110/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 111/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 112/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 113/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 114/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 115/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 116/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 117/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 118/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 119/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 120/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 121/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 122/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 123/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 124/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 125/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 126/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 127/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 128/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 129/10000, Loss: 13.4295, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 130/10000, Loss: 13.4294, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 131/10000, Loss: 13.4293, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 132/10000, Loss: 13.4291, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 133/10000, Loss: 13.4286, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 134/10000, Loss: 13.4279, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 135/10000, Loss: 13.4267, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 136/10000, Loss: 13.4250, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 137/10000, Loss: 13.4225, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 138/10000, Loss: 13.4194, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 139/10000, Loss: 13.4157, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 140/10000, Loss: 13.4116, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 141/10000, Loss: 13.4071, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 142/10000, Loss: 13.4024, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 143/10000, Loss: 13.3974, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 144/10000, Loss: 13.3921, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 145/10000, Loss: 13.3862, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 146/10000, Loss: 13.3796, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 147/10000, Loss: 13.3725, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 148/10000, Loss: 13.3650, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 149/10000, Loss: 13.3573, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 150/10000, Loss: 13.3495, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 151/10000, Loss: 13.3416, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 152/10000, Loss: 13.3337, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 153/10000, Loss: 13.3258, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 154/10000, Loss: 13.3179, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 155/10000, Loss: 13.3099, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 156/10000, Loss: 13.3016, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 157/10000, Loss: 13.2930, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 158/10000, Loss: 13.2838, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 159/10000, Loss: 13.2740, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 160/10000, Loss: 13.2636, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 161/10000, Loss: 13.2529, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 162/10000, Loss: 13.2421, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 163/10000, Loss: 13.2312, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 164/10000, Loss: 13.2205, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 165/10000, Loss: 13.2100, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 166/10000, Loss: 13.1997, Accuracy: 0.3538, Learning Rate: 0.000100\n",
      "Epoch 167/10000, Loss: 13.1893, Accuracy: 0.3538, Learning Rate: 0.000100\n",
      "Epoch 168/10000, Loss: 13.1788, Accuracy: 0.3557, Learning Rate: 0.000100\n",
      "Epoch 169/10000, Loss: 13.1683, Accuracy: 0.3575, Learning Rate: 0.000100\n",
      "Epoch 170/10000, Loss: 13.1583, Accuracy: 0.3575, Learning Rate: 0.000100\n",
      "Epoch 171/10000, Loss: 13.1483, Accuracy: 0.3594, Learning Rate: 0.000100\n",
      "Epoch 172/10000, Loss: 13.1373, Accuracy: 0.3631, Learning Rate: 0.000100\n",
      "Epoch 173/10000, Loss: 13.1239, Accuracy: 0.3631, Learning Rate: 0.000100\n",
      "Epoch 174/10000, Loss: 13.1073, Accuracy: 0.3631, Learning Rate: 0.000100\n",
      "Epoch 175/10000, Loss: 13.0868, Accuracy: 0.3631, Learning Rate: 0.000100\n",
      "Epoch 176/10000, Loss: 13.0616, Accuracy: 0.3613, Learning Rate: 0.000100\n",
      "Epoch 177/10000, Loss: 13.0318, Accuracy: 0.3613, Learning Rate: 0.000100\n",
      "Epoch 178/10000, Loss: 12.9967, Accuracy: 0.3594, Learning Rate: 0.000100\n",
      "Epoch 179/10000, Loss: 12.9552, Accuracy: 0.3594, Learning Rate: 0.000100\n",
      "Epoch 180/10000, Loss: 12.9064, Accuracy: 0.3594, Learning Rate: 0.000100\n",
      "Epoch 181/10000, Loss: 12.8513, Accuracy: 0.3594, Learning Rate: 0.000100\n",
      "Epoch 182/10000, Loss: 12.7915, Accuracy: 0.3594, Learning Rate: 0.000100\n",
      "Epoch 183/10000, Loss: 12.7282, Accuracy: 0.3594, Learning Rate: 0.000100\n",
      "Epoch 184/10000, Loss: 12.6629, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 185/10000, Loss: 12.5952, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 186/10000, Loss: 12.5239, Accuracy: 0.3501, Learning Rate: 0.000100\n",
      "Epoch 187/10000, Loss: 12.4481, Accuracy: 0.3482, Learning Rate: 0.000100\n",
      "Epoch 188/10000, Loss: 12.3648, Accuracy: 0.3464, Learning Rate: 0.000100\n",
      "Epoch 189/10000, Loss: 12.2713, Accuracy: 0.3464, Learning Rate: 0.000100\n",
      "Epoch 190/10000, Loss: 12.1677, Accuracy: 0.3501, Learning Rate: 0.000100\n",
      "Epoch 191/10000, Loss: 12.0574, Accuracy: 0.3482, Learning Rate: 0.000100\n",
      "Epoch 192/10000, Loss: 11.9455, Accuracy: 0.3445, Learning Rate: 0.000100\n",
      "Epoch 193/10000, Loss: 11.8334, Accuracy: 0.3464, Learning Rate: 0.000100\n",
      "Epoch 194/10000, Loss: 11.7188, Accuracy: 0.3464, Learning Rate: 0.000100\n",
      "Epoch 195/10000, Loss: 11.5993, Accuracy: 0.3557, Learning Rate: 0.000100\n",
      "Epoch 196/10000, Loss: 11.4740, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 197/10000, Loss: 11.3420, Accuracy: 0.3594, Learning Rate: 0.000100\n",
      "Epoch 198/10000, Loss: 11.2032, Accuracy: 0.3575, Learning Rate: 0.000100\n",
      "Epoch 199/10000, Loss: 11.0563, Accuracy: 0.3538, Learning Rate: 0.000100\n",
      "Epoch 200/10000, Loss: 10.9009, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 201/10000, Loss: 10.7425, Accuracy: 0.3557, Learning Rate: 0.000100\n",
      "Epoch 202/10000, Loss: 10.5843, Accuracy: 0.3613, Learning Rate: 0.000100\n",
      "Epoch 203/10000, Loss: 10.4276, Accuracy: 0.3706, Learning Rate: 0.000100\n",
      "Epoch 204/10000, Loss: 10.2741, Accuracy: 0.3743, Learning Rate: 0.000100\n",
      "Epoch 205/10000, Loss: 10.1241, Accuracy: 0.3762, Learning Rate: 0.000100\n",
      "Epoch 206/10000, Loss: 9.9776, Accuracy: 0.3743, Learning Rate: 0.000100\n",
      "Epoch 207/10000, Loss: 9.8368, Accuracy: 0.3855, Learning Rate: 0.000100\n",
      "Epoch 208/10000, Loss: 9.7002, Accuracy: 0.3855, Learning Rate: 0.000100\n",
      "Epoch 209/10000, Loss: 9.5617, Accuracy: 0.3799, Learning Rate: 0.000100\n",
      "Epoch 210/10000, Loss: 9.4165, Accuracy: 0.3855, Learning Rate: 0.000100\n",
      "Epoch 211/10000, Loss: 9.2648, Accuracy: 0.3873, Learning Rate: 0.000100\n",
      "Epoch 212/10000, Loss: 9.1056, Accuracy: 0.3873, Learning Rate: 0.000100\n",
      "Epoch 213/10000, Loss: 8.9404, Accuracy: 0.3855, Learning Rate: 0.000100\n",
      "Epoch 214/10000, Loss: 8.7757, Accuracy: 0.3911, Learning Rate: 0.000100\n",
      "Epoch 215/10000, Loss: 8.6153, Accuracy: 0.4022, Learning Rate: 0.000100\n",
      "Epoch 216/10000, Loss: 8.4626, Accuracy: 0.4078, Learning Rate: 0.000100\n",
      "Epoch 217/10000, Loss: 8.3193, Accuracy: 0.4097, Learning Rate: 0.000100\n",
      "Epoch 218/10000, Loss: 8.1858, Accuracy: 0.4153, Learning Rate: 0.000100\n",
      "Epoch 219/10000, Loss: 8.0609, Accuracy: 0.4153, Learning Rate: 0.000100\n",
      "Epoch 220/10000, Loss: 7.9435, Accuracy: 0.4209, Learning Rate: 0.000100\n",
      "Epoch 221/10000, Loss: 7.8348, Accuracy: 0.4209, Learning Rate: 0.000100\n",
      "Epoch 222/10000, Loss: 7.7333, Accuracy: 0.4190, Learning Rate: 0.000100\n",
      "Epoch 223/10000, Loss: 7.6397, Accuracy: 0.4246, Learning Rate: 0.000100\n",
      "Epoch 224/10000, Loss: 7.5547, Accuracy: 0.4246, Learning Rate: 0.000100\n",
      "Epoch 225/10000, Loss: 7.4782, Accuracy: 0.4302, Learning Rate: 0.000100\n",
      "Epoch 226/10000, Loss: 7.4101, Accuracy: 0.4376, Learning Rate: 0.000100\n",
      "Epoch 227/10000, Loss: 7.3505, Accuracy: 0.4395, Learning Rate: 0.000100\n",
      "Epoch 228/10000, Loss: 7.2993, Accuracy: 0.4432, Learning Rate: 0.000100\n",
      "Epoch 229/10000, Loss: 7.2550, Accuracy: 0.4488, Learning Rate: 0.000100\n",
      "Epoch 230/10000, Loss: 7.2151, Accuracy: 0.4525, Learning Rate: 0.000100\n",
      "Epoch 231/10000, Loss: 7.1785, Accuracy: 0.4562, Learning Rate: 0.000100\n",
      "Epoch 232/10000, Loss: 7.1445, Accuracy: 0.4637, Learning Rate: 0.000100\n",
      "Epoch 233/10000, Loss: 7.1129, Accuracy: 0.4655, Learning Rate: 0.000100\n",
      "Epoch 234/10000, Loss: 7.0839, Accuracy: 0.4655, Learning Rate: 0.000100\n",
      "Epoch 235/10000, Loss: 7.0574, Accuracy: 0.4674, Learning Rate: 0.000100\n",
      "Epoch 236/10000, Loss: 7.0334, Accuracy: 0.4693, Learning Rate: 0.000100\n",
      "Epoch 237/10000, Loss: 7.0116, Accuracy: 0.4711, Learning Rate: 0.000100\n",
      "Epoch 238/10000, Loss: 6.9917, Accuracy: 0.4767, Learning Rate: 0.000100\n",
      "Epoch 239/10000, Loss: 6.9735, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 240/10000, Loss: 6.9569, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 241/10000, Loss: 6.9416, Accuracy: 0.4823, Learning Rate: 0.000100\n",
      "Epoch 242/10000, Loss: 6.9275, Accuracy: 0.4823, Learning Rate: 0.000100\n",
      "Epoch 243/10000, Loss: 6.9145, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 244/10000, Loss: 6.9024, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 245/10000, Loss: 6.8911, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 246/10000, Loss: 6.8805, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 247/10000, Loss: 6.8705, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 248/10000, Loss: 6.8610, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 249/10000, Loss: 6.8520, Accuracy: 0.4823, Learning Rate: 0.000100\n",
      "Epoch 250/10000, Loss: 6.8434, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 251/10000, Loss: 6.8352, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 252/10000, Loss: 6.8274, Accuracy: 0.4767, Learning Rate: 0.000100\n",
      "Epoch 253/10000, Loss: 6.8198, Accuracy: 0.4749, Learning Rate: 0.000100\n",
      "Epoch 254/10000, Loss: 6.8125, Accuracy: 0.4767, Learning Rate: 0.000100\n",
      "Epoch 255/10000, Loss: 6.8055, Accuracy: 0.4767, Learning Rate: 0.000100\n",
      "Epoch 256/10000, Loss: 6.7986, Accuracy: 0.4767, Learning Rate: 0.000100\n",
      "Epoch 257/10000, Loss: 6.7920, Accuracy: 0.4767, Learning Rate: 0.000100\n",
      "Epoch 258/10000, Loss: 6.7855, Accuracy: 0.4767, Learning Rate: 0.000100\n",
      "Epoch 259/10000, Loss: 6.7792, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 260/10000, Loss: 6.7730, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 261/10000, Loss: 6.7670, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 262/10000, Loss: 6.7611, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 263/10000, Loss: 6.7553, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 264/10000, Loss: 6.7496, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 265/10000, Loss: 6.7439, Accuracy: 0.4804, Learning Rate: 0.000100\n",
      "Epoch 266/10000, Loss: 6.7384, Accuracy: 0.4804, Learning Rate: 0.000100\n",
      "Epoch 267/10000, Loss: 6.7329, Accuracy: 0.4804, Learning Rate: 0.000100\n",
      "Epoch 268/10000, Loss: 6.7275, Accuracy: 0.4823, Learning Rate: 0.000100\n",
      "Epoch 269/10000, Loss: 6.7222, Accuracy: 0.4823, Learning Rate: 0.000100\n",
      "Epoch 270/10000, Loss: 6.7169, Accuracy: 0.4823, Learning Rate: 0.000100\n",
      "Epoch 271/10000, Loss: 6.7117, Accuracy: 0.4823, Learning Rate: 0.000100\n",
      "Epoch 272/10000, Loss: 6.7066, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 273/10000, Loss: 6.7014, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 274/10000, Loss: 6.6964, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 275/10000, Loss: 6.6913, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 276/10000, Loss: 6.6863, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 277/10000, Loss: 6.6814, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 278/10000, Loss: 6.6764, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 279/10000, Loss: 6.6715, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 280/10000, Loss: 6.6666, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 281/10000, Loss: 6.6618, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 282/10000, Loss: 6.6570, Accuracy: 0.4879, Learning Rate: 0.000100\n",
      "Epoch 283/10000, Loss: 6.6522, Accuracy: 0.4879, Learning Rate: 0.000100\n",
      "Epoch 284/10000, Loss: 6.6474, Accuracy: 0.4879, Learning Rate: 0.000100\n",
      "Epoch 285/10000, Loss: 6.6426, Accuracy: 0.4879, Learning Rate: 0.000100\n",
      "Epoch 286/10000, Loss: 6.6378, Accuracy: 0.4879, Learning Rate: 0.000100\n",
      "Epoch 287/10000, Loss: 6.6331, Accuracy: 0.4879, Learning Rate: 0.000100\n",
      "Epoch 288/10000, Loss: 6.6284, Accuracy: 0.4879, Learning Rate: 0.000100\n",
      "Epoch 289/10000, Loss: 6.6237, Accuracy: 0.4879, Learning Rate: 0.000100\n",
      "Epoch 290/10000, Loss: 6.6190, Accuracy: 0.4879, Learning Rate: 0.000100\n",
      "Epoch 291/10000, Loss: 6.6143, Accuracy: 0.4879, Learning Rate: 0.000100\n",
      "Epoch 292/10000, Loss: 6.6097, Accuracy: 0.4879, Learning Rate: 0.000100\n",
      "Epoch 293/10000, Loss: 6.6050, Accuracy: 0.4879, Learning Rate: 0.000100\n",
      "Epoch 294/10000, Loss: 6.6004, Accuracy: 0.4879, Learning Rate: 0.000100\n",
      "Epoch 295/10000, Loss: 6.5957, Accuracy: 0.4879, Learning Rate: 0.000100\n",
      "Epoch 296/10000, Loss: 6.5911, Accuracy: 0.4879, Learning Rate: 0.000100\n",
      "Epoch 297/10000, Loss: 6.5865, Accuracy: 0.4879, Learning Rate: 0.000100\n",
      "Epoch 298/10000, Loss: 6.5819, Accuracy: 0.4879, Learning Rate: 0.000100\n",
      "Epoch 299/10000, Loss: 6.5773, Accuracy: 0.4879, Learning Rate: 0.000100\n",
      "Epoch 300/10000, Loss: 6.5727, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 301/10000, Loss: 6.5681, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 302/10000, Loss: 6.5636, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 303/10000, Loss: 6.5590, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 304/10000, Loss: 6.5544, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 305/10000, Loss: 6.5499, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 306/10000, Loss: 6.5453, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 307/10000, Loss: 6.5408, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 308/10000, Loss: 6.5362, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 309/10000, Loss: 6.5317, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 310/10000, Loss: 6.5272, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 311/10000, Loss: 6.5227, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 312/10000, Loss: 6.5181, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 313/10000, Loss: 6.5136, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 314/10000, Loss: 6.5091, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 315/10000, Loss: 6.5046, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 316/10000, Loss: 6.5001, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 317/10000, Loss: 6.4956, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 318/10000, Loss: 6.4911, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 319/10000, Loss: 6.4866, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 320/10000, Loss: 6.4821, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 321/10000, Loss: 6.4776, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 322/10000, Loss: 6.4732, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 323/10000, Loss: 6.4687, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 324/10000, Loss: 6.4642, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 325/10000, Loss: 6.4597, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 326/10000, Loss: 6.4553, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 327/10000, Loss: 6.4508, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 328/10000, Loss: 6.4463, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 329/10000, Loss: 6.4419, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 330/10000, Loss: 6.4374, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 331/10000, Loss: 6.4330, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 332/10000, Loss: 6.4285, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 333/10000, Loss: 6.4240, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 334/10000, Loss: 6.4196, Accuracy: 0.4879, Learning Rate: 0.000100\n",
      "Epoch 335/10000, Loss: 6.4151, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 336/10000, Loss: 6.4107, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 337/10000, Loss: 6.4063, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 338/10000, Loss: 6.4018, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 339/10000, Loss: 6.3974, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 340/10000, Loss: 6.3929, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 341/10000, Loss: 6.3885, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 342/10000, Loss: 6.3841, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 343/10000, Loss: 6.3796, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 344/10000, Loss: 6.3752, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 345/10000, Loss: 6.3708, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 346/10000, Loss: 6.3664, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 347/10000, Loss: 6.3619, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 348/10000, Loss: 6.3575, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 349/10000, Loss: 6.3531, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 350/10000, Loss: 6.3487, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 351/10000, Loss: 6.3443, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 352/10000, Loss: 6.3398, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 353/10000, Loss: 6.3354, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 354/10000, Loss: 6.3310, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 355/10000, Loss: 6.3266, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 356/10000, Loss: 6.3222, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 357/10000, Loss: 6.3178, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 358/10000, Loss: 6.3134, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 359/10000, Loss: 6.3090, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 360/10000, Loss: 6.3046, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 361/10000, Loss: 6.3001, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 362/10000, Loss: 6.2957, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 363/10000, Loss: 6.2913, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 364/10000, Loss: 6.2869, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 365/10000, Loss: 6.2825, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 366/10000, Loss: 6.2781, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 367/10000, Loss: 6.2737, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 368/10000, Loss: 6.2693, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 369/10000, Loss: 6.2649, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 370/10000, Loss: 6.2605, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 371/10000, Loss: 6.2561, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 372/10000, Loss: 6.2517, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 373/10000, Loss: 6.2473, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 374/10000, Loss: 6.2429, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 375/10000, Loss: 6.2385, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 376/10000, Loss: 6.2341, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 377/10000, Loss: 6.2297, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 378/10000, Loss: 6.2253, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 379/10000, Loss: 6.2209, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 380/10000, Loss: 6.2166, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 381/10000, Loss: 6.2122, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 382/10000, Loss: 6.2078, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 383/10000, Loss: 6.2034, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 384/10000, Loss: 6.1990, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 385/10000, Loss: 6.1945, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 386/10000, Loss: 6.1901, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 387/10000, Loss: 6.1857, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 388/10000, Loss: 6.1813, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 389/10000, Loss: 6.1769, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 390/10000, Loss: 6.1725, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 391/10000, Loss: 6.1681, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 392/10000, Loss: 6.1637, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 393/10000, Loss: 6.1593, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 394/10000, Loss: 6.1549, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 395/10000, Loss: 6.1505, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 396/10000, Loss: 6.1460, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 397/10000, Loss: 6.1416, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 398/10000, Loss: 6.1372, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 399/10000, Loss: 6.1328, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 400/10000, Loss: 6.1284, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 401/10000, Loss: 6.1239, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 402/10000, Loss: 6.1195, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 403/10000, Loss: 6.1151, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 404/10000, Loss: 6.1106, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 405/10000, Loss: 6.1062, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 406/10000, Loss: 6.1018, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 407/10000, Loss: 6.0973, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 408/10000, Loss: 6.0929, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 409/10000, Loss: 6.0884, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 410/10000, Loss: 6.0840, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 411/10000, Loss: 6.0795, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 412/10000, Loss: 6.0751, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 413/10000, Loss: 6.0706, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 414/10000, Loss: 6.0662, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 415/10000, Loss: 6.0617, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 416/10000, Loss: 6.0572, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 417/10000, Loss: 6.0528, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 418/10000, Loss: 6.0483, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 419/10000, Loss: 6.0439, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 420/10000, Loss: 6.0394, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 421/10000, Loss: 6.0349, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 422/10000, Loss: 6.0304, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 423/10000, Loss: 6.0260, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 424/10000, Loss: 6.0215, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 425/10000, Loss: 6.0170, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 426/10000, Loss: 6.0125, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 427/10000, Loss: 6.0080, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 428/10000, Loss: 6.0035, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 429/10000, Loss: 5.9991, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 430/10000, Loss: 5.9946, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 431/10000, Loss: 5.9901, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 432/10000, Loss: 5.9856, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 433/10000, Loss: 5.9811, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 434/10000, Loss: 5.9766, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 435/10000, Loss: 5.9721, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 436/10000, Loss: 5.9676, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 437/10000, Loss: 5.9631, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 438/10000, Loss: 5.9586, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 439/10000, Loss: 5.9541, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 440/10000, Loss: 5.9495, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 441/10000, Loss: 5.9450, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 442/10000, Loss: 5.9405, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 443/10000, Loss: 5.9360, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 444/10000, Loss: 5.9315, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 445/10000, Loss: 5.9270, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 446/10000, Loss: 5.9224, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 447/10000, Loss: 5.9179, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 448/10000, Loss: 5.9134, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 449/10000, Loss: 5.9089, Accuracy: 0.4991, Learning Rate: 0.000100\n",
      "Epoch 450/10000, Loss: 5.9043, Accuracy: 0.4991, Learning Rate: 0.000100\n",
      "Epoch 451/10000, Loss: 5.8998, Accuracy: 0.4991, Learning Rate: 0.000100\n",
      "Epoch 452/10000, Loss: 5.8953, Accuracy: 0.4991, Learning Rate: 0.000100\n",
      "Epoch 453/10000, Loss: 5.8907, Accuracy: 0.4991, Learning Rate: 0.000100\n",
      "Epoch 454/10000, Loss: 5.8862, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 455/10000, Loss: 5.8816, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 456/10000, Loss: 5.8771, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 457/10000, Loss: 5.8725, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 458/10000, Loss: 5.8680, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 459/10000, Loss: 5.8634, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 460/10000, Loss: 5.8589, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 461/10000, Loss: 5.8543, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 462/10000, Loss: 5.8498, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 463/10000, Loss: 5.8452, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 464/10000, Loss: 5.8406, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 465/10000, Loss: 5.8361, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 466/10000, Loss: 5.8315, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 467/10000, Loss: 5.8269, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 468/10000, Loss: 5.8224, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 469/10000, Loss: 5.8178, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 470/10000, Loss: 5.8132, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 471/10000, Loss: 5.8086, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 472/10000, Loss: 5.8040, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 473/10000, Loss: 5.7994, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 474/10000, Loss: 5.7949, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 475/10000, Loss: 5.7903, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 476/10000, Loss: 5.7857, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 477/10000, Loss: 5.7811, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 478/10000, Loss: 5.7765, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 479/10000, Loss: 5.7719, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 480/10000, Loss: 5.7673, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 481/10000, Loss: 5.7627, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 482/10000, Loss: 5.7580, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 483/10000, Loss: 5.7534, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 484/10000, Loss: 5.7488, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 485/10000, Loss: 5.7442, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 486/10000, Loss: 5.7396, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 487/10000, Loss: 5.7350, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 488/10000, Loss: 5.7304, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 489/10000, Loss: 5.7257, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 490/10000, Loss: 5.7211, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 491/10000, Loss: 5.7165, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 492/10000, Loss: 5.7118, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 493/10000, Loss: 5.7072, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 494/10000, Loss: 5.7026, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 495/10000, Loss: 5.6979, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 496/10000, Loss: 5.6933, Accuracy: 0.4991, Learning Rate: 0.000100\n",
      "Epoch 497/10000, Loss: 5.6887, Accuracy: 0.4991, Learning Rate: 0.000100\n",
      "Epoch 498/10000, Loss: 5.6840, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 499/10000, Loss: 5.6794, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 500/10000, Loss: 5.6747, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 501/10000, Loss: 5.6701, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 502/10000, Loss: 5.6654, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 503/10000, Loss: 5.6608, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 504/10000, Loss: 5.6561, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 505/10000, Loss: 5.6514, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 506/10000, Loss: 5.6468, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 507/10000, Loss: 5.6421, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 508/10000, Loss: 5.6374, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 509/10000, Loss: 5.6328, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 510/10000, Loss: 5.6281, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 511/10000, Loss: 5.6234, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 512/10000, Loss: 5.6187, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 513/10000, Loss: 5.6141, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 514/10000, Loss: 5.6094, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 515/10000, Loss: 5.6047, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 516/10000, Loss: 5.6000, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 517/10000, Loss: 5.5953, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 518/10000, Loss: 5.5906, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 519/10000, Loss: 5.5859, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 520/10000, Loss: 5.5812, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 521/10000, Loss: 5.5765, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 522/10000, Loss: 5.5718, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 523/10000, Loss: 5.5671, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 524/10000, Loss: 5.5624, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 525/10000, Loss: 5.5577, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 526/10000, Loss: 5.5529, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 527/10000, Loss: 5.5482, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 528/10000, Loss: 5.5435, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 529/10000, Loss: 5.5388, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 530/10000, Loss: 5.5341, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 531/10000, Loss: 5.5293, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 532/10000, Loss: 5.5246, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 533/10000, Loss: 5.5199, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 534/10000, Loss: 5.5151, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 535/10000, Loss: 5.5104, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 536/10000, Loss: 5.5057, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 537/10000, Loss: 5.5009, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 538/10000, Loss: 5.4962, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 539/10000, Loss: 5.4914, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 540/10000, Loss: 5.4867, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 541/10000, Loss: 5.4820, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 542/10000, Loss: 5.4772, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 543/10000, Loss: 5.4725, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 544/10000, Loss: 5.4677, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 545/10000, Loss: 5.4630, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 546/10000, Loss: 5.4582, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 547/10000, Loss: 5.4534, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 548/10000, Loss: 5.4487, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 549/10000, Loss: 5.4439, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 550/10000, Loss: 5.4392, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 551/10000, Loss: 5.4344, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 552/10000, Loss: 5.4296, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 553/10000, Loss: 5.4249, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 554/10000, Loss: 5.4201, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 555/10000, Loss: 5.4153, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 556/10000, Loss: 5.4106, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 557/10000, Loss: 5.4058, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 558/10000, Loss: 5.4010, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 559/10000, Loss: 5.3963, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 560/10000, Loss: 5.3915, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 561/10000, Loss: 5.3867, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 562/10000, Loss: 5.3820, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 563/10000, Loss: 5.3772, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 564/10000, Loss: 5.3724, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 565/10000, Loss: 5.3676, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 566/10000, Loss: 5.3629, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 567/10000, Loss: 5.3581, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 568/10000, Loss: 5.3533, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 569/10000, Loss: 5.3485, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 570/10000, Loss: 5.3437, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 571/10000, Loss: 5.3390, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 572/10000, Loss: 5.3342, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 573/10000, Loss: 5.3294, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 574/10000, Loss: 5.3246, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 575/10000, Loss: 5.3198, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 576/10000, Loss: 5.3150, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 577/10000, Loss: 5.3102, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 578/10000, Loss: 5.3055, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 579/10000, Loss: 5.3007, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 580/10000, Loss: 5.2959, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 581/10000, Loss: 5.2911, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 582/10000, Loss: 5.2863, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 583/10000, Loss: 5.2815, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 584/10000, Loss: 5.2767, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 585/10000, Loss: 5.2719, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 586/10000, Loss: 5.2671, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 587/10000, Loss: 5.2623, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 588/10000, Loss: 5.2575, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 589/10000, Loss: 5.2527, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 590/10000, Loss: 5.2479, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 591/10000, Loss: 5.2431, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 592/10000, Loss: 5.2383, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 593/10000, Loss: 5.2335, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 594/10000, Loss: 5.2286, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 595/10000, Loss: 5.2238, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 596/10000, Loss: 5.2190, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 597/10000, Loss: 5.2142, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 598/10000, Loss: 5.2094, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 599/10000, Loss: 5.2045, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 600/10000, Loss: 5.1997, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 601/10000, Loss: 5.1949, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 602/10000, Loss: 5.1900, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 603/10000, Loss: 5.1852, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 604/10000, Loss: 5.1804, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 605/10000, Loss: 5.1755, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 606/10000, Loss: 5.1707, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 607/10000, Loss: 5.1658, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 608/10000, Loss: 5.1610, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 609/10000, Loss: 5.1562, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 610/10000, Loss: 5.1513, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 611/10000, Loss: 5.1464, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 612/10000, Loss: 5.1416, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 613/10000, Loss: 5.1367, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 614/10000, Loss: 5.1319, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 615/10000, Loss: 5.1270, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 616/10000, Loss: 5.1221, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 617/10000, Loss: 5.1172, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 618/10000, Loss: 5.1124, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 619/10000, Loss: 5.1075, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 620/10000, Loss: 5.1026, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 621/10000, Loss: 5.0977, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 622/10000, Loss: 5.0928, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 623/10000, Loss: 5.0879, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 624/10000, Loss: 5.0831, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 625/10000, Loss: 5.0782, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 626/10000, Loss: 5.0733, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 627/10000, Loss: 5.0684, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 628/10000, Loss: 5.0634, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 629/10000, Loss: 5.0585, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 630/10000, Loss: 5.0536, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 631/10000, Loss: 5.0487, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 632/10000, Loss: 5.0438, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 633/10000, Loss: 5.0389, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 634/10000, Loss: 5.0340, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 635/10000, Loss: 5.0290, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 636/10000, Loss: 5.0241, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 637/10000, Loss: 5.0192, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 638/10000, Loss: 5.0142, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 639/10000, Loss: 5.0093, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 640/10000, Loss: 5.0044, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 641/10000, Loss: 4.9994, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 642/10000, Loss: 4.9945, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 643/10000, Loss: 4.9895, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 644/10000, Loss: 4.9846, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 645/10000, Loss: 4.9796, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 646/10000, Loss: 4.9747, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 647/10000, Loss: 4.9697, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 648/10000, Loss: 4.9647, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 649/10000, Loss: 4.9598, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 650/10000, Loss: 4.9548, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 651/10000, Loss: 4.9498, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 652/10000, Loss: 4.9449, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 653/10000, Loss: 4.9399, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 654/10000, Loss: 4.9349, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 655/10000, Loss: 4.9299, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 656/10000, Loss: 4.9249, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 657/10000, Loss: 4.9199, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 658/10000, Loss: 4.9149, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 659/10000, Loss: 4.9099, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 660/10000, Loss: 4.9049, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 661/10000, Loss: 4.8999, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 662/10000, Loss: 4.8949, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 663/10000, Loss: 4.8899, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 664/10000, Loss: 4.8849, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 665/10000, Loss: 4.8799, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 666/10000, Loss: 4.8749, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 667/10000, Loss: 4.8698, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 668/10000, Loss: 4.8648, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 669/10000, Loss: 4.8598, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 670/10000, Loss: 4.8548, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 671/10000, Loss: 4.8497, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 672/10000, Loss: 4.8447, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 673/10000, Loss: 4.8396, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 674/10000, Loss: 4.8346, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 675/10000, Loss: 4.8295, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 676/10000, Loss: 4.8245, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 677/10000, Loss: 4.8194, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 678/10000, Loss: 4.8144, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 679/10000, Loss: 4.8093, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 680/10000, Loss: 4.8042, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 681/10000, Loss: 4.7992, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 682/10000, Loss: 4.7941, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 683/10000, Loss: 4.7890, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 684/10000, Loss: 4.7839, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 685/10000, Loss: 4.7789, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 686/10000, Loss: 4.7738, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 687/10000, Loss: 4.7687, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 688/10000, Loss: 4.7636, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 689/10000, Loss: 4.7585, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 690/10000, Loss: 4.7534, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 691/10000, Loss: 4.7483, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 692/10000, Loss: 4.7432, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 693/10000, Loss: 4.7381, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 694/10000, Loss: 4.7330, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 695/10000, Loss: 4.7279, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 696/10000, Loss: 4.7227, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 697/10000, Loss: 4.7176, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 698/10000, Loss: 4.7125, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 699/10000, Loss: 4.7074, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 700/10000, Loss: 4.7022, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 701/10000, Loss: 4.6971, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 702/10000, Loss: 4.6920, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 703/10000, Loss: 4.6868, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 704/10000, Loss: 4.6817, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 705/10000, Loss: 4.6766, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 706/10000, Loss: 4.6714, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 707/10000, Loss: 4.6663, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 708/10000, Loss: 4.6611, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 709/10000, Loss: 4.6560, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 710/10000, Loss: 4.6508, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 711/10000, Loss: 4.6457, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 712/10000, Loss: 4.6405, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 713/10000, Loss: 4.6353, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 714/10000, Loss: 4.6302, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 715/10000, Loss: 4.6250, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 716/10000, Loss: 4.6198, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 717/10000, Loss: 4.6147, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 718/10000, Loss: 4.6095, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 719/10000, Loss: 4.6043, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 720/10000, Loss: 4.5992, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 721/10000, Loss: 4.5940, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 722/10000, Loss: 4.5888, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 723/10000, Loss: 4.5836, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 724/10000, Loss: 4.5785, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 725/10000, Loss: 4.5733, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 726/10000, Loss: 4.5681, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 727/10000, Loss: 4.5629, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 728/10000, Loss: 4.5577, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 729/10000, Loss: 4.5525, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 730/10000, Loss: 4.5474, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 731/10000, Loss: 4.5422, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 732/10000, Loss: 4.5370, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 733/10000, Loss: 4.5318, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 734/10000, Loss: 4.5266, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 735/10000, Loss: 4.5214, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 736/10000, Loss: 4.5162, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 737/10000, Loss: 4.5111, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 738/10000, Loss: 4.5059, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 739/10000, Loss: 4.5007, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 740/10000, Loss: 4.4955, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 741/10000, Loss: 4.4903, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 742/10000, Loss: 4.4851, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 743/10000, Loss: 4.4799, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 744/10000, Loss: 4.4748, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 745/10000, Loss: 4.4696, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 746/10000, Loss: 4.4644, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 747/10000, Loss: 4.4592, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 748/10000, Loss: 4.4540, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 749/10000, Loss: 4.4489, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 750/10000, Loss: 4.4437, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 751/10000, Loss: 4.4385, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 752/10000, Loss: 4.4334, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 753/10000, Loss: 4.4282, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 754/10000, Loss: 4.4230, Accuracy: 0.5196, Learning Rate: 0.000100\n",
      "Epoch 755/10000, Loss: 4.4179, Accuracy: 0.5196, Learning Rate: 0.000100\n",
      "Epoch 756/10000, Loss: 4.4127, Accuracy: 0.5196, Learning Rate: 0.000100\n",
      "Epoch 757/10000, Loss: 4.4075, Accuracy: 0.5196, Learning Rate: 0.000100\n",
      "Epoch 758/10000, Loss: 4.4024, Accuracy: 0.5196, Learning Rate: 0.000100\n",
      "Epoch 759/10000, Loss: 4.3972, Accuracy: 0.5196, Learning Rate: 0.000100\n",
      "Epoch 760/10000, Loss: 4.3921, Accuracy: 0.5214, Learning Rate: 0.000100\n",
      "Epoch 761/10000, Loss: 4.3870, Accuracy: 0.5214, Learning Rate: 0.000100\n",
      "Epoch 762/10000, Loss: 4.3818, Accuracy: 0.5214, Learning Rate: 0.000100\n",
      "Epoch 763/10000, Loss: 4.3767, Accuracy: 0.5214, Learning Rate: 0.000100\n",
      "Epoch 764/10000, Loss: 4.3715, Accuracy: 0.5214, Learning Rate: 0.000100\n",
      "Epoch 765/10000, Loss: 4.3664, Accuracy: 0.5214, Learning Rate: 0.000100\n",
      "Epoch 766/10000, Loss: 4.3613, Accuracy: 0.5233, Learning Rate: 0.000100\n",
      "Epoch 767/10000, Loss: 4.3562, Accuracy: 0.5233, Learning Rate: 0.000100\n",
      "Epoch 768/10000, Loss: 4.3511, Accuracy: 0.5233, Learning Rate: 0.000100\n",
      "Epoch 769/10000, Loss: 4.3459, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 770/10000, Loss: 4.3408, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 771/10000, Loss: 4.3357, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 772/10000, Loss: 4.3306, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 773/10000, Loss: 4.3255, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 774/10000, Loss: 4.3204, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 775/10000, Loss: 4.3154, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 776/10000, Loss: 4.3103, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 777/10000, Loss: 4.3052, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 778/10000, Loss: 4.3002, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 779/10000, Loss: 4.2951, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 780/10000, Loss: 4.2900, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 781/10000, Loss: 4.2850, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 782/10000, Loss: 4.2799, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 783/10000, Loss: 4.2749, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 784/10000, Loss: 4.2699, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 785/10000, Loss: 4.2649, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 786/10000, Loss: 4.2598, Accuracy: 0.5270, Learning Rate: 0.000100\n",
      "Epoch 787/10000, Loss: 4.2548, Accuracy: 0.5270, Learning Rate: 0.000100\n",
      "Epoch 788/10000, Loss: 4.2498, Accuracy: 0.5270, Learning Rate: 0.000100\n",
      "Epoch 789/10000, Loss: 4.2448, Accuracy: 0.5270, Learning Rate: 0.000100\n",
      "Epoch 790/10000, Loss: 4.2398, Accuracy: 0.5270, Learning Rate: 0.000100\n",
      "Epoch 791/10000, Loss: 4.2348, Accuracy: 0.5270, Learning Rate: 0.000100\n",
      "Epoch 792/10000, Loss: 4.2299, Accuracy: 0.5307, Learning Rate: 0.000100\n",
      "Epoch 793/10000, Loss: 4.2249, Accuracy: 0.5307, Learning Rate: 0.000100\n",
      "Epoch 794/10000, Loss: 4.2199, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 795/10000, Loss: 4.2150, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 796/10000, Loss: 4.2100, Accuracy: 0.5307, Learning Rate: 0.000100\n",
      "Epoch 797/10000, Loss: 4.2051, Accuracy: 0.5307, Learning Rate: 0.000100\n",
      "Epoch 798/10000, Loss: 4.2002, Accuracy: 0.5307, Learning Rate: 0.000100\n",
      "Epoch 799/10000, Loss: 4.1952, Accuracy: 0.5307, Learning Rate: 0.000100\n",
      "Epoch 800/10000, Loss: 4.1903, Accuracy: 0.5307, Learning Rate: 0.000100\n",
      "Epoch 801/10000, Loss: 4.1854, Accuracy: 0.5307, Learning Rate: 0.000100\n",
      "Epoch 802/10000, Loss: 4.1805, Accuracy: 0.5307, Learning Rate: 0.000100\n",
      "Epoch 803/10000, Loss: 4.1756, Accuracy: 0.5307, Learning Rate: 0.000100\n",
      "Epoch 804/10000, Loss: 4.1707, Accuracy: 0.5307, Learning Rate: 0.000100\n",
      "Epoch 805/10000, Loss: 4.1658, Accuracy: 0.5307, Learning Rate: 0.000100\n",
      "Epoch 806/10000, Loss: 4.1610, Accuracy: 0.5307, Learning Rate: 0.000100\n",
      "Epoch 807/10000, Loss: 4.1561, Accuracy: 0.5289, Learning Rate: 0.000100\n",
      "Epoch 808/10000, Loss: 4.1513, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 809/10000, Loss: 4.1464, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 810/10000, Loss: 4.1416, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 811/10000, Loss: 4.1367, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 812/10000, Loss: 4.1319, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 813/10000, Loss: 4.1271, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 814/10000, Loss: 4.1223, Accuracy: 0.5345, Learning Rate: 0.000100\n",
      "Epoch 815/10000, Loss: 4.1175, Accuracy: 0.5363, Learning Rate: 0.000100\n",
      "Epoch 816/10000, Loss: 4.1127, Accuracy: 0.5363, Learning Rate: 0.000100\n",
      "Epoch 817/10000, Loss: 4.1080, Accuracy: 0.5363, Learning Rate: 0.000100\n",
      "Epoch 818/10000, Loss: 4.1032, Accuracy: 0.5363, Learning Rate: 0.000100\n",
      "Epoch 819/10000, Loss: 4.0984, Accuracy: 0.5363, Learning Rate: 0.000100\n",
      "Epoch 820/10000, Loss: 4.0937, Accuracy: 0.5363, Learning Rate: 0.000100\n",
      "Epoch 821/10000, Loss: 4.0889, Accuracy: 0.5382, Learning Rate: 0.000100\n",
      "Epoch 822/10000, Loss: 4.0842, Accuracy: 0.5382, Learning Rate: 0.000100\n",
      "Epoch 823/10000, Loss: 4.0795, Accuracy: 0.5382, Learning Rate: 0.000100\n",
      "Epoch 824/10000, Loss: 4.0748, Accuracy: 0.5382, Learning Rate: 0.000100\n",
      "Epoch 825/10000, Loss: 4.0701, Accuracy: 0.5382, Learning Rate: 0.000100\n",
      "Epoch 826/10000, Loss: 4.0654, Accuracy: 0.5382, Learning Rate: 0.000100\n",
      "Epoch 827/10000, Loss: 4.0607, Accuracy: 0.5382, Learning Rate: 0.000100\n",
      "Epoch 828/10000, Loss: 4.0560, Accuracy: 0.5382, Learning Rate: 0.000100\n",
      "Epoch 829/10000, Loss: 4.0513, Accuracy: 0.5382, Learning Rate: 0.000100\n",
      "Epoch 830/10000, Loss: 4.0467, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 831/10000, Loss: 4.0420, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 832/10000, Loss: 4.0374, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 833/10000, Loss: 4.0328, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 834/10000, Loss: 4.0281, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 835/10000, Loss: 4.0235, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 836/10000, Loss: 4.0189, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 837/10000, Loss: 4.0143, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 838/10000, Loss: 4.0097, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 839/10000, Loss: 4.0052, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 840/10000, Loss: 4.0006, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 841/10000, Loss: 3.9960, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 842/10000, Loss: 3.9915, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 843/10000, Loss: 3.9869, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 844/10000, Loss: 3.9824, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 845/10000, Loss: 3.9779, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 846/10000, Loss: 3.9734, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 847/10000, Loss: 3.9689, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 848/10000, Loss: 3.9644, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 849/10000, Loss: 3.9599, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 850/10000, Loss: 3.9554, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 851/10000, Loss: 3.9509, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 852/10000, Loss: 3.9464, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 853/10000, Loss: 3.9420, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 854/10000, Loss: 3.9375, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 855/10000, Loss: 3.9331, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 856/10000, Loss: 3.9287, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 857/10000, Loss: 3.9242, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 858/10000, Loss: 3.9198, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 859/10000, Loss: 3.9154, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 860/10000, Loss: 3.9110, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 861/10000, Loss: 3.9066, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 862/10000, Loss: 3.9022, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 863/10000, Loss: 3.8979, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 864/10000, Loss: 3.8935, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 865/10000, Loss: 3.8891, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 866/10000, Loss: 3.8848, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 867/10000, Loss: 3.8804, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 868/10000, Loss: 3.8761, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 869/10000, Loss: 3.8717, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 870/10000, Loss: 3.8674, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 871/10000, Loss: 3.8631, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 872/10000, Loss: 3.8588, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 873/10000, Loss: 3.8545, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 874/10000, Loss: 3.8502, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 875/10000, Loss: 3.8459, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 876/10000, Loss: 3.8416, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 877/10000, Loss: 3.8373, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 878/10000, Loss: 3.8330, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 879/10000, Loss: 3.8288, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 880/10000, Loss: 3.8245, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 881/10000, Loss: 3.8202, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 882/10000, Loss: 3.8160, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 883/10000, Loss: 3.8118, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 884/10000, Loss: 3.8075, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 885/10000, Loss: 3.8033, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 886/10000, Loss: 3.7991, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 887/10000, Loss: 3.7949, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 888/10000, Loss: 3.7906, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 889/10000, Loss: 3.7864, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 890/10000, Loss: 3.7822, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 891/10000, Loss: 3.7781, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 892/10000, Loss: 3.7739, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 893/10000, Loss: 3.7697, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 894/10000, Loss: 3.7655, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 895/10000, Loss: 3.7613, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 896/10000, Loss: 3.7572, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 897/10000, Loss: 3.7530, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 898/10000, Loss: 3.7489, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 899/10000, Loss: 3.7447, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 900/10000, Loss: 3.7406, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 901/10000, Loss: 3.7365, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 902/10000, Loss: 3.7323, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 903/10000, Loss: 3.7282, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 904/10000, Loss: 3.7241, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 905/10000, Loss: 3.7200, Accuracy: 0.5493, Learning Rate: 0.000100\n",
      "Epoch 906/10000, Loss: 3.7159, Accuracy: 0.5493, Learning Rate: 0.000100\n",
      "Epoch 907/10000, Loss: 3.7118, Accuracy: 0.5493, Learning Rate: 0.000100\n",
      "Epoch 908/10000, Loss: 3.7077, Accuracy: 0.5493, Learning Rate: 0.000100\n",
      "Epoch 909/10000, Loss: 3.7036, Accuracy: 0.5493, Learning Rate: 0.000100\n",
      "Epoch 910/10000, Loss: 3.6995, Accuracy: 0.5493, Learning Rate: 0.000100\n",
      "Epoch 911/10000, Loss: 3.6955, Accuracy: 0.5493, Learning Rate: 0.000100\n",
      "Epoch 912/10000, Loss: 3.6914, Accuracy: 0.5493, Learning Rate: 0.000100\n",
      "Epoch 913/10000, Loss: 3.6873, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 914/10000, Loss: 3.6833, Accuracy: 0.5493, Learning Rate: 0.000100\n",
      "Epoch 915/10000, Loss: 3.6792, Accuracy: 0.5493, Learning Rate: 0.000100\n",
      "Epoch 916/10000, Loss: 3.6752, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 917/10000, Loss: 3.6711, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 918/10000, Loss: 3.6671, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 919/10000, Loss: 3.6631, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 920/10000, Loss: 3.6590, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 921/10000, Loss: 3.6550, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 922/10000, Loss: 3.6510, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 923/10000, Loss: 3.6470, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 924/10000, Loss: 3.6430, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 925/10000, Loss: 3.6390, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 926/10000, Loss: 3.6350, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 927/10000, Loss: 3.6310, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 928/10000, Loss: 3.6270, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 929/10000, Loss: 3.6231, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 930/10000, Loss: 3.6191, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 931/10000, Loss: 3.6151, Accuracy: 0.5531, Learning Rate: 0.000100\n",
      "Epoch 932/10000, Loss: 3.6112, Accuracy: 0.5549, Learning Rate: 0.000100\n",
      "Epoch 933/10000, Loss: 3.6072, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 934/10000, Loss: 3.6033, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 935/10000, Loss: 3.5993, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 936/10000, Loss: 3.5954, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 937/10000, Loss: 3.5915, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 938/10000, Loss: 3.5876, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 939/10000, Loss: 3.5836, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 940/10000, Loss: 3.5797, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 941/10000, Loss: 3.5758, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 942/10000, Loss: 3.5719, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 943/10000, Loss: 3.5680, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 944/10000, Loss: 3.5641, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 945/10000, Loss: 3.5603, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 946/10000, Loss: 3.5564, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 947/10000, Loss: 3.5525, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 948/10000, Loss: 3.5487, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 949/10000, Loss: 3.5448, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 950/10000, Loss: 3.5409, Accuracy: 0.5587, Learning Rate: 0.000100\n",
      "Epoch 951/10000, Loss: 3.5371, Accuracy: 0.5587, Learning Rate: 0.000100\n",
      "Epoch 952/10000, Loss: 3.5333, Accuracy: 0.5587, Learning Rate: 0.000100\n",
      "Epoch 953/10000, Loss: 3.5294, Accuracy: 0.5587, Learning Rate: 0.000100\n",
      "Epoch 954/10000, Loss: 3.5256, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 955/10000, Loss: 3.5218, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 956/10000, Loss: 3.5180, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 957/10000, Loss: 3.5142, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 958/10000, Loss: 3.5104, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 959/10000, Loss: 3.5066, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 960/10000, Loss: 3.5028, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 961/10000, Loss: 3.4990, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 962/10000, Loss: 3.4952, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 963/10000, Loss: 3.4914, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 964/10000, Loss: 3.4877, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 965/10000, Loss: 3.4839, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 966/10000, Loss: 3.4802, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 967/10000, Loss: 3.4764, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 968/10000, Loss: 3.4727, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 969/10000, Loss: 3.4689, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 970/10000, Loss: 3.4652, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 971/10000, Loss: 3.4615, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 972/10000, Loss: 3.4578, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 973/10000, Loss: 3.4541, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 974/10000, Loss: 3.4504, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 975/10000, Loss: 3.4467, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 976/10000, Loss: 3.4430, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 977/10000, Loss: 3.4393, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 978/10000, Loss: 3.4356, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 979/10000, Loss: 3.4320, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 980/10000, Loss: 3.4283, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 981/10000, Loss: 3.4247, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 982/10000, Loss: 3.4210, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 983/10000, Loss: 3.4174, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 984/10000, Loss: 3.4137, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 985/10000, Loss: 3.4101, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 986/10000, Loss: 3.4065, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 987/10000, Loss: 3.4029, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 988/10000, Loss: 3.3993, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 989/10000, Loss: 3.3957, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 990/10000, Loss: 3.3921, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 991/10000, Loss: 3.3885, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 992/10000, Loss: 3.3849, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 993/10000, Loss: 3.3813, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 994/10000, Loss: 3.3778, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 995/10000, Loss: 3.3742, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 996/10000, Loss: 3.3706, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 997/10000, Loss: 3.3671, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 998/10000, Loss: 3.3636, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 999/10000, Loss: 3.3600, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1000/10000, Loss: 3.3565, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1001/10000, Loss: 3.3530, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1002/10000, Loss: 3.3495, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1003/10000, Loss: 3.3460, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1004/10000, Loss: 3.3425, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1005/10000, Loss: 3.3390, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 1006/10000, Loss: 3.3355, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 1007/10000, Loss: 3.3320, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 1008/10000, Loss: 3.3285, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1009/10000, Loss: 3.3251, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1010/10000, Loss: 3.3216, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1011/10000, Loss: 3.3182, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1012/10000, Loss: 3.3147, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1013/10000, Loss: 3.3113, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1014/10000, Loss: 3.3079, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1015/10000, Loss: 3.3044, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1016/10000, Loss: 3.3010, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1017/10000, Loss: 3.2976, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1018/10000, Loss: 3.2942, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1019/10000, Loss: 3.2908, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1020/10000, Loss: 3.2874, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1021/10000, Loss: 3.2840, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1022/10000, Loss: 3.2806, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1023/10000, Loss: 3.2773, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1024/10000, Loss: 3.2739, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1025/10000, Loss: 3.2706, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1026/10000, Loss: 3.2672, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1027/10000, Loss: 3.2639, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1028/10000, Loss: 3.2605, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1029/10000, Loss: 3.2572, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1030/10000, Loss: 3.2539, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1031/10000, Loss: 3.2505, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1032/10000, Loss: 3.2472, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1033/10000, Loss: 3.2439, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1034/10000, Loss: 3.2406, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1035/10000, Loss: 3.2373, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1036/10000, Loss: 3.2341, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1037/10000, Loss: 3.2308, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1038/10000, Loss: 3.2275, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1039/10000, Loss: 3.2242, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1040/10000, Loss: 3.2210, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1041/10000, Loss: 3.2177, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1042/10000, Loss: 3.2145, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1043/10000, Loss: 3.2112, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1044/10000, Loss: 3.2080, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1045/10000, Loss: 3.2048, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1046/10000, Loss: 3.2015, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1047/10000, Loss: 3.1983, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1048/10000, Loss: 3.1951, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1049/10000, Loss: 3.1919, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1050/10000, Loss: 3.1887, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1051/10000, Loss: 3.1855, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1052/10000, Loss: 3.1823, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1053/10000, Loss: 3.1791, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1054/10000, Loss: 3.1760, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1055/10000, Loss: 3.1728, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1056/10000, Loss: 3.1696, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1057/10000, Loss: 3.1665, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1058/10000, Loss: 3.1633, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1059/10000, Loss: 3.1602, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1060/10000, Loss: 3.1570, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1061/10000, Loss: 3.1539, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1062/10000, Loss: 3.1508, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1063/10000, Loss: 3.1476, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1064/10000, Loss: 3.1445, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1065/10000, Loss: 3.1414, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1066/10000, Loss: 3.1383, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1067/10000, Loss: 3.1352, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1068/10000, Loss: 3.1321, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1069/10000, Loss: 3.1290, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1070/10000, Loss: 3.1259, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1071/10000, Loss: 3.1229, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1072/10000, Loss: 3.1198, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1073/10000, Loss: 3.1167, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1074/10000, Loss: 3.1137, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1075/10000, Loss: 3.1106, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1076/10000, Loss: 3.1075, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1077/10000, Loss: 3.1045, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1078/10000, Loss: 3.1015, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1079/10000, Loss: 3.0984, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1080/10000, Loss: 3.0954, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1081/10000, Loss: 3.0924, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1082/10000, Loss: 3.0894, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1083/10000, Loss: 3.0863, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1084/10000, Loss: 3.0833, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1085/10000, Loss: 3.0803, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1086/10000, Loss: 3.0773, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1087/10000, Loss: 3.0743, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1088/10000, Loss: 3.0714, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1089/10000, Loss: 3.0684, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1090/10000, Loss: 3.0654, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1091/10000, Loss: 3.0624, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1092/10000, Loss: 3.0595, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1093/10000, Loss: 3.0565, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1094/10000, Loss: 3.0536, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1095/10000, Loss: 3.0506, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1096/10000, Loss: 3.0477, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1097/10000, Loss: 3.0447, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1098/10000, Loss: 3.0418, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1099/10000, Loss: 3.0389, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1100/10000, Loss: 3.0359, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1101/10000, Loss: 3.0330, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1102/10000, Loss: 3.0301, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1103/10000, Loss: 3.0272, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1104/10000, Loss: 3.0243, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1105/10000, Loss: 3.0214, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1106/10000, Loss: 3.0185, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1107/10000, Loss: 3.0156, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1108/10000, Loss: 3.0127, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1109/10000, Loss: 3.0098, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1110/10000, Loss: 3.0070, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1111/10000, Loss: 3.0041, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1112/10000, Loss: 3.0012, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1113/10000, Loss: 2.9984, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1114/10000, Loss: 2.9955, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1115/10000, Loss: 2.9927, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1116/10000, Loss: 2.9898, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1117/10000, Loss: 2.9870, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1118/10000, Loss: 2.9841, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1119/10000, Loss: 2.9813, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1120/10000, Loss: 2.9785, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1121/10000, Loss: 2.9757, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1122/10000, Loss: 2.9729, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1123/10000, Loss: 2.9700, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1124/10000, Loss: 2.9672, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1125/10000, Loss: 2.9644, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1126/10000, Loss: 2.9616, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1127/10000, Loss: 2.9588, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1128/10000, Loss: 2.9561, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1129/10000, Loss: 2.9533, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1130/10000, Loss: 2.9505, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1131/10000, Loss: 2.9477, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1132/10000, Loss: 2.9450, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1133/10000, Loss: 2.9422, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1134/10000, Loss: 2.9394, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1135/10000, Loss: 2.9367, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1136/10000, Loss: 2.9339, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1137/10000, Loss: 2.9312, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1138/10000, Loss: 2.9284, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1139/10000, Loss: 2.9257, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1140/10000, Loss: 2.9230, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1141/10000, Loss: 2.9202, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1142/10000, Loss: 2.9175, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1143/10000, Loss: 2.9148, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1144/10000, Loss: 2.9121, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1145/10000, Loss: 2.9094, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1146/10000, Loss: 2.9067, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1147/10000, Loss: 2.9040, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1148/10000, Loss: 2.9013, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1149/10000, Loss: 2.8986, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1150/10000, Loss: 2.8959, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1151/10000, Loss: 2.8932, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1152/10000, Loss: 2.8905, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1153/10000, Loss: 2.8879, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1154/10000, Loss: 2.8852, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1155/10000, Loss: 2.8825, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1156/10000, Loss: 2.8799, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1157/10000, Loss: 2.8772, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1158/10000, Loss: 2.8746, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1159/10000, Loss: 2.8719, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1160/10000, Loss: 2.8693, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1161/10000, Loss: 2.8667, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1162/10000, Loss: 2.8640, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1163/10000, Loss: 2.8614, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1164/10000, Loss: 2.8588, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1165/10000, Loss: 2.8562, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1166/10000, Loss: 2.8535, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1167/10000, Loss: 2.8509, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1168/10000, Loss: 2.8483, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1169/10000, Loss: 2.8457, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1170/10000, Loss: 2.8431, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1171/10000, Loss: 2.8405, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1172/10000, Loss: 2.8379, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1173/10000, Loss: 2.8354, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1174/10000, Loss: 2.8328, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1175/10000, Loss: 2.8302, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1176/10000, Loss: 2.8276, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1177/10000, Loss: 2.8251, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1178/10000, Loss: 2.8225, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1179/10000, Loss: 2.8199, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1180/10000, Loss: 2.8174, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1181/10000, Loss: 2.8148, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1182/10000, Loss: 2.8123, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1183/10000, Loss: 2.8098, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1184/10000, Loss: 2.8072, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1185/10000, Loss: 2.8047, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1186/10000, Loss: 2.8022, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1187/10000, Loss: 2.7996, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1188/10000, Loss: 2.7971, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1189/10000, Loss: 2.7946, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1190/10000, Loss: 2.7921, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1191/10000, Loss: 2.7896, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1192/10000, Loss: 2.7871, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1193/10000, Loss: 2.7846, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1194/10000, Loss: 2.7821, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1195/10000, Loss: 2.7796, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1196/10000, Loss: 2.7771, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1197/10000, Loss: 2.7746, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1198/10000, Loss: 2.7721, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1199/10000, Loss: 2.7697, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1200/10000, Loss: 2.7672, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1201/10000, Loss: 2.7647, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1202/10000, Loss: 2.7623, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1203/10000, Loss: 2.7598, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1204/10000, Loss: 2.7574, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1205/10000, Loss: 2.7549, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1206/10000, Loss: 2.7525, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1207/10000, Loss: 2.7500, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1208/10000, Loss: 2.7476, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1209/10000, Loss: 2.7451, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1210/10000, Loss: 2.7427, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1211/10000, Loss: 2.7403, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1212/10000, Loss: 2.7379, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1213/10000, Loss: 2.7354, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1214/10000, Loss: 2.7330, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1215/10000, Loss: 2.7306, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1216/10000, Loss: 2.7282, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1217/10000, Loss: 2.7258, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1218/10000, Loss: 2.7234, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1219/10000, Loss: 2.7210, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1220/10000, Loss: 2.7186, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1221/10000, Loss: 2.7163, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1222/10000, Loss: 2.7139, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1223/10000, Loss: 2.7115, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1224/10000, Loss: 2.7091, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1225/10000, Loss: 2.7067, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1226/10000, Loss: 2.7044, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1227/10000, Loss: 2.7020, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1228/10000, Loss: 2.6997, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1229/10000, Loss: 2.6973, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1230/10000, Loss: 2.6950, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1231/10000, Loss: 2.6926, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1232/10000, Loss: 2.6903, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1233/10000, Loss: 2.6879, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1234/10000, Loss: 2.6856, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1235/10000, Loss: 2.6833, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1236/10000, Loss: 2.6809, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1237/10000, Loss: 2.6786, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1238/10000, Loss: 2.6763, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1239/10000, Loss: 2.6740, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1240/10000, Loss: 2.6716, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1241/10000, Loss: 2.6693, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1242/10000, Loss: 2.6670, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1243/10000, Loss: 2.6647, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1244/10000, Loss: 2.6624, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1245/10000, Loss: 2.6601, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1246/10000, Loss: 2.6578, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1247/10000, Loss: 2.6556, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1248/10000, Loss: 2.6533, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1249/10000, Loss: 2.6510, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1250/10000, Loss: 2.6487, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1251/10000, Loss: 2.6464, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1252/10000, Loss: 2.6442, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1253/10000, Loss: 2.6419, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1254/10000, Loss: 2.6397, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1255/10000, Loss: 2.6374, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1256/10000, Loss: 2.6351, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1257/10000, Loss: 2.6329, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1258/10000, Loss: 2.6306, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1259/10000, Loss: 2.6284, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1260/10000, Loss: 2.6262, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1261/10000, Loss: 2.6239, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1262/10000, Loss: 2.6217, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1263/10000, Loss: 2.6195, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1264/10000, Loss: 2.6172, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1265/10000, Loss: 2.6150, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1266/10000, Loss: 2.6128, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1267/10000, Loss: 2.6106, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1268/10000, Loss: 2.6084, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1269/10000, Loss: 2.6061, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1270/10000, Loss: 2.6039, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1271/10000, Loss: 2.6017, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1272/10000, Loss: 2.5995, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1273/10000, Loss: 2.5973, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1274/10000, Loss: 2.5951, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1275/10000, Loss: 2.5930, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1276/10000, Loss: 2.5908, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1277/10000, Loss: 2.5886, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1278/10000, Loss: 2.5864, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1279/10000, Loss: 2.5842, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1280/10000, Loss: 2.5821, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1281/10000, Loss: 2.5799, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1282/10000, Loss: 2.5777, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1283/10000, Loss: 2.5756, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1284/10000, Loss: 2.5734, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1285/10000, Loss: 2.5713, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1286/10000, Loss: 2.5691, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1287/10000, Loss: 2.5669, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1288/10000, Loss: 2.5648, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1289/10000, Loss: 2.5627, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1290/10000, Loss: 2.5605, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1291/10000, Loss: 2.5584, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1292/10000, Loss: 2.5563, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1293/10000, Loss: 2.5541, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1294/10000, Loss: 2.5520, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1295/10000, Loss: 2.5499, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1296/10000, Loss: 2.5478, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1297/10000, Loss: 2.5456, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1298/10000, Loss: 2.5435, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1299/10000, Loss: 2.5414, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1300/10000, Loss: 2.5393, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1301/10000, Loss: 2.5372, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1302/10000, Loss: 2.5351, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1303/10000, Loss: 2.5330, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1304/10000, Loss: 2.5309, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1305/10000, Loss: 2.5288, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1306/10000, Loss: 2.5267, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1307/10000, Loss: 2.5246, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1308/10000, Loss: 2.5226, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1309/10000, Loss: 2.5205, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1310/10000, Loss: 2.5184, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1311/10000, Loss: 2.5163, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1312/10000, Loss: 2.5143, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1313/10000, Loss: 2.5122, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1314/10000, Loss: 2.5101, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1315/10000, Loss: 2.5081, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1316/10000, Loss: 2.5060, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1317/10000, Loss: 2.5040, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1318/10000, Loss: 2.5019, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1319/10000, Loss: 2.4999, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1320/10000, Loss: 2.4978, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1321/10000, Loss: 2.4958, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1322/10000, Loss: 2.4937, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1323/10000, Loss: 2.4917, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1324/10000, Loss: 2.4897, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1325/10000, Loss: 2.4876, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1326/10000, Loss: 2.4856, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1327/10000, Loss: 2.4836, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1328/10000, Loss: 2.4815, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1329/10000, Loss: 2.4795, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1330/10000, Loss: 2.4775, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1331/10000, Loss: 2.4755, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1332/10000, Loss: 2.4735, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1333/10000, Loss: 2.4715, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1334/10000, Loss: 2.4695, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1335/10000, Loss: 2.4675, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1336/10000, Loss: 2.4655, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1337/10000, Loss: 2.4635, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1338/10000, Loss: 2.4615, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1339/10000, Loss: 2.4595, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1340/10000, Loss: 2.4575, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1341/10000, Loss: 2.4555, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1342/10000, Loss: 2.4536, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1343/10000, Loss: 2.4516, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1344/10000, Loss: 2.4496, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1345/10000, Loss: 2.4476, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1346/10000, Loss: 2.4457, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1347/10000, Loss: 2.4437, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1348/10000, Loss: 2.4417, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1349/10000, Loss: 2.4398, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1350/10000, Loss: 2.4378, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1351/10000, Loss: 2.4359, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1352/10000, Loss: 2.4339, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1353/10000, Loss: 2.4320, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1354/10000, Loss: 2.4300, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1355/10000, Loss: 2.4281, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1356/10000, Loss: 2.4261, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1357/10000, Loss: 2.4242, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1358/10000, Loss: 2.4223, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1359/10000, Loss: 2.4203, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1360/10000, Loss: 2.4184, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1361/10000, Loss: 2.4165, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1362/10000, Loss: 2.4145, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1363/10000, Loss: 2.4126, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1364/10000, Loss: 2.4107, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1365/10000, Loss: 2.4088, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1366/10000, Loss: 2.4069, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1367/10000, Loss: 2.4050, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1368/10000, Loss: 2.4031, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1369/10000, Loss: 2.4012, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1370/10000, Loss: 2.3993, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1371/10000, Loss: 2.3974, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1372/10000, Loss: 2.3955, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1373/10000, Loss: 2.3936, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1374/10000, Loss: 2.3917, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1375/10000, Loss: 2.3898, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1376/10000, Loss: 2.3879, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1377/10000, Loss: 2.3860, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1378/10000, Loss: 2.3841, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1379/10000, Loss: 2.3823, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1380/10000, Loss: 2.3804, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1381/10000, Loss: 2.3785, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1382/10000, Loss: 2.3767, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1383/10000, Loss: 2.3748, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1384/10000, Loss: 2.3729, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1385/10000, Loss: 2.3711, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1386/10000, Loss: 2.3692, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1387/10000, Loss: 2.3674, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1388/10000, Loss: 2.3655, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1389/10000, Loss: 2.3637, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1390/10000, Loss: 2.3618, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1391/10000, Loss: 2.3600, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1392/10000, Loss: 2.3581, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1393/10000, Loss: 2.3563, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1394/10000, Loss: 2.3545, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1395/10000, Loss: 2.3526, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1396/10000, Loss: 2.3508, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1397/10000, Loss: 2.3490, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1398/10000, Loss: 2.3471, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1399/10000, Loss: 2.3453, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1400/10000, Loss: 2.3435, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1401/10000, Loss: 2.3417, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1402/10000, Loss: 2.3399, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1403/10000, Loss: 2.3381, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1404/10000, Loss: 2.3363, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1405/10000, Loss: 2.3344, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1406/10000, Loss: 2.3326, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1407/10000, Loss: 2.3308, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1408/10000, Loss: 2.3290, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1409/10000, Loss: 2.3273, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1410/10000, Loss: 2.3255, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1411/10000, Loss: 2.3237, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1412/10000, Loss: 2.3219, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1413/10000, Loss: 2.3201, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1414/10000, Loss: 2.3183, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1415/10000, Loss: 2.3165, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1416/10000, Loss: 2.3148, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1417/10000, Loss: 2.3130, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1418/10000, Loss: 2.3112, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1419/10000, Loss: 2.3095, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1420/10000, Loss: 2.3077, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1421/10000, Loss: 2.3059, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1422/10000, Loss: 2.3042, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1423/10000, Loss: 2.3024, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1424/10000, Loss: 2.3007, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1425/10000, Loss: 2.2989, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1426/10000, Loss: 2.2971, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1427/10000, Loss: 2.2954, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1428/10000, Loss: 2.2937, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1429/10000, Loss: 2.2919, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1430/10000, Loss: 2.2902, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1431/10000, Loss: 2.2884, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1432/10000, Loss: 2.2867, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1433/10000, Loss: 2.2850, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1434/10000, Loss: 2.2832, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1435/10000, Loss: 2.2815, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1436/10000, Loss: 2.2798, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1437/10000, Loss: 2.2781, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1438/10000, Loss: 2.2764, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1439/10000, Loss: 2.2746, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1440/10000, Loss: 2.2729, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1441/10000, Loss: 2.2712, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1442/10000, Loss: 2.2695, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1443/10000, Loss: 2.2678, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1444/10000, Loss: 2.2661, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1445/10000, Loss: 2.2644, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1446/10000, Loss: 2.2627, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1447/10000, Loss: 2.2610, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1448/10000, Loss: 2.2593, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1449/10000, Loss: 2.2576, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1450/10000, Loss: 2.2559, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1451/10000, Loss: 2.2543, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1452/10000, Loss: 2.2526, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1453/10000, Loss: 2.2509, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1454/10000, Loss: 2.2492, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1455/10000, Loss: 2.2476, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1456/10000, Loss: 2.2459, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1457/10000, Loss: 2.2442, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1458/10000, Loss: 2.2425, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1459/10000, Loss: 2.2409, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1460/10000, Loss: 2.2392, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1461/10000, Loss: 2.2376, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1462/10000, Loss: 2.2359, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1463/10000, Loss: 2.2343, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1464/10000, Loss: 2.2326, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1465/10000, Loss: 2.2310, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1466/10000, Loss: 2.2293, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1467/10000, Loss: 2.2277, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1468/10000, Loss: 2.2260, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1469/10000, Loss: 2.2244, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1470/10000, Loss: 2.2228, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1471/10000, Loss: 2.2211, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1472/10000, Loss: 2.2195, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1473/10000, Loss: 2.2179, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1474/10000, Loss: 2.2162, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1475/10000, Loss: 2.2146, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1476/10000, Loss: 2.2130, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1477/10000, Loss: 2.2114, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1478/10000, Loss: 2.2098, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1479/10000, Loss: 2.2081, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1480/10000, Loss: 2.2065, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1481/10000, Loss: 2.2049, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1482/10000, Loss: 2.2033, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1483/10000, Loss: 2.2017, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1484/10000, Loss: 2.2001, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1485/10000, Loss: 2.1985, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1486/10000, Loss: 2.1969, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1487/10000, Loss: 2.1953, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1488/10000, Loss: 2.1938, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1489/10000, Loss: 2.1922, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1490/10000, Loss: 2.1906, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1491/10000, Loss: 2.1890, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1492/10000, Loss: 2.1874, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1493/10000, Loss: 2.1858, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1494/10000, Loss: 2.1843, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1495/10000, Loss: 2.1827, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1496/10000, Loss: 2.1811, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1497/10000, Loss: 2.1796, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1498/10000, Loss: 2.1780, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1499/10000, Loss: 2.1764, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1500/10000, Loss: 2.1749, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1501/10000, Loss: 2.1733, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1502/10000, Loss: 2.1718, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1503/10000, Loss: 2.1702, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1504/10000, Loss: 2.1687, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1505/10000, Loss: 2.1671, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1506/10000, Loss: 2.1656, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1507/10000, Loss: 2.1640, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1508/10000, Loss: 2.1625, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1509/10000, Loss: 2.1610, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1510/10000, Loss: 2.1594, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1511/10000, Loss: 2.1579, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1512/10000, Loss: 2.1564, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1513/10000, Loss: 2.1548, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1514/10000, Loss: 2.1533, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1515/10000, Loss: 2.1518, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1516/10000, Loss: 2.1503, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1517/10000, Loss: 2.1488, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1518/10000, Loss: 2.1472, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1519/10000, Loss: 2.1457, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1520/10000, Loss: 2.1442, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1521/10000, Loss: 2.1427, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1522/10000, Loss: 2.1412, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1523/10000, Loss: 2.1397, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1524/10000, Loss: 2.1382, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1525/10000, Loss: 2.1367, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1526/10000, Loss: 2.1352, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1527/10000, Loss: 2.1337, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1528/10000, Loss: 2.1322, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1529/10000, Loss: 2.1307, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1530/10000, Loss: 2.1293, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1531/10000, Loss: 2.1278, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1532/10000, Loss: 2.1263, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1533/10000, Loss: 2.1248, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1534/10000, Loss: 2.1233, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1535/10000, Loss: 2.1219, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1536/10000, Loss: 2.1204, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1537/10000, Loss: 2.1189, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1538/10000, Loss: 2.1175, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1539/10000, Loss: 2.1160, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1540/10000, Loss: 2.1145, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1541/10000, Loss: 2.1131, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1542/10000, Loss: 2.1116, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1543/10000, Loss: 2.1102, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1544/10000, Loss: 2.1087, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1545/10000, Loss: 2.1073, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1546/10000, Loss: 2.1058, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1547/10000, Loss: 2.1044, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1548/10000, Loss: 2.1030, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1549/10000, Loss: 2.1015, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1550/10000, Loss: 2.1001, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1551/10000, Loss: 2.0986, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1552/10000, Loss: 2.0972, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1553/10000, Loss: 2.0958, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1554/10000, Loss: 2.0944, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1555/10000, Loss: 2.0929, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1556/10000, Loss: 2.0915, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1557/10000, Loss: 2.0901, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1558/10000, Loss: 2.0887, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1559/10000, Loss: 2.0873, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1560/10000, Loss: 2.0858, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1561/10000, Loss: 2.0844, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1562/10000, Loss: 2.0830, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1563/10000, Loss: 2.0816, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1564/10000, Loss: 2.0802, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1565/10000, Loss: 2.0788, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1566/10000, Loss: 2.0774, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1567/10000, Loss: 2.0760, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1568/10000, Loss: 2.0746, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1569/10000, Loss: 2.0732, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1570/10000, Loss: 2.0719, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1571/10000, Loss: 2.0705, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1572/10000, Loss: 2.0691, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1573/10000, Loss: 2.0677, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1574/10000, Loss: 2.0663, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1575/10000, Loss: 2.0650, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1576/10000, Loss: 2.0636, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1577/10000, Loss: 2.0622, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1578/10000, Loss: 2.0608, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1579/10000, Loss: 2.0595, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1580/10000, Loss: 2.0581, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1581/10000, Loss: 2.0567, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1582/10000, Loss: 2.0554, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1583/10000, Loss: 2.0540, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1584/10000, Loss: 2.0527, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1585/10000, Loss: 2.0513, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1586/10000, Loss: 2.0500, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1587/10000, Loss: 2.0486, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1588/10000, Loss: 2.0473, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1589/10000, Loss: 2.0459, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1590/10000, Loss: 2.0446, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1591/10000, Loss: 2.0432, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1592/10000, Loss: 2.0419, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1593/10000, Loss: 2.0406, Accuracy: 0.5866, Learning Rate: 0.000100\n",
      "Epoch 1594/10000, Loss: 2.0392, Accuracy: 0.5866, Learning Rate: 0.000100\n",
      "Epoch 1595/10000, Loss: 2.0379, Accuracy: 0.5866, Learning Rate: 0.000100\n",
      "Epoch 1596/10000, Loss: 2.0366, Accuracy: 0.5866, Learning Rate: 0.000100\n",
      "Epoch 1597/10000, Loss: 2.0352, Accuracy: 0.5866, Learning Rate: 0.000100\n",
      "Epoch 1598/10000, Loss: 2.0339, Accuracy: 0.5866, Learning Rate: 0.000100\n",
      "Epoch 1599/10000, Loss: 2.0326, Accuracy: 0.5866, Learning Rate: 0.000100\n",
      "Epoch 1600/10000, Loss: 2.0313, Accuracy: 0.5866, Learning Rate: 0.000100\n",
      "Epoch 1601/10000, Loss: 2.0300, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1602/10000, Loss: 2.0286, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1603/10000, Loss: 2.0273, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1604/10000, Loss: 2.0260, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1605/10000, Loss: 2.0247, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1606/10000, Loss: 2.0234, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1607/10000, Loss: 2.0221, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1608/10000, Loss: 2.0208, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1609/10000, Loss: 2.0195, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1610/10000, Loss: 2.0182, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1611/10000, Loss: 2.0169, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1612/10000, Loss: 2.0156, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1613/10000, Loss: 2.0143, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1614/10000, Loss: 2.0130, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1615/10000, Loss: 2.0117, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1616/10000, Loss: 2.0104, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1617/10000, Loss: 2.0092, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1618/10000, Loss: 2.0079, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1619/10000, Loss: 2.0066, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1620/10000, Loss: 2.0053, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1621/10000, Loss: 2.0041, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1622/10000, Loss: 2.0028, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1623/10000, Loss: 2.0015, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1624/10000, Loss: 2.0002, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1625/10000, Loss: 1.9990, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1626/10000, Loss: 1.9977, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1627/10000, Loss: 1.9965, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1628/10000, Loss: 1.9952, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1629/10000, Loss: 1.9939, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1630/10000, Loss: 1.9927, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1631/10000, Loss: 1.9914, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1632/10000, Loss: 1.9902, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1633/10000, Loss: 1.9889, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1634/10000, Loss: 1.9877, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1635/10000, Loss: 1.9864, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1636/10000, Loss: 1.9852, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1637/10000, Loss: 1.9839, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1638/10000, Loss: 1.9827, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1639/10000, Loss: 1.9815, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1640/10000, Loss: 1.9802, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1641/10000, Loss: 1.9790, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1642/10000, Loss: 1.9778, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1643/10000, Loss: 1.9765, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1644/10000, Loss: 1.9753, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1645/10000, Loss: 1.9741, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1646/10000, Loss: 1.9729, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1647/10000, Loss: 1.9716, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1648/10000, Loss: 1.9704, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1649/10000, Loss: 1.9692, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1650/10000, Loss: 1.9680, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1651/10000, Loss: 1.9668, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1652/10000, Loss: 1.9656, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1653/10000, Loss: 1.9643, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1654/10000, Loss: 1.9631, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1655/10000, Loss: 1.9619, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1656/10000, Loss: 1.9607, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1657/10000, Loss: 1.9595, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1658/10000, Loss: 1.9583, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1659/10000, Loss: 1.9571, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1660/10000, Loss: 1.9559, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1661/10000, Loss: 1.9547, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1662/10000, Loss: 1.9535, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1663/10000, Loss: 1.9524, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1664/10000, Loss: 1.9512, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1665/10000, Loss: 1.9500, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1666/10000, Loss: 1.9488, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1667/10000, Loss: 1.9476, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1668/10000, Loss: 1.9464, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1669/10000, Loss: 1.9452, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1670/10000, Loss: 1.9441, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1671/10000, Loss: 1.9429, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1672/10000, Loss: 1.9417, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1673/10000, Loss: 1.9405, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1674/10000, Loss: 1.9394, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1675/10000, Loss: 1.9382, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1676/10000, Loss: 1.9370, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1677/10000, Loss: 1.9359, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1678/10000, Loss: 1.9347, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1679/10000, Loss: 1.9335, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1680/10000, Loss: 1.9324, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1681/10000, Loss: 1.9312, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1682/10000, Loss: 1.9301, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1683/10000, Loss: 1.9289, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1684/10000, Loss: 1.9278, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1685/10000, Loss: 1.9266, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1686/10000, Loss: 1.9255, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1687/10000, Loss: 1.9243, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1688/10000, Loss: 1.9232, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1689/10000, Loss: 1.9220, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1690/10000, Loss: 1.9209, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1691/10000, Loss: 1.9197, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1692/10000, Loss: 1.9186, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1693/10000, Loss: 1.9175, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1694/10000, Loss: 1.9163, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1695/10000, Loss: 1.9152, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1696/10000, Loss: 1.9141, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1697/10000, Loss: 1.9129, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1698/10000, Loss: 1.9118, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1699/10000, Loss: 1.9107, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1700/10000, Loss: 1.9095, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1701/10000, Loss: 1.9084, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1702/10000, Loss: 1.9073, Accuracy: 0.5996, Learning Rate: 0.000100\n",
      "Epoch 1703/10000, Loss: 1.9062, Accuracy: 0.5996, Learning Rate: 0.000100\n",
      "Epoch 1704/10000, Loss: 1.9050, Accuracy: 0.5996, Learning Rate: 0.000100\n",
      "Epoch 1705/10000, Loss: 1.9039, Accuracy: 0.5996, Learning Rate: 0.000100\n",
      "Epoch 1706/10000, Loss: 1.9028, Accuracy: 0.5996, Learning Rate: 0.000100\n",
      "Epoch 1707/10000, Loss: 1.9017, Accuracy: 0.5996, Learning Rate: 0.000100\n",
      "Epoch 1708/10000, Loss: 1.9006, Accuracy: 0.6015, Learning Rate: 0.000100\n",
      "Epoch 1709/10000, Loss: 1.8995, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1710/10000, Loss: 1.8984, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1711/10000, Loss: 1.8973, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1712/10000, Loss: 1.8961, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1713/10000, Loss: 1.8950, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1714/10000, Loss: 1.8939, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1715/10000, Loss: 1.8928, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1716/10000, Loss: 1.8917, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1717/10000, Loss: 1.8906, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1718/10000, Loss: 1.8895, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1719/10000, Loss: 1.8884, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1720/10000, Loss: 1.8873, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1721/10000, Loss: 1.8863, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1722/10000, Loss: 1.8852, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1723/10000, Loss: 1.8841, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1724/10000, Loss: 1.8830, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1725/10000, Loss: 1.8819, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1726/10000, Loss: 1.8808, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1727/10000, Loss: 1.8797, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1728/10000, Loss: 1.8786, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1729/10000, Loss: 1.8776, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1730/10000, Loss: 1.8765, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1731/10000, Loss: 1.8754, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1732/10000, Loss: 1.8743, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1733/10000, Loss: 1.8733, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1734/10000, Loss: 1.8722, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1735/10000, Loss: 1.8711, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1736/10000, Loss: 1.8700, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1737/10000, Loss: 1.8690, Accuracy: 0.6071, Learning Rate: 0.000100\n",
      "Epoch 1738/10000, Loss: 1.8679, Accuracy: 0.6071, Learning Rate: 0.000100\n",
      "Epoch 1739/10000, Loss: 1.8668, Accuracy: 0.6071, Learning Rate: 0.000100\n",
      "Epoch 1740/10000, Loss: 1.8658, Accuracy: 0.6071, Learning Rate: 0.000100\n",
      "Epoch 1741/10000, Loss: 1.8647, Accuracy: 0.6071, Learning Rate: 0.000100\n",
      "Epoch 1742/10000, Loss: 1.8636, Accuracy: 0.6071, Learning Rate: 0.000100\n",
      "Epoch 1743/10000, Loss: 1.8626, Accuracy: 0.6071, Learning Rate: 0.000100\n",
      "Epoch 1744/10000, Loss: 1.8615, Accuracy: 0.6071, Learning Rate: 0.000100\n",
      "Epoch 1745/10000, Loss: 1.8605, Accuracy: 0.6071, Learning Rate: 0.000100\n",
      "Epoch 1746/10000, Loss: 1.8594, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1747/10000, Loss: 1.8583, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1748/10000, Loss: 1.8573, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1749/10000, Loss: 1.8562, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1750/10000, Loss: 1.8552, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1751/10000, Loss: 1.8541, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1752/10000, Loss: 1.8531, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1753/10000, Loss: 1.8520, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1754/10000, Loss: 1.8510, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1755/10000, Loss: 1.8500, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1756/10000, Loss: 1.8489, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1757/10000, Loss: 1.8479, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1758/10000, Loss: 1.8468, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1759/10000, Loss: 1.8458, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1760/10000, Loss: 1.8448, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1761/10000, Loss: 1.8437, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1762/10000, Loss: 1.8427, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1763/10000, Loss: 1.8416, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1764/10000, Loss: 1.8406, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1765/10000, Loss: 1.8396, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1766/10000, Loss: 1.8386, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1767/10000, Loss: 1.8375, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1768/10000, Loss: 1.8365, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1769/10000, Loss: 1.8355, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1770/10000, Loss: 1.8344, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1771/10000, Loss: 1.8334, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1772/10000, Loss: 1.8324, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1773/10000, Loss: 1.8314, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1774/10000, Loss: 1.8304, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1775/10000, Loss: 1.8293, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1776/10000, Loss: 1.8283, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1777/10000, Loss: 1.8273, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1778/10000, Loss: 1.8263, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1779/10000, Loss: 1.8253, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1780/10000, Loss: 1.8243, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1781/10000, Loss: 1.8233, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1782/10000, Loss: 1.8223, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1783/10000, Loss: 1.8212, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1784/10000, Loss: 1.8202, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1785/10000, Loss: 1.8192, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1786/10000, Loss: 1.8182, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1787/10000, Loss: 1.8172, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1788/10000, Loss: 1.8162, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1789/10000, Loss: 1.8152, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1790/10000, Loss: 1.8142, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1791/10000, Loss: 1.8132, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1792/10000, Loss: 1.8122, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1793/10000, Loss: 1.8112, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1794/10000, Loss: 1.8102, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1795/10000, Loss: 1.8092, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1796/10000, Loss: 1.8082, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1797/10000, Loss: 1.8072, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1798/10000, Loss: 1.8063, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1799/10000, Loss: 1.8053, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1800/10000, Loss: 1.8043, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1801/10000, Loss: 1.8033, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1802/10000, Loss: 1.8023, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1803/10000, Loss: 1.8013, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1804/10000, Loss: 1.8003, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1805/10000, Loss: 1.7994, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1806/10000, Loss: 1.7984, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1807/10000, Loss: 1.7974, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1808/10000, Loss: 1.7964, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1809/10000, Loss: 1.7954, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1810/10000, Loss: 1.7945, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1811/10000, Loss: 1.7935, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1812/10000, Loss: 1.7925, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1813/10000, Loss: 1.7915, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1814/10000, Loss: 1.7906, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1815/10000, Loss: 1.7896, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1816/10000, Loss: 1.7886, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1817/10000, Loss: 1.7876, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1818/10000, Loss: 1.7867, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1819/10000, Loss: 1.7857, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1820/10000, Loss: 1.7847, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1821/10000, Loss: 1.7838, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1822/10000, Loss: 1.7828, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1823/10000, Loss: 1.7819, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1824/10000, Loss: 1.7809, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1825/10000, Loss: 1.7799, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1826/10000, Loss: 1.7790, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1827/10000, Loss: 1.7780, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1828/10000, Loss: 1.7771, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1829/10000, Loss: 1.7761, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1830/10000, Loss: 1.7751, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1831/10000, Loss: 1.7742, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1832/10000, Loss: 1.7732, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1833/10000, Loss: 1.7723, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1834/10000, Loss: 1.7713, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1835/10000, Loss: 1.7704, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1836/10000, Loss: 1.7694, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1837/10000, Loss: 1.7685, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1838/10000, Loss: 1.7675, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1839/10000, Loss: 1.7666, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1840/10000, Loss: 1.7656, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1841/10000, Loss: 1.7647, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1842/10000, Loss: 1.7638, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1843/10000, Loss: 1.7628, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1844/10000, Loss: 1.7619, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1845/10000, Loss: 1.7609, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1846/10000, Loss: 1.7600, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1847/10000, Loss: 1.7591, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1848/10000, Loss: 1.7581, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1849/10000, Loss: 1.7572, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1850/10000, Loss: 1.7562, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1851/10000, Loss: 1.7553, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1852/10000, Loss: 1.7544, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1853/10000, Loss: 1.7534, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1854/10000, Loss: 1.7525, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1855/10000, Loss: 1.7516, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1856/10000, Loss: 1.7507, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1857/10000, Loss: 1.7497, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1858/10000, Loss: 1.7488, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1859/10000, Loss: 1.7479, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1860/10000, Loss: 1.7469, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1861/10000, Loss: 1.7460, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1862/10000, Loss: 1.7451, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1863/10000, Loss: 1.7442, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1864/10000, Loss: 1.7433, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1865/10000, Loss: 1.7423, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1866/10000, Loss: 1.7414, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1867/10000, Loss: 1.7405, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1868/10000, Loss: 1.7396, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1869/10000, Loss: 1.7387, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1870/10000, Loss: 1.7377, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1871/10000, Loss: 1.7368, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1872/10000, Loss: 1.7359, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1873/10000, Loss: 1.7350, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1874/10000, Loss: 1.7341, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1875/10000, Loss: 1.7332, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1876/10000, Loss: 1.7323, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1877/10000, Loss: 1.7313, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1878/10000, Loss: 1.7304, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1879/10000, Loss: 1.7295, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1880/10000, Loss: 1.7286, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1881/10000, Loss: 1.7277, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1882/10000, Loss: 1.7268, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1883/10000, Loss: 1.7259, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1884/10000, Loss: 1.7250, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1885/10000, Loss: 1.7241, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1886/10000, Loss: 1.7232, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1887/10000, Loss: 1.7223, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1888/10000, Loss: 1.7214, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1889/10000, Loss: 1.7205, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1890/10000, Loss: 1.7196, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1891/10000, Loss: 1.7187, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1892/10000, Loss: 1.7178, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1893/10000, Loss: 1.7169, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1894/10000, Loss: 1.7160, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1895/10000, Loss: 1.7151, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1896/10000, Loss: 1.7142, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1897/10000, Loss: 1.7133, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1898/10000, Loss: 1.7124, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1899/10000, Loss: 1.7116, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1900/10000, Loss: 1.7107, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1901/10000, Loss: 1.7098, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1902/10000, Loss: 1.7089, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1903/10000, Loss: 1.7080, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1904/10000, Loss: 1.7071, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1905/10000, Loss: 1.7062, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1906/10000, Loss: 1.7053, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1907/10000, Loss: 1.7045, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1908/10000, Loss: 1.7036, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1909/10000, Loss: 1.7027, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1910/10000, Loss: 1.7018, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1911/10000, Loss: 1.7009, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1912/10000, Loss: 1.7001, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1913/10000, Loss: 1.6992, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1914/10000, Loss: 1.6983, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1915/10000, Loss: 1.6974, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1916/10000, Loss: 1.6965, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1917/10000, Loss: 1.6957, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1918/10000, Loss: 1.6948, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1919/10000, Loss: 1.6939, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1920/10000, Loss: 1.6930, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1921/10000, Loss: 1.6922, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1922/10000, Loss: 1.6913, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1923/10000, Loss: 1.6904, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1924/10000, Loss: 1.6896, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1925/10000, Loss: 1.6887, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1926/10000, Loss: 1.6878, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1927/10000, Loss: 1.6870, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1928/10000, Loss: 1.6861, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1929/10000, Loss: 1.6852, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1930/10000, Loss: 1.6844, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1931/10000, Loss: 1.6835, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1932/10000, Loss: 1.6826, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1933/10000, Loss: 1.6818, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1934/10000, Loss: 1.6809, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1935/10000, Loss: 1.6800, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1936/10000, Loss: 1.6792, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1937/10000, Loss: 1.6783, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1938/10000, Loss: 1.6775, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1939/10000, Loss: 1.6766, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1940/10000, Loss: 1.6757, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1941/10000, Loss: 1.6749, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1942/10000, Loss: 1.6740, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1943/10000, Loss: 1.6732, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1944/10000, Loss: 1.6723, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1945/10000, Loss: 1.6715, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1946/10000, Loss: 1.6706, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1947/10000, Loss: 1.6698, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1948/10000, Loss: 1.6689, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1949/10000, Loss: 1.6681, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1950/10000, Loss: 1.6672, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1951/10000, Loss: 1.6664, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1952/10000, Loss: 1.6655, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1953/10000, Loss: 1.6647, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1954/10000, Loss: 1.6638, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1955/10000, Loss: 1.6630, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1956/10000, Loss: 1.6621, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1957/10000, Loss: 1.6613, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1958/10000, Loss: 1.6604, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1959/10000, Loss: 1.6596, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1960/10000, Loss: 1.6588, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1961/10000, Loss: 1.6579, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1962/10000, Loss: 1.6571, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1963/10000, Loss: 1.6562, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1964/10000, Loss: 1.6554, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1965/10000, Loss: 1.6546, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1966/10000, Loss: 1.6537, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1967/10000, Loss: 1.6529, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 1968/10000, Loss: 1.6521, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1969/10000, Loss: 1.6512, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1970/10000, Loss: 1.6504, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1971/10000, Loss: 1.6495, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1972/10000, Loss: 1.6487, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1973/10000, Loss: 1.6479, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1974/10000, Loss: 1.6470, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1975/10000, Loss: 1.6462, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1976/10000, Loss: 1.6454, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1977/10000, Loss: 1.6446, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1978/10000, Loss: 1.6437, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1979/10000, Loss: 1.6429, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1980/10000, Loss: 1.6421, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1981/10000, Loss: 1.6412, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1982/10000, Loss: 1.6404, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1983/10000, Loss: 1.6396, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1984/10000, Loss: 1.6388, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1985/10000, Loss: 1.6379, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1986/10000, Loss: 1.6371, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1987/10000, Loss: 1.6363, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1988/10000, Loss: 1.6355, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1989/10000, Loss: 1.6347, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1990/10000, Loss: 1.6338, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1991/10000, Loss: 1.6330, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1992/10000, Loss: 1.6322, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1993/10000, Loss: 1.6314, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1994/10000, Loss: 1.6306, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1995/10000, Loss: 1.6297, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1996/10000, Loss: 1.6289, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1997/10000, Loss: 1.6281, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1998/10000, Loss: 1.6273, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1999/10000, Loss: 1.6265, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2000/10000, Loss: 1.6257, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2001/10000, Loss: 1.6249, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2002/10000, Loss: 1.6240, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2003/10000, Loss: 1.6232, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2004/10000, Loss: 1.6224, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2005/10000, Loss: 1.6216, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2006/10000, Loss: 1.6208, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2007/10000, Loss: 1.6200, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2008/10000, Loss: 1.6192, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2009/10000, Loss: 1.6184, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2010/10000, Loss: 1.6176, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2011/10000, Loss: 1.6168, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2012/10000, Loss: 1.6160, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2013/10000, Loss: 1.6152, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2014/10000, Loss: 1.6144, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2015/10000, Loss: 1.6135, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2016/10000, Loss: 1.6127, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2017/10000, Loss: 1.6119, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2018/10000, Loss: 1.6111, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2019/10000, Loss: 1.6103, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2020/10000, Loss: 1.6095, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2021/10000, Loss: 1.6087, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2022/10000, Loss: 1.6079, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2023/10000, Loss: 1.6071, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2024/10000, Loss: 1.6063, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2025/10000, Loss: 1.6056, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2026/10000, Loss: 1.6048, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2027/10000, Loss: 1.6040, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2028/10000, Loss: 1.6032, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2029/10000, Loss: 1.6024, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2030/10000, Loss: 1.6016, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2031/10000, Loss: 1.6008, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2032/10000, Loss: 1.6000, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2033/10000, Loss: 1.5992, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2034/10000, Loss: 1.5984, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2035/10000, Loss: 1.5976, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2036/10000, Loss: 1.5968, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2037/10000, Loss: 1.5960, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2038/10000, Loss: 1.5953, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2039/10000, Loss: 1.5945, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2040/10000, Loss: 1.5937, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2041/10000, Loss: 1.5929, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2042/10000, Loss: 1.5921, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2043/10000, Loss: 1.5913, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2044/10000, Loss: 1.5905, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2045/10000, Loss: 1.5898, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2046/10000, Loss: 1.5890, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2047/10000, Loss: 1.5882, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2048/10000, Loss: 1.5874, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2049/10000, Loss: 1.5866, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2050/10000, Loss: 1.5858, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2051/10000, Loss: 1.5851, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2052/10000, Loss: 1.5843, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2053/10000, Loss: 1.5835, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2054/10000, Loss: 1.5827, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2055/10000, Loss: 1.5820, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2056/10000, Loss: 1.5812, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2057/10000, Loss: 1.5804, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2058/10000, Loss: 1.5796, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2059/10000, Loss: 1.5789, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2060/10000, Loss: 1.5781, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2061/10000, Loss: 1.5773, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2062/10000, Loss: 1.5765, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2063/10000, Loss: 1.5758, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2064/10000, Loss: 1.5750, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2065/10000, Loss: 1.5742, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2066/10000, Loss: 1.5734, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2067/10000, Loss: 1.5727, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2068/10000, Loss: 1.5719, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2069/10000, Loss: 1.5711, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2070/10000, Loss: 1.5704, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2071/10000, Loss: 1.5696, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2072/10000, Loss: 1.5688, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2073/10000, Loss: 1.5681, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2074/10000, Loss: 1.5673, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2075/10000, Loss: 1.5665, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2076/10000, Loss: 1.5658, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2077/10000, Loss: 1.5650, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2078/10000, Loss: 1.5643, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2079/10000, Loss: 1.5635, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2080/10000, Loss: 1.5627, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2081/10000, Loss: 1.5620, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2082/10000, Loss: 1.5612, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2083/10000, Loss: 1.5604, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2084/10000, Loss: 1.5597, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2085/10000, Loss: 1.5589, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2086/10000, Loss: 1.5582, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2087/10000, Loss: 1.5574, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2088/10000, Loss: 1.5567, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2089/10000, Loss: 1.5559, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2090/10000, Loss: 1.5551, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2091/10000, Loss: 1.5544, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2092/10000, Loss: 1.5536, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2093/10000, Loss: 1.5529, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2094/10000, Loss: 1.5521, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2095/10000, Loss: 1.5514, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2096/10000, Loss: 1.5506, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2097/10000, Loss: 1.5499, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2098/10000, Loss: 1.5491, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2099/10000, Loss: 1.5484, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2100/10000, Loss: 1.5476, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2101/10000, Loss: 1.5469, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2102/10000, Loss: 1.5461, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2103/10000, Loss: 1.5454, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2104/10000, Loss: 1.5446, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2105/10000, Loss: 1.5439, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2106/10000, Loss: 1.5431, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2107/10000, Loss: 1.5424, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2108/10000, Loss: 1.5416, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2109/10000, Loss: 1.5409, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2110/10000, Loss: 1.5402, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2111/10000, Loss: 1.5394, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2112/10000, Loss: 1.5387, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2113/10000, Loss: 1.5379, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2114/10000, Loss: 1.5372, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2115/10000, Loss: 1.5364, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2116/10000, Loss: 1.5357, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2117/10000, Loss: 1.5350, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2118/10000, Loss: 1.5342, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2119/10000, Loss: 1.5335, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2120/10000, Loss: 1.5327, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2121/10000, Loss: 1.5320, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2122/10000, Loss: 1.5313, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2123/10000, Loss: 1.5305, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2124/10000, Loss: 1.5298, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2125/10000, Loss: 1.5291, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2126/10000, Loss: 1.5283, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2127/10000, Loss: 1.5276, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2128/10000, Loss: 1.5269, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2129/10000, Loss: 1.5261, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2130/10000, Loss: 1.5254, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2131/10000, Loss: 1.5247, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2132/10000, Loss: 1.5239, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2133/10000, Loss: 1.5232, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2134/10000, Loss: 1.5225, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2135/10000, Loss: 1.5217, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2136/10000, Loss: 1.5210, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2137/10000, Loss: 1.5203, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2138/10000, Loss: 1.5196, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2139/10000, Loss: 1.5188, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2140/10000, Loss: 1.5181, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2141/10000, Loss: 1.5174, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2142/10000, Loss: 1.5166, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2143/10000, Loss: 1.5159, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2144/10000, Loss: 1.5152, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2145/10000, Loss: 1.5145, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2146/10000, Loss: 1.5137, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2147/10000, Loss: 1.5130, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2148/10000, Loss: 1.5123, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2149/10000, Loss: 1.5116, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2150/10000, Loss: 1.5109, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2151/10000, Loss: 1.5101, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2152/10000, Loss: 1.5094, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2153/10000, Loss: 1.5087, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2154/10000, Loss: 1.5080, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2155/10000, Loss: 1.5073, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2156/10000, Loss: 1.5065, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2157/10000, Loss: 1.5058, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2158/10000, Loss: 1.5051, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2159/10000, Loss: 1.5044, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2160/10000, Loss: 1.5037, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2161/10000, Loss: 1.5030, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2162/10000, Loss: 1.5022, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2163/10000, Loss: 1.5015, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2164/10000, Loss: 1.5008, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2165/10000, Loss: 1.5001, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2166/10000, Loss: 1.4994, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2167/10000, Loss: 1.4987, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2168/10000, Loss: 1.4980, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2169/10000, Loss: 1.4973, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2170/10000, Loss: 1.4966, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2171/10000, Loss: 1.4958, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2172/10000, Loss: 1.4951, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2173/10000, Loss: 1.4944, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2174/10000, Loss: 1.4937, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2175/10000, Loss: 1.4930, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2176/10000, Loss: 1.4923, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2177/10000, Loss: 1.4916, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2178/10000, Loss: 1.4909, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2179/10000, Loss: 1.4902, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2180/10000, Loss: 1.4895, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2181/10000, Loss: 1.4888, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2182/10000, Loss: 1.4881, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2183/10000, Loss: 1.4874, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2184/10000, Loss: 1.4867, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2185/10000, Loss: 1.4860, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2186/10000, Loss: 1.4853, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2187/10000, Loss: 1.4846, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2188/10000, Loss: 1.4839, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2189/10000, Loss: 1.4832, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2190/10000, Loss: 1.4825, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2191/10000, Loss: 1.4818, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2192/10000, Loss: 1.4811, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2193/10000, Loss: 1.4804, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2194/10000, Loss: 1.4797, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2195/10000, Loss: 1.4790, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2196/10000, Loss: 1.4783, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2197/10000, Loss: 1.4776, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2198/10000, Loss: 1.4769, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2199/10000, Loss: 1.4762, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2200/10000, Loss: 1.4755, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2201/10000, Loss: 1.4748, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2202/10000, Loss: 1.4741, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2203/10000, Loss: 1.4734, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2204/10000, Loss: 1.4727, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2205/10000, Loss: 1.4720, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2206/10000, Loss: 1.4713, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2207/10000, Loss: 1.4706, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2208/10000, Loss: 1.4700, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2209/10000, Loss: 1.4693, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2210/10000, Loss: 1.4686, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2211/10000, Loss: 1.4679, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2212/10000, Loss: 1.4672, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2213/10000, Loss: 1.4665, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2214/10000, Loss: 1.4658, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2215/10000, Loss: 1.4651, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2216/10000, Loss: 1.4645, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2217/10000, Loss: 1.4638, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2218/10000, Loss: 1.4631, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2219/10000, Loss: 1.4624, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2220/10000, Loss: 1.4617, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2221/10000, Loss: 1.4610, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2222/10000, Loss: 1.4603, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2223/10000, Loss: 1.4597, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2224/10000, Loss: 1.4590, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2225/10000, Loss: 1.4583, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2226/10000, Loss: 1.4576, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2227/10000, Loss: 1.4569, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2228/10000, Loss: 1.4563, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2229/10000, Loss: 1.4556, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2230/10000, Loss: 1.4549, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2231/10000, Loss: 1.4542, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2232/10000, Loss: 1.4535, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2233/10000, Loss: 1.4529, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2234/10000, Loss: 1.4522, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2235/10000, Loss: 1.4515, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2236/10000, Loss: 1.4508, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2237/10000, Loss: 1.4502, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2238/10000, Loss: 1.4495, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2239/10000, Loss: 1.4488, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2240/10000, Loss: 1.4481, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2241/10000, Loss: 1.4475, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2242/10000, Loss: 1.4468, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2243/10000, Loss: 1.4461, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2244/10000, Loss: 1.4454, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2245/10000, Loss: 1.4448, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2246/10000, Loss: 1.4441, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2247/10000, Loss: 1.4434, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2248/10000, Loss: 1.4428, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2249/10000, Loss: 1.4421, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2250/10000, Loss: 1.4414, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2251/10000, Loss: 1.4408, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2252/10000, Loss: 1.4401, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2253/10000, Loss: 1.4394, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2254/10000, Loss: 1.4388, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2255/10000, Loss: 1.4381, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2256/10000, Loss: 1.4374, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2257/10000, Loss: 1.4368, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2258/10000, Loss: 1.4361, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2259/10000, Loss: 1.4354, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2260/10000, Loss: 1.4348, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2261/10000, Loss: 1.4341, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2262/10000, Loss: 1.4334, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2263/10000, Loss: 1.4328, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2264/10000, Loss: 1.4321, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2265/10000, Loss: 1.4315, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2266/10000, Loss: 1.4308, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2267/10000, Loss: 1.4301, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2268/10000, Loss: 1.4295, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2269/10000, Loss: 1.4288, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2270/10000, Loss: 1.4282, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2271/10000, Loss: 1.4275, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2272/10000, Loss: 1.4268, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2273/10000, Loss: 1.4262, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2274/10000, Loss: 1.4255, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2275/10000, Loss: 1.4249, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2276/10000, Loss: 1.4242, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2277/10000, Loss: 1.4236, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2278/10000, Loss: 1.4229, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2279/10000, Loss: 1.4222, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2280/10000, Loss: 1.4216, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2281/10000, Loss: 1.4209, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2282/10000, Loss: 1.4203, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2283/10000, Loss: 1.4196, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2284/10000, Loss: 1.4190, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2285/10000, Loss: 1.4183, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2286/10000, Loss: 1.4177, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2287/10000, Loss: 1.4170, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2288/10000, Loss: 1.4164, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2289/10000, Loss: 1.4157, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2290/10000, Loss: 1.4151, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2291/10000, Loss: 1.4144, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2292/10000, Loss: 1.4138, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2293/10000, Loss: 1.4131, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2294/10000, Loss: 1.4125, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2295/10000, Loss: 1.4118, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2296/10000, Loss: 1.4112, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2297/10000, Loss: 1.4105, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2298/10000, Loss: 1.4099, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2299/10000, Loss: 1.4093, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2300/10000, Loss: 1.4086, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2301/10000, Loss: 1.4080, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2302/10000, Loss: 1.4073, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2303/10000, Loss: 1.4067, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2304/10000, Loss: 1.4060, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2305/10000, Loss: 1.4054, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2306/10000, Loss: 1.4048, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2307/10000, Loss: 1.4041, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2308/10000, Loss: 1.4035, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2309/10000, Loss: 1.4028, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2310/10000, Loss: 1.4022, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2311/10000, Loss: 1.4016, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2312/10000, Loss: 1.4009, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2313/10000, Loss: 1.4003, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2314/10000, Loss: 1.3996, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2315/10000, Loss: 1.3990, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2316/10000, Loss: 1.3984, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2317/10000, Loss: 1.3977, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2318/10000, Loss: 1.3971, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2319/10000, Loss: 1.3965, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2320/10000, Loss: 1.3958, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2321/10000, Loss: 1.3952, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2322/10000, Loss: 1.3946, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2323/10000, Loss: 1.3939, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2324/10000, Loss: 1.3933, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2325/10000, Loss: 1.3927, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2326/10000, Loss: 1.3920, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2327/10000, Loss: 1.3914, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2328/10000, Loss: 1.3908, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2329/10000, Loss: 1.3901, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2330/10000, Loss: 1.3895, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2331/10000, Loss: 1.3889, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2332/10000, Loss: 1.3882, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2333/10000, Loss: 1.3876, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2334/10000, Loss: 1.3870, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2335/10000, Loss: 1.3864, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2336/10000, Loss: 1.3857, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2337/10000, Loss: 1.3851, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2338/10000, Loss: 1.3845, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2339/10000, Loss: 1.3839, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2340/10000, Loss: 1.3832, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2341/10000, Loss: 1.3826, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2342/10000, Loss: 1.3820, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2343/10000, Loss: 1.3814, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2344/10000, Loss: 1.3807, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2345/10000, Loss: 1.3801, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2346/10000, Loss: 1.3795, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2347/10000, Loss: 1.3789, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2348/10000, Loss: 1.3782, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2349/10000, Loss: 1.3776, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2350/10000, Loss: 1.3770, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2351/10000, Loss: 1.3764, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2352/10000, Loss: 1.3758, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2353/10000, Loss: 1.3751, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2354/10000, Loss: 1.3745, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2355/10000, Loss: 1.3739, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2356/10000, Loss: 1.3733, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2357/10000, Loss: 1.3727, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2358/10000, Loss: 1.3721, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2359/10000, Loss: 1.3714, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2360/10000, Loss: 1.3708, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2361/10000, Loss: 1.3702, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2362/10000, Loss: 1.3696, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2363/10000, Loss: 1.3690, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2364/10000, Loss: 1.3684, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2365/10000, Loss: 1.3677, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2366/10000, Loss: 1.3671, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2367/10000, Loss: 1.3665, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2368/10000, Loss: 1.3659, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2369/10000, Loss: 1.3653, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2370/10000, Loss: 1.3647, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2371/10000, Loss: 1.3641, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2372/10000, Loss: 1.3635, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2373/10000, Loss: 1.3629, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2374/10000, Loss: 1.3622, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2375/10000, Loss: 1.3616, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2376/10000, Loss: 1.3610, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2377/10000, Loss: 1.3604, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2378/10000, Loss: 1.3598, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2379/10000, Loss: 1.3592, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2380/10000, Loss: 1.3586, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2381/10000, Loss: 1.3580, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2382/10000, Loss: 1.3574, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2383/10000, Loss: 1.3568, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2384/10000, Loss: 1.3562, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2385/10000, Loss: 1.3556, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2386/10000, Loss: 1.3550, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2387/10000, Loss: 1.3544, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2388/10000, Loss: 1.3538, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2389/10000, Loss: 1.3532, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2390/10000, Loss: 1.3526, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2391/10000, Loss: 1.3520, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2392/10000, Loss: 1.3514, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2393/10000, Loss: 1.3508, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2394/10000, Loss: 1.3502, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2395/10000, Loss: 1.3496, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2396/10000, Loss: 1.3490, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2397/10000, Loss: 1.3484, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2398/10000, Loss: 1.3478, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2399/10000, Loss: 1.3472, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2400/10000, Loss: 1.3466, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2401/10000, Loss: 1.3460, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2402/10000, Loss: 1.3454, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2403/10000, Loss: 1.3448, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2404/10000, Loss: 1.3442, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2405/10000, Loss: 1.3436, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2406/10000, Loss: 1.3430, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2407/10000, Loss: 1.3424, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2408/10000, Loss: 1.3418, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2409/10000, Loss: 1.3412, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2410/10000, Loss: 1.3406, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2411/10000, Loss: 1.3400, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2412/10000, Loss: 1.3394, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2413/10000, Loss: 1.3388, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2414/10000, Loss: 1.3382, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2415/10000, Loss: 1.3377, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2416/10000, Loss: 1.3371, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2417/10000, Loss: 1.3365, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2418/10000, Loss: 1.3359, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2419/10000, Loss: 1.3353, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2420/10000, Loss: 1.3347, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2421/10000, Loss: 1.3341, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2422/10000, Loss: 1.3335, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2423/10000, Loss: 1.3329, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2424/10000, Loss: 1.3324, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2425/10000, Loss: 1.3318, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2426/10000, Loss: 1.3312, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2427/10000, Loss: 1.3306, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2428/10000, Loss: 1.3300, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2429/10000, Loss: 1.3294, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2430/10000, Loss: 1.3288, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2431/10000, Loss: 1.3283, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2432/10000, Loss: 1.3277, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2433/10000, Loss: 1.3271, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2434/10000, Loss: 1.3265, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2435/10000, Loss: 1.3259, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2436/10000, Loss: 1.3254, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2437/10000, Loss: 1.3248, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2438/10000, Loss: 1.3242, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2439/10000, Loss: 1.3236, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2440/10000, Loss: 1.3230, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2441/10000, Loss: 1.3225, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2442/10000, Loss: 1.3219, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2443/10000, Loss: 1.3213, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2444/10000, Loss: 1.3207, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2445/10000, Loss: 1.3201, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2446/10000, Loss: 1.3196, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2447/10000, Loss: 1.3190, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2448/10000, Loss: 1.3184, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2449/10000, Loss: 1.3178, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2450/10000, Loss: 1.3173, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2451/10000, Loss: 1.3167, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2452/10000, Loss: 1.3161, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2453/10000, Loss: 1.3155, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2454/10000, Loss: 1.3150, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2455/10000, Loss: 1.3144, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2456/10000, Loss: 1.3138, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2457/10000, Loss: 1.3133, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2458/10000, Loss: 1.3127, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2459/10000, Loss: 1.3121, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2460/10000, Loss: 1.3115, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2461/10000, Loss: 1.3110, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2462/10000, Loss: 1.3104, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2463/10000, Loss: 1.3098, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2464/10000, Loss: 1.3093, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2465/10000, Loss: 1.3087, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2466/10000, Loss: 1.3081, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2467/10000, Loss: 1.3076, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2468/10000, Loss: 1.3070, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2469/10000, Loss: 1.3064, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2470/10000, Loss: 1.3059, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2471/10000, Loss: 1.3053, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2472/10000, Loss: 1.3047, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2473/10000, Loss: 1.3042, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2474/10000, Loss: 1.3036, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2475/10000, Loss: 1.3030, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2476/10000, Loss: 1.3025, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2477/10000, Loss: 1.3019, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2478/10000, Loss: 1.3014, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2479/10000, Loss: 1.3008, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2480/10000, Loss: 1.3002, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2481/10000, Loss: 1.2997, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2482/10000, Loss: 1.2991, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2483/10000, Loss: 1.2986, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2484/10000, Loss: 1.2980, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2485/10000, Loss: 1.2974, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2486/10000, Loss: 1.2969, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2487/10000, Loss: 1.2963, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2488/10000, Loss: 1.2958, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2489/10000, Loss: 1.2952, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2490/10000, Loss: 1.2947, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2491/10000, Loss: 1.2941, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2492/10000, Loss: 1.2935, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2493/10000, Loss: 1.2930, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2494/10000, Loss: 1.2924, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2495/10000, Loss: 1.2919, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2496/10000, Loss: 1.2913, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2497/10000, Loss: 1.2908, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2498/10000, Loss: 1.2902, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2499/10000, Loss: 1.2897, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2500/10000, Loss: 1.2891, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2501/10000, Loss: 1.2886, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2502/10000, Loss: 1.2880, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2503/10000, Loss: 1.2875, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2504/10000, Loss: 1.2869, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2505/10000, Loss: 1.2864, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2506/10000, Loss: 1.2858, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2507/10000, Loss: 1.2853, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2508/10000, Loss: 1.2847, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2509/10000, Loss: 1.2842, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2510/10000, Loss: 1.2836, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2511/10000, Loss: 1.2831, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2512/10000, Loss: 1.2825, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2513/10000, Loss: 1.2820, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2514/10000, Loss: 1.2814, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2515/10000, Loss: 1.2809, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2516/10000, Loss: 1.2803, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2517/10000, Loss: 1.2798, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2518/10000, Loss: 1.2792, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2519/10000, Loss: 1.2787, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2520/10000, Loss: 1.2782, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2521/10000, Loss: 1.2776, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2522/10000, Loss: 1.2771, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2523/10000, Loss: 1.2765, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2524/10000, Loss: 1.2760, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2525/10000, Loss: 1.2754, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2526/10000, Loss: 1.2749, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2527/10000, Loss: 1.2744, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2528/10000, Loss: 1.2738, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2529/10000, Loss: 1.2733, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2530/10000, Loss: 1.2728, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2531/10000, Loss: 1.2722, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2532/10000, Loss: 1.2717, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2533/10000, Loss: 1.2711, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2534/10000, Loss: 1.2706, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2535/10000, Loss: 1.2701, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2536/10000, Loss: 1.2695, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2537/10000, Loss: 1.2690, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2538/10000, Loss: 1.2685, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2539/10000, Loss: 1.2679, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2540/10000, Loss: 1.2674, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2541/10000, Loss: 1.2669, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2542/10000, Loss: 1.2663, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2543/10000, Loss: 1.2658, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2544/10000, Loss: 1.2653, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2545/10000, Loss: 1.2647, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2546/10000, Loss: 1.2642, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2547/10000, Loss: 1.2637, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2548/10000, Loss: 1.2631, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2549/10000, Loss: 1.2626, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2550/10000, Loss: 1.2621, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2551/10000, Loss: 1.2615, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2552/10000, Loss: 1.2610, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2553/10000, Loss: 1.2605, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2554/10000, Loss: 1.2600, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2555/10000, Loss: 1.2594, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2556/10000, Loss: 1.2589, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2557/10000, Loss: 1.2584, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2558/10000, Loss: 1.2578, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2559/10000, Loss: 1.2573, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2560/10000, Loss: 1.2568, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2561/10000, Loss: 1.2563, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2562/10000, Loss: 1.2557, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2563/10000, Loss: 1.2552, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2564/10000, Loss: 1.2547, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2565/10000, Loss: 1.2542, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2566/10000, Loss: 1.2537, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2567/10000, Loss: 1.2531, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2568/10000, Loss: 1.2526, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2569/10000, Loss: 1.2521, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2570/10000, Loss: 1.2516, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2571/10000, Loss: 1.2510, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2572/10000, Loss: 1.2505, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2573/10000, Loss: 1.2500, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2574/10000, Loss: 1.2495, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2575/10000, Loss: 1.2490, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2576/10000, Loss: 1.2485, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2577/10000, Loss: 1.2479, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2578/10000, Loss: 1.2474, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2579/10000, Loss: 1.2469, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2580/10000, Loss: 1.2464, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2581/10000, Loss: 1.2459, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2582/10000, Loss: 1.2454, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2583/10000, Loss: 1.2448, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2584/10000, Loss: 1.2443, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2585/10000, Loss: 1.2438, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2586/10000, Loss: 1.2433, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2587/10000, Loss: 1.2428, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2588/10000, Loss: 1.2423, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2589/10000, Loss: 1.2418, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2590/10000, Loss: 1.2412, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2591/10000, Loss: 1.2407, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2592/10000, Loss: 1.2402, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2593/10000, Loss: 1.2397, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2594/10000, Loss: 1.2392, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2595/10000, Loss: 1.2387, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2596/10000, Loss: 1.2382, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2597/10000, Loss: 1.2377, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2598/10000, Loss: 1.2372, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2599/10000, Loss: 1.2367, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2600/10000, Loss: 1.2361, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2601/10000, Loss: 1.2356, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2602/10000, Loss: 1.2351, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2603/10000, Loss: 1.2346, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2604/10000, Loss: 1.2341, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2605/10000, Loss: 1.2336, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2606/10000, Loss: 1.2331, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2607/10000, Loss: 1.2326, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2608/10000, Loss: 1.2321, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2609/10000, Loss: 1.2316, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2610/10000, Loss: 1.2311, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2611/10000, Loss: 1.2306, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2612/10000, Loss: 1.2301, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2613/10000, Loss: 1.2296, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2614/10000, Loss: 1.2291, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2615/10000, Loss: 1.2286, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2616/10000, Loss: 1.2281, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2617/10000, Loss: 1.2276, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2618/10000, Loss: 1.2271, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2619/10000, Loss: 1.2266, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2620/10000, Loss: 1.2261, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2621/10000, Loss: 1.2256, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2622/10000, Loss: 1.2251, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2623/10000, Loss: 1.2246, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2624/10000, Loss: 1.2241, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2625/10000, Loss: 1.2236, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2626/10000, Loss: 1.2231, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2627/10000, Loss: 1.2226, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2628/10000, Loss: 1.2221, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2629/10000, Loss: 1.2216, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2630/10000, Loss: 1.2211, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2631/10000, Loss: 1.2206, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2632/10000, Loss: 1.2201, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2633/10000, Loss: 1.2196, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2634/10000, Loss: 1.2192, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2635/10000, Loss: 1.2187, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2636/10000, Loss: 1.2182, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2637/10000, Loss: 1.2177, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2638/10000, Loss: 1.2172, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2639/10000, Loss: 1.2167, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2640/10000, Loss: 1.2162, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2641/10000, Loss: 1.2157, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2642/10000, Loss: 1.2152, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2643/10000, Loss: 1.2147, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2644/10000, Loss: 1.2143, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2645/10000, Loss: 1.2138, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2646/10000, Loss: 1.2133, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2647/10000, Loss: 1.2128, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2648/10000, Loss: 1.2123, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2649/10000, Loss: 1.2118, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2650/10000, Loss: 1.2113, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2651/10000, Loss: 1.2109, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2652/10000, Loss: 1.2104, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2653/10000, Loss: 1.2099, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2654/10000, Loss: 1.2094, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2655/10000, Loss: 1.2089, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2656/10000, Loss: 1.2084, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2657/10000, Loss: 1.2080, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2658/10000, Loss: 1.2075, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2659/10000, Loss: 1.2070, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2660/10000, Loss: 1.2065, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2661/10000, Loss: 1.2060, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2662/10000, Loss: 1.2055, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2663/10000, Loss: 1.2051, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2664/10000, Loss: 1.2046, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2665/10000, Loss: 1.2041, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2666/10000, Loss: 1.2036, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2667/10000, Loss: 1.2032, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2668/10000, Loss: 1.2027, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2669/10000, Loss: 1.2022, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2670/10000, Loss: 1.2017, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2671/10000, Loss: 1.2012, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2672/10000, Loss: 1.2008, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2673/10000, Loss: 1.2003, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2674/10000, Loss: 1.1998, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2675/10000, Loss: 1.1993, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2676/10000, Loss: 1.1989, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2677/10000, Loss: 1.1984, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2678/10000, Loss: 1.1979, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2679/10000, Loss: 1.1975, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2680/10000, Loss: 1.1970, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2681/10000, Loss: 1.1965, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2682/10000, Loss: 1.1960, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2683/10000, Loss: 1.1956, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2684/10000, Loss: 1.1951, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2685/10000, Loss: 1.1946, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2686/10000, Loss: 1.1942, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2687/10000, Loss: 1.1937, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2688/10000, Loss: 1.1932, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2689/10000, Loss: 1.1927, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2690/10000, Loss: 1.1923, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2691/10000, Loss: 1.1918, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2692/10000, Loss: 1.1913, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2693/10000, Loss: 1.1909, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2694/10000, Loss: 1.1904, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2695/10000, Loss: 1.1899, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2696/10000, Loss: 1.1895, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2697/10000, Loss: 1.1890, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2698/10000, Loss: 1.1886, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2699/10000, Loss: 1.1881, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2700/10000, Loss: 1.1876, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2701/10000, Loss: 1.1872, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2702/10000, Loss: 1.1867, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2703/10000, Loss: 1.1862, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2704/10000, Loss: 1.1858, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2705/10000, Loss: 1.1853, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2706/10000, Loss: 1.1849, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2707/10000, Loss: 1.1844, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2708/10000, Loss: 1.1839, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2709/10000, Loss: 1.1835, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2710/10000, Loss: 1.1830, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2711/10000, Loss: 1.1826, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2712/10000, Loss: 1.1821, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2713/10000, Loss: 1.1816, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2714/10000, Loss: 1.1812, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2715/10000, Loss: 1.1807, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2716/10000, Loss: 1.1803, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2717/10000, Loss: 1.1798, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2718/10000, Loss: 1.1794, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2719/10000, Loss: 1.1789, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2720/10000, Loss: 1.1784, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2721/10000, Loss: 1.1780, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2722/10000, Loss: 1.1775, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2723/10000, Loss: 1.1771, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2724/10000, Loss: 1.1766, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2725/10000, Loss: 1.1762, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2726/10000, Loss: 1.1757, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2727/10000, Loss: 1.1753, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2728/10000, Loss: 1.1748, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2729/10000, Loss: 1.1744, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2730/10000, Loss: 1.1739, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2731/10000, Loss: 1.1735, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2732/10000, Loss: 1.1730, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2733/10000, Loss: 1.1726, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2734/10000, Loss: 1.1721, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2735/10000, Loss: 1.1717, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2736/10000, Loss: 1.1712, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2737/10000, Loss: 1.1708, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2738/10000, Loss: 1.1703, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2739/10000, Loss: 1.1699, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2740/10000, Loss: 1.1694, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2741/10000, Loss: 1.1690, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2742/10000, Loss: 1.1686, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2743/10000, Loss: 1.1681, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2744/10000, Loss: 1.1677, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2745/10000, Loss: 1.1672, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2746/10000, Loss: 1.1668, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2747/10000, Loss: 1.1663, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2748/10000, Loss: 1.1659, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2749/10000, Loss: 1.1654, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2750/10000, Loss: 1.1650, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2751/10000, Loss: 1.1646, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2752/10000, Loss: 1.1641, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2753/10000, Loss: 1.1637, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2754/10000, Loss: 1.1632, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2755/10000, Loss: 1.1628, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2756/10000, Loss: 1.1624, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2757/10000, Loss: 1.1619, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2758/10000, Loss: 1.1615, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2759/10000, Loss: 1.1611, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2760/10000, Loss: 1.1606, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2761/10000, Loss: 1.1602, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2762/10000, Loss: 1.1597, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2763/10000, Loss: 1.1593, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2764/10000, Loss: 1.1589, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2765/10000, Loss: 1.1584, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2766/10000, Loss: 1.1580, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2767/10000, Loss: 1.1576, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2768/10000, Loss: 1.1571, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2769/10000, Loss: 1.1567, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2770/10000, Loss: 1.1563, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2771/10000, Loss: 1.1558, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2772/10000, Loss: 1.1554, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2773/10000, Loss: 1.1550, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2774/10000, Loss: 1.1545, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2775/10000, Loss: 1.1541, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2776/10000, Loss: 1.1537, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2777/10000, Loss: 1.1532, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2778/10000, Loss: 1.1528, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2779/10000, Loss: 1.1524, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2780/10000, Loss: 1.1520, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2781/10000, Loss: 1.1515, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2782/10000, Loss: 1.1511, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2783/10000, Loss: 1.1507, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2784/10000, Loss: 1.1502, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2785/10000, Loss: 1.1498, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2786/10000, Loss: 1.1494, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2787/10000, Loss: 1.1490, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2788/10000, Loss: 1.1485, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2789/10000, Loss: 1.1481, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2790/10000, Loss: 1.1477, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2791/10000, Loss: 1.1473, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2792/10000, Loss: 1.1468, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2793/10000, Loss: 1.1464, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2794/10000, Loss: 1.1460, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2795/10000, Loss: 1.1456, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2796/10000, Loss: 1.1451, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2797/10000, Loss: 1.1447, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2798/10000, Loss: 1.1443, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2799/10000, Loss: 1.1439, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2800/10000, Loss: 1.1435, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2801/10000, Loss: 1.1430, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2802/10000, Loss: 1.1426, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2803/10000, Loss: 1.1422, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2804/10000, Loss: 1.1418, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2805/10000, Loss: 1.1414, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2806/10000, Loss: 1.1410, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2807/10000, Loss: 1.1405, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2808/10000, Loss: 1.1401, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2809/10000, Loss: 1.1397, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2810/10000, Loss: 1.1393, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2811/10000, Loss: 1.1389, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2812/10000, Loss: 1.1385, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2813/10000, Loss: 1.1380, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2814/10000, Loss: 1.1376, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2815/10000, Loss: 1.1372, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2816/10000, Loss: 1.1368, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2817/10000, Loss: 1.1364, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2818/10000, Loss: 1.1360, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2819/10000, Loss: 1.1356, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2820/10000, Loss: 1.1351, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2821/10000, Loss: 1.1347, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2822/10000, Loss: 1.1343, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2823/10000, Loss: 1.1339, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2824/10000, Loss: 1.1335, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2825/10000, Loss: 1.1331, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2826/10000, Loss: 1.1327, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2827/10000, Loss: 1.1323, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2828/10000, Loss: 1.1319, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2829/10000, Loss: 1.1315, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2830/10000, Loss: 1.1310, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2831/10000, Loss: 1.1306, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2832/10000, Loss: 1.1302, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2833/10000, Loss: 1.1298, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2834/10000, Loss: 1.1294, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2835/10000, Loss: 1.1290, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2836/10000, Loss: 1.1286, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2837/10000, Loss: 1.1282, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2838/10000, Loss: 1.1278, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2839/10000, Loss: 1.1274, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2840/10000, Loss: 1.1270, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2841/10000, Loss: 1.1266, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2842/10000, Loss: 1.1262, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2843/10000, Loss: 1.1258, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2844/10000, Loss: 1.1254, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2845/10000, Loss: 1.1250, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2846/10000, Loss: 1.1246, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2847/10000, Loss: 1.1242, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2848/10000, Loss: 1.1238, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2849/10000, Loss: 1.1234, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2850/10000, Loss: 1.1230, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2851/10000, Loss: 1.1226, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2852/10000, Loss: 1.1222, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2853/10000, Loss: 1.1218, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2854/10000, Loss: 1.1214, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2855/10000, Loss: 1.1210, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2856/10000, Loss: 1.1206, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2857/10000, Loss: 1.1202, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2858/10000, Loss: 1.1198, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2859/10000, Loss: 1.1194, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2860/10000, Loss: 1.1190, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2861/10000, Loss: 1.1186, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2862/10000, Loss: 1.1182, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2863/10000, Loss: 1.1178, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2864/10000, Loss: 1.1174, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2865/10000, Loss: 1.1170, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2866/10000, Loss: 1.1166, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2867/10000, Loss: 1.1163, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2868/10000, Loss: 1.1159, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2869/10000, Loss: 1.1155, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2870/10000, Loss: 1.1151, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2871/10000, Loss: 1.1147, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2872/10000, Loss: 1.1143, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2873/10000, Loss: 1.1139, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2874/10000, Loss: 1.1135, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2875/10000, Loss: 1.1131, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2876/10000, Loss: 1.1127, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2877/10000, Loss: 1.1123, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2878/10000, Loss: 1.1120, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2879/10000, Loss: 1.1116, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2880/10000, Loss: 1.1112, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2881/10000, Loss: 1.1108, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2882/10000, Loss: 1.1104, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2883/10000, Loss: 1.1100, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2884/10000, Loss: 1.1096, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2885/10000, Loss: 1.1093, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2886/10000, Loss: 1.1089, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2887/10000, Loss: 1.1085, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2888/10000, Loss: 1.1081, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2889/10000, Loss: 1.1077, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2890/10000, Loss: 1.1073, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2891/10000, Loss: 1.1070, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2892/10000, Loss: 1.1066, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2893/10000, Loss: 1.1062, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2894/10000, Loss: 1.1058, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2895/10000, Loss: 1.1054, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2896/10000, Loss: 1.1050, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2897/10000, Loss: 1.1047, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2898/10000, Loss: 1.1043, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2899/10000, Loss: 1.1039, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2900/10000, Loss: 1.1035, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2901/10000, Loss: 1.1031, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2902/10000, Loss: 1.1028, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2903/10000, Loss: 1.1024, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2904/10000, Loss: 1.1020, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2905/10000, Loss: 1.1016, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2906/10000, Loss: 1.1013, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2907/10000, Loss: 1.1009, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2908/10000, Loss: 1.1005, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2909/10000, Loss: 1.1001, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2910/10000, Loss: 1.0998, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2911/10000, Loss: 1.0994, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2912/10000, Loss: 1.0990, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2913/10000, Loss: 1.0986, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2914/10000, Loss: 1.0983, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2915/10000, Loss: 1.0979, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2916/10000, Loss: 1.0975, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2917/10000, Loss: 1.0971, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2918/10000, Loss: 1.0968, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2919/10000, Loss: 1.0964, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2920/10000, Loss: 1.0960, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2921/10000, Loss: 1.0957, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2922/10000, Loss: 1.0953, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2923/10000, Loss: 1.0949, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2924/10000, Loss: 1.0945, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2925/10000, Loss: 1.0942, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2926/10000, Loss: 1.0938, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2927/10000, Loss: 1.0934, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2928/10000, Loss: 1.0931, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2929/10000, Loss: 1.0927, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2930/10000, Loss: 1.0923, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2931/10000, Loss: 1.0920, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2932/10000, Loss: 1.0916, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2933/10000, Loss: 1.0912, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2934/10000, Loss: 1.0909, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2935/10000, Loss: 1.0905, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2936/10000, Loss: 1.0901, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2937/10000, Loss: 1.0898, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2938/10000, Loss: 1.0894, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2939/10000, Loss: 1.0891, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2940/10000, Loss: 1.0887, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2941/10000, Loss: 1.0883, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2942/10000, Loss: 1.0880, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2943/10000, Loss: 1.0876, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2944/10000, Loss: 1.0872, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2945/10000, Loss: 1.0869, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2946/10000, Loss: 1.0865, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2947/10000, Loss: 1.0862, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2948/10000, Loss: 1.0858, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2949/10000, Loss: 1.0854, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2950/10000, Loss: 1.0851, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2951/10000, Loss: 1.0847, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2952/10000, Loss: 1.0844, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2953/10000, Loss: 1.0840, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2954/10000, Loss: 1.0836, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2955/10000, Loss: 1.0833, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2956/10000, Loss: 1.0829, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2957/10000, Loss: 1.0826, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2958/10000, Loss: 1.0822, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2959/10000, Loss: 1.0819, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2960/10000, Loss: 1.0815, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2961/10000, Loss: 1.0811, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2962/10000, Loss: 1.0808, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2963/10000, Loss: 1.0804, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2964/10000, Loss: 1.0801, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2965/10000, Loss: 1.0797, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2966/10000, Loss: 1.0794, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2967/10000, Loss: 1.0790, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2968/10000, Loss: 1.0787, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2969/10000, Loss: 1.0783, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2970/10000, Loss: 1.0780, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2971/10000, Loss: 1.0776, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2972/10000, Loss: 1.0773, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2973/10000, Loss: 1.0769, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2974/10000, Loss: 1.0766, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2975/10000, Loss: 1.0762, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2976/10000, Loss: 1.0759, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2977/10000, Loss: 1.0755, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2978/10000, Loss: 1.0752, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2979/10000, Loss: 1.0748, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2980/10000, Loss: 1.0745, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2981/10000, Loss: 1.0741, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2982/10000, Loss: 1.0738, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2983/10000, Loss: 1.0734, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2984/10000, Loss: 1.0731, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2985/10000, Loss: 1.0727, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2986/10000, Loss: 1.0724, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2987/10000, Loss: 1.0720, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2988/10000, Loss: 1.0717, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2989/10000, Loss: 1.0714, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2990/10000, Loss: 1.0710, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2991/10000, Loss: 1.0707, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2992/10000, Loss: 1.0703, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2993/10000, Loss: 1.0700, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2994/10000, Loss: 1.0696, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 2995/10000, Loss: 1.0693, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2996/10000, Loss: 1.0690, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2997/10000, Loss: 1.0686, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2998/10000, Loss: 1.0683, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 2999/10000, Loss: 1.0679, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3000/10000, Loss: 1.0676, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3001/10000, Loss: 1.0673, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3002/10000, Loss: 1.0669, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3003/10000, Loss: 1.0666, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3004/10000, Loss: 1.0662, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3005/10000, Loss: 1.0659, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3006/10000, Loss: 1.0656, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3007/10000, Loss: 1.0652, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3008/10000, Loss: 1.0649, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3009/10000, Loss: 1.0645, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3010/10000, Loss: 1.0642, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3011/10000, Loss: 1.0639, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3012/10000, Loss: 1.0635, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3013/10000, Loss: 1.0632, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3014/10000, Loss: 1.0629, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3015/10000, Loss: 1.0625, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3016/10000, Loss: 1.0622, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3017/10000, Loss: 1.0619, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3018/10000, Loss: 1.0615, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3019/10000, Loss: 1.0612, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3020/10000, Loss: 1.0609, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3021/10000, Loss: 1.0605, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3022/10000, Loss: 1.0602, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3023/10000, Loss: 1.0599, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3024/10000, Loss: 1.0595, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3025/10000, Loss: 1.0592, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3026/10000, Loss: 1.0589, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3027/10000, Loss: 1.0585, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3028/10000, Loss: 1.0582, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3029/10000, Loss: 1.0579, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3030/10000, Loss: 1.0575, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3031/10000, Loss: 1.0572, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3032/10000, Loss: 1.0569, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3033/10000, Loss: 1.0566, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3034/10000, Loss: 1.0562, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3035/10000, Loss: 1.0559, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3036/10000, Loss: 1.0556, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3037/10000, Loss: 1.0552, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3038/10000, Loss: 1.0549, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3039/10000, Loss: 1.0546, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3040/10000, Loss: 1.0543, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3041/10000, Loss: 1.0539, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3042/10000, Loss: 1.0536, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3043/10000, Loss: 1.0533, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3044/10000, Loss: 1.0530, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3045/10000, Loss: 1.0526, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3046/10000, Loss: 1.0523, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3047/10000, Loss: 1.0520, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3048/10000, Loss: 1.0517, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3049/10000, Loss: 1.0514, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3050/10000, Loss: 1.0510, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3051/10000, Loss: 1.0507, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3052/10000, Loss: 1.0504, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3053/10000, Loss: 1.0501, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3054/10000, Loss: 1.0497, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3055/10000, Loss: 1.0494, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3056/10000, Loss: 1.0491, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3057/10000, Loss: 1.0488, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3058/10000, Loss: 1.0485, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3059/10000, Loss: 1.0481, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3060/10000, Loss: 1.0478, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3061/10000, Loss: 1.0475, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3062/10000, Loss: 1.0472, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3063/10000, Loss: 1.0469, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3064/10000, Loss: 1.0466, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3065/10000, Loss: 1.0462, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3066/10000, Loss: 1.0459, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3067/10000, Loss: 1.0456, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3068/10000, Loss: 1.0453, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3069/10000, Loss: 1.0450, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3070/10000, Loss: 1.0447, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3071/10000, Loss: 1.0443, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3072/10000, Loss: 1.0440, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3073/10000, Loss: 1.0437, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3074/10000, Loss: 1.0434, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3075/10000, Loss: 1.0431, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3076/10000, Loss: 1.0428, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3077/10000, Loss: 1.0425, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3078/10000, Loss: 1.0421, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3079/10000, Loss: 1.0418, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3080/10000, Loss: 1.0415, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3081/10000, Loss: 1.0412, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3082/10000, Loss: 1.0409, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3083/10000, Loss: 1.0406, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3084/10000, Loss: 1.0403, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3085/10000, Loss: 1.0400, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3086/10000, Loss: 1.0397, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3087/10000, Loss: 1.0393, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3088/10000, Loss: 1.0390, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3089/10000, Loss: 1.0387, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3090/10000, Loss: 1.0384, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3091/10000, Loss: 1.0381, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3092/10000, Loss: 1.0378, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3093/10000, Loss: 1.0375, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3094/10000, Loss: 1.0372, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3095/10000, Loss: 1.0369, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3096/10000, Loss: 1.0366, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3097/10000, Loss: 1.0363, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3098/10000, Loss: 1.0360, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3099/10000, Loss: 1.0357, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3100/10000, Loss: 1.0354, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3101/10000, Loss: 1.0350, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3102/10000, Loss: 1.0347, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3103/10000, Loss: 1.0344, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3104/10000, Loss: 1.0341, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3105/10000, Loss: 1.0338, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3106/10000, Loss: 1.0335, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3107/10000, Loss: 1.0332, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3108/10000, Loss: 1.0329, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3109/10000, Loss: 1.0326, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3110/10000, Loss: 1.0323, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3111/10000, Loss: 1.0320, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3112/10000, Loss: 1.0317, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3113/10000, Loss: 1.0314, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3114/10000, Loss: 1.0311, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3115/10000, Loss: 1.0308, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3116/10000, Loss: 1.0305, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3117/10000, Loss: 1.0302, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3118/10000, Loss: 1.0299, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3119/10000, Loss: 1.0296, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3120/10000, Loss: 1.0293, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3121/10000, Loss: 1.0290, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3122/10000, Loss: 1.0287, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3123/10000, Loss: 1.0284, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3124/10000, Loss: 1.0281, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3125/10000, Loss: 1.0278, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3126/10000, Loss: 1.0275, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3127/10000, Loss: 1.0272, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3128/10000, Loss: 1.0269, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3129/10000, Loss: 1.0266, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3130/10000, Loss: 1.0263, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3131/10000, Loss: 1.0261, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3132/10000, Loss: 1.0258, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3133/10000, Loss: 1.0255, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3134/10000, Loss: 1.0252, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3135/10000, Loss: 1.0249, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3136/10000, Loss: 1.0246, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3137/10000, Loss: 1.0243, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3138/10000, Loss: 1.0240, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3139/10000, Loss: 1.0237, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3140/10000, Loss: 1.0234, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3141/10000, Loss: 1.0231, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3142/10000, Loss: 1.0228, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3143/10000, Loss: 1.0225, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3144/10000, Loss: 1.0222, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3145/10000, Loss: 1.0220, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3146/10000, Loss: 1.0217, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3147/10000, Loss: 1.0214, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3148/10000, Loss: 1.0211, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3149/10000, Loss: 1.0208, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3150/10000, Loss: 1.0205, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3151/10000, Loss: 1.0202, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3152/10000, Loss: 1.0199, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3153/10000, Loss: 1.0196, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3154/10000, Loss: 1.0194, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3155/10000, Loss: 1.0191, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3156/10000, Loss: 1.0188, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3157/10000, Loss: 1.0185, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3158/10000, Loss: 1.0182, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3159/10000, Loss: 1.0179, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3160/10000, Loss: 1.0176, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3161/10000, Loss: 1.0173, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3162/10000, Loss: 1.0171, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3163/10000, Loss: 1.0168, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3164/10000, Loss: 1.0165, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3165/10000, Loss: 1.0162, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3166/10000, Loss: 1.0159, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3167/10000, Loss: 1.0156, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3168/10000, Loss: 1.0154, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3169/10000, Loss: 1.0151, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3170/10000, Loss: 1.0148, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3171/10000, Loss: 1.0145, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3172/10000, Loss: 1.0142, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3173/10000, Loss: 1.0139, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3174/10000, Loss: 1.0137, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3175/10000, Loss: 1.0134, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3176/10000, Loss: 1.0131, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3177/10000, Loss: 1.0128, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3178/10000, Loss: 1.0125, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3179/10000, Loss: 1.0123, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3180/10000, Loss: 1.0120, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3181/10000, Loss: 1.0117, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3182/10000, Loss: 1.0114, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3183/10000, Loss: 1.0111, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3184/10000, Loss: 1.0109, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3185/10000, Loss: 1.0106, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3186/10000, Loss: 1.0103, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3187/10000, Loss: 1.0100, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3188/10000, Loss: 1.0098, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3189/10000, Loss: 1.0095, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3190/10000, Loss: 1.0092, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3191/10000, Loss: 1.0089, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3192/10000, Loss: 1.0086, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3193/10000, Loss: 1.0084, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3194/10000, Loss: 1.0081, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3195/10000, Loss: 1.0078, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3196/10000, Loss: 1.0075, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3197/10000, Loss: 1.0073, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3198/10000, Loss: 1.0070, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3199/10000, Loss: 1.0067, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3200/10000, Loss: 1.0065, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3201/10000, Loss: 1.0062, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3202/10000, Loss: 1.0059, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3203/10000, Loss: 1.0056, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3204/10000, Loss: 1.0054, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3205/10000, Loss: 1.0051, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3206/10000, Loss: 1.0048, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3207/10000, Loss: 1.0045, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3208/10000, Loss: 1.0043, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3209/10000, Loss: 1.0040, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3210/10000, Loss: 1.0037, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3211/10000, Loss: 1.0035, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3212/10000, Loss: 1.0032, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3213/10000, Loss: 1.0029, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3214/10000, Loss: 1.0027, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3215/10000, Loss: 1.0024, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3216/10000, Loss: 1.0021, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3217/10000, Loss: 1.0018, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3218/10000, Loss: 1.0016, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3219/10000, Loss: 1.0013, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3220/10000, Loss: 1.0010, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3221/10000, Loss: 1.0008, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3222/10000, Loss: 1.0005, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3223/10000, Loss: 1.0002, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3224/10000, Loss: 1.0000, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3225/10000, Loss: 0.9997, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3226/10000, Loss: 0.9994, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3227/10000, Loss: 0.9992, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3228/10000, Loss: 0.9989, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3229/10000, Loss: 0.9986, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3230/10000, Loss: 0.9984, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3231/10000, Loss: 0.9981, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3232/10000, Loss: 0.9978, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3233/10000, Loss: 0.9976, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3234/10000, Loss: 0.9973, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3235/10000, Loss: 0.9971, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3236/10000, Loss: 0.9968, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3237/10000, Loss: 0.9965, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3238/10000, Loss: 0.9963, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3239/10000, Loss: 0.9960, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3240/10000, Loss: 0.9957, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3241/10000, Loss: 0.9955, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3242/10000, Loss: 0.9952, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3243/10000, Loss: 0.9950, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3244/10000, Loss: 0.9947, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3245/10000, Loss: 0.9944, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3246/10000, Loss: 0.9942, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3247/10000, Loss: 0.9939, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3248/10000, Loss: 0.9937, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3249/10000, Loss: 0.9934, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3250/10000, Loss: 0.9931, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3251/10000, Loss: 0.9929, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3252/10000, Loss: 0.9926, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3253/10000, Loss: 0.9924, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3254/10000, Loss: 0.9921, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3255/10000, Loss: 0.9918, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3256/10000, Loss: 0.9916, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3257/10000, Loss: 0.9913, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3258/10000, Loss: 0.9911, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3259/10000, Loss: 0.9908, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3260/10000, Loss: 0.9906, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3261/10000, Loss: 0.9903, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3262/10000, Loss: 0.9900, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3263/10000, Loss: 0.9898, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3264/10000, Loss: 0.9895, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3265/10000, Loss: 0.9893, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3266/10000, Loss: 0.9890, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3267/10000, Loss: 0.9888, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3268/10000, Loss: 0.9885, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3269/10000, Loss: 0.9883, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3270/10000, Loss: 0.9880, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3271/10000, Loss: 0.9878, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3272/10000, Loss: 0.9875, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3273/10000, Loss: 0.9873, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3274/10000, Loss: 0.9870, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3275/10000, Loss: 0.9867, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3276/10000, Loss: 0.9865, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3277/10000, Loss: 0.9862, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3278/10000, Loss: 0.9860, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3279/10000, Loss: 0.9857, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3280/10000, Loss: 0.9855, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3281/10000, Loss: 0.9852, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3282/10000, Loss: 0.9850, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3283/10000, Loss: 0.9847, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3284/10000, Loss: 0.9845, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3285/10000, Loss: 0.9842, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3286/10000, Loss: 0.9840, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3287/10000, Loss: 0.9837, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3288/10000, Loss: 0.9835, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3289/10000, Loss: 0.9832, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3290/10000, Loss: 0.9830, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3291/10000, Loss: 0.9827, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3292/10000, Loss: 0.9825, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3293/10000, Loss: 0.9822, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3294/10000, Loss: 0.9820, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3295/10000, Loss: 0.9818, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3296/10000, Loss: 0.9815, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3297/10000, Loss: 0.9813, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3298/10000, Loss: 0.9810, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3299/10000, Loss: 0.9808, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3300/10000, Loss: 0.9805, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3301/10000, Loss: 0.9803, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3302/10000, Loss: 0.9800, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3303/10000, Loss: 0.9798, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3304/10000, Loss: 0.9795, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3305/10000, Loss: 0.9793, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3306/10000, Loss: 0.9791, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3307/10000, Loss: 0.9788, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3308/10000, Loss: 0.9786, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3309/10000, Loss: 0.9783, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3310/10000, Loss: 0.9781, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3311/10000, Loss: 0.9778, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3312/10000, Loss: 0.9776, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3313/10000, Loss: 0.9774, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3314/10000, Loss: 0.9771, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3315/10000, Loss: 0.9769, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3316/10000, Loss: 0.9766, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3317/10000, Loss: 0.9764, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3318/10000, Loss: 0.9761, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3319/10000, Loss: 0.9759, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3320/10000, Loss: 0.9757, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3321/10000, Loss: 0.9754, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3322/10000, Loss: 0.9752, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3323/10000, Loss: 0.9749, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3324/10000, Loss: 0.9747, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3325/10000, Loss: 0.9745, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3326/10000, Loss: 0.9742, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3327/10000, Loss: 0.9740, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3328/10000, Loss: 0.9737, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3329/10000, Loss: 0.9735, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3330/10000, Loss: 0.9733, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3331/10000, Loss: 0.9730, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3332/10000, Loss: 0.9728, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3333/10000, Loss: 0.9726, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3334/10000, Loss: 0.9723, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3335/10000, Loss: 0.9721, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3336/10000, Loss: 0.9718, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3337/10000, Loss: 0.9716, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3338/10000, Loss: 0.9714, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3339/10000, Loss: 0.9711, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3340/10000, Loss: 0.9709, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3341/10000, Loss: 0.9707, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3342/10000, Loss: 0.9704, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3343/10000, Loss: 0.9702, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3344/10000, Loss: 0.9700, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3345/10000, Loss: 0.9697, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3346/10000, Loss: 0.9695, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3347/10000, Loss: 0.9693, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3348/10000, Loss: 0.9690, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3349/10000, Loss: 0.9688, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3350/10000, Loss: 0.9686, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3351/10000, Loss: 0.9683, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3352/10000, Loss: 0.9681, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3353/10000, Loss: 0.9679, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3354/10000, Loss: 0.9676, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3355/10000, Loss: 0.9674, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3356/10000, Loss: 0.9672, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3357/10000, Loss: 0.9669, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3358/10000, Loss: 0.9667, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3359/10000, Loss: 0.9665, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3360/10000, Loss: 0.9662, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3361/10000, Loss: 0.9660, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3362/10000, Loss: 0.9658, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3363/10000, Loss: 0.9656, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3364/10000, Loss: 0.9653, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3365/10000, Loss: 0.9651, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3366/10000, Loss: 0.9649, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3367/10000, Loss: 0.9646, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3368/10000, Loss: 0.9644, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3369/10000, Loss: 0.9642, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3370/10000, Loss: 0.9639, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3371/10000, Loss: 0.9637, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3372/10000, Loss: 0.9635, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3373/10000, Loss: 0.9633, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3374/10000, Loss: 0.9630, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3375/10000, Loss: 0.9628, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3376/10000, Loss: 0.9626, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3377/10000, Loss: 0.9624, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3378/10000, Loss: 0.9621, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3379/10000, Loss: 0.9619, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3380/10000, Loss: 0.9617, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3381/10000, Loss: 0.9615, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3382/10000, Loss: 0.9612, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3383/10000, Loss: 0.9610, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3384/10000, Loss: 0.9608, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3385/10000, Loss: 0.9606, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3386/10000, Loss: 0.9603, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3387/10000, Loss: 0.9601, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3388/10000, Loss: 0.9599, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3389/10000, Loss: 0.9597, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3390/10000, Loss: 0.9594, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3391/10000, Loss: 0.9592, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3392/10000, Loss: 0.9590, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3393/10000, Loss: 0.9588, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3394/10000, Loss: 0.9585, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3395/10000, Loss: 0.9583, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3396/10000, Loss: 0.9581, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3397/10000, Loss: 0.9579, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3398/10000, Loss: 0.9577, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3399/10000, Loss: 0.9574, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3400/10000, Loss: 0.9572, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3401/10000, Loss: 0.9570, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3402/10000, Loss: 0.9568, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3403/10000, Loss: 0.9565, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3404/10000, Loss: 0.9563, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3405/10000, Loss: 0.9561, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3406/10000, Loss: 0.9559, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3407/10000, Loss: 0.9557, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3408/10000, Loss: 0.9555, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3409/10000, Loss: 0.9552, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3410/10000, Loss: 0.9550, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3411/10000, Loss: 0.9548, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3412/10000, Loss: 0.9546, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3413/10000, Loss: 0.9544, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3414/10000, Loss: 0.9541, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3415/10000, Loss: 0.9539, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3416/10000, Loss: 0.9537, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3417/10000, Loss: 0.9535, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3418/10000, Loss: 0.9533, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3419/10000, Loss: 0.9531, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3420/10000, Loss: 0.9528, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3421/10000, Loss: 0.9526, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3422/10000, Loss: 0.9524, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3423/10000, Loss: 0.9522, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3424/10000, Loss: 0.9520, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3425/10000, Loss: 0.9518, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3426/10000, Loss: 0.9515, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3427/10000, Loss: 0.9513, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3428/10000, Loss: 0.9511, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3429/10000, Loss: 0.9509, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3430/10000, Loss: 0.9507, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3431/10000, Loss: 0.9505, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3432/10000, Loss: 0.9503, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3433/10000, Loss: 0.9500, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3434/10000, Loss: 0.9498, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3435/10000, Loss: 0.9496, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3436/10000, Loss: 0.9494, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3437/10000, Loss: 0.9492, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3438/10000, Loss: 0.9490, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3439/10000, Loss: 0.9488, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3440/10000, Loss: 0.9485, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3441/10000, Loss: 0.9483, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3442/10000, Loss: 0.9481, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3443/10000, Loss: 0.9479, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3444/10000, Loss: 0.9477, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3445/10000, Loss: 0.9475, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3446/10000, Loss: 0.9473, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3447/10000, Loss: 0.9471, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3448/10000, Loss: 0.9469, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3449/10000, Loss: 0.9466, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3450/10000, Loss: 0.9464, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3451/10000, Loss: 0.9462, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3452/10000, Loss: 0.9460, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3453/10000, Loss: 0.9458, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3454/10000, Loss: 0.9456, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3455/10000, Loss: 0.9454, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3456/10000, Loss: 0.9452, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3457/10000, Loss: 0.9450, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3458/10000, Loss: 0.9448, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3459/10000, Loss: 0.9446, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3460/10000, Loss: 0.9444, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3461/10000, Loss: 0.9441, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3462/10000, Loss: 0.9439, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3463/10000, Loss: 0.9437, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3464/10000, Loss: 0.9435, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3465/10000, Loss: 0.9433, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3466/10000, Loss: 0.9431, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3467/10000, Loss: 0.9429, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3468/10000, Loss: 0.9427, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3469/10000, Loss: 0.9425, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3470/10000, Loss: 0.9423, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3471/10000, Loss: 0.9421, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3472/10000, Loss: 0.9419, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3473/10000, Loss: 0.9417, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3474/10000, Loss: 0.9415, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3475/10000, Loss: 0.9413, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3476/10000, Loss: 0.9411, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3477/10000, Loss: 0.9408, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3478/10000, Loss: 0.9406, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3479/10000, Loss: 0.9404, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3480/10000, Loss: 0.9402, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3481/10000, Loss: 0.9400, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3482/10000, Loss: 0.9398, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3483/10000, Loss: 0.9396, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3484/10000, Loss: 0.9394, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3485/10000, Loss: 0.9392, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3486/10000, Loss: 0.9390, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3487/10000, Loss: 0.9388, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3488/10000, Loss: 0.9386, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3489/10000, Loss: 0.9384, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3490/10000, Loss: 0.9382, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3491/10000, Loss: 0.9380, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3492/10000, Loss: 0.9378, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3493/10000, Loss: 0.9376, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3494/10000, Loss: 0.9374, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3495/10000, Loss: 0.9372, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3496/10000, Loss: 0.9370, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3497/10000, Loss: 0.9368, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3498/10000, Loss: 0.9366, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3499/10000, Loss: 0.9364, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3500/10000, Loss: 0.9362, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3501/10000, Loss: 0.9360, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3502/10000, Loss: 0.9358, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3503/10000, Loss: 0.9356, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3504/10000, Loss: 0.9354, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3505/10000, Loss: 0.9352, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3506/10000, Loss: 0.9350, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3507/10000, Loss: 0.9348, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3508/10000, Loss: 0.9346, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3509/10000, Loss: 0.9344, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3510/10000, Loss: 0.9342, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3511/10000, Loss: 0.9340, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3512/10000, Loss: 0.9338, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3513/10000, Loss: 0.9336, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3514/10000, Loss: 0.9334, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3515/10000, Loss: 0.9332, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3516/10000, Loss: 0.9330, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3517/10000, Loss: 0.9328, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3518/10000, Loss: 0.9327, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3519/10000, Loss: 0.9325, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3520/10000, Loss: 0.9323, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3521/10000, Loss: 0.9321, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3522/10000, Loss: 0.9319, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3523/10000, Loss: 0.9317, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3524/10000, Loss: 0.9315, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3525/10000, Loss: 0.9313, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3526/10000, Loss: 0.9311, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3527/10000, Loss: 0.9309, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3528/10000, Loss: 0.9307, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3529/10000, Loss: 0.9305, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3530/10000, Loss: 0.9303, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3531/10000, Loss: 0.9301, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3532/10000, Loss: 0.9299, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3533/10000, Loss: 0.9297, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3534/10000, Loss: 0.9295, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3535/10000, Loss: 0.9294, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3536/10000, Loss: 0.9292, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3537/10000, Loss: 0.9290, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3538/10000, Loss: 0.9288, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3539/10000, Loss: 0.9286, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3540/10000, Loss: 0.9284, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3541/10000, Loss: 0.9282, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3542/10000, Loss: 0.9280, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3543/10000, Loss: 0.9278, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3544/10000, Loss: 0.9276, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3545/10000, Loss: 0.9274, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3546/10000, Loss: 0.9273, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3547/10000, Loss: 0.9271, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3548/10000, Loss: 0.9269, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3549/10000, Loss: 0.9267, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3550/10000, Loss: 0.9265, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3551/10000, Loss: 0.9263, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3552/10000, Loss: 0.9261, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3553/10000, Loss: 0.9259, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3554/10000, Loss: 0.9257, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3555/10000, Loss: 0.9255, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3556/10000, Loss: 0.9254, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3557/10000, Loss: 0.9252, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3558/10000, Loss: 0.9250, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3559/10000, Loss: 0.9248, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3560/10000, Loss: 0.9246, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3561/10000, Loss: 0.9244, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3562/10000, Loss: 0.9242, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3563/10000, Loss: 0.9240, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3564/10000, Loss: 0.9239, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3565/10000, Loss: 0.9237, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3566/10000, Loss: 0.9235, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3567/10000, Loss: 0.9233, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3568/10000, Loss: 0.9231, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3569/10000, Loss: 0.9229, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3570/10000, Loss: 0.9227, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3571/10000, Loss: 0.9226, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3572/10000, Loss: 0.9224, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3573/10000, Loss: 0.9222, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3574/10000, Loss: 0.9220, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3575/10000, Loss: 0.9218, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3576/10000, Loss: 0.9216, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3577/10000, Loss: 0.9215, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3578/10000, Loss: 0.9213, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3579/10000, Loss: 0.9211, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3580/10000, Loss: 0.9209, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3581/10000, Loss: 0.9207, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3582/10000, Loss: 0.9205, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3583/10000, Loss: 0.9203, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3584/10000, Loss: 0.9202, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3585/10000, Loss: 0.9200, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3586/10000, Loss: 0.9198, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3587/10000, Loss: 0.9196, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3588/10000, Loss: 0.9194, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3589/10000, Loss: 0.9193, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3590/10000, Loss: 0.9191, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3591/10000, Loss: 0.9189, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3592/10000, Loss: 0.9187, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3593/10000, Loss: 0.9185, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3594/10000, Loss: 0.9183, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3595/10000, Loss: 0.9182, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3596/10000, Loss: 0.9180, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3597/10000, Loss: 0.9178, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3598/10000, Loss: 0.9176, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3599/10000, Loss: 0.9174, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3600/10000, Loss: 0.9173, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3601/10000, Loss: 0.9171, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3602/10000, Loss: 0.9169, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3603/10000, Loss: 0.9167, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3604/10000, Loss: 0.9165, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3605/10000, Loss: 0.9164, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3606/10000, Loss: 0.9162, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3607/10000, Loss: 0.9160, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3608/10000, Loss: 0.9158, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3609/10000, Loss: 0.9157, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3610/10000, Loss: 0.9155, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3611/10000, Loss: 0.9153, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3612/10000, Loss: 0.9151, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3613/10000, Loss: 0.9149, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3614/10000, Loss: 0.9148, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3615/10000, Loss: 0.9146, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3616/10000, Loss: 0.9144, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3617/10000, Loss: 0.9142, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3618/10000, Loss: 0.9141, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3619/10000, Loss: 0.9139, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3620/10000, Loss: 0.9137, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3621/10000, Loss: 0.9135, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3622/10000, Loss: 0.9134, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3623/10000, Loss: 0.9132, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3624/10000, Loss: 0.9130, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3625/10000, Loss: 0.9128, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3626/10000, Loss: 0.9126, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3627/10000, Loss: 0.9125, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3628/10000, Loss: 0.9123, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3629/10000, Loss: 0.9121, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3630/10000, Loss: 0.9119, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3631/10000, Loss: 0.9118, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3632/10000, Loss: 0.9116, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3633/10000, Loss: 0.9114, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3634/10000, Loss: 0.9113, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3635/10000, Loss: 0.9111, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3636/10000, Loss: 0.9109, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3637/10000, Loss: 0.9107, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3638/10000, Loss: 0.9106, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3639/10000, Loss: 0.9104, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3640/10000, Loss: 0.9102, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3641/10000, Loss: 0.9100, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3642/10000, Loss: 0.9099, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3643/10000, Loss: 0.9097, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3644/10000, Loss: 0.9095, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3645/10000, Loss: 0.9094, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3646/10000, Loss: 0.9092, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3647/10000, Loss: 0.9090, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3648/10000, Loss: 0.9088, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3649/10000, Loss: 0.9087, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3650/10000, Loss: 0.9085, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3651/10000, Loss: 0.9083, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3652/10000, Loss: 0.9082, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3653/10000, Loss: 0.9080, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3654/10000, Loss: 0.9078, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3655/10000, Loss: 0.9076, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3656/10000, Loss: 0.9075, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3657/10000, Loss: 0.9073, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3658/10000, Loss: 0.9071, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3659/10000, Loss: 0.9070, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3660/10000, Loss: 0.9068, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3661/10000, Loss: 0.9066, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3662/10000, Loss: 0.9065, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3663/10000, Loss: 0.9063, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3664/10000, Loss: 0.9061, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3665/10000, Loss: 0.9060, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3666/10000, Loss: 0.9058, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3667/10000, Loss: 0.9056, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3668/10000, Loss: 0.9054, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3669/10000, Loss: 0.9053, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3670/10000, Loss: 0.9051, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3671/10000, Loss: 0.9049, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3672/10000, Loss: 0.9048, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3673/10000, Loss: 0.9046, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3674/10000, Loss: 0.9044, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3675/10000, Loss: 0.9043, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3676/10000, Loss: 0.9041, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3677/10000, Loss: 0.9039, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3678/10000, Loss: 0.9038, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3679/10000, Loss: 0.9036, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3680/10000, Loss: 0.9034, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3681/10000, Loss: 0.9033, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3682/10000, Loss: 0.9031, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3683/10000, Loss: 0.9030, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3684/10000, Loss: 0.9028, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3685/10000, Loss: 0.9026, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3686/10000, Loss: 0.9025, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3687/10000, Loss: 0.9023, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3688/10000, Loss: 0.9021, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3689/10000, Loss: 0.9020, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3690/10000, Loss: 0.9018, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3691/10000, Loss: 0.9016, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3692/10000, Loss: 0.9015, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3693/10000, Loss: 0.9013, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3694/10000, Loss: 0.9011, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3695/10000, Loss: 0.9010, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3696/10000, Loss: 0.9008, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3697/10000, Loss: 0.9007, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3698/10000, Loss: 0.9005, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3699/10000, Loss: 0.9003, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3700/10000, Loss: 0.9002, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3701/10000, Loss: 0.9000, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3702/10000, Loss: 0.8998, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3703/10000, Loss: 0.8997, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3704/10000, Loss: 0.8995, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3705/10000, Loss: 0.8994, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3706/10000, Loss: 0.8992, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3707/10000, Loss: 0.8990, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3708/10000, Loss: 0.8989, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3709/10000, Loss: 0.8987, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3710/10000, Loss: 0.8986, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3711/10000, Loss: 0.8984, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3712/10000, Loss: 0.8982, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3713/10000, Loss: 0.8981, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3714/10000, Loss: 0.8979, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3715/10000, Loss: 0.8978, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3716/10000, Loss: 0.8976, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3717/10000, Loss: 0.8974, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3718/10000, Loss: 0.8973, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3719/10000, Loss: 0.8971, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3720/10000, Loss: 0.8970, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3721/10000, Loss: 0.8968, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3722/10000, Loss: 0.8966, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3723/10000, Loss: 0.8965, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3724/10000, Loss: 0.8963, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3725/10000, Loss: 0.8962, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3726/10000, Loss: 0.8960, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3727/10000, Loss: 0.8958, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3728/10000, Loss: 0.8957, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3729/10000, Loss: 0.8955, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3730/10000, Loss: 0.8954, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3731/10000, Loss: 0.8952, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3732/10000, Loss: 0.8951, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3733/10000, Loss: 0.8949, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3734/10000, Loss: 0.8947, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3735/10000, Loss: 0.8946, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3736/10000, Loss: 0.8944, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3737/10000, Loss: 0.8943, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3738/10000, Loss: 0.8941, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3739/10000, Loss: 0.8940, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3740/10000, Loss: 0.8938, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3741/10000, Loss: 0.8937, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3742/10000, Loss: 0.8935, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3743/10000, Loss: 0.8933, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3744/10000, Loss: 0.8932, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3745/10000, Loss: 0.8930, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3746/10000, Loss: 0.8929, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3747/10000, Loss: 0.8927, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3748/10000, Loss: 0.8926, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3749/10000, Loss: 0.8924, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3750/10000, Loss: 0.8923, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3751/10000, Loss: 0.8921, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3752/10000, Loss: 0.8920, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3753/10000, Loss: 0.8918, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3754/10000, Loss: 0.8916, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3755/10000, Loss: 0.8915, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3756/10000, Loss: 0.8913, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3757/10000, Loss: 0.8912, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3758/10000, Loss: 0.8910, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3759/10000, Loss: 0.8909, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3760/10000, Loss: 0.8907, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3761/10000, Loss: 0.8906, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3762/10000, Loss: 0.8904, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3763/10000, Loss: 0.8903, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3764/10000, Loss: 0.8901, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3765/10000, Loss: 0.8900, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3766/10000, Loss: 0.8898, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3767/10000, Loss: 0.8897, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3768/10000, Loss: 0.8895, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3769/10000, Loss: 0.8894, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3770/10000, Loss: 0.8892, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3771/10000, Loss: 0.8891, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3772/10000, Loss: 0.8889, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3773/10000, Loss: 0.8888, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3774/10000, Loss: 0.8886, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3775/10000, Loss: 0.8885, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3776/10000, Loss: 0.8883, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3777/10000, Loss: 0.8882, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3778/10000, Loss: 0.8880, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3779/10000, Loss: 0.8879, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3780/10000, Loss: 0.8877, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3781/10000, Loss: 0.8876, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3782/10000, Loss: 0.8874, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3783/10000, Loss: 0.8873, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3784/10000, Loss: 0.8871, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3785/10000, Loss: 0.8870, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3786/10000, Loss: 0.8868, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3787/10000, Loss: 0.8867, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3788/10000, Loss: 0.8865, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3789/10000, Loss: 0.8864, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3790/10000, Loss: 0.8862, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3791/10000, Loss: 0.8861, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3792/10000, Loss: 0.8859, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3793/10000, Loss: 0.8858, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3794/10000, Loss: 0.8856, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3795/10000, Loss: 0.8855, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3796/10000, Loss: 0.8853, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3797/10000, Loss: 0.8852, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3798/10000, Loss: 0.8850, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3799/10000, Loss: 0.8849, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3800/10000, Loss: 0.8847, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3801/10000, Loss: 0.8846, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3802/10000, Loss: 0.8845, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3803/10000, Loss: 0.8843, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3804/10000, Loss: 0.8842, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3805/10000, Loss: 0.8840, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3806/10000, Loss: 0.8839, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3807/10000, Loss: 0.8837, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3808/10000, Loss: 0.8836, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3809/10000, Loss: 0.8834, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3810/10000, Loss: 0.8833, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3811/10000, Loss: 0.8831, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3812/10000, Loss: 0.8830, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3813/10000, Loss: 0.8829, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3814/10000, Loss: 0.8827, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3815/10000, Loss: 0.8826, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3816/10000, Loss: 0.8824, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3817/10000, Loss: 0.8823, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3818/10000, Loss: 0.8821, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3819/10000, Loss: 0.8820, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3820/10000, Loss: 0.8818, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3821/10000, Loss: 0.8817, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3822/10000, Loss: 0.8816, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3823/10000, Loss: 0.8814, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3824/10000, Loss: 0.8813, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3825/10000, Loss: 0.8811, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3826/10000, Loss: 0.8810, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3827/10000, Loss: 0.8808, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3828/10000, Loss: 0.8807, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3829/10000, Loss: 0.8806, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3830/10000, Loss: 0.8804, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3831/10000, Loss: 0.8803, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3832/10000, Loss: 0.8801, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3833/10000, Loss: 0.8800, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3834/10000, Loss: 0.8799, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3835/10000, Loss: 0.8797, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3836/10000, Loss: 0.8796, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3837/10000, Loss: 0.8794, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3838/10000, Loss: 0.8793, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3839/10000, Loss: 0.8792, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3840/10000, Loss: 0.8790, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3841/10000, Loss: 0.8789, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3842/10000, Loss: 0.8787, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3843/10000, Loss: 0.8786, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3844/10000, Loss: 0.8785, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3845/10000, Loss: 0.8783, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3846/10000, Loss: 0.8782, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3847/10000, Loss: 0.8780, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3848/10000, Loss: 0.8779, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3849/10000, Loss: 0.8778, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3850/10000, Loss: 0.8776, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3851/10000, Loss: 0.8775, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3852/10000, Loss: 0.8773, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3853/10000, Loss: 0.8772, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3854/10000, Loss: 0.8771, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3855/10000, Loss: 0.8769, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3856/10000, Loss: 0.8768, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3857/10000, Loss: 0.8766, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3858/10000, Loss: 0.8765, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3859/10000, Loss: 0.8764, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3860/10000, Loss: 0.8762, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3861/10000, Loss: 0.8761, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3862/10000, Loss: 0.8760, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3863/10000, Loss: 0.8758, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3864/10000, Loss: 0.8757, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3865/10000, Loss: 0.8755, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3866/10000, Loss: 0.8754, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3867/10000, Loss: 0.8753, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3868/10000, Loss: 0.8751, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3869/10000, Loss: 0.8750, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3870/10000, Loss: 0.8749, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3871/10000, Loss: 0.8747, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3872/10000, Loss: 0.8746, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3873/10000, Loss: 0.8745, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3874/10000, Loss: 0.8743, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3875/10000, Loss: 0.8742, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3876/10000, Loss: 0.8740, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3877/10000, Loss: 0.8739, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3878/10000, Loss: 0.8738, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3879/10000, Loss: 0.8736, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3880/10000, Loss: 0.8735, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3881/10000, Loss: 0.8734, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3882/10000, Loss: 0.8732, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3883/10000, Loss: 0.8731, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3884/10000, Loss: 0.8730, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3885/10000, Loss: 0.8728, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3886/10000, Loss: 0.8727, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3887/10000, Loss: 0.8726, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3888/10000, Loss: 0.8724, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3889/10000, Loss: 0.8723, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3890/10000, Loss: 0.8722, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3891/10000, Loss: 0.8720, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3892/10000, Loss: 0.8719, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3893/10000, Loss: 0.8718, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3894/10000, Loss: 0.8716, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3895/10000, Loss: 0.8715, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3896/10000, Loss: 0.8714, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3897/10000, Loss: 0.8712, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3898/10000, Loss: 0.8711, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3899/10000, Loss: 0.8710, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3900/10000, Loss: 0.8708, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3901/10000, Loss: 0.8707, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3902/10000, Loss: 0.8706, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3903/10000, Loss: 0.8704, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3904/10000, Loss: 0.8703, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3905/10000, Loss: 0.8702, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3906/10000, Loss: 0.8700, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3907/10000, Loss: 0.8699, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3908/10000, Loss: 0.8698, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3909/10000, Loss: 0.8697, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3910/10000, Loss: 0.8695, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3911/10000, Loss: 0.8694, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3912/10000, Loss: 0.8693, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3913/10000, Loss: 0.8691, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3914/10000, Loss: 0.8690, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3915/10000, Loss: 0.8689, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3916/10000, Loss: 0.8687, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3917/10000, Loss: 0.8686, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3918/10000, Loss: 0.8685, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3919/10000, Loss: 0.8683, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3920/10000, Loss: 0.8682, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3921/10000, Loss: 0.8681, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3922/10000, Loss: 0.8680, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3923/10000, Loss: 0.8678, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3924/10000, Loss: 0.8677, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3925/10000, Loss: 0.8676, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3926/10000, Loss: 0.8674, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3927/10000, Loss: 0.8673, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3928/10000, Loss: 0.8672, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3929/10000, Loss: 0.8671, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3930/10000, Loss: 0.8669, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3931/10000, Loss: 0.8668, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3932/10000, Loss: 0.8667, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3933/10000, Loss: 0.8665, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3934/10000, Loss: 0.8664, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3935/10000, Loss: 0.8663, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3936/10000, Loss: 0.8662, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3937/10000, Loss: 0.8660, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3938/10000, Loss: 0.8659, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3939/10000, Loss: 0.8658, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3940/10000, Loss: 0.8657, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3941/10000, Loss: 0.8655, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3942/10000, Loss: 0.8654, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3943/10000, Loss: 0.8653, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3944/10000, Loss: 0.8651, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3945/10000, Loss: 0.8650, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3946/10000, Loss: 0.8649, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3947/10000, Loss: 0.8648, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3948/10000, Loss: 0.8646, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3949/10000, Loss: 0.8645, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3950/10000, Loss: 0.8644, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3951/10000, Loss: 0.8643, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3952/10000, Loss: 0.8641, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3953/10000, Loss: 0.8640, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3954/10000, Loss: 0.8639, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3955/10000, Loss: 0.8638, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3956/10000, Loss: 0.8636, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3957/10000, Loss: 0.8635, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3958/10000, Loss: 0.8634, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3959/10000, Loss: 0.8633, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3960/10000, Loss: 0.8631, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3961/10000, Loss: 0.8630, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3962/10000, Loss: 0.8629, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3963/10000, Loss: 0.8628, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3964/10000, Loss: 0.8626, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3965/10000, Loss: 0.8625, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3966/10000, Loss: 0.8624, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3967/10000, Loss: 0.8623, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3968/10000, Loss: 0.8621, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3969/10000, Loss: 0.8620, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3970/10000, Loss: 0.8619, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3971/10000, Loss: 0.8618, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3972/10000, Loss: 0.8617, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3973/10000, Loss: 0.8615, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3974/10000, Loss: 0.8614, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3975/10000, Loss: 0.8613, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3976/10000, Loss: 0.8612, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3977/10000, Loss: 0.8610, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3978/10000, Loss: 0.8609, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3979/10000, Loss: 0.8608, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3980/10000, Loss: 0.8607, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3981/10000, Loss: 0.8606, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3982/10000, Loss: 0.8604, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3983/10000, Loss: 0.8603, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3984/10000, Loss: 0.8602, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3985/10000, Loss: 0.8601, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3986/10000, Loss: 0.8599, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3987/10000, Loss: 0.8598, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3988/10000, Loss: 0.8597, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3989/10000, Loss: 0.8596, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3990/10000, Loss: 0.8595, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3991/10000, Loss: 0.8593, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3992/10000, Loss: 0.8592, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3993/10000, Loss: 0.8591, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3994/10000, Loss: 0.8590, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3995/10000, Loss: 0.8589, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3996/10000, Loss: 0.8587, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3997/10000, Loss: 0.8586, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3998/10000, Loss: 0.8585, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3999/10000, Loss: 0.8584, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4000/10000, Loss: 0.8583, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4001/10000, Loss: 0.8581, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4002/10000, Loss: 0.8580, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4003/10000, Loss: 0.8579, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4004/10000, Loss: 0.8578, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4005/10000, Loss: 0.8577, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4006/10000, Loss: 0.8575, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4007/10000, Loss: 0.8574, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4008/10000, Loss: 0.8573, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4009/10000, Loss: 0.8572, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4010/10000, Loss: 0.8571, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4011/10000, Loss: 0.8570, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4012/10000, Loss: 0.8568, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4013/10000, Loss: 0.8567, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4014/10000, Loss: 0.8566, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4015/10000, Loss: 0.8565, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4016/10000, Loss: 0.8564, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4017/10000, Loss: 0.8562, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4018/10000, Loss: 0.8561, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4019/10000, Loss: 0.8560, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4020/10000, Loss: 0.8559, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4021/10000, Loss: 0.8558, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4022/10000, Loss: 0.8557, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4023/10000, Loss: 0.8555, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4024/10000, Loss: 0.8554, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4025/10000, Loss: 0.8553, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4026/10000, Loss: 0.8552, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4027/10000, Loss: 0.8551, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4028/10000, Loss: 0.8550, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4029/10000, Loss: 0.8548, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4030/10000, Loss: 0.8547, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4031/10000, Loss: 0.8546, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4032/10000, Loss: 0.8545, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4033/10000, Loss: 0.8544, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4034/10000, Loss: 0.8543, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4035/10000, Loss: 0.8541, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4036/10000, Loss: 0.8540, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4037/10000, Loss: 0.8539, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4038/10000, Loss: 0.8538, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4039/10000, Loss: 0.8537, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4040/10000, Loss: 0.8536, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4041/10000, Loss: 0.8535, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4042/10000, Loss: 0.8533, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4043/10000, Loss: 0.8532, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4044/10000, Loss: 0.8531, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4045/10000, Loss: 0.8530, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4046/10000, Loss: 0.8529, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4047/10000, Loss: 0.8528, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4048/10000, Loss: 0.8527, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4049/10000, Loss: 0.8525, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4050/10000, Loss: 0.8524, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4051/10000, Loss: 0.8523, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4052/10000, Loss: 0.8522, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4053/10000, Loss: 0.8521, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4054/10000, Loss: 0.8520, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4055/10000, Loss: 0.8519, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4056/10000, Loss: 0.8517, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4057/10000, Loss: 0.8516, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4058/10000, Loss: 0.8515, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4059/10000, Loss: 0.8514, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4060/10000, Loss: 0.8513, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4061/10000, Loss: 0.8512, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4062/10000, Loss: 0.8511, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4063/10000, Loss: 0.8510, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4064/10000, Loss: 0.8508, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4065/10000, Loss: 0.8507, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4066/10000, Loss: 0.8506, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4067/10000, Loss: 0.8505, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4068/10000, Loss: 0.8504, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4069/10000, Loss: 0.8503, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4070/10000, Loss: 0.8502, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4071/10000, Loss: 0.8501, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4072/10000, Loss: 0.8499, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4073/10000, Loss: 0.8498, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4074/10000, Loss: 0.8497, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4075/10000, Loss: 0.8496, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4076/10000, Loss: 0.8495, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4077/10000, Loss: 0.8494, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4078/10000, Loss: 0.8493, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4079/10000, Loss: 0.8492, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4080/10000, Loss: 0.8491, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4081/10000, Loss: 0.8489, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4082/10000, Loss: 0.8488, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4083/10000, Loss: 0.8487, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4084/10000, Loss: 0.8486, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4085/10000, Loss: 0.8485, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4086/10000, Loss: 0.8484, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4087/10000, Loss: 0.8483, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4088/10000, Loss: 0.8482, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4089/10000, Loss: 0.8481, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4090/10000, Loss: 0.8480, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4091/10000, Loss: 0.8478, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4092/10000, Loss: 0.8477, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4093/10000, Loss: 0.8476, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4094/10000, Loss: 0.8475, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4095/10000, Loss: 0.8474, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4096/10000, Loss: 0.8473, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4097/10000, Loss: 0.8472, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4098/10000, Loss: 0.8471, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4099/10000, Loss: 0.8470, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4100/10000, Loss: 0.8469, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4101/10000, Loss: 0.8468, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4102/10000, Loss: 0.8466, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4103/10000, Loss: 0.8465, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4104/10000, Loss: 0.8464, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4105/10000, Loss: 0.8463, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4106/10000, Loss: 0.8462, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4107/10000, Loss: 0.8461, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4108/10000, Loss: 0.8460, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4109/10000, Loss: 0.8459, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4110/10000, Loss: 0.8458, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4111/10000, Loss: 0.8457, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4112/10000, Loss: 0.8456, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4113/10000, Loss: 0.8455, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4114/10000, Loss: 0.8453, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4115/10000, Loss: 0.8452, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4116/10000, Loss: 0.8451, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4117/10000, Loss: 0.8450, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4118/10000, Loss: 0.8449, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4119/10000, Loss: 0.8448, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4120/10000, Loss: 0.8447, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4121/10000, Loss: 0.8446, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4122/10000, Loss: 0.8445, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4123/10000, Loss: 0.8444, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4124/10000, Loss: 0.8443, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4125/10000, Loss: 0.8442, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4126/10000, Loss: 0.8441, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4127/10000, Loss: 0.8440, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4128/10000, Loss: 0.8439, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4129/10000, Loss: 0.8438, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4130/10000, Loss: 0.8436, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4131/10000, Loss: 0.8435, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4132/10000, Loss: 0.8434, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4133/10000, Loss: 0.8433, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4134/10000, Loss: 0.8432, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4135/10000, Loss: 0.8431, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4136/10000, Loss: 0.8430, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4137/10000, Loss: 0.8429, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4138/10000, Loss: 0.8428, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4139/10000, Loss: 0.8427, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4140/10000, Loss: 0.8426, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4141/10000, Loss: 0.8425, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4142/10000, Loss: 0.8424, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4143/10000, Loss: 0.8423, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4144/10000, Loss: 0.8422, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4145/10000, Loss: 0.8421, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4146/10000, Loss: 0.8420, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4147/10000, Loss: 0.8419, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4148/10000, Loss: 0.8418, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4149/10000, Loss: 0.8417, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4150/10000, Loss: 0.8416, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4151/10000, Loss: 0.8414, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4152/10000, Loss: 0.8413, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4153/10000, Loss: 0.8412, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4154/10000, Loss: 0.8411, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4155/10000, Loss: 0.8410, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4156/10000, Loss: 0.8409, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4157/10000, Loss: 0.8408, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4158/10000, Loss: 0.8407, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4159/10000, Loss: 0.8406, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4160/10000, Loss: 0.8405, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4161/10000, Loss: 0.8404, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4162/10000, Loss: 0.8403, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4163/10000, Loss: 0.8402, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4164/10000, Loss: 0.8401, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4165/10000, Loss: 0.8400, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4166/10000, Loss: 0.8399, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4167/10000, Loss: 0.8398, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4168/10000, Loss: 0.8397, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4169/10000, Loss: 0.8396, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4170/10000, Loss: 0.8395, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4171/10000, Loss: 0.8394, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4172/10000, Loss: 0.8393, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4173/10000, Loss: 0.8392, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4174/10000, Loss: 0.8391, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4175/10000, Loss: 0.8390, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4176/10000, Loss: 0.8389, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4177/10000, Loss: 0.8388, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4178/10000, Loss: 0.8387, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4179/10000, Loss: 0.8386, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4180/10000, Loss: 0.8385, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4181/10000, Loss: 0.8384, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4182/10000, Loss: 0.8383, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4183/10000, Loss: 0.8382, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4184/10000, Loss: 0.8381, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4185/10000, Loss: 0.8380, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4186/10000, Loss: 0.8379, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4187/10000, Loss: 0.8378, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4188/10000, Loss: 0.8377, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4189/10000, Loss: 0.8376, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4190/10000, Loss: 0.8375, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4191/10000, Loss: 0.8374, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4192/10000, Loss: 0.8373, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4193/10000, Loss: 0.8372, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4194/10000, Loss: 0.8371, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4195/10000, Loss: 0.8370, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4196/10000, Loss: 0.8369, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4197/10000, Loss: 0.8368, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4198/10000, Loss: 0.8367, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4199/10000, Loss: 0.8366, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4200/10000, Loss: 0.8365, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4201/10000, Loss: 0.8364, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4202/10000, Loss: 0.8363, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4203/10000, Loss: 0.8362, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4204/10000, Loss: 0.8361, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4205/10000, Loss: 0.8360, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4206/10000, Loss: 0.8359, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4207/10000, Loss: 0.8358, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4208/10000, Loss: 0.8357, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4209/10000, Loss: 0.8356, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4210/10000, Loss: 0.8355, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4211/10000, Loss: 0.8354, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4212/10000, Loss: 0.8353, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4213/10000, Loss: 0.8352, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4214/10000, Loss: 0.8351, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4215/10000, Loss: 0.8350, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4216/10000, Loss: 0.8349, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4217/10000, Loss: 0.8348, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4218/10000, Loss: 0.8347, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4219/10000, Loss: 0.8346, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4220/10000, Loss: 0.8345, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4221/10000, Loss: 0.8344, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4222/10000, Loss: 0.8343, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4223/10000, Loss: 0.8342, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4224/10000, Loss: 0.8341, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4225/10000, Loss: 0.8340, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4226/10000, Loss: 0.8339, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4227/10000, Loss: 0.8338, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4228/10000, Loss: 0.8337, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4229/10000, Loss: 0.8336, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4230/10000, Loss: 0.8335, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4231/10000, Loss: 0.8334, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4232/10000, Loss: 0.8334, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4233/10000, Loss: 0.8333, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4234/10000, Loss: 0.8332, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4235/10000, Loss: 0.8331, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4236/10000, Loss: 0.8330, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4237/10000, Loss: 0.8329, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4238/10000, Loss: 0.8328, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4239/10000, Loss: 0.8327, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4240/10000, Loss: 0.8326, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4241/10000, Loss: 0.8325, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4242/10000, Loss: 0.8324, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4243/10000, Loss: 0.8323, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4244/10000, Loss: 0.8322, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4245/10000, Loss: 0.8321, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4246/10000, Loss: 0.8320, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4247/10000, Loss: 0.8319, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4248/10000, Loss: 0.8318, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4249/10000, Loss: 0.8317, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4250/10000, Loss: 0.8316, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4251/10000, Loss: 0.8315, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4252/10000, Loss: 0.8314, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4253/10000, Loss: 0.8313, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4254/10000, Loss: 0.8313, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4255/10000, Loss: 0.8312, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4256/10000, Loss: 0.8311, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4257/10000, Loss: 0.8310, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4258/10000, Loss: 0.8309, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4259/10000, Loss: 0.8308, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4260/10000, Loss: 0.8307, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4261/10000, Loss: 0.8306, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4262/10000, Loss: 0.8305, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4263/10000, Loss: 0.8304, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4264/10000, Loss: 0.8303, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4265/10000, Loss: 0.8302, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4266/10000, Loss: 0.8301, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4267/10000, Loss: 0.8300, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4268/10000, Loss: 0.8299, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4269/10000, Loss: 0.8298, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4270/10000, Loss: 0.8297, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4271/10000, Loss: 0.8297, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4272/10000, Loss: 0.8296, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4273/10000, Loss: 0.8295, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4274/10000, Loss: 0.8294, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4275/10000, Loss: 0.8293, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4276/10000, Loss: 0.8292, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4277/10000, Loss: 0.8291, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4278/10000, Loss: 0.8290, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4279/10000, Loss: 0.8289, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4280/10000, Loss: 0.8288, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4281/10000, Loss: 0.8287, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4282/10000, Loss: 0.8286, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4283/10000, Loss: 0.8285, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4284/10000, Loss: 0.8285, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4285/10000, Loss: 0.8284, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4286/10000, Loss: 0.8283, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4287/10000, Loss: 0.8282, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4288/10000, Loss: 0.8281, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4289/10000, Loss: 0.8280, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4290/10000, Loss: 0.8279, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4291/10000, Loss: 0.8278, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4292/10000, Loss: 0.8277, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4293/10000, Loss: 0.8276, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4294/10000, Loss: 0.8275, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4295/10000, Loss: 0.8274, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4296/10000, Loss: 0.8274, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4297/10000, Loss: 0.8273, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4298/10000, Loss: 0.8272, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4299/10000, Loss: 0.8271, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4300/10000, Loss: 0.8270, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4301/10000, Loss: 0.8269, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4302/10000, Loss: 0.8268, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4303/10000, Loss: 0.8267, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4304/10000, Loss: 0.8266, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4305/10000, Loss: 0.8265, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4306/10000, Loss: 0.8264, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4307/10000, Loss: 0.8264, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4308/10000, Loss: 0.8263, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4309/10000, Loss: 0.8262, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4310/10000, Loss: 0.8261, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4311/10000, Loss: 0.8260, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4312/10000, Loss: 0.8259, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4313/10000, Loss: 0.8258, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4314/10000, Loss: 0.8257, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4315/10000, Loss: 0.8256, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4316/10000, Loss: 0.8255, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4317/10000, Loss: 0.8255, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4318/10000, Loss: 0.8254, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4319/10000, Loss: 0.8253, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4320/10000, Loss: 0.8252, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4321/10000, Loss: 0.8251, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4322/10000, Loss: 0.8250, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4323/10000, Loss: 0.8249, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4324/10000, Loss: 0.8248, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4325/10000, Loss: 0.8247, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4326/10000, Loss: 0.8247, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4327/10000, Loss: 0.8246, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4328/10000, Loss: 0.8245, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4329/10000, Loss: 0.8244, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4330/10000, Loss: 0.8243, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4331/10000, Loss: 0.8242, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4332/10000, Loss: 0.8241, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4333/10000, Loss: 0.8240, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4334/10000, Loss: 0.8239, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4335/10000, Loss: 0.8239, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4336/10000, Loss: 0.8238, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4337/10000, Loss: 0.8237, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4338/10000, Loss: 0.8236, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4339/10000, Loss: 0.8235, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4340/10000, Loss: 0.8234, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4341/10000, Loss: 0.8233, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4342/10000, Loss: 0.8232, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4343/10000, Loss: 0.8232, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4344/10000, Loss: 0.8231, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4345/10000, Loss: 0.8230, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4346/10000, Loss: 0.8229, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4347/10000, Loss: 0.8228, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4348/10000, Loss: 0.8227, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4349/10000, Loss: 0.8226, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4350/10000, Loss: 0.8225, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4351/10000, Loss: 0.8225, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4352/10000, Loss: 0.8224, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4353/10000, Loss: 0.8223, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4354/10000, Loss: 0.8222, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4355/10000, Loss: 0.8221, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4356/10000, Loss: 0.8220, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4357/10000, Loss: 0.8219, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4358/10000, Loss: 0.8218, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4359/10000, Loss: 0.8218, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4360/10000, Loss: 0.8217, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4361/10000, Loss: 0.8216, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4362/10000, Loss: 0.8215, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4363/10000, Loss: 0.8214, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4364/10000, Loss: 0.8213, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4365/10000, Loss: 0.8212, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4366/10000, Loss: 0.8212, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4367/10000, Loss: 0.8211, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4368/10000, Loss: 0.8210, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4369/10000, Loss: 0.8209, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4370/10000, Loss: 0.8208, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4371/10000, Loss: 0.8207, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4372/10000, Loss: 0.8206, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4373/10000, Loss: 0.8206, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4374/10000, Loss: 0.8205, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4375/10000, Loss: 0.8204, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4376/10000, Loss: 0.8203, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4377/10000, Loss: 0.8202, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4378/10000, Loss: 0.8201, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4379/10000, Loss: 0.8200, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4380/10000, Loss: 0.8200, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4381/10000, Loss: 0.8199, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4382/10000, Loss: 0.8198, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4383/10000, Loss: 0.8197, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4384/10000, Loss: 0.8196, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4385/10000, Loss: 0.8195, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4386/10000, Loss: 0.8195, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4387/10000, Loss: 0.8194, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4388/10000, Loss: 0.8193, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4389/10000, Loss: 0.8192, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4390/10000, Loss: 0.8191, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4391/10000, Loss: 0.8190, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4392/10000, Loss: 0.8190, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4393/10000, Loss: 0.8189, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4394/10000, Loss: 0.8188, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4395/10000, Loss: 0.8187, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4396/10000, Loss: 0.8186, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4397/10000, Loss: 0.8185, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4398/10000, Loss: 0.8184, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4399/10000, Loss: 0.8184, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4400/10000, Loss: 0.8183, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4401/10000, Loss: 0.8182, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4402/10000, Loss: 0.8181, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4403/10000, Loss: 0.8180, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4404/10000, Loss: 0.8179, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4405/10000, Loss: 0.8179, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4406/10000, Loss: 0.8178, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4407/10000, Loss: 0.8177, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4408/10000, Loss: 0.8176, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4409/10000, Loss: 0.8175, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4410/10000, Loss: 0.8175, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4411/10000, Loss: 0.8174, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4412/10000, Loss: 0.8173, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4413/10000, Loss: 0.8172, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4414/10000, Loss: 0.8171, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4415/10000, Loss: 0.8170, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4416/10000, Loss: 0.8170, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4417/10000, Loss: 0.8169, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4418/10000, Loss: 0.8168, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4419/10000, Loss: 0.8167, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4420/10000, Loss: 0.8166, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4421/10000, Loss: 0.8165, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4422/10000, Loss: 0.8165, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4423/10000, Loss: 0.8164, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4424/10000, Loss: 0.8163, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4425/10000, Loss: 0.8162, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4426/10000, Loss: 0.8161, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4427/10000, Loss: 0.8161, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4428/10000, Loss: 0.8160, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4429/10000, Loss: 0.8159, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4430/10000, Loss: 0.8158, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4431/10000, Loss: 0.8157, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4432/10000, Loss: 0.8156, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4433/10000, Loss: 0.8156, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4434/10000, Loss: 0.8155, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4435/10000, Loss: 0.8154, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4436/10000, Loss: 0.8153, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4437/10000, Loss: 0.8152, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4438/10000, Loss: 0.8152, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4439/10000, Loss: 0.8151, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4440/10000, Loss: 0.8150, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4441/10000, Loss: 0.8149, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4442/10000, Loss: 0.8148, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4443/10000, Loss: 0.8148, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4444/10000, Loss: 0.8147, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4445/10000, Loss: 0.8146, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4446/10000, Loss: 0.8145, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4447/10000, Loss: 0.8144, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4448/10000, Loss: 0.8144, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4449/10000, Loss: 0.8143, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4450/10000, Loss: 0.8142, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4451/10000, Loss: 0.8141, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4452/10000, Loss: 0.8140, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4453/10000, Loss: 0.8140, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4454/10000, Loss: 0.8139, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4455/10000, Loss: 0.8138, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4456/10000, Loss: 0.8137, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4457/10000, Loss: 0.8136, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4458/10000, Loss: 0.8136, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4459/10000, Loss: 0.8135, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4460/10000, Loss: 0.8134, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4461/10000, Loss: 0.8133, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4462/10000, Loss: 0.8132, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4463/10000, Loss: 0.8132, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4464/10000, Loss: 0.8131, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4465/10000, Loss: 0.8130, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4466/10000, Loss: 0.8129, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4467/10000, Loss: 0.8128, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4468/10000, Loss: 0.8128, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4469/10000, Loss: 0.8127, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4470/10000, Loss: 0.8126, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4471/10000, Loss: 0.8125, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4472/10000, Loss: 0.8124, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4473/10000, Loss: 0.8124, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4474/10000, Loss: 0.8123, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4475/10000, Loss: 0.8122, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4476/10000, Loss: 0.8121, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4477/10000, Loss: 0.8121, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4478/10000, Loss: 0.8120, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4479/10000, Loss: 0.8119, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4480/10000, Loss: 0.8118, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4481/10000, Loss: 0.8117, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4482/10000, Loss: 0.8117, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4483/10000, Loss: 0.8116, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4484/10000, Loss: 0.8115, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4485/10000, Loss: 0.8114, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4486/10000, Loss: 0.8114, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4487/10000, Loss: 0.8113, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4488/10000, Loss: 0.8112, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4489/10000, Loss: 0.8111, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4490/10000, Loss: 0.8110, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4491/10000, Loss: 0.8110, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4492/10000, Loss: 0.8109, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4493/10000, Loss: 0.8108, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4494/10000, Loss: 0.8107, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4495/10000, Loss: 0.8107, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4496/10000, Loss: 0.8106, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4497/10000, Loss: 0.8105, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4498/10000, Loss: 0.8104, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4499/10000, Loss: 0.8103, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4500/10000, Loss: 0.8103, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4501/10000, Loss: 0.8102, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4502/10000, Loss: 0.8101, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4503/10000, Loss: 0.8100, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4504/10000, Loss: 0.8100, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4505/10000, Loss: 0.8099, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4506/10000, Loss: 0.8098, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4507/10000, Loss: 0.8097, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4508/10000, Loss: 0.8097, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4509/10000, Loss: 0.8096, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4510/10000, Loss: 0.8095, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4511/10000, Loss: 0.8094, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4512/10000, Loss: 0.8094, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4513/10000, Loss: 0.8093, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4514/10000, Loss: 0.8092, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4515/10000, Loss: 0.8091, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4516/10000, Loss: 0.8091, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4517/10000, Loss: 0.8090, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4518/10000, Loss: 0.8089, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4519/10000, Loss: 0.8088, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4520/10000, Loss: 0.8087, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4521/10000, Loss: 0.8087, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4522/10000, Loss: 0.8086, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4523/10000, Loss: 0.8085, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4524/10000, Loss: 0.8084, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4525/10000, Loss: 0.8084, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4526/10000, Loss: 0.8083, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4527/10000, Loss: 0.8082, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4528/10000, Loss: 0.8081, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4529/10000, Loss: 0.8081, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4530/10000, Loss: 0.8080, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4531/10000, Loss: 0.8079, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4532/10000, Loss: 0.8078, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4533/10000, Loss: 0.8078, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4534/10000, Loss: 0.8077, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4535/10000, Loss: 0.8076, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4536/10000, Loss: 0.8075, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4537/10000, Loss: 0.8075, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4538/10000, Loss: 0.8074, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4539/10000, Loss: 0.8073, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4540/10000, Loss: 0.8072, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4541/10000, Loss: 0.8072, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4542/10000, Loss: 0.8071, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4543/10000, Loss: 0.8070, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4544/10000, Loss: 0.8070, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4545/10000, Loss: 0.8069, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4546/10000, Loss: 0.8068, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4547/10000, Loss: 0.8067, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4548/10000, Loss: 0.8067, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4549/10000, Loss: 0.8066, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4550/10000, Loss: 0.8065, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4551/10000, Loss: 0.8064, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4552/10000, Loss: 0.8064, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4553/10000, Loss: 0.8063, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4554/10000, Loss: 0.8062, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4555/10000, Loss: 0.8061, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4556/10000, Loss: 0.8061, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4557/10000, Loss: 0.8060, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4558/10000, Loss: 0.8059, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4559/10000, Loss: 0.8058, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4560/10000, Loss: 0.8058, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4561/10000, Loss: 0.8057, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4562/10000, Loss: 0.8056, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4563/10000, Loss: 0.8056, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4564/10000, Loss: 0.8055, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4565/10000, Loss: 0.8054, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4566/10000, Loss: 0.8053, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4567/10000, Loss: 0.8053, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4568/10000, Loss: 0.8052, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4569/10000, Loss: 0.8051, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4570/10000, Loss: 0.8050, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4571/10000, Loss: 0.8050, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4572/10000, Loss: 0.8049, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4573/10000, Loss: 0.8048, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4574/10000, Loss: 0.8048, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4575/10000, Loss: 0.8047, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4576/10000, Loss: 0.8046, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4577/10000, Loss: 0.8045, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4578/10000, Loss: 0.8045, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4579/10000, Loss: 0.8044, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4580/10000, Loss: 0.8043, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4581/10000, Loss: 0.8042, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4582/10000, Loss: 0.8042, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4583/10000, Loss: 0.8041, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4584/10000, Loss: 0.8040, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4585/10000, Loss: 0.8040, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4586/10000, Loss: 0.8039, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4587/10000, Loss: 0.8038, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4588/10000, Loss: 0.8037, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4589/10000, Loss: 0.8037, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4590/10000, Loss: 0.8036, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4591/10000, Loss: 0.8035, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4592/10000, Loss: 0.8035, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4593/10000, Loss: 0.8034, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4594/10000, Loss: 0.8033, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4595/10000, Loss: 0.8032, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4596/10000, Loss: 0.8032, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4597/10000, Loss: 0.8031, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4598/10000, Loss: 0.8030, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4599/10000, Loss: 0.8030, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4600/10000, Loss: 0.8029, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4601/10000, Loss: 0.8028, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4602/10000, Loss: 0.8027, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4603/10000, Loss: 0.8027, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4604/10000, Loss: 0.8026, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4605/10000, Loss: 0.8025, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4606/10000, Loss: 0.8025, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4607/10000, Loss: 0.8024, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4608/10000, Loss: 0.8023, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4609/10000, Loss: 0.8023, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4610/10000, Loss: 0.8022, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4611/10000, Loss: 0.8021, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4612/10000, Loss: 0.8020, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4613/10000, Loss: 0.8020, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4614/10000, Loss: 0.8019, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4615/10000, Loss: 0.8018, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4616/10000, Loss: 0.8018, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4617/10000, Loss: 0.8017, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4618/10000, Loss: 0.8016, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4619/10000, Loss: 0.8016, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4620/10000, Loss: 0.8015, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4621/10000, Loss: 0.8014, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4622/10000, Loss: 0.8013, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4623/10000, Loss: 0.8013, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4624/10000, Loss: 0.8012, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4625/10000, Loss: 0.8011, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4626/10000, Loss: 0.8011, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4627/10000, Loss: 0.8010, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4628/10000, Loss: 0.8009, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4629/10000, Loss: 0.8009, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4630/10000, Loss: 0.8008, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4631/10000, Loss: 0.8007, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4632/10000, Loss: 0.8006, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4633/10000, Loss: 0.8006, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4634/10000, Loss: 0.8005, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4635/10000, Loss: 0.8004, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4636/10000, Loss: 0.8004, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4637/10000, Loss: 0.8003, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4638/10000, Loss: 0.8002, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4639/10000, Loss: 0.8002, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4640/10000, Loss: 0.8001, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4641/10000, Loss: 0.8000, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4642/10000, Loss: 0.8000, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4643/10000, Loss: 0.7999, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4644/10000, Loss: 0.7998, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4645/10000, Loss: 0.7998, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4646/10000, Loss: 0.7997, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4647/10000, Loss: 0.7996, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4648/10000, Loss: 0.7995, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4649/10000, Loss: 0.7995, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4650/10000, Loss: 0.7994, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4651/10000, Loss: 0.7993, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4652/10000, Loss: 0.7993, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4653/10000, Loss: 0.7992, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4654/10000, Loss: 0.7991, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4655/10000, Loss: 0.7991, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4656/10000, Loss: 0.7990, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4657/10000, Loss: 0.7989, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4658/10000, Loss: 0.7989, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4659/10000, Loss: 0.7988, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4660/10000, Loss: 0.7987, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4661/10000, Loss: 0.7987, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4662/10000, Loss: 0.7986, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4663/10000, Loss: 0.7985, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4664/10000, Loss: 0.7985, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4665/10000, Loss: 0.7984, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4666/10000, Loss: 0.7983, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4667/10000, Loss: 0.7983, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4668/10000, Loss: 0.7982, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4669/10000, Loss: 0.7981, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4670/10000, Loss: 0.7981, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4671/10000, Loss: 0.7980, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4672/10000, Loss: 0.7979, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4673/10000, Loss: 0.7979, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4674/10000, Loss: 0.7978, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4675/10000, Loss: 0.7977, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4676/10000, Loss: 0.7977, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4677/10000, Loss: 0.7976, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4678/10000, Loss: 0.7975, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4679/10000, Loss: 0.7975, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4680/10000, Loss: 0.7974, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4681/10000, Loss: 0.7973, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4682/10000, Loss: 0.7973, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4683/10000, Loss: 0.7972, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4684/10000, Loss: 0.7971, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4685/10000, Loss: 0.7971, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4686/10000, Loss: 0.7970, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4687/10000, Loss: 0.7969, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4688/10000, Loss: 0.7969, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4689/10000, Loss: 0.7968, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4690/10000, Loss: 0.7967, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4691/10000, Loss: 0.7967, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4692/10000, Loss: 0.7966, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4693/10000, Loss: 0.7965, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4694/10000, Loss: 0.7965, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4695/10000, Loss: 0.7964, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4696/10000, Loss: 0.7963, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4697/10000, Loss: 0.7963, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4698/10000, Loss: 0.7962, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4699/10000, Loss: 0.7961, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4700/10000, Loss: 0.7961, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4701/10000, Loss: 0.7960, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4702/10000, Loss: 0.7959, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4703/10000, Loss: 0.7959, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4704/10000, Loss: 0.7958, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4705/10000, Loss: 0.7957, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4706/10000, Loss: 0.7957, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4707/10000, Loss: 0.7956, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4708/10000, Loss: 0.7955, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4709/10000, Loss: 0.7955, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4710/10000, Loss: 0.7954, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4711/10000, Loss: 0.7954, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4712/10000, Loss: 0.7953, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4713/10000, Loss: 0.7952, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4714/10000, Loss: 0.7952, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4715/10000, Loss: 0.7951, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4716/10000, Loss: 0.7950, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4717/10000, Loss: 0.7950, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4718/10000, Loss: 0.7949, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4719/10000, Loss: 0.7948, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4720/10000, Loss: 0.7948, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4721/10000, Loss: 0.7947, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4722/10000, Loss: 0.7946, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4723/10000, Loss: 0.7946, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4724/10000, Loss: 0.7945, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4725/10000, Loss: 0.7944, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4726/10000, Loss: 0.7944, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4727/10000, Loss: 0.7943, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4728/10000, Loss: 0.7943, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4729/10000, Loss: 0.7942, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4730/10000, Loss: 0.7941, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4731/10000, Loss: 0.7941, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4732/10000, Loss: 0.7940, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4733/10000, Loss: 0.7939, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4734/10000, Loss: 0.7939, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4735/10000, Loss: 0.7938, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4736/10000, Loss: 0.7937, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4737/10000, Loss: 0.7937, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4738/10000, Loss: 0.7936, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4739/10000, Loss: 0.7936, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4740/10000, Loss: 0.7935, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4741/10000, Loss: 0.7934, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4742/10000, Loss: 0.7934, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4743/10000, Loss: 0.7933, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4744/10000, Loss: 0.7932, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4745/10000, Loss: 0.7932, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4746/10000, Loss: 0.7931, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4747/10000, Loss: 0.7930, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4748/10000, Loss: 0.7930, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4749/10000, Loss: 0.7929, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4750/10000, Loss: 0.7929, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4751/10000, Loss: 0.7928, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4752/10000, Loss: 0.7927, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4753/10000, Loss: 0.7927, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4754/10000, Loss: 0.7926, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4755/10000, Loss: 0.7925, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4756/10000, Loss: 0.7925, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4757/10000, Loss: 0.7924, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4758/10000, Loss: 0.7924, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4759/10000, Loss: 0.7923, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4760/10000, Loss: 0.7922, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4761/10000, Loss: 0.7922, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4762/10000, Loss: 0.7921, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4763/10000, Loss: 0.7920, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4764/10000, Loss: 0.7920, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4765/10000, Loss: 0.7919, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4766/10000, Loss: 0.7919, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4767/10000, Loss: 0.7918, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4768/10000, Loss: 0.7917, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4769/10000, Loss: 0.7917, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4770/10000, Loss: 0.7916, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4771/10000, Loss: 0.7915, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4772/10000, Loss: 0.7915, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4773/10000, Loss: 0.7914, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4774/10000, Loss: 0.7914, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4775/10000, Loss: 0.7913, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4776/10000, Loss: 0.7912, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4777/10000, Loss: 0.7912, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4778/10000, Loss: 0.7911, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4779/10000, Loss: 0.7910, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4780/10000, Loss: 0.7910, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4781/10000, Loss: 0.7909, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4782/10000, Loss: 0.7909, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4783/10000, Loss: 0.7908, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4784/10000, Loss: 0.7907, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4785/10000, Loss: 0.7907, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4786/10000, Loss: 0.7906, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4787/10000, Loss: 0.7906, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4788/10000, Loss: 0.7905, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4789/10000, Loss: 0.7904, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4790/10000, Loss: 0.7904, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4791/10000, Loss: 0.7903, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4792/10000, Loss: 0.7903, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4793/10000, Loss: 0.7902, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4794/10000, Loss: 0.7901, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4795/10000, Loss: 0.7901, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4796/10000, Loss: 0.7900, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4797/10000, Loss: 0.7899, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4798/10000, Loss: 0.7899, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4799/10000, Loss: 0.7898, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4800/10000, Loss: 0.7898, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4801/10000, Loss: 0.7897, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4802/10000, Loss: 0.7896, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4803/10000, Loss: 0.7896, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4804/10000, Loss: 0.7895, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4805/10000, Loss: 0.7895, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4806/10000, Loss: 0.7894, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4807/10000, Loss: 0.7893, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4808/10000, Loss: 0.7893, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4809/10000, Loss: 0.7892, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4810/10000, Loss: 0.7892, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4811/10000, Loss: 0.7891, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4812/10000, Loss: 0.7890, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4813/10000, Loss: 0.7890, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4814/10000, Loss: 0.7889, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4815/10000, Loss: 0.7889, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4816/10000, Loss: 0.7888, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4817/10000, Loss: 0.7887, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4818/10000, Loss: 0.7887, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4819/10000, Loss: 0.7886, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4820/10000, Loss: 0.7886, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4821/10000, Loss: 0.7885, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4822/10000, Loss: 0.7884, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4823/10000, Loss: 0.7884, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4824/10000, Loss: 0.7883, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4825/10000, Loss: 0.7883, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4826/10000, Loss: 0.7882, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4827/10000, Loss: 0.7881, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4828/10000, Loss: 0.7881, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4829/10000, Loss: 0.7880, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4830/10000, Loss: 0.7880, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4831/10000, Loss: 0.7879, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4832/10000, Loss: 0.7878, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4833/10000, Loss: 0.7878, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4834/10000, Loss: 0.7877, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4835/10000, Loss: 0.7877, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4836/10000, Loss: 0.7876, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4837/10000, Loss: 0.7875, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4838/10000, Loss: 0.7875, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4839/10000, Loss: 0.7874, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4840/10000, Loss: 0.7874, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4841/10000, Loss: 0.7873, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4842/10000, Loss: 0.7873, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4843/10000, Loss: 0.7872, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4844/10000, Loss: 0.7871, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4845/10000, Loss: 0.7871, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4846/10000, Loss: 0.7870, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4847/10000, Loss: 0.7870, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4848/10000, Loss: 0.7869, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4849/10000, Loss: 0.7868, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4850/10000, Loss: 0.7868, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4851/10000, Loss: 0.7867, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4852/10000, Loss: 0.7867, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4853/10000, Loss: 0.7866, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4854/10000, Loss: 0.7866, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4855/10000, Loss: 0.7865, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4856/10000, Loss: 0.7864, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4857/10000, Loss: 0.7864, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4858/10000, Loss: 0.7863, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4859/10000, Loss: 0.7863, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4860/10000, Loss: 0.7862, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4861/10000, Loss: 0.7861, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4862/10000, Loss: 0.7861, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 4863/10000, Loss: 0.7860, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4864/10000, Loss: 0.7860, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4865/10000, Loss: 0.7859, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4866/10000, Loss: 0.7859, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4867/10000, Loss: 0.7858, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4868/10000, Loss: 0.7857, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4869/10000, Loss: 0.7857, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4870/10000, Loss: 0.7856, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4871/10000, Loss: 0.7856, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4872/10000, Loss: 0.7855, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4873/10000, Loss: 0.7855, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4874/10000, Loss: 0.7854, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4875/10000, Loss: 0.7853, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4876/10000, Loss: 0.7853, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4877/10000, Loss: 0.7852, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4878/10000, Loss: 0.7852, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4879/10000, Loss: 0.7851, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4880/10000, Loss: 0.7851, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4881/10000, Loss: 0.7850, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4882/10000, Loss: 0.7849, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4883/10000, Loss: 0.7849, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4884/10000, Loss: 0.7848, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4885/10000, Loss: 0.7848, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4886/10000, Loss: 0.7847, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4887/10000, Loss: 0.7847, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4888/10000, Loss: 0.7846, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4889/10000, Loss: 0.7845, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4890/10000, Loss: 0.7845, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4891/10000, Loss: 0.7844, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4892/10000, Loss: 0.7844, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4893/10000, Loss: 0.7843, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4894/10000, Loss: 0.7843, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4895/10000, Loss: 0.7842, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4896/10000, Loss: 0.7841, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4897/10000, Loss: 0.7841, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4898/10000, Loss: 0.7840, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4899/10000, Loss: 0.7840, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4900/10000, Loss: 0.7839, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4901/10000, Loss: 0.7839, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4902/10000, Loss: 0.7838, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4903/10000, Loss: 0.7837, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4904/10000, Loss: 0.7837, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4905/10000, Loss: 0.7836, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4906/10000, Loss: 0.7836, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4907/10000, Loss: 0.7835, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4908/10000, Loss: 0.7835, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4909/10000, Loss: 0.7834, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4910/10000, Loss: 0.7834, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4911/10000, Loss: 0.7833, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4912/10000, Loss: 0.7832, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4913/10000, Loss: 0.7832, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4914/10000, Loss: 0.7831, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4915/10000, Loss: 0.7831, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4916/10000, Loss: 0.7830, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4917/10000, Loss: 0.7830, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4918/10000, Loss: 0.7829, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4919/10000, Loss: 0.7829, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4920/10000, Loss: 0.7828, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4921/10000, Loss: 0.7827, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4922/10000, Loss: 0.7827, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4923/10000, Loss: 0.7826, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4924/10000, Loss: 0.7826, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4925/10000, Loss: 0.7825, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4926/10000, Loss: 0.7825, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4927/10000, Loss: 0.7824, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4928/10000, Loss: 0.7824, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4929/10000, Loss: 0.7823, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4930/10000, Loss: 0.7822, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4931/10000, Loss: 0.7822, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4932/10000, Loss: 0.7821, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4933/10000, Loss: 0.7821, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4934/10000, Loss: 0.7820, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4935/10000, Loss: 0.7820, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4936/10000, Loss: 0.7819, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4937/10000, Loss: 0.7819, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4938/10000, Loss: 0.7818, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4939/10000, Loss: 0.7818, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4940/10000, Loss: 0.7817, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4941/10000, Loss: 0.7816, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4942/10000, Loss: 0.7816, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4943/10000, Loss: 0.7815, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4944/10000, Loss: 0.7815, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4945/10000, Loss: 0.7814, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4946/10000, Loss: 0.7814, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4947/10000, Loss: 0.7813, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4948/10000, Loss: 0.7813, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4949/10000, Loss: 0.7812, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4950/10000, Loss: 0.7812, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4951/10000, Loss: 0.7811, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4952/10000, Loss: 0.7810, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4953/10000, Loss: 0.7810, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4954/10000, Loss: 0.7809, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4955/10000, Loss: 0.7809, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4956/10000, Loss: 0.7808, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4957/10000, Loss: 0.7808, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4958/10000, Loss: 0.7807, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4959/10000, Loss: 0.7807, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4960/10000, Loss: 0.7806, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4961/10000, Loss: 0.7806, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4962/10000, Loss: 0.7805, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4963/10000, Loss: 0.7805, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4964/10000, Loss: 0.7804, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4965/10000, Loss: 0.7803, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4966/10000, Loss: 0.7803, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4967/10000, Loss: 0.7802, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4968/10000, Loss: 0.7802, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4969/10000, Loss: 0.7801, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4970/10000, Loss: 0.7801, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4971/10000, Loss: 0.7800, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4972/10000, Loss: 0.7800, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4973/10000, Loss: 0.7799, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4974/10000, Loss: 0.7799, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4975/10000, Loss: 0.7798, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4976/10000, Loss: 0.7798, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4977/10000, Loss: 0.7797, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4978/10000, Loss: 0.7796, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4979/10000, Loss: 0.7796, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4980/10000, Loss: 0.7795, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4981/10000, Loss: 0.7795, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4982/10000, Loss: 0.7794, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4983/10000, Loss: 0.7794, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4984/10000, Loss: 0.7793, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4985/10000, Loss: 0.7793, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4986/10000, Loss: 0.7792, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4987/10000, Loss: 0.7792, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4988/10000, Loss: 0.7791, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4989/10000, Loss: 0.7791, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4990/10000, Loss: 0.7790, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4991/10000, Loss: 0.7790, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4992/10000, Loss: 0.7789, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4993/10000, Loss: 0.7789, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4994/10000, Loss: 0.7788, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4995/10000, Loss: 0.7788, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4996/10000, Loss: 0.7787, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4997/10000, Loss: 0.7786, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 4998/10000, Loss: 0.7786, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 4999/10000, Loss: 0.7785, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5000/10000, Loss: 0.7785, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5001/10000, Loss: 0.7784, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5002/10000, Loss: 0.7784, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5003/10000, Loss: 0.7783, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5004/10000, Loss: 0.7783, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5005/10000, Loss: 0.7782, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5006/10000, Loss: 0.7782, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5007/10000, Loss: 0.7781, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5008/10000, Loss: 0.7781, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5009/10000, Loss: 0.7780, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5010/10000, Loss: 0.7780, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5011/10000, Loss: 0.7779, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5012/10000, Loss: 0.7779, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5013/10000, Loss: 0.7778, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5014/10000, Loss: 0.7778, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5015/10000, Loss: 0.7777, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5016/10000, Loss: 0.7777, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5017/10000, Loss: 0.7776, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5018/10000, Loss: 0.7776, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5019/10000, Loss: 0.7775, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5020/10000, Loss: 0.7774, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5021/10000, Loss: 0.7774, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5022/10000, Loss: 0.7773, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5023/10000, Loss: 0.7773, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5024/10000, Loss: 0.7772, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5025/10000, Loss: 0.7772, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5026/10000, Loss: 0.7771, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5027/10000, Loss: 0.7771, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5028/10000, Loss: 0.7770, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5029/10000, Loss: 0.7770, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5030/10000, Loss: 0.7769, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5031/10000, Loss: 0.7769, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5032/10000, Loss: 0.7768, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5033/10000, Loss: 0.7768, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5034/10000, Loss: 0.7767, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5035/10000, Loss: 0.7767, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5036/10000, Loss: 0.7766, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5037/10000, Loss: 0.7766, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5038/10000, Loss: 0.7765, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5039/10000, Loss: 0.7765, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5040/10000, Loss: 0.7764, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5041/10000, Loss: 0.7764, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5042/10000, Loss: 0.7763, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5043/10000, Loss: 0.7763, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5044/10000, Loss: 0.7762, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5045/10000, Loss: 0.7762, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5046/10000, Loss: 0.7761, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5047/10000, Loss: 0.7761, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5048/10000, Loss: 0.7760, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5049/10000, Loss: 0.7760, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5050/10000, Loss: 0.7759, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5051/10000, Loss: 0.7759, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5052/10000, Loss: 0.7758, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5053/10000, Loss: 0.7758, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5054/10000, Loss: 0.7757, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5055/10000, Loss: 0.7757, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5056/10000, Loss: 0.7756, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5057/10000, Loss: 0.7756, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5058/10000, Loss: 0.7755, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5059/10000, Loss: 0.7755, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5060/10000, Loss: 0.7754, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5061/10000, Loss: 0.7754, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5062/10000, Loss: 0.7753, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5063/10000, Loss: 0.7753, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5064/10000, Loss: 0.7752, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5065/10000, Loss: 0.7752, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5066/10000, Loss: 0.7751, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5067/10000, Loss: 0.7751, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5068/10000, Loss: 0.7750, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5069/10000, Loss: 0.7750, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5070/10000, Loss: 0.7749, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5071/10000, Loss: 0.7749, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5072/10000, Loss: 0.7748, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5073/10000, Loss: 0.7748, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5074/10000, Loss: 0.7747, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5075/10000, Loss: 0.7747, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5076/10000, Loss: 0.7746, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5077/10000, Loss: 0.7746, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5078/10000, Loss: 0.7745, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5079/10000, Loss: 0.7745, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5080/10000, Loss: 0.7744, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5081/10000, Loss: 0.7744, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5082/10000, Loss: 0.7743, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5083/10000, Loss: 0.7743, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5084/10000, Loss: 0.7742, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5085/10000, Loss: 0.7742, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5086/10000, Loss: 0.7741, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5087/10000, Loss: 0.7741, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5088/10000, Loss: 0.7740, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5089/10000, Loss: 0.7740, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5090/10000, Loss: 0.7739, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5091/10000, Loss: 0.7739, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5092/10000, Loss: 0.7738, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5093/10000, Loss: 0.7738, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5094/10000, Loss: 0.7737, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5095/10000, Loss: 0.7737, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5096/10000, Loss: 0.7736, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5097/10000, Loss: 0.7736, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5098/10000, Loss: 0.7735, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5099/10000, Loss: 0.7735, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5100/10000, Loss: 0.7734, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5101/10000, Loss: 0.7734, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5102/10000, Loss: 0.7733, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5103/10000, Loss: 0.7733, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5104/10000, Loss: 0.7732, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5105/10000, Loss: 0.7732, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5106/10000, Loss: 0.7731, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5107/10000, Loss: 0.7731, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5108/10000, Loss: 0.7730, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5109/10000, Loss: 0.7730, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5110/10000, Loss: 0.7729, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5111/10000, Loss: 0.7729, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5112/10000, Loss: 0.7728, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5113/10000, Loss: 0.7728, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5114/10000, Loss: 0.7728, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5115/10000, Loss: 0.7727, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5116/10000, Loss: 0.7727, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5117/10000, Loss: 0.7726, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5118/10000, Loss: 0.7726, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5119/10000, Loss: 0.7725, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5120/10000, Loss: 0.7725, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5121/10000, Loss: 0.7724, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5122/10000, Loss: 0.7724, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5123/10000, Loss: 0.7723, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5124/10000, Loss: 0.7723, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5125/10000, Loss: 0.7722, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5126/10000, Loss: 0.7722, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5127/10000, Loss: 0.7721, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5128/10000, Loss: 0.7721, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5129/10000, Loss: 0.7720, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5130/10000, Loss: 0.7720, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5131/10000, Loss: 0.7719, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5132/10000, Loss: 0.7719, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5133/10000, Loss: 0.7718, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5134/10000, Loss: 0.7718, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5135/10000, Loss: 0.7717, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5136/10000, Loss: 0.7717, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5137/10000, Loss: 0.7716, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5138/10000, Loss: 0.7716, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5139/10000, Loss: 0.7716, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5140/10000, Loss: 0.7715, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5141/10000, Loss: 0.7715, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5142/10000, Loss: 0.7714, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5143/10000, Loss: 0.7714, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5144/10000, Loss: 0.7713, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5145/10000, Loss: 0.7713, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5146/10000, Loss: 0.7712, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5147/10000, Loss: 0.7712, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5148/10000, Loss: 0.7711, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5149/10000, Loss: 0.7711, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5150/10000, Loss: 0.7710, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5151/10000, Loss: 0.7710, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5152/10000, Loss: 0.7709, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5153/10000, Loss: 0.7709, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5154/10000, Loss: 0.7708, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5155/10000, Loss: 0.7708, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5156/10000, Loss: 0.7707, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5157/10000, Loss: 0.7707, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5158/10000, Loss: 0.7707, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5159/10000, Loss: 0.7706, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5160/10000, Loss: 0.7706, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5161/10000, Loss: 0.7705, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5162/10000, Loss: 0.7705, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5163/10000, Loss: 0.7704, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5164/10000, Loss: 0.7704, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5165/10000, Loss: 0.7703, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5166/10000, Loss: 0.7703, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5167/10000, Loss: 0.7702, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5168/10000, Loss: 0.7702, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5169/10000, Loss: 0.7701, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5170/10000, Loss: 0.7701, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5171/10000, Loss: 0.7700, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5172/10000, Loss: 0.7700, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5173/10000, Loss: 0.7700, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5174/10000, Loss: 0.7699, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5175/10000, Loss: 0.7699, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5176/10000, Loss: 0.7698, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5177/10000, Loss: 0.7698, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5178/10000, Loss: 0.7697, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5179/10000, Loss: 0.7697, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5180/10000, Loss: 0.7696, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5181/10000, Loss: 0.7696, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5182/10000, Loss: 0.7695, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5183/10000, Loss: 0.7695, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5184/10000, Loss: 0.7694, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5185/10000, Loss: 0.7694, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5186/10000, Loss: 0.7694, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5187/10000, Loss: 0.7693, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5188/10000, Loss: 0.7693, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5189/10000, Loss: 0.7692, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5190/10000, Loss: 0.7692, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5191/10000, Loss: 0.7691, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5192/10000, Loss: 0.7691, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5193/10000, Loss: 0.7690, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5194/10000, Loss: 0.7690, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5195/10000, Loss: 0.7689, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5196/10000, Loss: 0.7689, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5197/10000, Loss: 0.7688, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5198/10000, Loss: 0.7688, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5199/10000, Loss: 0.7688, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5200/10000, Loss: 0.7687, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5201/10000, Loss: 0.7687, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5202/10000, Loss: 0.7686, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5203/10000, Loss: 0.7686, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5204/10000, Loss: 0.7685, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5205/10000, Loss: 0.7685, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5206/10000, Loss: 0.7684, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5207/10000, Loss: 0.7684, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5208/10000, Loss: 0.7683, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5209/10000, Loss: 0.7683, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5210/10000, Loss: 0.7683, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5211/10000, Loss: 0.7682, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5212/10000, Loss: 0.7682, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5213/10000, Loss: 0.7681, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5214/10000, Loss: 0.7681, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5215/10000, Loss: 0.7680, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5216/10000, Loss: 0.7680, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5217/10000, Loss: 0.7679, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5218/10000, Loss: 0.7679, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5219/10000, Loss: 0.7679, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5220/10000, Loss: 0.7678, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5221/10000, Loss: 0.7678, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5222/10000, Loss: 0.7677, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5223/10000, Loss: 0.7677, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5224/10000, Loss: 0.7676, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5225/10000, Loss: 0.7676, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5226/10000, Loss: 0.7675, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5227/10000, Loss: 0.7675, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5228/10000, Loss: 0.7674, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5229/10000, Loss: 0.7674, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5230/10000, Loss: 0.7674, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5231/10000, Loss: 0.7673, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5232/10000, Loss: 0.7673, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5233/10000, Loss: 0.7672, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5234/10000, Loss: 0.7672, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5235/10000, Loss: 0.7671, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5236/10000, Loss: 0.7671, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5237/10000, Loss: 0.7670, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5238/10000, Loss: 0.7670, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5239/10000, Loss: 0.7670, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5240/10000, Loss: 0.7669, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5241/10000, Loss: 0.7669, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5242/10000, Loss: 0.7668, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5243/10000, Loss: 0.7668, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5244/10000, Loss: 0.7667, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5245/10000, Loss: 0.7667, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5246/10000, Loss: 0.7666, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5247/10000, Loss: 0.7666, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5248/10000, Loss: 0.7666, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5249/10000, Loss: 0.7665, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5250/10000, Loss: 0.7665, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5251/10000, Loss: 0.7664, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5252/10000, Loss: 0.7664, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5253/10000, Loss: 0.7663, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5254/10000, Loss: 0.7663, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5255/10000, Loss: 0.7662, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5256/10000, Loss: 0.7662, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5257/10000, Loss: 0.7662, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5258/10000, Loss: 0.7661, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5259/10000, Loss: 0.7661, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5260/10000, Loss: 0.7660, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5261/10000, Loss: 0.7660, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5262/10000, Loss: 0.7659, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5263/10000, Loss: 0.7659, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5264/10000, Loss: 0.7659, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5265/10000, Loss: 0.7658, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5266/10000, Loss: 0.7658, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5267/10000, Loss: 0.7657, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5268/10000, Loss: 0.7657, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5269/10000, Loss: 0.7656, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5270/10000, Loss: 0.7656, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5271/10000, Loss: 0.7655, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5272/10000, Loss: 0.7655, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5273/10000, Loss: 0.7655, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5274/10000, Loss: 0.7654, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5275/10000, Loss: 0.7654, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5276/10000, Loss: 0.7653, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5277/10000, Loss: 0.7653, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5278/10000, Loss: 0.7652, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5279/10000, Loss: 0.7652, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5280/10000, Loss: 0.7652, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5281/10000, Loss: 0.7651, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5282/10000, Loss: 0.7651, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5283/10000, Loss: 0.7650, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5284/10000, Loss: 0.7650, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5285/10000, Loss: 0.7649, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5286/10000, Loss: 0.7649, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5287/10000, Loss: 0.7649, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5288/10000, Loss: 0.7648, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5289/10000, Loss: 0.7648, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5290/10000, Loss: 0.7647, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5291/10000, Loss: 0.7647, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5292/10000, Loss: 0.7646, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5293/10000, Loss: 0.7646, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5294/10000, Loss: 0.7646, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5295/10000, Loss: 0.7645, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5296/10000, Loss: 0.7645, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5297/10000, Loss: 0.7644, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5298/10000, Loss: 0.7644, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5299/10000, Loss: 0.7643, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5300/10000, Loss: 0.7643, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5301/10000, Loss: 0.7642, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5302/10000, Loss: 0.7642, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5303/10000, Loss: 0.7642, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5304/10000, Loss: 0.7641, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5305/10000, Loss: 0.7641, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5306/10000, Loss: 0.7640, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5307/10000, Loss: 0.7640, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5308/10000, Loss: 0.7640, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5309/10000, Loss: 0.7639, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5310/10000, Loss: 0.7639, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5311/10000, Loss: 0.7638, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5312/10000, Loss: 0.7638, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5313/10000, Loss: 0.7637, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5314/10000, Loss: 0.7637, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5315/10000, Loss: 0.7637, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5316/10000, Loss: 0.7636, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5317/10000, Loss: 0.7636, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5318/10000, Loss: 0.7635, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5319/10000, Loss: 0.7635, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5320/10000, Loss: 0.7634, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5321/10000, Loss: 0.7634, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5322/10000, Loss: 0.7634, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5323/10000, Loss: 0.7633, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5324/10000, Loss: 0.7633, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5325/10000, Loss: 0.7632, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5326/10000, Loss: 0.7632, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5327/10000, Loss: 0.7631, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5328/10000, Loss: 0.7631, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5329/10000, Loss: 0.7631, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5330/10000, Loss: 0.7630, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5331/10000, Loss: 0.7630, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5332/10000, Loss: 0.7629, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5333/10000, Loss: 0.7629, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5334/10000, Loss: 0.7629, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5335/10000, Loss: 0.7628, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5336/10000, Loss: 0.7628, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5337/10000, Loss: 0.7627, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5338/10000, Loss: 0.7627, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5339/10000, Loss: 0.7626, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5340/10000, Loss: 0.7626, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5341/10000, Loss: 0.7626, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5342/10000, Loss: 0.7625, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5343/10000, Loss: 0.7625, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5344/10000, Loss: 0.7624, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5345/10000, Loss: 0.7624, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5346/10000, Loss: 0.7624, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5347/10000, Loss: 0.7623, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5348/10000, Loss: 0.7623, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5349/10000, Loss: 0.7622, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5350/10000, Loss: 0.7622, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5351/10000, Loss: 0.7621, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5352/10000, Loss: 0.7621, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5353/10000, Loss: 0.7621, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5354/10000, Loss: 0.7620, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5355/10000, Loss: 0.7620, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5356/10000, Loss: 0.7619, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5357/10000, Loss: 0.7619, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5358/10000, Loss: 0.7619, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5359/10000, Loss: 0.7618, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5360/10000, Loss: 0.7618, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5361/10000, Loss: 0.7617, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5362/10000, Loss: 0.7617, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5363/10000, Loss: 0.7616, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5364/10000, Loss: 0.7616, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5365/10000, Loss: 0.7616, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5366/10000, Loss: 0.7615, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5367/10000, Loss: 0.7615, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5368/10000, Loss: 0.7614, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5369/10000, Loss: 0.7614, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5370/10000, Loss: 0.7614, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5371/10000, Loss: 0.7613, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5372/10000, Loss: 0.7613, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5373/10000, Loss: 0.7612, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5374/10000, Loss: 0.7612, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5375/10000, Loss: 0.7612, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5376/10000, Loss: 0.7611, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5377/10000, Loss: 0.7611, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5378/10000, Loss: 0.7610, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5379/10000, Loss: 0.7610, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5380/10000, Loss: 0.7610, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5381/10000, Loss: 0.7609, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5382/10000, Loss: 0.7609, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5383/10000, Loss: 0.7608, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5384/10000, Loss: 0.7608, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5385/10000, Loss: 0.7607, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5386/10000, Loss: 0.7607, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5387/10000, Loss: 0.7607, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5388/10000, Loss: 0.7606, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5389/10000, Loss: 0.7606, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5390/10000, Loss: 0.7605, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5391/10000, Loss: 0.7605, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5392/10000, Loss: 0.7605, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5393/10000, Loss: 0.7604, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5394/10000, Loss: 0.7604, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5395/10000, Loss: 0.7603, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5396/10000, Loss: 0.7603, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5397/10000, Loss: 0.7603, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5398/10000, Loss: 0.7602, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5399/10000, Loss: 0.7602, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5400/10000, Loss: 0.7601, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5401/10000, Loss: 0.7601, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5402/10000, Loss: 0.7601, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5403/10000, Loss: 0.7600, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5404/10000, Loss: 0.7600, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5405/10000, Loss: 0.7599, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5406/10000, Loss: 0.7599, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5407/10000, Loss: 0.7599, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5408/10000, Loss: 0.7598, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5409/10000, Loss: 0.7598, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5410/10000, Loss: 0.7597, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5411/10000, Loss: 0.7597, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5412/10000, Loss: 0.7597, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5413/10000, Loss: 0.7596, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5414/10000, Loss: 0.7596, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5415/10000, Loss: 0.7595, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5416/10000, Loss: 0.7595, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5417/10000, Loss: 0.7595, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5418/10000, Loss: 0.7594, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5419/10000, Loss: 0.7594, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5420/10000, Loss: 0.7593, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5421/10000, Loss: 0.7593, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5422/10000, Loss: 0.7593, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5423/10000, Loss: 0.7592, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5424/10000, Loss: 0.7592, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5425/10000, Loss: 0.7591, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5426/10000, Loss: 0.7591, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5427/10000, Loss: 0.7591, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5428/10000, Loss: 0.7590, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5429/10000, Loss: 0.7590, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5430/10000, Loss: 0.7589, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5431/10000, Loss: 0.7589, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5432/10000, Loss: 0.7589, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5433/10000, Loss: 0.7588, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5434/10000, Loss: 0.7588, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5435/10000, Loss: 0.7587, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5436/10000, Loss: 0.7587, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5437/10000, Loss: 0.7587, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5438/10000, Loss: 0.7586, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5439/10000, Loss: 0.7586, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5440/10000, Loss: 0.7585, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5441/10000, Loss: 0.7585, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5442/10000, Loss: 0.7585, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5443/10000, Loss: 0.7584, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5444/10000, Loss: 0.7584, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5445/10000, Loss: 0.7584, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5446/10000, Loss: 0.7583, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5447/10000, Loss: 0.7583, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5448/10000, Loss: 0.7582, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5449/10000, Loss: 0.7582, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5450/10000, Loss: 0.7582, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5451/10000, Loss: 0.7581, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5452/10000, Loss: 0.7581, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5453/10000, Loss: 0.7580, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5454/10000, Loss: 0.7580, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5455/10000, Loss: 0.7580, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5456/10000, Loss: 0.7579, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5457/10000, Loss: 0.7579, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5458/10000, Loss: 0.7578, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5459/10000, Loss: 0.7578, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5460/10000, Loss: 0.7578, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5461/10000, Loss: 0.7577, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5462/10000, Loss: 0.7577, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5463/10000, Loss: 0.7577, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5464/10000, Loss: 0.7576, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5465/10000, Loss: 0.7576, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5466/10000, Loss: 0.7575, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5467/10000, Loss: 0.7575, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5468/10000, Loss: 0.7575, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5469/10000, Loss: 0.7574, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5470/10000, Loss: 0.7574, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5471/10000, Loss: 0.7573, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5472/10000, Loss: 0.7573, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5473/10000, Loss: 0.7573, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5474/10000, Loss: 0.7572, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5475/10000, Loss: 0.7572, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5476/10000, Loss: 0.7571, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5477/10000, Loss: 0.7571, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5478/10000, Loss: 0.7571, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5479/10000, Loss: 0.7570, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5480/10000, Loss: 0.7570, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5481/10000, Loss: 0.7570, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5482/10000, Loss: 0.7569, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5483/10000, Loss: 0.7569, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5484/10000, Loss: 0.7568, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5485/10000, Loss: 0.7568, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5486/10000, Loss: 0.7568, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5487/10000, Loss: 0.7567, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5488/10000, Loss: 0.7567, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5489/10000, Loss: 0.7566, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5490/10000, Loss: 0.7566, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5491/10000, Loss: 0.7566, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5492/10000, Loss: 0.7565, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5493/10000, Loss: 0.7565, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5494/10000, Loss: 0.7565, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5495/10000, Loss: 0.7564, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5496/10000, Loss: 0.7564, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5497/10000, Loss: 0.7563, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5498/10000, Loss: 0.7563, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5499/10000, Loss: 0.7563, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5500/10000, Loss: 0.7562, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5501/10000, Loss: 0.7562, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5502/10000, Loss: 0.7562, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5503/10000, Loss: 0.7561, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5504/10000, Loss: 0.7561, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5505/10000, Loss: 0.7560, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5506/10000, Loss: 0.7560, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5507/10000, Loss: 0.7560, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5508/10000, Loss: 0.7559, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5509/10000, Loss: 0.7559, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5510/10000, Loss: 0.7559, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5511/10000, Loss: 0.7558, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5512/10000, Loss: 0.7558, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5513/10000, Loss: 0.7557, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5514/10000, Loss: 0.7557, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5515/10000, Loss: 0.7557, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5516/10000, Loss: 0.7556, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5517/10000, Loss: 0.7556, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5518/10000, Loss: 0.7555, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5519/10000, Loss: 0.7555, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5520/10000, Loss: 0.7555, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5521/10000, Loss: 0.7554, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5522/10000, Loss: 0.7554, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5523/10000, Loss: 0.7554, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5524/10000, Loss: 0.7553, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5525/10000, Loss: 0.7553, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5526/10000, Loss: 0.7552, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5527/10000, Loss: 0.7552, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5528/10000, Loss: 0.7552, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5529/10000, Loss: 0.7551, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5530/10000, Loss: 0.7551, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5531/10000, Loss: 0.7551, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5532/10000, Loss: 0.7550, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5533/10000, Loss: 0.7550, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5534/10000, Loss: 0.7549, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5535/10000, Loss: 0.7549, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5536/10000, Loss: 0.7549, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5537/10000, Loss: 0.7548, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5538/10000, Loss: 0.7548, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5539/10000, Loss: 0.7548, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5540/10000, Loss: 0.7547, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5541/10000, Loss: 0.7547, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5542/10000, Loss: 0.7547, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5543/10000, Loss: 0.7546, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5544/10000, Loss: 0.7546, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5545/10000, Loss: 0.7545, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5546/10000, Loss: 0.7545, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5547/10000, Loss: 0.7545, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5548/10000, Loss: 0.7544, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5549/10000, Loss: 0.7544, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5550/10000, Loss: 0.7544, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5551/10000, Loss: 0.7543, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5552/10000, Loss: 0.7543, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5553/10000, Loss: 0.7542, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5554/10000, Loss: 0.7542, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5555/10000, Loss: 0.7542, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5556/10000, Loss: 0.7541, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5557/10000, Loss: 0.7541, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5558/10000, Loss: 0.7541, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5559/10000, Loss: 0.7540, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5560/10000, Loss: 0.7540, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5561/10000, Loss: 0.7539, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5562/10000, Loss: 0.7539, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5563/10000, Loss: 0.7539, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5564/10000, Loss: 0.7538, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5565/10000, Loss: 0.7538, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5566/10000, Loss: 0.7538, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5567/10000, Loss: 0.7537, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5568/10000, Loss: 0.7537, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5569/10000, Loss: 0.7537, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5570/10000, Loss: 0.7536, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5571/10000, Loss: 0.7536, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5572/10000, Loss: 0.7535, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5573/10000, Loss: 0.7535, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5574/10000, Loss: 0.7535, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5575/10000, Loss: 0.7534, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5576/10000, Loss: 0.7534, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5577/10000, Loss: 0.7534, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5578/10000, Loss: 0.7533, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5579/10000, Loss: 0.7533, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5580/10000, Loss: 0.7533, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5581/10000, Loss: 0.7532, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5582/10000, Loss: 0.7532, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5583/10000, Loss: 0.7531, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5584/10000, Loss: 0.7531, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5585/10000, Loss: 0.7531, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5586/10000, Loss: 0.7530, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5587/10000, Loss: 0.7530, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5588/10000, Loss: 0.7530, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5589/10000, Loss: 0.7529, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5590/10000, Loss: 0.7529, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5591/10000, Loss: 0.7529, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5592/10000, Loss: 0.7528, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5593/10000, Loss: 0.7528, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5594/10000, Loss: 0.7527, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5595/10000, Loss: 0.7527, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5596/10000, Loss: 0.7527, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5597/10000, Loss: 0.7526, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5598/10000, Loss: 0.7526, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5599/10000, Loss: 0.7526, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5600/10000, Loss: 0.7525, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5601/10000, Loss: 0.7525, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5602/10000, Loss: 0.7525, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5603/10000, Loss: 0.7524, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5604/10000, Loss: 0.7524, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5605/10000, Loss: 0.7524, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5606/10000, Loss: 0.7523, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5607/10000, Loss: 0.7523, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5608/10000, Loss: 0.7522, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5609/10000, Loss: 0.7522, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5610/10000, Loss: 0.7522, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5611/10000, Loss: 0.7521, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5612/10000, Loss: 0.7521, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5613/10000, Loss: 0.7521, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5614/10000, Loss: 0.7520, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5615/10000, Loss: 0.7520, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5616/10000, Loss: 0.7520, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5617/10000, Loss: 0.7519, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5618/10000, Loss: 0.7519, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5619/10000, Loss: 0.7519, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5620/10000, Loss: 0.7518, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5621/10000, Loss: 0.7518, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5622/10000, Loss: 0.7517, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5623/10000, Loss: 0.7517, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5624/10000, Loss: 0.7517, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5625/10000, Loss: 0.7516, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5626/10000, Loss: 0.7516, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5627/10000, Loss: 0.7516, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5628/10000, Loss: 0.7515, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5629/10000, Loss: 0.7515, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5630/10000, Loss: 0.7515, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5631/10000, Loss: 0.7514, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5632/10000, Loss: 0.7514, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5633/10000, Loss: 0.7514, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5634/10000, Loss: 0.7513, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5635/10000, Loss: 0.7513, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5636/10000, Loss: 0.7512, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5637/10000, Loss: 0.7512, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5638/10000, Loss: 0.7512, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5639/10000, Loss: 0.7511, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5640/10000, Loss: 0.7511, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5641/10000, Loss: 0.7511, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5642/10000, Loss: 0.7510, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5643/10000, Loss: 0.7510, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5644/10000, Loss: 0.7510, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5645/10000, Loss: 0.7509, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5646/10000, Loss: 0.7509, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5647/10000, Loss: 0.7509, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5648/10000, Loss: 0.7508, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5649/10000, Loss: 0.7508, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5650/10000, Loss: 0.7508, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5651/10000, Loss: 0.7507, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5652/10000, Loss: 0.7507, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5653/10000, Loss: 0.7506, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5654/10000, Loss: 0.7506, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5655/10000, Loss: 0.7506, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5656/10000, Loss: 0.7505, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5657/10000, Loss: 0.7505, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5658/10000, Loss: 0.7505, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5659/10000, Loss: 0.7504, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5660/10000, Loss: 0.7504, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5661/10000, Loss: 0.7504, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5662/10000, Loss: 0.7503, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5663/10000, Loss: 0.7503, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5664/10000, Loss: 0.7503, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5665/10000, Loss: 0.7502, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5666/10000, Loss: 0.7502, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5667/10000, Loss: 0.7502, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5668/10000, Loss: 0.7501, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5669/10000, Loss: 0.7501, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5670/10000, Loss: 0.7501, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5671/10000, Loss: 0.7500, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5672/10000, Loss: 0.7500, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5673/10000, Loss: 0.7500, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5674/10000, Loss: 0.7499, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5675/10000, Loss: 0.7499, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5676/10000, Loss: 0.7498, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5677/10000, Loss: 0.7498, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5678/10000, Loss: 0.7498, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5679/10000, Loss: 0.7497, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5680/10000, Loss: 0.7497, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5681/10000, Loss: 0.7497, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5682/10000, Loss: 0.7496, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5683/10000, Loss: 0.7496, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5684/10000, Loss: 0.7496, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5685/10000, Loss: 0.7495, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5686/10000, Loss: 0.7495, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5687/10000, Loss: 0.7495, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5688/10000, Loss: 0.7494, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5689/10000, Loss: 0.7494, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5690/10000, Loss: 0.7494, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5691/10000, Loss: 0.7493, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5692/10000, Loss: 0.7493, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5693/10000, Loss: 0.7493, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5694/10000, Loss: 0.7492, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5695/10000, Loss: 0.7492, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5696/10000, Loss: 0.7492, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5697/10000, Loss: 0.7491, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5698/10000, Loss: 0.7491, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5699/10000, Loss: 0.7491, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5700/10000, Loss: 0.7490, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5701/10000, Loss: 0.7490, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5702/10000, Loss: 0.7490, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5703/10000, Loss: 0.7489, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5704/10000, Loss: 0.7489, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5705/10000, Loss: 0.7489, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5706/10000, Loss: 0.7488, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5707/10000, Loss: 0.7488, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5708/10000, Loss: 0.7487, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5709/10000, Loss: 0.7487, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5710/10000, Loss: 0.7487, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5711/10000, Loss: 0.7486, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5712/10000, Loss: 0.7486, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5713/10000, Loss: 0.7486, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5714/10000, Loss: 0.7485, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5715/10000, Loss: 0.7485, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5716/10000, Loss: 0.7485, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5717/10000, Loss: 0.7484, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5718/10000, Loss: 0.7484, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5719/10000, Loss: 0.7484, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5720/10000, Loss: 0.7483, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5721/10000, Loss: 0.7483, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5722/10000, Loss: 0.7483, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5723/10000, Loss: 0.7482, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5724/10000, Loss: 0.7482, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5725/10000, Loss: 0.7482, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5726/10000, Loss: 0.7481, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5727/10000, Loss: 0.7481, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5728/10000, Loss: 0.7481, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5729/10000, Loss: 0.7480, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5730/10000, Loss: 0.7480, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5731/10000, Loss: 0.7480, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5732/10000, Loss: 0.7479, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5733/10000, Loss: 0.7479, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5734/10000, Loss: 0.7479, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5735/10000, Loss: 0.7478, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5736/10000, Loss: 0.7478, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5737/10000, Loss: 0.7478, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5738/10000, Loss: 0.7477, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5739/10000, Loss: 0.7477, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5740/10000, Loss: 0.7477, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5741/10000, Loss: 0.7476, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5742/10000, Loss: 0.7476, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5743/10000, Loss: 0.7476, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5744/10000, Loss: 0.7475, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5745/10000, Loss: 0.7475, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5746/10000, Loss: 0.7475, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5747/10000, Loss: 0.7474, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5748/10000, Loss: 0.7474, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5749/10000, Loss: 0.7474, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5750/10000, Loss: 0.7473, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5751/10000, Loss: 0.7473, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5752/10000, Loss: 0.7473, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5753/10000, Loss: 0.7472, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5754/10000, Loss: 0.7472, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5755/10000, Loss: 0.7472, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5756/10000, Loss: 0.7471, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5757/10000, Loss: 0.7471, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5758/10000, Loss: 0.7471, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5759/10000, Loss: 0.7470, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5760/10000, Loss: 0.7470, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5761/10000, Loss: 0.7470, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5762/10000, Loss: 0.7469, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5763/10000, Loss: 0.7469, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5764/10000, Loss: 0.7469, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5765/10000, Loss: 0.7468, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5766/10000, Loss: 0.7468, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5767/10000, Loss: 0.7468, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5768/10000, Loss: 0.7467, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5769/10000, Loss: 0.7467, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5770/10000, Loss: 0.7467, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5771/10000, Loss: 0.7466, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5772/10000, Loss: 0.7466, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5773/10000, Loss: 0.7466, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5774/10000, Loss: 0.7465, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5775/10000, Loss: 0.7465, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5776/10000, Loss: 0.7465, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5777/10000, Loss: 0.7464, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5778/10000, Loss: 0.7464, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5779/10000, Loss: 0.7464, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5780/10000, Loss: 0.7463, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5781/10000, Loss: 0.7463, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5782/10000, Loss: 0.7463, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5783/10000, Loss: 0.7462, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5784/10000, Loss: 0.7462, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5785/10000, Loss: 0.7462, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5786/10000, Loss: 0.7461, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5787/10000, Loss: 0.7461, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5788/10000, Loss: 0.7461, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5789/10000, Loss: 0.7460, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5790/10000, Loss: 0.7460, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5791/10000, Loss: 0.7460, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5792/10000, Loss: 0.7459, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5793/10000, Loss: 0.7459, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5794/10000, Loss: 0.7459, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5795/10000, Loss: 0.7458, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5796/10000, Loss: 0.7458, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5797/10000, Loss: 0.7458, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5798/10000, Loss: 0.7457, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5799/10000, Loss: 0.7457, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5800/10000, Loss: 0.7457, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5801/10000, Loss: 0.7456, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5802/10000, Loss: 0.7456, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5803/10000, Loss: 0.7456, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5804/10000, Loss: 0.7456, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5805/10000, Loss: 0.7455, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5806/10000, Loss: 0.7455, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5807/10000, Loss: 0.7455, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5808/10000, Loss: 0.7454, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5809/10000, Loss: 0.7454, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5810/10000, Loss: 0.7454, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5811/10000, Loss: 0.7453, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5812/10000, Loss: 0.7453, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5813/10000, Loss: 0.7453, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5814/10000, Loss: 0.7452, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5815/10000, Loss: 0.7452, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5816/10000, Loss: 0.7452, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5817/10000, Loss: 0.7451, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5818/10000, Loss: 0.7451, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5819/10000, Loss: 0.7451, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5820/10000, Loss: 0.7450, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5821/10000, Loss: 0.7450, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5822/10000, Loss: 0.7450, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5823/10000, Loss: 0.7449, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5824/10000, Loss: 0.7449, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5825/10000, Loss: 0.7449, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5826/10000, Loss: 0.7448, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5827/10000, Loss: 0.7448, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5828/10000, Loss: 0.7448, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5829/10000, Loss: 0.7447, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5830/10000, Loss: 0.7447, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5831/10000, Loss: 0.7447, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5832/10000, Loss: 0.7446, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5833/10000, Loss: 0.7446, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5834/10000, Loss: 0.7446, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5835/10000, Loss: 0.7445, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5836/10000, Loss: 0.7445, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5837/10000, Loss: 0.7445, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5838/10000, Loss: 0.7445, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5839/10000, Loss: 0.7444, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5840/10000, Loss: 0.7444, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5841/10000, Loss: 0.7444, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5842/10000, Loss: 0.7443, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5843/10000, Loss: 0.7443, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5844/10000, Loss: 0.7443, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5845/10000, Loss: 0.7442, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5846/10000, Loss: 0.7442, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5847/10000, Loss: 0.7442, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5848/10000, Loss: 0.7441, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5849/10000, Loss: 0.7441, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5850/10000, Loss: 0.7441, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5851/10000, Loss: 0.7440, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5852/10000, Loss: 0.7440, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5853/10000, Loss: 0.7440, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5854/10000, Loss: 0.7439, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5855/10000, Loss: 0.7439, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5856/10000, Loss: 0.7439, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5857/10000, Loss: 0.7438, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5858/10000, Loss: 0.7438, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5859/10000, Loss: 0.7438, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5860/10000, Loss: 0.7437, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5861/10000, Loss: 0.7437, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5862/10000, Loss: 0.7437, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5863/10000, Loss: 0.7437, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5864/10000, Loss: 0.7436, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5865/10000, Loss: 0.7436, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5866/10000, Loss: 0.7436, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5867/10000, Loss: 0.7435, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5868/10000, Loss: 0.7435, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5869/10000, Loss: 0.7435, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5870/10000, Loss: 0.7434, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5871/10000, Loss: 0.7434, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5872/10000, Loss: 0.7434, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5873/10000, Loss: 0.7433, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5874/10000, Loss: 0.7433, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5875/10000, Loss: 0.7433, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5876/10000, Loss: 0.7432, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5877/10000, Loss: 0.7432, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5878/10000, Loss: 0.7432, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5879/10000, Loss: 0.7431, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5880/10000, Loss: 0.7431, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5881/10000, Loss: 0.7431, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5882/10000, Loss: 0.7431, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5883/10000, Loss: 0.7430, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5884/10000, Loss: 0.7430, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5885/10000, Loss: 0.7430, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5886/10000, Loss: 0.7429, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5887/10000, Loss: 0.7429, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5888/10000, Loss: 0.7429, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5889/10000, Loss: 0.7428, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5890/10000, Loss: 0.7428, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5891/10000, Loss: 0.7428, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5892/10000, Loss: 0.7427, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5893/10000, Loss: 0.7427, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5894/10000, Loss: 0.7427, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5895/10000, Loss: 0.7426, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5896/10000, Loss: 0.7426, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5897/10000, Loss: 0.7426, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5898/10000, Loss: 0.7426, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5899/10000, Loss: 0.7425, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5900/10000, Loss: 0.7425, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5901/10000, Loss: 0.7425, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5902/10000, Loss: 0.7424, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5903/10000, Loss: 0.7424, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5904/10000, Loss: 0.7424, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5905/10000, Loss: 0.7423, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5906/10000, Loss: 0.7423, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5907/10000, Loss: 0.7423, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5908/10000, Loss: 0.7422, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5909/10000, Loss: 0.7422, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5910/10000, Loss: 0.7422, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5911/10000, Loss: 0.7421, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5912/10000, Loss: 0.7421, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5913/10000, Loss: 0.7421, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5914/10000, Loss: 0.7421, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5915/10000, Loss: 0.7420, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5916/10000, Loss: 0.7420, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5917/10000, Loss: 0.7420, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5918/10000, Loss: 0.7419, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5919/10000, Loss: 0.7419, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5920/10000, Loss: 0.7419, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5921/10000, Loss: 0.7418, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5922/10000, Loss: 0.7418, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5923/10000, Loss: 0.7418, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5924/10000, Loss: 0.7417, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5925/10000, Loss: 0.7417, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5926/10000, Loss: 0.7417, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5927/10000, Loss: 0.7417, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5928/10000, Loss: 0.7416, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5929/10000, Loss: 0.7416, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5930/10000, Loss: 0.7416, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5931/10000, Loss: 0.7415, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5932/10000, Loss: 0.7415, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5933/10000, Loss: 0.7415, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5934/10000, Loss: 0.7414, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5935/10000, Loss: 0.7414, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5936/10000, Loss: 0.7414, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5937/10000, Loss: 0.7413, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5938/10000, Loss: 0.7413, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5939/10000, Loss: 0.7413, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5940/10000, Loss: 0.7413, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5941/10000, Loss: 0.7412, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5942/10000, Loss: 0.7412, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5943/10000, Loss: 0.7412, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5944/10000, Loss: 0.7411, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5945/10000, Loss: 0.7411, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5946/10000, Loss: 0.7411, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5947/10000, Loss: 0.7410, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5948/10000, Loss: 0.7410, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5949/10000, Loss: 0.7410, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5950/10000, Loss: 0.7409, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5951/10000, Loss: 0.7409, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5952/10000, Loss: 0.7409, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5953/10000, Loss: 0.7409, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5954/10000, Loss: 0.7408, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5955/10000, Loss: 0.7408, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5956/10000, Loss: 0.7408, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5957/10000, Loss: 0.7407, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5958/10000, Loss: 0.7407, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5959/10000, Loss: 0.7407, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5960/10000, Loss: 0.7406, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5961/10000, Loss: 0.7406, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5962/10000, Loss: 0.7406, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5963/10000, Loss: 0.7405, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5964/10000, Loss: 0.7405, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5965/10000, Loss: 0.7405, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5966/10000, Loss: 0.7405, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5967/10000, Loss: 0.7404, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5968/10000, Loss: 0.7404, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5969/10000, Loss: 0.7404, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5970/10000, Loss: 0.7403, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5971/10000, Loss: 0.7403, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5972/10000, Loss: 0.7403, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5973/10000, Loss: 0.7402, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5974/10000, Loss: 0.7402, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5975/10000, Loss: 0.7402, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5976/10000, Loss: 0.7402, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5977/10000, Loss: 0.7401, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5978/10000, Loss: 0.7401, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5979/10000, Loss: 0.7401, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5980/10000, Loss: 0.7400, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5981/10000, Loss: 0.7400, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5982/10000, Loss: 0.7400, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5983/10000, Loss: 0.7399, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5984/10000, Loss: 0.7399, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5985/10000, Loss: 0.7399, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5986/10000, Loss: 0.7399, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5987/10000, Loss: 0.7398, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5988/10000, Loss: 0.7398, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5989/10000, Loss: 0.7398, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5990/10000, Loss: 0.7397, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5991/10000, Loss: 0.7397, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5992/10000, Loss: 0.7397, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5993/10000, Loss: 0.7396, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5994/10000, Loss: 0.7396, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5995/10000, Loss: 0.7396, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5996/10000, Loss: 0.7396, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 5997/10000, Loss: 0.7395, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5998/10000, Loss: 0.7395, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5999/10000, Loss: 0.7395, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6000/10000, Loss: 0.7394, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6001/10000, Loss: 0.7394, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6002/10000, Loss: 0.7394, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6003/10000, Loss: 0.7393, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6004/10000, Loss: 0.7393, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6005/10000, Loss: 0.7393, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6006/10000, Loss: 0.7393, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6007/10000, Loss: 0.7392, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6008/10000, Loss: 0.7392, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6009/10000, Loss: 0.7392, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6010/10000, Loss: 0.7391, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6011/10000, Loss: 0.7391, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6012/10000, Loss: 0.7391, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6013/10000, Loss: 0.7390, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6014/10000, Loss: 0.7390, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6015/10000, Loss: 0.7390, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6016/10000, Loss: 0.7390, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6017/10000, Loss: 0.7389, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6018/10000, Loss: 0.7389, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6019/10000, Loss: 0.7389, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6020/10000, Loss: 0.7388, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6021/10000, Loss: 0.7388, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6022/10000, Loss: 0.7388, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6023/10000, Loss: 0.7387, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6024/10000, Loss: 0.7387, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6025/10000, Loss: 0.7387, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6026/10000, Loss: 0.7387, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6027/10000, Loss: 0.7386, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6028/10000, Loss: 0.7386, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6029/10000, Loss: 0.7386, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6030/10000, Loss: 0.7385, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6031/10000, Loss: 0.7385, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6032/10000, Loss: 0.7385, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6033/10000, Loss: 0.7385, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6034/10000, Loss: 0.7384, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6035/10000, Loss: 0.7384, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6036/10000, Loss: 0.7384, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6037/10000, Loss: 0.7383, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6038/10000, Loss: 0.7383, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6039/10000, Loss: 0.7383, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6040/10000, Loss: 0.7382, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6041/10000, Loss: 0.7382, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6042/10000, Loss: 0.7382, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6043/10000, Loss: 0.7382, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6044/10000, Loss: 0.7381, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6045/10000, Loss: 0.7381, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6046/10000, Loss: 0.7381, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6047/10000, Loss: 0.7380, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6048/10000, Loss: 0.7380, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6049/10000, Loss: 0.7380, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6050/10000, Loss: 0.7379, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6051/10000, Loss: 0.7379, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6052/10000, Loss: 0.7379, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6053/10000, Loss: 0.7379, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6054/10000, Loss: 0.7378, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6055/10000, Loss: 0.7378, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6056/10000, Loss: 0.7378, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6057/10000, Loss: 0.7377, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6058/10000, Loss: 0.7377, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6059/10000, Loss: 0.7377, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6060/10000, Loss: 0.7377, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6061/10000, Loss: 0.7376, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6062/10000, Loss: 0.7376, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6063/10000, Loss: 0.7376, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6064/10000, Loss: 0.7375, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6065/10000, Loss: 0.7375, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6066/10000, Loss: 0.7375, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6067/10000, Loss: 0.7375, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6068/10000, Loss: 0.7374, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6069/10000, Loss: 0.7374, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6070/10000, Loss: 0.7374, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6071/10000, Loss: 0.7373, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6072/10000, Loss: 0.7373, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6073/10000, Loss: 0.7373, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6074/10000, Loss: 0.7372, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6075/10000, Loss: 0.7372, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6076/10000, Loss: 0.7372, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6077/10000, Loss: 0.7372, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6078/10000, Loss: 0.7371, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6079/10000, Loss: 0.7371, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6080/10000, Loss: 0.7371, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6081/10000, Loss: 0.7370, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6082/10000, Loss: 0.7370, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6083/10000, Loss: 0.7370, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6084/10000, Loss: 0.7370, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6085/10000, Loss: 0.7369, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6086/10000, Loss: 0.7369, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6087/10000, Loss: 0.7369, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6088/10000, Loss: 0.7368, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6089/10000, Loss: 0.7368, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6090/10000, Loss: 0.7368, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6091/10000, Loss: 0.7368, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6092/10000, Loss: 0.7367, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6093/10000, Loss: 0.7367, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6094/10000, Loss: 0.7367, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6095/10000, Loss: 0.7366, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6096/10000, Loss: 0.7366, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6097/10000, Loss: 0.7366, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6098/10000, Loss: 0.7366, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6099/10000, Loss: 0.7365, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6100/10000, Loss: 0.7365, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6101/10000, Loss: 0.7365, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6102/10000, Loss: 0.7364, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6103/10000, Loss: 0.7364, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6104/10000, Loss: 0.7364, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6105/10000, Loss: 0.7364, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6106/10000, Loss: 0.7363, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6107/10000, Loss: 0.7363, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6108/10000, Loss: 0.7363, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6109/10000, Loss: 0.7362, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6110/10000, Loss: 0.7362, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6111/10000, Loss: 0.7362, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6112/10000, Loss: 0.7362, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6113/10000, Loss: 0.7361, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6114/10000, Loss: 0.7361, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6115/10000, Loss: 0.7361, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6116/10000, Loss: 0.7360, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6117/10000, Loss: 0.7360, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6118/10000, Loss: 0.7360, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6119/10000, Loss: 0.7359, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6120/10000, Loss: 0.7359, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6121/10000, Loss: 0.7359, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6122/10000, Loss: 0.7359, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6123/10000, Loss: 0.7358, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6124/10000, Loss: 0.7358, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6125/10000, Loss: 0.7358, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6126/10000, Loss: 0.7357, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6127/10000, Loss: 0.7357, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6128/10000, Loss: 0.7357, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6129/10000, Loss: 0.7357, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6130/10000, Loss: 0.7356, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6131/10000, Loss: 0.7356, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6132/10000, Loss: 0.7356, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6133/10000, Loss: 0.7355, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6134/10000, Loss: 0.7355, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6135/10000, Loss: 0.7355, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6136/10000, Loss: 0.7355, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6137/10000, Loss: 0.7354, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6138/10000, Loss: 0.7354, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6139/10000, Loss: 0.7354, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6140/10000, Loss: 0.7354, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6141/10000, Loss: 0.7353, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6142/10000, Loss: 0.7353, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6143/10000, Loss: 0.7353, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6144/10000, Loss: 0.7352, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6145/10000, Loss: 0.7352, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6146/10000, Loss: 0.7352, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6147/10000, Loss: 0.7352, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6148/10000, Loss: 0.7351, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6149/10000, Loss: 0.7351, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6150/10000, Loss: 0.7351, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6151/10000, Loss: 0.7350, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6152/10000, Loss: 0.7350, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6153/10000, Loss: 0.7350, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6154/10000, Loss: 0.7350, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6155/10000, Loss: 0.7349, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6156/10000, Loss: 0.7349, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6157/10000, Loss: 0.7349, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6158/10000, Loss: 0.7348, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6159/10000, Loss: 0.7348, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6160/10000, Loss: 0.7348, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6161/10000, Loss: 0.7348, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6162/10000, Loss: 0.7347, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6163/10000, Loss: 0.7347, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6164/10000, Loss: 0.7347, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6165/10000, Loss: 0.7346, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6166/10000, Loss: 0.7346, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6167/10000, Loss: 0.7346, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6168/10000, Loss: 0.7346, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6169/10000, Loss: 0.7345, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6170/10000, Loss: 0.7345, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6171/10000, Loss: 0.7345, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6172/10000, Loss: 0.7344, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6173/10000, Loss: 0.7344, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6174/10000, Loss: 0.7344, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6175/10000, Loss: 0.7344, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6176/10000, Loss: 0.7343, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6177/10000, Loss: 0.7343, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6178/10000, Loss: 0.7343, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6179/10000, Loss: 0.7343, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6180/10000, Loss: 0.7342, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6181/10000, Loss: 0.7342, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6182/10000, Loss: 0.7342, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6183/10000, Loss: 0.7341, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6184/10000, Loss: 0.7341, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6185/10000, Loss: 0.7341, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6186/10000, Loss: 0.7341, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6187/10000, Loss: 0.7340, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6188/10000, Loss: 0.7340, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6189/10000, Loss: 0.7340, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6190/10000, Loss: 0.7339, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6191/10000, Loss: 0.7339, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6192/10000, Loss: 0.7339, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6193/10000, Loss: 0.7339, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6194/10000, Loss: 0.7338, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6195/10000, Loss: 0.7338, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6196/10000, Loss: 0.7338, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6197/10000, Loss: 0.7337, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6198/10000, Loss: 0.7337, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6199/10000, Loss: 0.7337, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6200/10000, Loss: 0.7337, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6201/10000, Loss: 0.7336, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6202/10000, Loss: 0.7336, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6203/10000, Loss: 0.7336, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6204/10000, Loss: 0.7336, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6205/10000, Loss: 0.7335, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6206/10000, Loss: 0.7335, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6207/10000, Loss: 0.7335, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6208/10000, Loss: 0.7334, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6209/10000, Loss: 0.7334, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6210/10000, Loss: 0.7334, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6211/10000, Loss: 0.7334, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6212/10000, Loss: 0.7333, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6213/10000, Loss: 0.7333, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6214/10000, Loss: 0.7333, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6215/10000, Loss: 0.7332, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6216/10000, Loss: 0.7332, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6217/10000, Loss: 0.7332, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6218/10000, Loss: 0.7332, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6219/10000, Loss: 0.7331, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6220/10000, Loss: 0.7331, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6221/10000, Loss: 0.7331, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6222/10000, Loss: 0.7331, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6223/10000, Loss: 0.7330, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6224/10000, Loss: 0.7330, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6225/10000, Loss: 0.7330, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6226/10000, Loss: 0.7329, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6227/10000, Loss: 0.7329, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6228/10000, Loss: 0.7329, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6229/10000, Loss: 0.7329, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6230/10000, Loss: 0.7328, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6231/10000, Loss: 0.7328, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6232/10000, Loss: 0.7328, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6233/10000, Loss: 0.7328, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6234/10000, Loss: 0.7327, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6235/10000, Loss: 0.7327, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6236/10000, Loss: 0.7327, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6237/10000, Loss: 0.7326, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6238/10000, Loss: 0.7326, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6239/10000, Loss: 0.7326, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6240/10000, Loss: 0.7326, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6241/10000, Loss: 0.7325, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6242/10000, Loss: 0.7325, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 6243/10000, Loss: 0.7325, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 6244/10000, Loss: 0.7324, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 6245/10000, Loss: 0.7324, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 6246/10000, Loss: 0.7324, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 6247/10000, Loss: 0.7324, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 6248/10000, Loss: 0.7323, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 6249/10000, Loss: 0.7323, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 6250/10000, Loss: 0.7323, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 6251/10000, Loss: 0.7323, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 6252/10000, Loss: 0.7322, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 6253/10000, Loss: 0.7322, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6254/10000, Loss: 0.7322, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6255/10000, Loss: 0.7321, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6256/10000, Loss: 0.7321, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6257/10000, Loss: 0.7321, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6258/10000, Loss: 0.7321, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6259/10000, Loss: 0.7320, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6260/10000, Loss: 0.7320, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6261/10000, Loss: 0.7320, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6262/10000, Loss: 0.7320, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6263/10000, Loss: 0.7319, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6264/10000, Loss: 0.7319, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6265/10000, Loss: 0.7319, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6266/10000, Loss: 0.7318, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6267/10000, Loss: 0.7318, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6268/10000, Loss: 0.7318, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6269/10000, Loss: 0.7318, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6270/10000, Loss: 0.7317, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6271/10000, Loss: 0.7317, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6272/10000, Loss: 0.7317, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6273/10000, Loss: 0.7317, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6274/10000, Loss: 0.7316, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6275/10000, Loss: 0.7316, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6276/10000, Loss: 0.7316, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6277/10000, Loss: 0.7316, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6278/10000, Loss: 0.7315, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6279/10000, Loss: 0.7315, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6280/10000, Loss: 0.7315, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6281/10000, Loss: 0.7314, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6282/10000, Loss: 0.7314, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6283/10000, Loss: 0.7314, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6284/10000, Loss: 0.7314, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6285/10000, Loss: 0.7313, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6286/10000, Loss: 0.7313, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6287/10000, Loss: 0.7313, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6288/10000, Loss: 0.7313, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6289/10000, Loss: 0.7312, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6290/10000, Loss: 0.7312, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6291/10000, Loss: 0.7312, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6292/10000, Loss: 0.7311, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6293/10000, Loss: 0.7311, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6294/10000, Loss: 0.7311, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6295/10000, Loss: 0.7311, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6296/10000, Loss: 0.7310, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6297/10000, Loss: 0.7310, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6298/10000, Loss: 0.7310, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6299/10000, Loss: 0.7310, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6300/10000, Loss: 0.7309, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6301/10000, Loss: 0.7309, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6302/10000, Loss: 0.7309, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6303/10000, Loss: 0.7308, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6304/10000, Loss: 0.7308, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6305/10000, Loss: 0.7308, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6306/10000, Loss: 0.7308, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6307/10000, Loss: 0.7307, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6308/10000, Loss: 0.7307, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6309/10000, Loss: 0.7307, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6310/10000, Loss: 0.7307, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6311/10000, Loss: 0.7306, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6312/10000, Loss: 0.7306, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6313/10000, Loss: 0.7306, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6314/10000, Loss: 0.7306, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6315/10000, Loss: 0.7305, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6316/10000, Loss: 0.7305, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6317/10000, Loss: 0.7305, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6318/10000, Loss: 0.7304, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6319/10000, Loss: 0.7304, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6320/10000, Loss: 0.7304, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6321/10000, Loss: 0.7304, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6322/10000, Loss: 0.7303, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6323/10000, Loss: 0.7303, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6324/10000, Loss: 0.7303, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6325/10000, Loss: 0.7303, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6326/10000, Loss: 0.7302, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6327/10000, Loss: 0.7302, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6328/10000, Loss: 0.7302, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6329/10000, Loss: 0.7302, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6330/10000, Loss: 0.7301, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6331/10000, Loss: 0.7301, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6332/10000, Loss: 0.7301, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6333/10000, Loss: 0.7300, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6334/10000, Loss: 0.7300, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6335/10000, Loss: 0.7300, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6336/10000, Loss: 0.7300, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6337/10000, Loss: 0.7299, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6338/10000, Loss: 0.7299, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6339/10000, Loss: 0.7299, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6340/10000, Loss: 0.7299, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6341/10000, Loss: 0.7298, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6342/10000, Loss: 0.7298, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6343/10000, Loss: 0.7298, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6344/10000, Loss: 0.7298, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6345/10000, Loss: 0.7297, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6346/10000, Loss: 0.7297, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6347/10000, Loss: 0.7297, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6348/10000, Loss: 0.7296, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6349/10000, Loss: 0.7296, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6350/10000, Loss: 0.7296, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6351/10000, Loss: 0.7296, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6352/10000, Loss: 0.7295, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6353/10000, Loss: 0.7295, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6354/10000, Loss: 0.7295, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6355/10000, Loss: 0.7295, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6356/10000, Loss: 0.7294, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6357/10000, Loss: 0.7294, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6358/10000, Loss: 0.7294, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6359/10000, Loss: 0.7294, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6360/10000, Loss: 0.7293, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6361/10000, Loss: 0.7293, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6362/10000, Loss: 0.7293, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6363/10000, Loss: 0.7293, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6364/10000, Loss: 0.7292, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6365/10000, Loss: 0.7292, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6366/10000, Loss: 0.7292, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6367/10000, Loss: 0.7291, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6368/10000, Loss: 0.7291, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6369/10000, Loss: 0.7291, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6370/10000, Loss: 0.7291, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6371/10000, Loss: 0.7290, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6372/10000, Loss: 0.7290, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6373/10000, Loss: 0.7290, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6374/10000, Loss: 0.7290, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6375/10000, Loss: 0.7289, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6376/10000, Loss: 0.7289, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6377/10000, Loss: 0.7289, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6378/10000, Loss: 0.7289, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6379/10000, Loss: 0.7288, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6380/10000, Loss: 0.7288, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6381/10000, Loss: 0.7288, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6382/10000, Loss: 0.7288, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6383/10000, Loss: 0.7287, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6384/10000, Loss: 0.7287, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6385/10000, Loss: 0.7287, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6386/10000, Loss: 0.7286, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6387/10000, Loss: 0.7286, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6388/10000, Loss: 0.7286, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6389/10000, Loss: 0.7286, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6390/10000, Loss: 0.7285, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6391/10000, Loss: 0.7285, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6392/10000, Loss: 0.7285, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6393/10000, Loss: 0.7285, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6394/10000, Loss: 0.7284, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6395/10000, Loss: 0.7284, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6396/10000, Loss: 0.7284, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6397/10000, Loss: 0.7284, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6398/10000, Loss: 0.7283, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6399/10000, Loss: 0.7283, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6400/10000, Loss: 0.7283, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6401/10000, Loss: 0.7283, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6402/10000, Loss: 0.7282, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6403/10000, Loss: 0.7282, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6404/10000, Loss: 0.7282, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6405/10000, Loss: 0.7281, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6406/10000, Loss: 0.7281, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6407/10000, Loss: 0.7281, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6408/10000, Loss: 0.7281, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6409/10000, Loss: 0.7280, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6410/10000, Loss: 0.7280, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6411/10000, Loss: 0.7280, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6412/10000, Loss: 0.7280, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6413/10000, Loss: 0.7279, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6414/10000, Loss: 0.7279, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6415/10000, Loss: 0.7279, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6416/10000, Loss: 0.7279, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6417/10000, Loss: 0.7278, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6418/10000, Loss: 0.7278, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6419/10000, Loss: 0.7278, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6420/10000, Loss: 0.7278, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6421/10000, Loss: 0.7277, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6422/10000, Loss: 0.7277, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6423/10000, Loss: 0.7277, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6424/10000, Loss: 0.7277, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6425/10000, Loss: 0.7276, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6426/10000, Loss: 0.7276, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6427/10000, Loss: 0.7276, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6428/10000, Loss: 0.7276, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6429/10000, Loss: 0.7275, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6430/10000, Loss: 0.7275, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6431/10000, Loss: 0.7275, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6432/10000, Loss: 0.7274, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6433/10000, Loss: 0.7274, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6434/10000, Loss: 0.7274, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6435/10000, Loss: 0.7274, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6436/10000, Loss: 0.7273, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6437/10000, Loss: 0.7273, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6438/10000, Loss: 0.7273, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6439/10000, Loss: 0.7273, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6440/10000, Loss: 0.7272, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6441/10000, Loss: 0.7272, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6442/10000, Loss: 0.7272, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6443/10000, Loss: 0.7272, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6444/10000, Loss: 0.7271, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6445/10000, Loss: 0.7271, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6446/10000, Loss: 0.7271, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6447/10000, Loss: 0.7271, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6448/10000, Loss: 0.7270, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6449/10000, Loss: 0.7270, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6450/10000, Loss: 0.7270, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6451/10000, Loss: 0.7270, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6452/10000, Loss: 0.7269, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6453/10000, Loss: 0.7269, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6454/10000, Loss: 0.7269, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6455/10000, Loss: 0.7269, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6456/10000, Loss: 0.7268, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6457/10000, Loss: 0.7268, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6458/10000, Loss: 0.7268, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6459/10000, Loss: 0.7268, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6460/10000, Loss: 0.7267, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6461/10000, Loss: 0.7267, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6462/10000, Loss: 0.7267, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6463/10000, Loss: 0.7267, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6464/10000, Loss: 0.7266, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6465/10000, Loss: 0.7266, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6466/10000, Loss: 0.7266, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6467/10000, Loss: 0.7265, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6468/10000, Loss: 0.7265, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6469/10000, Loss: 0.7265, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6470/10000, Loss: 0.7265, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6471/10000, Loss: 0.7264, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6472/10000, Loss: 0.7264, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6473/10000, Loss: 0.7264, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6474/10000, Loss: 0.7264, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6475/10000, Loss: 0.7263, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6476/10000, Loss: 0.7263, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6477/10000, Loss: 0.7263, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6478/10000, Loss: 0.7263, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6479/10000, Loss: 0.7262, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6480/10000, Loss: 0.7262, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6481/10000, Loss: 0.7262, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6482/10000, Loss: 0.7262, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6483/10000, Loss: 0.7261, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6484/10000, Loss: 0.7261, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6485/10000, Loss: 0.7261, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6486/10000, Loss: 0.7261, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6487/10000, Loss: 0.7260, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6488/10000, Loss: 0.7260, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6489/10000, Loss: 0.7260, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6490/10000, Loss: 0.7260, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6491/10000, Loss: 0.7259, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6492/10000, Loss: 0.7259, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6493/10000, Loss: 0.7259, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6494/10000, Loss: 0.7259, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6495/10000, Loss: 0.7258, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6496/10000, Loss: 0.7258, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6497/10000, Loss: 0.7258, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6498/10000, Loss: 0.7258, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6499/10000, Loss: 0.7257, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6500/10000, Loss: 0.7257, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6501/10000, Loss: 0.7257, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6502/10000, Loss: 0.7257, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6503/10000, Loss: 0.7256, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6504/10000, Loss: 0.7256, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6505/10000, Loss: 0.7256, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6506/10000, Loss: 0.7256, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6507/10000, Loss: 0.7255, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6508/10000, Loss: 0.7255, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6509/10000, Loss: 0.7255, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6510/10000, Loss: 0.7255, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6511/10000, Loss: 0.7254, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6512/10000, Loss: 0.7254, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6513/10000, Loss: 0.7254, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6514/10000, Loss: 0.7254, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6515/10000, Loss: 0.7253, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6516/10000, Loss: 0.7253, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6517/10000, Loss: 0.7253, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6518/10000, Loss: 0.7253, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6519/10000, Loss: 0.7252, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6520/10000, Loss: 0.7252, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6521/10000, Loss: 0.7252, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6522/10000, Loss: 0.7252, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6523/10000, Loss: 0.7251, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6524/10000, Loss: 0.7251, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6525/10000, Loss: 0.7251, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6526/10000, Loss: 0.7251, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6527/10000, Loss: 0.7250, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6528/10000, Loss: 0.7250, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6529/10000, Loss: 0.7250, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6530/10000, Loss: 0.7250, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6531/10000, Loss: 0.7249, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6532/10000, Loss: 0.7249, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6533/10000, Loss: 0.7249, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6534/10000, Loss: 0.7249, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6535/10000, Loss: 0.7248, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6536/10000, Loss: 0.7248, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6537/10000, Loss: 0.7248, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6538/10000, Loss: 0.7248, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6539/10000, Loss: 0.7247, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6540/10000, Loss: 0.7247, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6541/10000, Loss: 0.7247, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6542/10000, Loss: 0.7247, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6543/10000, Loss: 0.7246, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6544/10000, Loss: 0.7246, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6545/10000, Loss: 0.7246, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6546/10000, Loss: 0.7246, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6547/10000, Loss: 0.7245, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6548/10000, Loss: 0.7245, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6549/10000, Loss: 0.7245, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6550/10000, Loss: 0.7245, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6551/10000, Loss: 0.7244, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6552/10000, Loss: 0.7244, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6553/10000, Loss: 0.7244, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6554/10000, Loss: 0.7244, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6555/10000, Loss: 0.7243, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6556/10000, Loss: 0.7243, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6557/10000, Loss: 0.7243, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6558/10000, Loss: 0.7243, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6559/10000, Loss: 0.7242, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6560/10000, Loss: 0.7242, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6561/10000, Loss: 0.7242, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6562/10000, Loss: 0.7242, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6563/10000, Loss: 0.7241, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6564/10000, Loss: 0.7241, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6565/10000, Loss: 0.7241, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6566/10000, Loss: 0.7241, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6567/10000, Loss: 0.7240, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6568/10000, Loss: 0.7240, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6569/10000, Loss: 0.7240, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6570/10000, Loss: 0.7240, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6571/10000, Loss: 0.7239, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6572/10000, Loss: 0.7239, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6573/10000, Loss: 0.7239, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6574/10000, Loss: 0.7239, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6575/10000, Loss: 0.7238, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6576/10000, Loss: 0.7238, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6577/10000, Loss: 0.7238, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6578/10000, Loss: 0.7238, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6579/10000, Loss: 0.7237, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6580/10000, Loss: 0.7237, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6581/10000, Loss: 0.7237, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6582/10000, Loss: 0.7237, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6583/10000, Loss: 0.7236, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6584/10000, Loss: 0.7236, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6585/10000, Loss: 0.7236, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6586/10000, Loss: 0.7236, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6587/10000, Loss: 0.7235, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6588/10000, Loss: 0.7235, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6589/10000, Loss: 0.7235, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6590/10000, Loss: 0.7235, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6591/10000, Loss: 0.7234, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6592/10000, Loss: 0.7234, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6593/10000, Loss: 0.7234, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6594/10000, Loss: 0.7234, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6595/10000, Loss: 0.7233, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6596/10000, Loss: 0.7233, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6597/10000, Loss: 0.7233, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6598/10000, Loss: 0.7233, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6599/10000, Loss: 0.7232, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6600/10000, Loss: 0.7232, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6601/10000, Loss: 0.7232, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6602/10000, Loss: 0.7232, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6603/10000, Loss: 0.7231, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6604/10000, Loss: 0.7231, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6605/10000, Loss: 0.7231, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6606/10000, Loss: 0.7231, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6607/10000, Loss: 0.7230, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6608/10000, Loss: 0.7230, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6609/10000, Loss: 0.7230, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6610/10000, Loss: 0.7230, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6611/10000, Loss: 0.7229, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6612/10000, Loss: 0.7229, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6613/10000, Loss: 0.7229, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6614/10000, Loss: 0.7229, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6615/10000, Loss: 0.7228, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6616/10000, Loss: 0.7228, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6617/10000, Loss: 0.7228, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6618/10000, Loss: 0.7228, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6619/10000, Loss: 0.7227, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6620/10000, Loss: 0.7227, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6621/10000, Loss: 0.7227, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6622/10000, Loss: 0.7227, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6623/10000, Loss: 0.7226, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6624/10000, Loss: 0.7226, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6625/10000, Loss: 0.7226, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6626/10000, Loss: 0.7226, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6627/10000, Loss: 0.7225, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6628/10000, Loss: 0.7225, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6629/10000, Loss: 0.7225, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6630/10000, Loss: 0.7225, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6631/10000, Loss: 0.7224, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6632/10000, Loss: 0.7224, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6633/10000, Loss: 0.7224, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6634/10000, Loss: 0.7224, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6635/10000, Loss: 0.7223, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6636/10000, Loss: 0.7223, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6637/10000, Loss: 0.7223, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6638/10000, Loss: 0.7223, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6639/10000, Loss: 0.7223, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6640/10000, Loss: 0.7222, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6641/10000, Loss: 0.7222, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6642/10000, Loss: 0.7222, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6643/10000, Loss: 0.7222, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6644/10000, Loss: 0.7221, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6645/10000, Loss: 0.7221, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6646/10000, Loss: 0.7221, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6647/10000, Loss: 0.7221, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6648/10000, Loss: 0.7220, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6649/10000, Loss: 0.7220, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6650/10000, Loss: 0.7220, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6651/10000, Loss: 0.7220, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6652/10000, Loss: 0.7219, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6653/10000, Loss: 0.7219, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6654/10000, Loss: 0.7219, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6655/10000, Loss: 0.7219, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6656/10000, Loss: 0.7218, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6657/10000, Loss: 0.7218, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6658/10000, Loss: 0.7218, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6659/10000, Loss: 0.7218, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 6660/10000, Loss: 0.7217, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 6661/10000, Loss: 0.7217, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 6662/10000, Loss: 0.7217, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 6663/10000, Loss: 0.7217, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 6664/10000, Loss: 0.7216, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 6665/10000, Loss: 0.7216, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6666/10000, Loss: 0.7216, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6667/10000, Loss: 0.7216, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6668/10000, Loss: 0.7215, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6669/10000, Loss: 0.7215, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6670/10000, Loss: 0.7215, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6671/10000, Loss: 0.7215, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6672/10000, Loss: 0.7214, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6673/10000, Loss: 0.7214, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6674/10000, Loss: 0.7214, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6675/10000, Loss: 0.7214, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6676/10000, Loss: 0.7214, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6677/10000, Loss: 0.7213, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6678/10000, Loss: 0.7213, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6679/10000, Loss: 0.7213, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6680/10000, Loss: 0.7213, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6681/10000, Loss: 0.7212, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6682/10000, Loss: 0.7212, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6683/10000, Loss: 0.7212, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6684/10000, Loss: 0.7212, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6685/10000, Loss: 0.7211, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6686/10000, Loss: 0.7211, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6687/10000, Loss: 0.7211, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6688/10000, Loss: 0.7211, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6689/10000, Loss: 0.7210, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6690/10000, Loss: 0.7210, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6691/10000, Loss: 0.7210, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6692/10000, Loss: 0.7210, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6693/10000, Loss: 0.7209, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6694/10000, Loss: 0.7209, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6695/10000, Loss: 0.7209, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6696/10000, Loss: 0.7209, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6697/10000, Loss: 0.7208, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6698/10000, Loss: 0.7208, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6699/10000, Loss: 0.7208, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6700/10000, Loss: 0.7208, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6701/10000, Loss: 0.7207, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6702/10000, Loss: 0.7207, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6703/10000, Loss: 0.7207, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6704/10000, Loss: 0.7207, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6705/10000, Loss: 0.7207, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6706/10000, Loss: 0.7206, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6707/10000, Loss: 0.7206, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6708/10000, Loss: 0.7206, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6709/10000, Loss: 0.7206, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6710/10000, Loss: 0.7205, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6711/10000, Loss: 0.7205, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6712/10000, Loss: 0.7205, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6713/10000, Loss: 0.7205, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6714/10000, Loss: 0.7204, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6715/10000, Loss: 0.7204, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6716/10000, Loss: 0.7204, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6717/10000, Loss: 0.7204, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6718/10000, Loss: 0.7203, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6719/10000, Loss: 0.7203, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6720/10000, Loss: 0.7203, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6721/10000, Loss: 0.7203, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6722/10000, Loss: 0.7202, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6723/10000, Loss: 0.7202, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6724/10000, Loss: 0.7202, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6725/10000, Loss: 0.7202, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6726/10000, Loss: 0.7201, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6727/10000, Loss: 0.7201, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6728/10000, Loss: 0.7201, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6729/10000, Loss: 0.7201, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6730/10000, Loss: 0.7201, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6731/10000, Loss: 0.7200, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6732/10000, Loss: 0.7200, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6733/10000, Loss: 0.7200, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6734/10000, Loss: 0.7200, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6735/10000, Loss: 0.7199, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6736/10000, Loss: 0.7199, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6737/10000, Loss: 0.7199, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6738/10000, Loss: 0.7199, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6739/10000, Loss: 0.7198, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6740/10000, Loss: 0.7198, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6741/10000, Loss: 0.7198, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6742/10000, Loss: 0.7198, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6743/10000, Loss: 0.7197, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6744/10000, Loss: 0.7197, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6745/10000, Loss: 0.7197, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6746/10000, Loss: 0.7197, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6747/10000, Loss: 0.7196, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6748/10000, Loss: 0.7196, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6749/10000, Loss: 0.7196, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6750/10000, Loss: 0.7196, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6751/10000, Loss: 0.7196, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6752/10000, Loss: 0.7195, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6753/10000, Loss: 0.7195, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6754/10000, Loss: 0.7195, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6755/10000, Loss: 0.7195, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6756/10000, Loss: 0.7194, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6757/10000, Loss: 0.7194, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6758/10000, Loss: 0.7194, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6759/10000, Loss: 0.7194, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6760/10000, Loss: 0.7193, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6761/10000, Loss: 0.7193, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6762/10000, Loss: 0.7193, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6763/10000, Loss: 0.7193, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6764/10000, Loss: 0.7192, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6765/10000, Loss: 0.7192, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6766/10000, Loss: 0.7192, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6767/10000, Loss: 0.7192, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6768/10000, Loss: 0.7191, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6769/10000, Loss: 0.7191, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6770/10000, Loss: 0.7191, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6771/10000, Loss: 0.7191, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6772/10000, Loss: 0.7191, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6773/10000, Loss: 0.7190, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6774/10000, Loss: 0.7190, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6775/10000, Loss: 0.7190, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6776/10000, Loss: 0.7190, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6777/10000, Loss: 0.7189, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6778/10000, Loss: 0.7189, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6779/10000, Loss: 0.7189, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6780/10000, Loss: 0.7189, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6781/10000, Loss: 0.7188, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6782/10000, Loss: 0.7188, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6783/10000, Loss: 0.7188, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6784/10000, Loss: 0.7188, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6785/10000, Loss: 0.7187, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6786/10000, Loss: 0.7187, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6787/10000, Loss: 0.7187, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6788/10000, Loss: 0.7187, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6789/10000, Loss: 0.7187, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6790/10000, Loss: 0.7186, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6791/10000, Loss: 0.7186, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6792/10000, Loss: 0.7186, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6793/10000, Loss: 0.7186, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6794/10000, Loss: 0.7185, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6795/10000, Loss: 0.7185, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6796/10000, Loss: 0.7185, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6797/10000, Loss: 0.7185, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6798/10000, Loss: 0.7184, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6799/10000, Loss: 0.7184, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6800/10000, Loss: 0.7184, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6801/10000, Loss: 0.7184, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6802/10000, Loss: 0.7183, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6803/10000, Loss: 0.7183, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6804/10000, Loss: 0.7183, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6805/10000, Loss: 0.7183, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6806/10000, Loss: 0.7183, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6807/10000, Loss: 0.7182, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6808/10000, Loss: 0.7182, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6809/10000, Loss: 0.7182, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6810/10000, Loss: 0.7182, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6811/10000, Loss: 0.7181, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6812/10000, Loss: 0.7181, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6813/10000, Loss: 0.7181, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6814/10000, Loss: 0.7181, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6815/10000, Loss: 0.7180, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6816/10000, Loss: 0.7180, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6817/10000, Loss: 0.7180, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6818/10000, Loss: 0.7180, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6819/10000, Loss: 0.7179, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6820/10000, Loss: 0.7179, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6821/10000, Loss: 0.7179, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6822/10000, Loss: 0.7179, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6823/10000, Loss: 0.7179, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6824/10000, Loss: 0.7178, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6825/10000, Loss: 0.7178, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6826/10000, Loss: 0.7178, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6827/10000, Loss: 0.7178, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6828/10000, Loss: 0.7177, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6829/10000, Loss: 0.7177, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6830/10000, Loss: 0.7177, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6831/10000, Loss: 0.7177, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6832/10000, Loss: 0.7176, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6833/10000, Loss: 0.7176, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6834/10000, Loss: 0.7176, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6835/10000, Loss: 0.7176, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6836/10000, Loss: 0.7176, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6837/10000, Loss: 0.7175, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6838/10000, Loss: 0.7175, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6839/10000, Loss: 0.7175, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6840/10000, Loss: 0.7175, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6841/10000, Loss: 0.7174, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6842/10000, Loss: 0.7174, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6843/10000, Loss: 0.7174, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6844/10000, Loss: 0.7174, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6845/10000, Loss: 0.7173, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6846/10000, Loss: 0.7173, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6847/10000, Loss: 0.7173, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6848/10000, Loss: 0.7173, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6849/10000, Loss: 0.7173, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6850/10000, Loss: 0.7172, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6851/10000, Loss: 0.7172, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6852/10000, Loss: 0.7172, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6853/10000, Loss: 0.7172, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6854/10000, Loss: 0.7171, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6855/10000, Loss: 0.7171, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6856/10000, Loss: 0.7171, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6857/10000, Loss: 0.7171, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6858/10000, Loss: 0.7170, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6859/10000, Loss: 0.7170, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6860/10000, Loss: 0.7170, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6861/10000, Loss: 0.7170, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6862/10000, Loss: 0.7169, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6863/10000, Loss: 0.7169, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6864/10000, Loss: 0.7169, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6865/10000, Loss: 0.7169, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6866/10000, Loss: 0.7169, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6867/10000, Loss: 0.7168, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6868/10000, Loss: 0.7168, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6869/10000, Loss: 0.7168, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6870/10000, Loss: 0.7168, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6871/10000, Loss: 0.7167, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6872/10000, Loss: 0.7167, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6873/10000, Loss: 0.7167, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6874/10000, Loss: 0.7167, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6875/10000, Loss: 0.7166, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6876/10000, Loss: 0.7166, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6877/10000, Loss: 0.7166, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6878/10000, Loss: 0.7166, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6879/10000, Loss: 0.7166, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6880/10000, Loss: 0.7165, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6881/10000, Loss: 0.7165, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6882/10000, Loss: 0.7165, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6883/10000, Loss: 0.7165, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6884/10000, Loss: 0.7164, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6885/10000, Loss: 0.7164, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6886/10000, Loss: 0.7164, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6887/10000, Loss: 0.7164, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6888/10000, Loss: 0.7163, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6889/10000, Loss: 0.7163, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6890/10000, Loss: 0.7163, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6891/10000, Loss: 0.7163, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6892/10000, Loss: 0.7163, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6893/10000, Loss: 0.7162, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6894/10000, Loss: 0.7162, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6895/10000, Loss: 0.7162, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6896/10000, Loss: 0.7162, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6897/10000, Loss: 0.7161, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6898/10000, Loss: 0.7161, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6899/10000, Loss: 0.7161, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6900/10000, Loss: 0.7161, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6901/10000, Loss: 0.7160, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6902/10000, Loss: 0.7160, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6903/10000, Loss: 0.7160, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6904/10000, Loss: 0.7160, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6905/10000, Loss: 0.7160, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6906/10000, Loss: 0.7159, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6907/10000, Loss: 0.7159, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6908/10000, Loss: 0.7159, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6909/10000, Loss: 0.7159, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6910/10000, Loss: 0.7158, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6911/10000, Loss: 0.7158, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6912/10000, Loss: 0.7158, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6913/10000, Loss: 0.7158, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6914/10000, Loss: 0.7158, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6915/10000, Loss: 0.7157, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6916/10000, Loss: 0.7157, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6917/10000, Loss: 0.7157, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6918/10000, Loss: 0.7157, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6919/10000, Loss: 0.7156, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6920/10000, Loss: 0.7156, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6921/10000, Loss: 0.7156, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6922/10000, Loss: 0.7156, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6923/10000, Loss: 0.7155, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6924/10000, Loss: 0.7155, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6925/10000, Loss: 0.7155, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6926/10000, Loss: 0.7155, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6927/10000, Loss: 0.7155, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6928/10000, Loss: 0.7154, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6929/10000, Loss: 0.7154, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6930/10000, Loss: 0.7154, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6931/10000, Loss: 0.7154, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6932/10000, Loss: 0.7153, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6933/10000, Loss: 0.7153, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6934/10000, Loss: 0.7153, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6935/10000, Loss: 0.7153, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6936/10000, Loss: 0.7152, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6937/10000, Loss: 0.7152, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6938/10000, Loss: 0.7152, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6939/10000, Loss: 0.7152, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6940/10000, Loss: 0.7152, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6941/10000, Loss: 0.7151, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6942/10000, Loss: 0.7151, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6943/10000, Loss: 0.7151, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6944/10000, Loss: 0.7151, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6945/10000, Loss: 0.7150, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6946/10000, Loss: 0.7150, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6947/10000, Loss: 0.7150, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6948/10000, Loss: 0.7150, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6949/10000, Loss: 0.7150, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6950/10000, Loss: 0.7149, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 6951/10000, Loss: 0.7149, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 6952/10000, Loss: 0.7149, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 6953/10000, Loss: 0.7149, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 6954/10000, Loss: 0.7148, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 6955/10000, Loss: 0.7148, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 6956/10000, Loss: 0.7148, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 6957/10000, Loss: 0.7148, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 6958/10000, Loss: 0.7147, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 6959/10000, Loss: 0.7147, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 6960/10000, Loss: 0.7147, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 6961/10000, Loss: 0.7147, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 6962/10000, Loss: 0.7147, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 6963/10000, Loss: 0.7146, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 6964/10000, Loss: 0.7146, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 6965/10000, Loss: 0.7146, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 6966/10000, Loss: 0.7146, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 6967/10000, Loss: 0.7145, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 6968/10000, Loss: 0.7145, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 6969/10000, Loss: 0.7145, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 6970/10000, Loss: 0.7145, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 6971/10000, Loss: 0.7145, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 6972/10000, Loss: 0.7144, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 6973/10000, Loss: 0.7144, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 6974/10000, Loss: 0.7144, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 6975/10000, Loss: 0.7144, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 6976/10000, Loss: 0.7143, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 6977/10000, Loss: 0.7143, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 6978/10000, Loss: 0.7143, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 6979/10000, Loss: 0.7143, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 6980/10000, Loss: 0.7143, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 6981/10000, Loss: 0.7142, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 6982/10000, Loss: 0.7142, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 6983/10000, Loss: 0.7142, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 6984/10000, Loss: 0.7142, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 6985/10000, Loss: 0.7141, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 6986/10000, Loss: 0.7141, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 6987/10000, Loss: 0.7141, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 6988/10000, Loss: 0.7141, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 6989/10000, Loss: 0.7140, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 6990/10000, Loss: 0.7140, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 6991/10000, Loss: 0.7140, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 6992/10000, Loss: 0.7140, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 6993/10000, Loss: 0.7140, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 6994/10000, Loss: 0.7139, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 6995/10000, Loss: 0.7139, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 6996/10000, Loss: 0.7139, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 6997/10000, Loss: 0.7139, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 6998/10000, Loss: 0.7138, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 6999/10000, Loss: 0.7138, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7000/10000, Loss: 0.7138, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7001/10000, Loss: 0.7138, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7002/10000, Loss: 0.7138, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7003/10000, Loss: 0.7137, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7004/10000, Loss: 0.7137, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7005/10000, Loss: 0.7137, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7006/10000, Loss: 0.7137, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7007/10000, Loss: 0.7136, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7008/10000, Loss: 0.7136, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7009/10000, Loss: 0.7136, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7010/10000, Loss: 0.7136, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7011/10000, Loss: 0.7136, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7012/10000, Loss: 0.7135, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7013/10000, Loss: 0.7135, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7014/10000, Loss: 0.7135, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7015/10000, Loss: 0.7135, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7016/10000, Loss: 0.7134, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7017/10000, Loss: 0.7134, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7018/10000, Loss: 0.7134, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7019/10000, Loss: 0.7134, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7020/10000, Loss: 0.7134, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7021/10000, Loss: 0.7133, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7022/10000, Loss: 0.7133, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7023/10000, Loss: 0.7133, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7024/10000, Loss: 0.7133, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7025/10000, Loss: 0.7132, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7026/10000, Loss: 0.7132, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7027/10000, Loss: 0.7132, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7028/10000, Loss: 0.7132, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7029/10000, Loss: 0.7131, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7030/10000, Loss: 0.7131, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7031/10000, Loss: 0.7131, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7032/10000, Loss: 0.7131, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7033/10000, Loss: 0.7131, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7034/10000, Loss: 0.7130, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7035/10000, Loss: 0.7130, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7036/10000, Loss: 0.7130, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7037/10000, Loss: 0.7130, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7038/10000, Loss: 0.7129, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7039/10000, Loss: 0.7129, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7040/10000, Loss: 0.7129, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7041/10000, Loss: 0.7129, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7042/10000, Loss: 0.7129, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7043/10000, Loss: 0.7128, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7044/10000, Loss: 0.7128, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7045/10000, Loss: 0.7128, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7046/10000, Loss: 0.7128, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7047/10000, Loss: 0.7127, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7048/10000, Loss: 0.7127, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7049/10000, Loss: 0.7127, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7050/10000, Loss: 0.7127, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7051/10000, Loss: 0.7127, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7052/10000, Loss: 0.7126, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7053/10000, Loss: 0.7126, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7054/10000, Loss: 0.7126, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7055/10000, Loss: 0.7126, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7056/10000, Loss: 0.7125, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7057/10000, Loss: 0.7125, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7058/10000, Loss: 0.7125, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7059/10000, Loss: 0.7125, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7060/10000, Loss: 0.7125, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7061/10000, Loss: 0.7124, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7062/10000, Loss: 0.7124, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7063/10000, Loss: 0.7124, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7064/10000, Loss: 0.7124, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7065/10000, Loss: 0.7123, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7066/10000, Loss: 0.7123, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7067/10000, Loss: 0.7123, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7068/10000, Loss: 0.7123, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7069/10000, Loss: 0.7123, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7070/10000, Loss: 0.7122, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7071/10000, Loss: 0.7122, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7072/10000, Loss: 0.7122, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7073/10000, Loss: 0.7122, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7074/10000, Loss: 0.7121, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7075/10000, Loss: 0.7121, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7076/10000, Loss: 0.7121, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7077/10000, Loss: 0.7121, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7078/10000, Loss: 0.7121, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7079/10000, Loss: 0.7120, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7080/10000, Loss: 0.7120, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7081/10000, Loss: 0.7120, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7082/10000, Loss: 0.7120, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7083/10000, Loss: 0.7119, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7084/10000, Loss: 0.7119, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7085/10000, Loss: 0.7119, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7086/10000, Loss: 0.7119, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7087/10000, Loss: 0.7119, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7088/10000, Loss: 0.7118, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7089/10000, Loss: 0.7118, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7090/10000, Loss: 0.7118, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7091/10000, Loss: 0.7118, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7092/10000, Loss: 0.7118, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7093/10000, Loss: 0.7117, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7094/10000, Loss: 0.7117, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7095/10000, Loss: 0.7117, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7096/10000, Loss: 0.7117, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7097/10000, Loss: 0.7116, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7098/10000, Loss: 0.7116, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7099/10000, Loss: 0.7116, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7100/10000, Loss: 0.7116, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7101/10000, Loss: 0.7116, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7102/10000, Loss: 0.7115, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7103/10000, Loss: 0.7115, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7104/10000, Loss: 0.7115, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7105/10000, Loss: 0.7115, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7106/10000, Loss: 0.7114, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7107/10000, Loss: 0.7114, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7108/10000, Loss: 0.7114, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7109/10000, Loss: 0.7114, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7110/10000, Loss: 0.7114, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7111/10000, Loss: 0.7113, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7112/10000, Loss: 0.7113, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7113/10000, Loss: 0.7113, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7114/10000, Loss: 0.7113, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7115/10000, Loss: 0.7112, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7116/10000, Loss: 0.7112, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7117/10000, Loss: 0.7112, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7118/10000, Loss: 0.7112, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7119/10000, Loss: 0.7112, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7120/10000, Loss: 0.7111, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7121/10000, Loss: 0.7111, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7122/10000, Loss: 0.7111, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7123/10000, Loss: 0.7111, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7124/10000, Loss: 0.7110, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7125/10000, Loss: 0.7110, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7126/10000, Loss: 0.7110, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7127/10000, Loss: 0.7110, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7128/10000, Loss: 0.7110, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7129/10000, Loss: 0.7109, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7130/10000, Loss: 0.7109, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7131/10000, Loss: 0.7109, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7132/10000, Loss: 0.7109, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7133/10000, Loss: 0.7108, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7134/10000, Loss: 0.7108, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7135/10000, Loss: 0.7108, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7136/10000, Loss: 0.7108, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7137/10000, Loss: 0.7108, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7138/10000, Loss: 0.7107, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7139/10000, Loss: 0.7107, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7140/10000, Loss: 0.7107, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7141/10000, Loss: 0.7107, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7142/10000, Loss: 0.7107, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7143/10000, Loss: 0.7106, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7144/10000, Loss: 0.7106, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7145/10000, Loss: 0.7106, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7146/10000, Loss: 0.7106, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7147/10000, Loss: 0.7105, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7148/10000, Loss: 0.7105, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7149/10000, Loss: 0.7105, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7150/10000, Loss: 0.7105, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7151/10000, Loss: 0.7105, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7152/10000, Loss: 0.7104, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7153/10000, Loss: 0.7104, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7154/10000, Loss: 0.7104, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7155/10000, Loss: 0.7104, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7156/10000, Loss: 0.7103, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7157/10000, Loss: 0.7103, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7158/10000, Loss: 0.7103, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7159/10000, Loss: 0.7103, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7160/10000, Loss: 0.7103, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7161/10000, Loss: 0.7102, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7162/10000, Loss: 0.7102, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7163/10000, Loss: 0.7102, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7164/10000, Loss: 0.7102, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7165/10000, Loss: 0.7102, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7166/10000, Loss: 0.7101, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7167/10000, Loss: 0.7101, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7168/10000, Loss: 0.7101, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7169/10000, Loss: 0.7101, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7170/10000, Loss: 0.7100, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7171/10000, Loss: 0.7100, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7172/10000, Loss: 0.7100, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7173/10000, Loss: 0.7100, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7174/10000, Loss: 0.7100, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7175/10000, Loss: 0.7099, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7176/10000, Loss: 0.7099, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7177/10000, Loss: 0.7099, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7178/10000, Loss: 0.7099, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7179/10000, Loss: 0.7098, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7180/10000, Loss: 0.7098, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7181/10000, Loss: 0.7098, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7182/10000, Loss: 0.7098, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7183/10000, Loss: 0.7098, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7184/10000, Loss: 0.7097, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7185/10000, Loss: 0.7097, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7186/10000, Loss: 0.7097, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7187/10000, Loss: 0.7097, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7188/10000, Loss: 0.7097, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7189/10000, Loss: 0.7096, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7190/10000, Loss: 0.7096, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7191/10000, Loss: 0.7096, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7192/10000, Loss: 0.7096, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7193/10000, Loss: 0.7095, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7194/10000, Loss: 0.7095, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7195/10000, Loss: 0.7095, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7196/10000, Loss: 0.7095, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7197/10000, Loss: 0.7095, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7198/10000, Loss: 0.7094, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7199/10000, Loss: 0.7094, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7200/10000, Loss: 0.7094, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7201/10000, Loss: 0.7094, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7202/10000, Loss: 0.7093, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7203/10000, Loss: 0.7093, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7204/10000, Loss: 0.7093, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7205/10000, Loss: 0.7093, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7206/10000, Loss: 0.7093, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7207/10000, Loss: 0.7092, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7208/10000, Loss: 0.7092, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7209/10000, Loss: 0.7092, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7210/10000, Loss: 0.7092, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7211/10000, Loss: 0.7092, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7212/10000, Loss: 0.7091, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7213/10000, Loss: 0.7091, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7214/10000, Loss: 0.7091, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7215/10000, Loss: 0.7091, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7216/10000, Loss: 0.7090, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7217/10000, Loss: 0.7090, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7218/10000, Loss: 0.7090, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7219/10000, Loss: 0.7090, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7220/10000, Loss: 0.7090, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7221/10000, Loss: 0.7089, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7222/10000, Loss: 0.7089, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7223/10000, Loss: 0.7089, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7224/10000, Loss: 0.7089, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7225/10000, Loss: 0.7089, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7226/10000, Loss: 0.7088, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7227/10000, Loss: 0.7088, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7228/10000, Loss: 0.7088, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7229/10000, Loss: 0.7088, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7230/10000, Loss: 0.7087, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7231/10000, Loss: 0.7087, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7232/10000, Loss: 0.7087, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7233/10000, Loss: 0.7087, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7234/10000, Loss: 0.7087, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7235/10000, Loss: 0.7086, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7236/10000, Loss: 0.7086, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7237/10000, Loss: 0.7086, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7238/10000, Loss: 0.7086, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7239/10000, Loss: 0.7086, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7240/10000, Loss: 0.7085, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7241/10000, Loss: 0.7085, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7242/10000, Loss: 0.7085, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7243/10000, Loss: 0.7085, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7244/10000, Loss: 0.7084, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7245/10000, Loss: 0.7084, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7246/10000, Loss: 0.7084, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7247/10000, Loss: 0.7084, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7248/10000, Loss: 0.7084, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7249/10000, Loss: 0.7083, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7250/10000, Loss: 0.7083, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7251/10000, Loss: 0.7083, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7252/10000, Loss: 0.7083, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7253/10000, Loss: 0.7083, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7254/10000, Loss: 0.7082, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7255/10000, Loss: 0.7082, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7256/10000, Loss: 0.7082, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7257/10000, Loss: 0.7082, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7258/10000, Loss: 0.7081, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7259/10000, Loss: 0.7081, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7260/10000, Loss: 0.7081, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7261/10000, Loss: 0.7081, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7262/10000, Loss: 0.7081, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7263/10000, Loss: 0.7080, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7264/10000, Loss: 0.7080, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7265/10000, Loss: 0.7080, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7266/10000, Loss: 0.7080, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7267/10000, Loss: 0.7080, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7268/10000, Loss: 0.7079, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7269/10000, Loss: 0.7079, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7270/10000, Loss: 0.7079, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7271/10000, Loss: 0.7079, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7272/10000, Loss: 0.7078, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7273/10000, Loss: 0.7078, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7274/10000, Loss: 0.7078, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7275/10000, Loss: 0.7078, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7276/10000, Loss: 0.7078, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7277/10000, Loss: 0.7077, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7278/10000, Loss: 0.7077, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7279/10000, Loss: 0.7077, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7280/10000, Loss: 0.7077, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7281/10000, Loss: 0.7077, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7282/10000, Loss: 0.7076, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7283/10000, Loss: 0.7076, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7284/10000, Loss: 0.7076, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7285/10000, Loss: 0.7076, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7286/10000, Loss: 0.7075, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7287/10000, Loss: 0.7075, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7288/10000, Loss: 0.7075, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7289/10000, Loss: 0.7075, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7290/10000, Loss: 0.7075, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7291/10000, Loss: 0.7074, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7292/10000, Loss: 0.7074, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7293/10000, Loss: 0.7074, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7294/10000, Loss: 0.7074, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7295/10000, Loss: 0.7074, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7296/10000, Loss: 0.7073, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7297/10000, Loss: 0.7073, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7298/10000, Loss: 0.7073, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7299/10000, Loss: 0.7073, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7300/10000, Loss: 0.7073, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7301/10000, Loss: 0.7072, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7302/10000, Loss: 0.7072, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7303/10000, Loss: 0.7072, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7304/10000, Loss: 0.7072, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7305/10000, Loss: 0.7071, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7306/10000, Loss: 0.7071, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7307/10000, Loss: 0.7071, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 7308/10000, Loss: 0.7071, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7309/10000, Loss: 0.7071, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7310/10000, Loss: 0.7070, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7311/10000, Loss: 0.7070, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7312/10000, Loss: 0.7070, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7313/10000, Loss: 0.7070, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7314/10000, Loss: 0.7070, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7315/10000, Loss: 0.7069, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7316/10000, Loss: 0.7069, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7317/10000, Loss: 0.7069, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7318/10000, Loss: 0.7069, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7319/10000, Loss: 0.7068, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7320/10000, Loss: 0.7068, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7321/10000, Loss: 0.7068, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7322/10000, Loss: 0.7068, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7323/10000, Loss: 0.7068, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7324/10000, Loss: 0.7067, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7325/10000, Loss: 0.7067, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7326/10000, Loss: 0.7067, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7327/10000, Loss: 0.7067, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7328/10000, Loss: 0.7067, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7329/10000, Loss: 0.7066, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7330/10000, Loss: 0.7066, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7331/10000, Loss: 0.7066, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7332/10000, Loss: 0.7066, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7333/10000, Loss: 0.7066, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7334/10000, Loss: 0.7065, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7335/10000, Loss: 0.7065, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7336/10000, Loss: 0.7065, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7337/10000, Loss: 0.7065, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7338/10000, Loss: 0.7064, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7339/10000, Loss: 0.7064, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7340/10000, Loss: 0.7064, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7341/10000, Loss: 0.7064, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7342/10000, Loss: 0.7064, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7343/10000, Loss: 0.7063, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7344/10000, Loss: 0.7063, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7345/10000, Loss: 0.7063, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7346/10000, Loss: 0.7063, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7347/10000, Loss: 0.7063, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7348/10000, Loss: 0.7062, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7349/10000, Loss: 0.7062, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7350/10000, Loss: 0.7062, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7351/10000, Loss: 0.7062, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7352/10000, Loss: 0.7062, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7353/10000, Loss: 0.7061, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7354/10000, Loss: 0.7061, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7355/10000, Loss: 0.7061, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7356/10000, Loss: 0.7061, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7357/10000, Loss: 0.7060, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7358/10000, Loss: 0.7060, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7359/10000, Loss: 0.7060, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7360/10000, Loss: 0.7060, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7361/10000, Loss: 0.7060, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7362/10000, Loss: 0.7059, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7363/10000, Loss: 0.7059, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7364/10000, Loss: 0.7059, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7365/10000, Loss: 0.7059, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7366/10000, Loss: 0.7059, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7367/10000, Loss: 0.7058, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7368/10000, Loss: 0.7058, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7369/10000, Loss: 0.7058, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7370/10000, Loss: 0.7058, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7371/10000, Loss: 0.7058, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7372/10000, Loss: 0.7057, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7373/10000, Loss: 0.7057, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7374/10000, Loss: 0.7057, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7375/10000, Loss: 0.7057, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7376/10000, Loss: 0.7057, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7377/10000, Loss: 0.7056, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7378/10000, Loss: 0.7056, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7379/10000, Loss: 0.7056, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7380/10000, Loss: 0.7056, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7381/10000, Loss: 0.7055, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7382/10000, Loss: 0.7055, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7383/10000, Loss: 0.7055, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7384/10000, Loss: 0.7055, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7385/10000, Loss: 0.7055, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7386/10000, Loss: 0.7054, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7387/10000, Loss: 0.7054, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7388/10000, Loss: 0.7054, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7389/10000, Loss: 0.7054, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7390/10000, Loss: 0.7054, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7391/10000, Loss: 0.7053, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7392/10000, Loss: 0.7053, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7393/10000, Loss: 0.7053, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7394/10000, Loss: 0.7053, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7395/10000, Loss: 0.7053, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7396/10000, Loss: 0.7052, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7397/10000, Loss: 0.7052, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7398/10000, Loss: 0.7052, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7399/10000, Loss: 0.7052, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7400/10000, Loss: 0.7052, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7401/10000, Loss: 0.7051, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7402/10000, Loss: 0.7051, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7403/10000, Loss: 0.7051, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7404/10000, Loss: 0.7051, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7405/10000, Loss: 0.7050, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7406/10000, Loss: 0.7050, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7407/10000, Loss: 0.7050, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7408/10000, Loss: 0.7050, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7409/10000, Loss: 0.7050, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7410/10000, Loss: 0.7049, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7411/10000, Loss: 0.7049, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7412/10000, Loss: 0.7049, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7413/10000, Loss: 0.7049, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7414/10000, Loss: 0.7049, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7415/10000, Loss: 0.7048, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7416/10000, Loss: 0.7048, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7417/10000, Loss: 0.7048, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7418/10000, Loss: 0.7048, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7419/10000, Loss: 0.7048, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7420/10000, Loss: 0.7047, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7421/10000, Loss: 0.7047, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7422/10000, Loss: 0.7047, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7423/10000, Loss: 0.7047, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7424/10000, Loss: 0.7047, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7425/10000, Loss: 0.7046, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7426/10000, Loss: 0.7046, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7427/10000, Loss: 0.7046, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7428/10000, Loss: 0.7046, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7429/10000, Loss: 0.7045, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7430/10000, Loss: 0.7045, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7431/10000, Loss: 0.7045, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7432/10000, Loss: 0.7045, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7433/10000, Loss: 0.7045, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7434/10000, Loss: 0.7044, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7435/10000, Loss: 0.7044, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7436/10000, Loss: 0.7044, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7437/10000, Loss: 0.7044, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7438/10000, Loss: 0.7044, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7439/10000, Loss: 0.7043, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7440/10000, Loss: 0.7043, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7441/10000, Loss: 0.7043, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7442/10000, Loss: 0.7043, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7443/10000, Loss: 0.7043, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7444/10000, Loss: 0.7042, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7445/10000, Loss: 0.7042, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7446/10000, Loss: 0.7042, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7447/10000, Loss: 0.7042, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7448/10000, Loss: 0.7042, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7449/10000, Loss: 0.7041, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7450/10000, Loss: 0.7041, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7451/10000, Loss: 0.7041, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7452/10000, Loss: 0.7041, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7453/10000, Loss: 0.7041, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7454/10000, Loss: 0.7040, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7455/10000, Loss: 0.7040, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7456/10000, Loss: 0.7040, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7457/10000, Loss: 0.7040, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7458/10000, Loss: 0.7039, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7459/10000, Loss: 0.7039, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7460/10000, Loss: 0.7039, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7461/10000, Loss: 0.7039, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7462/10000, Loss: 0.7039, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7463/10000, Loss: 0.7038, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7464/10000, Loss: 0.7038, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7465/10000, Loss: 0.7038, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7466/10000, Loss: 0.7038, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7467/10000, Loss: 0.7038, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7468/10000, Loss: 0.7037, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7469/10000, Loss: 0.7037, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7470/10000, Loss: 0.7037, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7471/10000, Loss: 0.7037, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7472/10000, Loss: 0.7037, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7473/10000, Loss: 0.7036, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7474/10000, Loss: 0.7036, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7475/10000, Loss: 0.7036, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7476/10000, Loss: 0.7036, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7477/10000, Loss: 0.7036, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7478/10000, Loss: 0.7035, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7479/10000, Loss: 0.7035, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7480/10000, Loss: 0.7035, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7481/10000, Loss: 0.7035, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7482/10000, Loss: 0.7035, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7483/10000, Loss: 0.7034, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7484/10000, Loss: 0.7034, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7485/10000, Loss: 0.7034, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7486/10000, Loss: 0.7034, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7487/10000, Loss: 0.7034, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7488/10000, Loss: 0.7033, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7489/10000, Loss: 0.7033, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7490/10000, Loss: 0.7033, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7491/10000, Loss: 0.7033, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7492/10000, Loss: 0.7032, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7493/10000, Loss: 0.7032, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7494/10000, Loss: 0.7032, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7495/10000, Loss: 0.7032, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7496/10000, Loss: 0.7032, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7497/10000, Loss: 0.7031, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7498/10000, Loss: 0.7031, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7499/10000, Loss: 0.7031, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7500/10000, Loss: 0.7031, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7501/10000, Loss: 0.7031, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7502/10000, Loss: 0.7030, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7503/10000, Loss: 0.7030, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7504/10000, Loss: 0.7030, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7505/10000, Loss: 0.7030, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7506/10000, Loss: 0.7030, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7507/10000, Loss: 0.7029, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7508/10000, Loss: 0.7029, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7509/10000, Loss: 0.7029, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7510/10000, Loss: 0.7029, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7511/10000, Loss: 0.7029, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7512/10000, Loss: 0.7028, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7513/10000, Loss: 0.7028, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7514/10000, Loss: 0.7028, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7515/10000, Loss: 0.7028, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7516/10000, Loss: 0.7028, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7517/10000, Loss: 0.7027, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7518/10000, Loss: 0.7027, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7519/10000, Loss: 0.7027, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7520/10000, Loss: 0.7027, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7521/10000, Loss: 0.7027, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7522/10000, Loss: 0.7026, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7523/10000, Loss: 0.7026, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7524/10000, Loss: 0.7026, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7525/10000, Loss: 0.7026, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7526/10000, Loss: 0.7026, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7527/10000, Loss: 0.7025, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7528/10000, Loss: 0.7025, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7529/10000, Loss: 0.7025, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7530/10000, Loss: 0.7025, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7531/10000, Loss: 0.7025, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7532/10000, Loss: 0.7024, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7533/10000, Loss: 0.7024, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7534/10000, Loss: 0.7024, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7535/10000, Loss: 0.7024, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7536/10000, Loss: 0.7024, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7537/10000, Loss: 0.7023, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7538/10000, Loss: 0.7023, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7539/10000, Loss: 0.7023, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7540/10000, Loss: 0.7023, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7541/10000, Loss: 0.7022, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7542/10000, Loss: 0.7022, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7543/10000, Loss: 0.7022, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7544/10000, Loss: 0.7022, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7545/10000, Loss: 0.7022, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7546/10000, Loss: 0.7021, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7547/10000, Loss: 0.7021, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7548/10000, Loss: 0.7021, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7549/10000, Loss: 0.7021, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7550/10000, Loss: 0.7021, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7551/10000, Loss: 0.7020, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7552/10000, Loss: 0.7020, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7553/10000, Loss: 0.7020, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7554/10000, Loss: 0.7020, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7555/10000, Loss: 0.7020, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7556/10000, Loss: 0.7019, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7557/10000, Loss: 0.7019, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7558/10000, Loss: 0.7019, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7559/10000, Loss: 0.7019, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7560/10000, Loss: 0.7019, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7561/10000, Loss: 0.7018, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7562/10000, Loss: 0.7018, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7563/10000, Loss: 0.7018, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7564/10000, Loss: 0.7018, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7565/10000, Loss: 0.7018, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7566/10000, Loss: 0.7017, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7567/10000, Loss: 0.7017, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7568/10000, Loss: 0.7017, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7569/10000, Loss: 0.7017, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7570/10000, Loss: 0.7017, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7571/10000, Loss: 0.7016, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7572/10000, Loss: 0.7016, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7573/10000, Loss: 0.7016, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7574/10000, Loss: 0.7016, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7575/10000, Loss: 0.7016, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7576/10000, Loss: 0.7015, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7577/10000, Loss: 0.7015, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7578/10000, Loss: 0.7015, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7579/10000, Loss: 0.7015, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7580/10000, Loss: 0.7015, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7581/10000, Loss: 0.7014, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7582/10000, Loss: 0.7014, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7583/10000, Loss: 0.7014, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7584/10000, Loss: 0.7014, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7585/10000, Loss: 0.7014, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7586/10000, Loss: 0.7013, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7587/10000, Loss: 0.7013, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7588/10000, Loss: 0.7013, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7589/10000, Loss: 0.7013, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7590/10000, Loss: 0.7013, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7591/10000, Loss: 0.7012, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7592/10000, Loss: 0.7012, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7593/10000, Loss: 0.7012, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7594/10000, Loss: 0.7012, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7595/10000, Loss: 0.7012, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7596/10000, Loss: 0.7011, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7597/10000, Loss: 0.7011, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7598/10000, Loss: 0.7011, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7599/10000, Loss: 0.7011, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7600/10000, Loss: 0.7011, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7601/10000, Loss: 0.7010, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7602/10000, Loss: 0.7010, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7603/10000, Loss: 0.7010, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7604/10000, Loss: 0.7010, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7605/10000, Loss: 0.7010, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7606/10000, Loss: 0.7009, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7607/10000, Loss: 0.7009, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7608/10000, Loss: 0.7009, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7609/10000, Loss: 0.7009, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7610/10000, Loss: 0.7009, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7611/10000, Loss: 0.7008, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7612/10000, Loss: 0.7008, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7613/10000, Loss: 0.7008, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7614/10000, Loss: 0.7008, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7615/10000, Loss: 0.7008, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7616/10000, Loss: 0.7007, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7617/10000, Loss: 0.7007, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7618/10000, Loss: 0.7007, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7619/10000, Loss: 0.7007, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7620/10000, Loss: 0.7007, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7621/10000, Loss: 0.7006, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7622/10000, Loss: 0.7006, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7623/10000, Loss: 0.7006, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7624/10000, Loss: 0.7006, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7625/10000, Loss: 0.7006, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7626/10000, Loss: 0.7005, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7627/10000, Loss: 0.7005, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7628/10000, Loss: 0.7005, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7629/10000, Loss: 0.7005, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7630/10000, Loss: 0.7005, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7631/10000, Loss: 0.7004, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7632/10000, Loss: 0.7004, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7633/10000, Loss: 0.7004, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7634/10000, Loss: 0.7004, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7635/10000, Loss: 0.7004, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7636/10000, Loss: 0.7003, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7637/10000, Loss: 0.7003, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7638/10000, Loss: 0.7003, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7639/10000, Loss: 0.7003, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7640/10000, Loss: 0.7003, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7641/10000, Loss: 0.7002, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7642/10000, Loss: 0.7002, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7643/10000, Loss: 0.7002, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7644/10000, Loss: 0.7002, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7645/10000, Loss: 0.7002, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7646/10000, Loss: 0.7001, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7647/10000, Loss: 0.7001, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7648/10000, Loss: 0.7001, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7649/10000, Loss: 0.7001, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7650/10000, Loss: 0.7001, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7651/10000, Loss: 0.7000, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7652/10000, Loss: 0.7000, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7653/10000, Loss: 0.7000, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7654/10000, Loss: 0.7000, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7655/10000, Loss: 0.7000, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7656/10000, Loss: 0.6999, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7657/10000, Loss: 0.6999, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7658/10000, Loss: 0.6999, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7659/10000, Loss: 0.6999, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7660/10000, Loss: 0.6999, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7661/10000, Loss: 0.6998, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7662/10000, Loss: 0.6998, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7663/10000, Loss: 0.6998, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7664/10000, Loss: 0.6998, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7665/10000, Loss: 0.6998, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7666/10000, Loss: 0.6997, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7667/10000, Loss: 0.6997, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7668/10000, Loss: 0.6997, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7669/10000, Loss: 0.6997, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7670/10000, Loss: 0.6997, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7671/10000, Loss: 0.6996, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7672/10000, Loss: 0.6996, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7673/10000, Loss: 0.6996, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7674/10000, Loss: 0.6996, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7675/10000, Loss: 0.6996, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7676/10000, Loss: 0.6995, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7677/10000, Loss: 0.6995, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7678/10000, Loss: 0.6995, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7679/10000, Loss: 0.6995, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7680/10000, Loss: 0.6995, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7681/10000, Loss: 0.6994, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7682/10000, Loss: 0.6994, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7683/10000, Loss: 0.6994, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7684/10000, Loss: 0.6994, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7685/10000, Loss: 0.6994, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7686/10000, Loss: 0.6993, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7687/10000, Loss: 0.6993, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7688/10000, Loss: 0.6993, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7689/10000, Loss: 0.6993, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7690/10000, Loss: 0.6993, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7691/10000, Loss: 0.6992, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7692/10000, Loss: 0.6992, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7693/10000, Loss: 0.6992, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7694/10000, Loss: 0.6992, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7695/10000, Loss: 0.6992, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7696/10000, Loss: 0.6991, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7697/10000, Loss: 0.6991, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7698/10000, Loss: 0.6991, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7699/10000, Loss: 0.6991, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7700/10000, Loss: 0.6991, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7701/10000, Loss: 0.6990, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7702/10000, Loss: 0.6990, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7703/10000, Loss: 0.6990, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7704/10000, Loss: 0.6990, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7705/10000, Loss: 0.6990, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7706/10000, Loss: 0.6989, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7707/10000, Loss: 0.6989, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7708/10000, Loss: 0.6989, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7709/10000, Loss: 0.6989, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7710/10000, Loss: 0.6989, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7711/10000, Loss: 0.6988, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7712/10000, Loss: 0.6988, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7713/10000, Loss: 0.6988, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7714/10000, Loss: 0.6988, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7715/10000, Loss: 0.6988, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7716/10000, Loss: 0.6987, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7717/10000, Loss: 0.6987, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7718/10000, Loss: 0.6987, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7719/10000, Loss: 0.6987, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7720/10000, Loss: 0.6987, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7721/10000, Loss: 0.6986, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7722/10000, Loss: 0.6986, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7723/10000, Loss: 0.6986, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7724/10000, Loss: 0.6986, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7725/10000, Loss: 0.6986, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7726/10000, Loss: 0.6985, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7727/10000, Loss: 0.6985, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7728/10000, Loss: 0.6985, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7729/10000, Loss: 0.6985, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7730/10000, Loss: 0.6985, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7731/10000, Loss: 0.6984, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7732/10000, Loss: 0.6984, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7733/10000, Loss: 0.6984, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7734/10000, Loss: 0.6984, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7735/10000, Loss: 0.6984, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7736/10000, Loss: 0.6984, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7737/10000, Loss: 0.6983, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7738/10000, Loss: 0.6983, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7739/10000, Loss: 0.6983, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7740/10000, Loss: 0.6983, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7741/10000, Loss: 0.6983, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7742/10000, Loss: 0.6982, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7743/10000, Loss: 0.6982, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7744/10000, Loss: 0.6982, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7745/10000, Loss: 0.6982, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7746/10000, Loss: 0.6982, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7747/10000, Loss: 0.6981, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7748/10000, Loss: 0.6981, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7749/10000, Loss: 0.6981, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7750/10000, Loss: 0.6981, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7751/10000, Loss: 0.6981, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7752/10000, Loss: 0.6980, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7753/10000, Loss: 0.6980, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7754/10000, Loss: 0.6980, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7755/10000, Loss: 0.6980, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7756/10000, Loss: 0.6980, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7757/10000, Loss: 0.6979, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7758/10000, Loss: 0.6979, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7759/10000, Loss: 0.6979, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7760/10000, Loss: 0.6979, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7761/10000, Loss: 0.6979, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7762/10000, Loss: 0.6978, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7763/10000, Loss: 0.6978, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7764/10000, Loss: 0.6978, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7765/10000, Loss: 0.6978, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7766/10000, Loss: 0.6978, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7767/10000, Loss: 0.6977, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7768/10000, Loss: 0.6977, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7769/10000, Loss: 0.6977, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7770/10000, Loss: 0.6977, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7771/10000, Loss: 0.6977, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7772/10000, Loss: 0.6976, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7773/10000, Loss: 0.6976, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7774/10000, Loss: 0.6976, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 7775/10000, Loss: 0.6976, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7776/10000, Loss: 0.6976, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7777/10000, Loss: 0.6975, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7778/10000, Loss: 0.6975, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7779/10000, Loss: 0.6975, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7780/10000, Loss: 0.6975, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7781/10000, Loss: 0.6975, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7782/10000, Loss: 0.6975, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7783/10000, Loss: 0.6974, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7784/10000, Loss: 0.6974, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7785/10000, Loss: 0.6974, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7786/10000, Loss: 0.6974, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7787/10000, Loss: 0.6974, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7788/10000, Loss: 0.6973, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7789/10000, Loss: 0.6973, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7790/10000, Loss: 0.6973, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7791/10000, Loss: 0.6973, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7792/10000, Loss: 0.6973, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7793/10000, Loss: 0.6972, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7794/10000, Loss: 0.6972, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7795/10000, Loss: 0.6972, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7796/10000, Loss: 0.6972, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7797/10000, Loss: 0.6972, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7798/10000, Loss: 0.6971, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7799/10000, Loss: 0.6971, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7800/10000, Loss: 0.6971, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7801/10000, Loss: 0.6971, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7802/10000, Loss: 0.6971, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7803/10000, Loss: 0.6970, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7804/10000, Loss: 0.6970, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7805/10000, Loss: 0.6970, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7806/10000, Loss: 0.6970, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7807/10000, Loss: 0.6970, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7808/10000, Loss: 0.6969, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7809/10000, Loss: 0.6969, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7810/10000, Loss: 0.6969, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7811/10000, Loss: 0.6969, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7812/10000, Loss: 0.6969, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7813/10000, Loss: 0.6968, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7814/10000, Loss: 0.6968, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7815/10000, Loss: 0.6968, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7816/10000, Loss: 0.6968, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7817/10000, Loss: 0.6968, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7818/10000, Loss: 0.6967, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7819/10000, Loss: 0.6967, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7820/10000, Loss: 0.6967, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7821/10000, Loss: 0.6967, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7822/10000, Loss: 0.6967, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7823/10000, Loss: 0.6967, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7824/10000, Loss: 0.6966, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7825/10000, Loss: 0.6966, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7826/10000, Loss: 0.6966, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7827/10000, Loss: 0.6966, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7828/10000, Loss: 0.6966, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7829/10000, Loss: 0.6965, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7830/10000, Loss: 0.6965, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7831/10000, Loss: 0.6965, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7832/10000, Loss: 0.6965, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7833/10000, Loss: 0.6965, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7834/10000, Loss: 0.6964, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7835/10000, Loss: 0.6964, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7836/10000, Loss: 0.6964, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7837/10000, Loss: 0.6964, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7838/10000, Loss: 0.6964, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7839/10000, Loss: 0.6963, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7840/10000, Loss: 0.6963, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7841/10000, Loss: 0.6963, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7842/10000, Loss: 0.6963, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7843/10000, Loss: 0.6963, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7844/10000, Loss: 0.6962, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7845/10000, Loss: 0.6962, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7846/10000, Loss: 0.6962, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7847/10000, Loss: 0.6962, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7848/10000, Loss: 0.6962, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7849/10000, Loss: 0.6961, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7850/10000, Loss: 0.6961, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7851/10000, Loss: 0.6961, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7852/10000, Loss: 0.6961, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7853/10000, Loss: 0.6961, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7854/10000, Loss: 0.6961, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7855/10000, Loss: 0.6960, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7856/10000, Loss: 0.6960, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7857/10000, Loss: 0.6960, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7858/10000, Loss: 0.6960, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7859/10000, Loss: 0.6960, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7860/10000, Loss: 0.6959, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7861/10000, Loss: 0.6959, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7862/10000, Loss: 0.6959, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7863/10000, Loss: 0.6959, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7864/10000, Loss: 0.6959, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7865/10000, Loss: 0.6958, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7866/10000, Loss: 0.6958, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7867/10000, Loss: 0.6958, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7868/10000, Loss: 0.6958, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7869/10000, Loss: 0.6958, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7870/10000, Loss: 0.6957, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7871/10000, Loss: 0.6957, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7872/10000, Loss: 0.6957, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7873/10000, Loss: 0.6957, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7874/10000, Loss: 0.6957, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7875/10000, Loss: 0.6956, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7876/10000, Loss: 0.6956, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7877/10000, Loss: 0.6956, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7878/10000, Loss: 0.6956, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7879/10000, Loss: 0.6956, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7880/10000, Loss: 0.6956, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7881/10000, Loss: 0.6955, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7882/10000, Loss: 0.6955, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7883/10000, Loss: 0.6955, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7884/10000, Loss: 0.6955, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7885/10000, Loss: 0.6955, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7886/10000, Loss: 0.6954, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7887/10000, Loss: 0.6954, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7888/10000, Loss: 0.6954, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7889/10000, Loss: 0.6954, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7890/10000, Loss: 0.6954, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7891/10000, Loss: 0.6953, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7892/10000, Loss: 0.6953, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7893/10000, Loss: 0.6953, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7894/10000, Loss: 0.6953, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7895/10000, Loss: 0.6953, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7896/10000, Loss: 0.6952, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7897/10000, Loss: 0.6952, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7898/10000, Loss: 0.6952, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7899/10000, Loss: 0.6952, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7900/10000, Loss: 0.6952, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7901/10000, Loss: 0.6952, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7902/10000, Loss: 0.6951, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7903/10000, Loss: 0.6951, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7904/10000, Loss: 0.6951, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7905/10000, Loss: 0.6951, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7906/10000, Loss: 0.6951, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7907/10000, Loss: 0.6950, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7908/10000, Loss: 0.6950, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7909/10000, Loss: 0.6950, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7910/10000, Loss: 0.6950, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7911/10000, Loss: 0.6950, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7912/10000, Loss: 0.6949, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7913/10000, Loss: 0.6949, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7914/10000, Loss: 0.6949, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7915/10000, Loss: 0.6949, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7916/10000, Loss: 0.6949, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7917/10000, Loss: 0.6948, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7918/10000, Loss: 0.6948, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7919/10000, Loss: 0.6948, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7920/10000, Loss: 0.6948, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7921/10000, Loss: 0.6948, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7922/10000, Loss: 0.6947, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7923/10000, Loss: 0.6947, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7924/10000, Loss: 0.6947, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7925/10000, Loss: 0.6947, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7926/10000, Loss: 0.6947, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7927/10000, Loss: 0.6947, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7928/10000, Loss: 0.6946, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7929/10000, Loss: 0.6946, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7930/10000, Loss: 0.6946, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7931/10000, Loss: 0.6946, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7932/10000, Loss: 0.6946, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7933/10000, Loss: 0.6945, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7934/10000, Loss: 0.6945, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7935/10000, Loss: 0.6945, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7936/10000, Loss: 0.6945, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7937/10000, Loss: 0.6945, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7938/10000, Loss: 0.6944, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7939/10000, Loss: 0.6944, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7940/10000, Loss: 0.6944, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7941/10000, Loss: 0.6944, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7942/10000, Loss: 0.6944, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7943/10000, Loss: 0.6943, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7944/10000, Loss: 0.6943, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7945/10000, Loss: 0.6943, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7946/10000, Loss: 0.6943, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7947/10000, Loss: 0.6943, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7948/10000, Loss: 0.6943, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7949/10000, Loss: 0.6942, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7950/10000, Loss: 0.6942, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7951/10000, Loss: 0.6942, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7952/10000, Loss: 0.6942, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7953/10000, Loss: 0.6942, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7954/10000, Loss: 0.6941, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7955/10000, Loss: 0.6941, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7956/10000, Loss: 0.6941, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7957/10000, Loss: 0.6941, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7958/10000, Loss: 0.6941, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7959/10000, Loss: 0.6940, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7960/10000, Loss: 0.6940, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7961/10000, Loss: 0.6940, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7962/10000, Loss: 0.6940, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7963/10000, Loss: 0.6940, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7964/10000, Loss: 0.6940, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7965/10000, Loss: 0.6939, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7966/10000, Loss: 0.6939, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7967/10000, Loss: 0.6939, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7968/10000, Loss: 0.6939, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7969/10000, Loss: 0.6939, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7970/10000, Loss: 0.6938, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7971/10000, Loss: 0.6938, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7972/10000, Loss: 0.6938, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7973/10000, Loss: 0.6938, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7974/10000, Loss: 0.6938, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7975/10000, Loss: 0.6937, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7976/10000, Loss: 0.6937, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7977/10000, Loss: 0.6937, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7978/10000, Loss: 0.6937, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7979/10000, Loss: 0.6937, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7980/10000, Loss: 0.6936, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7981/10000, Loss: 0.6936, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7982/10000, Loss: 0.6936, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7983/10000, Loss: 0.6936, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7984/10000, Loss: 0.6936, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7985/10000, Loss: 0.6936, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7986/10000, Loss: 0.6935, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7987/10000, Loss: 0.6935, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7988/10000, Loss: 0.6935, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7989/10000, Loss: 0.6935, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7990/10000, Loss: 0.6935, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7991/10000, Loss: 0.6934, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7992/10000, Loss: 0.6934, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7993/10000, Loss: 0.6934, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7994/10000, Loss: 0.6934, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7995/10000, Loss: 0.6934, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7996/10000, Loss: 0.6933, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7997/10000, Loss: 0.6933, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7998/10000, Loss: 0.6933, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 7999/10000, Loss: 0.6933, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8000/10000, Loss: 0.6933, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8001/10000, Loss: 0.6933, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8002/10000, Loss: 0.6932, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8003/10000, Loss: 0.6932, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8004/10000, Loss: 0.6932, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8005/10000, Loss: 0.6932, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8006/10000, Loss: 0.6932, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8007/10000, Loss: 0.6931, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8008/10000, Loss: 0.6931, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8009/10000, Loss: 0.6931, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8010/10000, Loss: 0.6931, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8011/10000, Loss: 0.6931, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8012/10000, Loss: 0.6930, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8013/10000, Loss: 0.6930, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8014/10000, Loss: 0.6930, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8015/10000, Loss: 0.6930, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8016/10000, Loss: 0.6930, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8017/10000, Loss: 0.6929, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8018/10000, Loss: 0.6929, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8019/10000, Loss: 0.6929, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8020/10000, Loss: 0.6929, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8021/10000, Loss: 0.6929, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8022/10000, Loss: 0.6929, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8023/10000, Loss: 0.6928, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8024/10000, Loss: 0.6928, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8025/10000, Loss: 0.6928, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8026/10000, Loss: 0.6928, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8027/10000, Loss: 0.6928, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8028/10000, Loss: 0.6927, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8029/10000, Loss: 0.6927, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8030/10000, Loss: 0.6927, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8031/10000, Loss: 0.6927, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8032/10000, Loss: 0.6927, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8033/10000, Loss: 0.6926, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8034/10000, Loss: 0.6926, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8035/10000, Loss: 0.6926, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8036/10000, Loss: 0.6926, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8037/10000, Loss: 0.6926, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8038/10000, Loss: 0.6926, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8039/10000, Loss: 0.6925, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8040/10000, Loss: 0.6925, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8041/10000, Loss: 0.6925, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8042/10000, Loss: 0.6925, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8043/10000, Loss: 0.6925, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8044/10000, Loss: 0.6924, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8045/10000, Loss: 0.6924, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8046/10000, Loss: 0.6924, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8047/10000, Loss: 0.6924, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8048/10000, Loss: 0.6924, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8049/10000, Loss: 0.6924, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8050/10000, Loss: 0.6923, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8051/10000, Loss: 0.6923, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8052/10000, Loss: 0.6923, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8053/10000, Loss: 0.6923, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8054/10000, Loss: 0.6923, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8055/10000, Loss: 0.6922, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8056/10000, Loss: 0.6922, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8057/10000, Loss: 0.6922, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8058/10000, Loss: 0.6922, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8059/10000, Loss: 0.6922, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8060/10000, Loss: 0.6921, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8061/10000, Loss: 0.6921, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8062/10000, Loss: 0.6921, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8063/10000, Loss: 0.6921, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8064/10000, Loss: 0.6921, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8065/10000, Loss: 0.6921, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8066/10000, Loss: 0.6920, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8067/10000, Loss: 0.6920, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8068/10000, Loss: 0.6920, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8069/10000, Loss: 0.6920, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8070/10000, Loss: 0.6920, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8071/10000, Loss: 0.6919, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8072/10000, Loss: 0.6919, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8073/10000, Loss: 0.6919, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8074/10000, Loss: 0.6919, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8075/10000, Loss: 0.6919, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8076/10000, Loss: 0.6918, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8077/10000, Loss: 0.6918, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8078/10000, Loss: 0.6918, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8079/10000, Loss: 0.6918, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8080/10000, Loss: 0.6918, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8081/10000, Loss: 0.6918, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8082/10000, Loss: 0.6917, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8083/10000, Loss: 0.6917, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8084/10000, Loss: 0.6917, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8085/10000, Loss: 0.6917, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8086/10000, Loss: 0.6917, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8087/10000, Loss: 0.6916, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8088/10000, Loss: 0.6916, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8089/10000, Loss: 0.6916, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8090/10000, Loss: 0.6916, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8091/10000, Loss: 0.6916, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8092/10000, Loss: 0.6915, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8093/10000, Loss: 0.6915, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8094/10000, Loss: 0.6915, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8095/10000, Loss: 0.6915, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8096/10000, Loss: 0.6915, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8097/10000, Loss: 0.6915, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8098/10000, Loss: 0.6914, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8099/10000, Loss: 0.6914, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8100/10000, Loss: 0.6914, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8101/10000, Loss: 0.6914, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8102/10000, Loss: 0.6914, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8103/10000, Loss: 0.6913, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8104/10000, Loss: 0.6913, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8105/10000, Loss: 0.6913, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8106/10000, Loss: 0.6913, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8107/10000, Loss: 0.6913, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8108/10000, Loss: 0.6913, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8109/10000, Loss: 0.6912, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8110/10000, Loss: 0.6912, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8111/10000, Loss: 0.6912, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8112/10000, Loss: 0.6912, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8113/10000, Loss: 0.6912, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8114/10000, Loss: 0.6911, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8115/10000, Loss: 0.6911, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8116/10000, Loss: 0.6911, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8117/10000, Loss: 0.6911, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8118/10000, Loss: 0.6911, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8119/10000, Loss: 0.6910, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8120/10000, Loss: 0.6910, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8121/10000, Loss: 0.6910, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8122/10000, Loss: 0.6910, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8123/10000, Loss: 0.6910, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8124/10000, Loss: 0.6910, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8125/10000, Loss: 0.6909, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8126/10000, Loss: 0.6909, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8127/10000, Loss: 0.6909, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8128/10000, Loss: 0.6909, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8129/10000, Loss: 0.6909, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8130/10000, Loss: 0.6908, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8131/10000, Loss: 0.6908, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8132/10000, Loss: 0.6908, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8133/10000, Loss: 0.6908, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8134/10000, Loss: 0.6908, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8135/10000, Loss: 0.6908, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8136/10000, Loss: 0.6907, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8137/10000, Loss: 0.6907, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8138/10000, Loss: 0.6907, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8139/10000, Loss: 0.6907, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8140/10000, Loss: 0.6907, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8141/10000, Loss: 0.6906, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8142/10000, Loss: 0.6906, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8143/10000, Loss: 0.6906, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8144/10000, Loss: 0.6906, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8145/10000, Loss: 0.6906, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8146/10000, Loss: 0.6906, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8147/10000, Loss: 0.6905, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8148/10000, Loss: 0.6905, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8149/10000, Loss: 0.6905, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8150/10000, Loss: 0.6905, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8151/10000, Loss: 0.6905, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8152/10000, Loss: 0.6904, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8153/10000, Loss: 0.6904, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8154/10000, Loss: 0.6904, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8155/10000, Loss: 0.6904, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8156/10000, Loss: 0.6904, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8157/10000, Loss: 0.6903, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8158/10000, Loss: 0.6903, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8159/10000, Loss: 0.6903, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8160/10000, Loss: 0.6903, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8161/10000, Loss: 0.6903, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8162/10000, Loss: 0.6903, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8163/10000, Loss: 0.6902, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8164/10000, Loss: 0.6902, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8165/10000, Loss: 0.6902, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8166/10000, Loss: 0.6902, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8167/10000, Loss: 0.6902, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8168/10000, Loss: 0.6901, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8169/10000, Loss: 0.6901, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8170/10000, Loss: 0.6901, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8171/10000, Loss: 0.6901, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8172/10000, Loss: 0.6901, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8173/10000, Loss: 0.6901, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8174/10000, Loss: 0.6900, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8175/10000, Loss: 0.6900, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8176/10000, Loss: 0.6900, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8177/10000, Loss: 0.6900, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8178/10000, Loss: 0.6900, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8179/10000, Loss: 0.6899, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8180/10000, Loss: 0.6899, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8181/10000, Loss: 0.6899, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8182/10000, Loss: 0.6899, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8183/10000, Loss: 0.6899, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8184/10000, Loss: 0.6899, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8185/10000, Loss: 0.6898, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8186/10000, Loss: 0.6898, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8187/10000, Loss: 0.6898, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8188/10000, Loss: 0.6898, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8189/10000, Loss: 0.6898, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8190/10000, Loss: 0.6897, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8191/10000, Loss: 0.6897, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8192/10000, Loss: 0.6897, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8193/10000, Loss: 0.6897, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8194/10000, Loss: 0.6897, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8195/10000, Loss: 0.6897, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8196/10000, Loss: 0.6896, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8197/10000, Loss: 0.6896, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8198/10000, Loss: 0.6896, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8199/10000, Loss: 0.6896, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8200/10000, Loss: 0.6896, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8201/10000, Loss: 0.6895, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8202/10000, Loss: 0.6895, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8203/10000, Loss: 0.6895, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8204/10000, Loss: 0.6895, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8205/10000, Loss: 0.6895, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8206/10000, Loss: 0.6895, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8207/10000, Loss: 0.6894, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8208/10000, Loss: 0.6894, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8209/10000, Loss: 0.6894, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8210/10000, Loss: 0.6894, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8211/10000, Loss: 0.6894, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8212/10000, Loss: 0.6893, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8213/10000, Loss: 0.6893, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8214/10000, Loss: 0.6893, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8215/10000, Loss: 0.6893, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8216/10000, Loss: 0.6893, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8217/10000, Loss: 0.6893, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8218/10000, Loss: 0.6892, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8219/10000, Loss: 0.6892, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8220/10000, Loss: 0.6892, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8221/10000, Loss: 0.6892, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8222/10000, Loss: 0.6892, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8223/10000, Loss: 0.6891, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8224/10000, Loss: 0.6891, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8225/10000, Loss: 0.6891, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8226/10000, Loss: 0.6891, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8227/10000, Loss: 0.6891, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8228/10000, Loss: 0.6891, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8229/10000, Loss: 0.6890, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8230/10000, Loss: 0.6890, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8231/10000, Loss: 0.6890, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8232/10000, Loss: 0.6890, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8233/10000, Loss: 0.6890, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8234/10000, Loss: 0.6889, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8235/10000, Loss: 0.6889, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8236/10000, Loss: 0.6889, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8237/10000, Loss: 0.6889, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8238/10000, Loss: 0.6889, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8239/10000, Loss: 0.6889, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8240/10000, Loss: 0.6888, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8241/10000, Loss: 0.6888, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8242/10000, Loss: 0.6888, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8243/10000, Loss: 0.6888, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8244/10000, Loss: 0.6888, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8245/10000, Loss: 0.6887, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8246/10000, Loss: 0.6887, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8247/10000, Loss: 0.6887, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8248/10000, Loss: 0.6887, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8249/10000, Loss: 0.6887, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8250/10000, Loss: 0.6887, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8251/10000, Loss: 0.6886, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8252/10000, Loss: 0.6886, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8253/10000, Loss: 0.6886, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8254/10000, Loss: 0.6886, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8255/10000, Loss: 0.6886, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8256/10000, Loss: 0.6885, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8257/10000, Loss: 0.6885, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8258/10000, Loss: 0.6885, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8259/10000, Loss: 0.6885, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8260/10000, Loss: 0.6885, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8261/10000, Loss: 0.6885, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8262/10000, Loss: 0.6884, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8263/10000, Loss: 0.6884, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8264/10000, Loss: 0.6884, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8265/10000, Loss: 0.6884, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8266/10000, Loss: 0.6884, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8267/10000, Loss: 0.6883, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8268/10000, Loss: 0.6883, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8269/10000, Loss: 0.6883, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8270/10000, Loss: 0.6883, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8271/10000, Loss: 0.6883, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8272/10000, Loss: 0.6883, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8273/10000, Loss: 0.6882, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8274/10000, Loss: 0.6882, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8275/10000, Loss: 0.6882, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8276/10000, Loss: 0.6882, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8277/10000, Loss: 0.6882, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8278/10000, Loss: 0.6881, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8279/10000, Loss: 0.6881, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8280/10000, Loss: 0.6881, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8281/10000, Loss: 0.6881, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8282/10000, Loss: 0.6881, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8283/10000, Loss: 0.6881, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8284/10000, Loss: 0.6880, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8285/10000, Loss: 0.6880, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8286/10000, Loss: 0.6880, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8287/10000, Loss: 0.6880, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8288/10000, Loss: 0.6880, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8289/10000, Loss: 0.6879, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8290/10000, Loss: 0.6879, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8291/10000, Loss: 0.6879, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8292/10000, Loss: 0.6879, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8293/10000, Loss: 0.6879, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8294/10000, Loss: 0.6879, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8295/10000, Loss: 0.6878, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8296/10000, Loss: 0.6878, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8297/10000, Loss: 0.6878, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8298/10000, Loss: 0.6878, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8299/10000, Loss: 0.6878, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8300/10000, Loss: 0.6877, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8301/10000, Loss: 0.6877, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8302/10000, Loss: 0.6877, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8303/10000, Loss: 0.6877, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8304/10000, Loss: 0.6877, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8305/10000, Loss: 0.6877, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8306/10000, Loss: 0.6876, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8307/10000, Loss: 0.6876, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8308/10000, Loss: 0.6876, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8309/10000, Loss: 0.6876, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8310/10000, Loss: 0.6876, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8311/10000, Loss: 0.6876, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8312/10000, Loss: 0.6875, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8313/10000, Loss: 0.6875, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8314/10000, Loss: 0.6875, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8315/10000, Loss: 0.6875, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8316/10000, Loss: 0.6875, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8317/10000, Loss: 0.6874, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8318/10000, Loss: 0.6874, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8319/10000, Loss: 0.6874, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8320/10000, Loss: 0.6874, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8321/10000, Loss: 0.6874, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8322/10000, Loss: 0.6874, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8323/10000, Loss: 0.6873, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8324/10000, Loss: 0.6873, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8325/10000, Loss: 0.6873, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8326/10000, Loss: 0.6873, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8327/10000, Loss: 0.6873, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8328/10000, Loss: 0.6872, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8329/10000, Loss: 0.6872, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8330/10000, Loss: 0.6872, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8331/10000, Loss: 0.6872, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8332/10000, Loss: 0.6872, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8333/10000, Loss: 0.6872, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8334/10000, Loss: 0.6871, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8335/10000, Loss: 0.6871, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8336/10000, Loss: 0.6871, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8337/10000, Loss: 0.6871, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8338/10000, Loss: 0.6871, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8339/10000, Loss: 0.6871, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8340/10000, Loss: 0.6870, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8341/10000, Loss: 0.6870, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8342/10000, Loss: 0.6870, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8343/10000, Loss: 0.6870, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8344/10000, Loss: 0.6870, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8345/10000, Loss: 0.6869, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8346/10000, Loss: 0.6869, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8347/10000, Loss: 0.6869, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8348/10000, Loss: 0.6869, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8349/10000, Loss: 0.6869, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8350/10000, Loss: 0.6869, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8351/10000, Loss: 0.6868, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8352/10000, Loss: 0.6868, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8353/10000, Loss: 0.6868, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8354/10000, Loss: 0.6868, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8355/10000, Loss: 0.6868, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8356/10000, Loss: 0.6867, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8357/10000, Loss: 0.6867, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8358/10000, Loss: 0.6867, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8359/10000, Loss: 0.6867, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8360/10000, Loss: 0.6867, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8361/10000, Loss: 0.6867, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8362/10000, Loss: 0.6866, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8363/10000, Loss: 0.6866, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8364/10000, Loss: 0.6866, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8365/10000, Loss: 0.6866, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8366/10000, Loss: 0.6866, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8367/10000, Loss: 0.6866, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8368/10000, Loss: 0.6865, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8369/10000, Loss: 0.6865, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8370/10000, Loss: 0.6865, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8371/10000, Loss: 0.6865, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8372/10000, Loss: 0.6865, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8373/10000, Loss: 0.6864, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8374/10000, Loss: 0.6864, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8375/10000, Loss: 0.6864, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8376/10000, Loss: 0.6864, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8377/10000, Loss: 0.6864, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8378/10000, Loss: 0.6864, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8379/10000, Loss: 0.6863, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8380/10000, Loss: 0.6863, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8381/10000, Loss: 0.6863, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8382/10000, Loss: 0.6863, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8383/10000, Loss: 0.6863, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8384/10000, Loss: 0.6862, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8385/10000, Loss: 0.6862, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8386/10000, Loss: 0.6862, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8387/10000, Loss: 0.6862, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8388/10000, Loss: 0.6862, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8389/10000, Loss: 0.6862, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8390/10000, Loss: 0.6861, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8391/10000, Loss: 0.6861, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8392/10000, Loss: 0.6861, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8393/10000, Loss: 0.6861, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8394/10000, Loss: 0.6861, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8395/10000, Loss: 0.6861, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8396/10000, Loss: 0.6860, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8397/10000, Loss: 0.6860, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8398/10000, Loss: 0.6860, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8399/10000, Loss: 0.6860, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8400/10000, Loss: 0.6860, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8401/10000, Loss: 0.6859, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8402/10000, Loss: 0.6859, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8403/10000, Loss: 0.6859, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8404/10000, Loss: 0.6859, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8405/10000, Loss: 0.6859, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8406/10000, Loss: 0.6859, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8407/10000, Loss: 0.6858, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8408/10000, Loss: 0.6858, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8409/10000, Loss: 0.6858, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8410/10000, Loss: 0.6858, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8411/10000, Loss: 0.6858, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8412/10000, Loss: 0.6858, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8413/10000, Loss: 0.6857, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8414/10000, Loss: 0.6857, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8415/10000, Loss: 0.6857, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8416/10000, Loss: 0.6857, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8417/10000, Loss: 0.6857, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8418/10000, Loss: 0.6856, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8419/10000, Loss: 0.6856, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8420/10000, Loss: 0.6856, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8421/10000, Loss: 0.6856, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8422/10000, Loss: 0.6856, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8423/10000, Loss: 0.6856, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8424/10000, Loss: 0.6855, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8425/10000, Loss: 0.6855, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8426/10000, Loss: 0.6855, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8427/10000, Loss: 0.6855, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8428/10000, Loss: 0.6855, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8429/10000, Loss: 0.6855, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8430/10000, Loss: 0.6854, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8431/10000, Loss: 0.6854, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8432/10000, Loss: 0.6854, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8433/10000, Loss: 0.6854, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8434/10000, Loss: 0.6854, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8435/10000, Loss: 0.6853, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8436/10000, Loss: 0.6853, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8437/10000, Loss: 0.6853, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8438/10000, Loss: 0.6853, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8439/10000, Loss: 0.6853, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8440/10000, Loss: 0.6853, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8441/10000, Loss: 0.6852, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8442/10000, Loss: 0.6852, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8443/10000, Loss: 0.6852, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8444/10000, Loss: 0.6852, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8445/10000, Loss: 0.6852, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8446/10000, Loss: 0.6852, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8447/10000, Loss: 0.6851, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8448/10000, Loss: 0.6851, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8449/10000, Loss: 0.6851, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8450/10000, Loss: 0.6851, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8451/10000, Loss: 0.6851, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8452/10000, Loss: 0.6851, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8453/10000, Loss: 0.6850, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8454/10000, Loss: 0.6850, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8455/10000, Loss: 0.6850, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8456/10000, Loss: 0.6850, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8457/10000, Loss: 0.6850, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8458/10000, Loss: 0.6849, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8459/10000, Loss: 0.6849, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8460/10000, Loss: 0.6849, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8461/10000, Loss: 0.6849, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8462/10000, Loss: 0.6849, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8463/10000, Loss: 0.6849, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8464/10000, Loss: 0.6848, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8465/10000, Loss: 0.6848, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8466/10000, Loss: 0.6848, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8467/10000, Loss: 0.6848, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8468/10000, Loss: 0.6848, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8469/10000, Loss: 0.6848, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8470/10000, Loss: 0.6847, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8471/10000, Loss: 0.6847, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8472/10000, Loss: 0.6847, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8473/10000, Loss: 0.6847, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8474/10000, Loss: 0.6847, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8475/10000, Loss: 0.6846, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8476/10000, Loss: 0.6846, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8477/10000, Loss: 0.6846, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8478/10000, Loss: 0.6846, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8479/10000, Loss: 0.6846, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8480/10000, Loss: 0.6846, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8481/10000, Loss: 0.6845, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8482/10000, Loss: 0.6845, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8483/10000, Loss: 0.6845, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8484/10000, Loss: 0.6845, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8485/10000, Loss: 0.6845, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8486/10000, Loss: 0.6845, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8487/10000, Loss: 0.6844, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8488/10000, Loss: 0.6844, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8489/10000, Loss: 0.6844, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8490/10000, Loss: 0.6844, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8491/10000, Loss: 0.6844, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8492/10000, Loss: 0.6844, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8493/10000, Loss: 0.6843, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8494/10000, Loss: 0.6843, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8495/10000, Loss: 0.6843, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8496/10000, Loss: 0.6843, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8497/10000, Loss: 0.6843, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8498/10000, Loss: 0.6842, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8499/10000, Loss: 0.6842, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8500/10000, Loss: 0.6842, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8501/10000, Loss: 0.6842, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8502/10000, Loss: 0.6842, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8503/10000, Loss: 0.6842, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8504/10000, Loss: 0.6841, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8505/10000, Loss: 0.6841, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8506/10000, Loss: 0.6841, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8507/10000, Loss: 0.6841, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8508/10000, Loss: 0.6841, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8509/10000, Loss: 0.6841, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8510/10000, Loss: 0.6840, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8511/10000, Loss: 0.6840, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8512/10000, Loss: 0.6840, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8513/10000, Loss: 0.6840, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8514/10000, Loss: 0.6840, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8515/10000, Loss: 0.6840, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8516/10000, Loss: 0.6839, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8517/10000, Loss: 0.6839, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8518/10000, Loss: 0.6839, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8519/10000, Loss: 0.6839, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8520/10000, Loss: 0.6839, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8521/10000, Loss: 0.6838, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8522/10000, Loss: 0.6838, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8523/10000, Loss: 0.6838, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8524/10000, Loss: 0.6838, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8525/10000, Loss: 0.6838, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8526/10000, Loss: 0.6838, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8527/10000, Loss: 0.6837, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8528/10000, Loss: 0.6837, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8529/10000, Loss: 0.6837, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8530/10000, Loss: 0.6837, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8531/10000, Loss: 0.6837, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8532/10000, Loss: 0.6837, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8533/10000, Loss: 0.6836, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8534/10000, Loss: 0.6836, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8535/10000, Loss: 0.6836, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8536/10000, Loss: 0.6836, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8537/10000, Loss: 0.6836, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8538/10000, Loss: 0.6836, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8539/10000, Loss: 0.6835, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8540/10000, Loss: 0.6835, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8541/10000, Loss: 0.6835, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8542/10000, Loss: 0.6835, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8543/10000, Loss: 0.6835, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8544/10000, Loss: 0.6834, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8545/10000, Loss: 0.6834, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8546/10000, Loss: 0.6834, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8547/10000, Loss: 0.6834, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8548/10000, Loss: 0.6834, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8549/10000, Loss: 0.6834, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8550/10000, Loss: 0.6833, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8551/10000, Loss: 0.6833, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8552/10000, Loss: 0.6833, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8553/10000, Loss: 0.6833, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8554/10000, Loss: 0.6833, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8555/10000, Loss: 0.6833, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8556/10000, Loss: 0.6832, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8557/10000, Loss: 0.6832, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8558/10000, Loss: 0.6832, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8559/10000, Loss: 0.6832, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8560/10000, Loss: 0.6832, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8561/10000, Loss: 0.6832, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8562/10000, Loss: 0.6831, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8563/10000, Loss: 0.6831, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8564/10000, Loss: 0.6831, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8565/10000, Loss: 0.6831, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8566/10000, Loss: 0.6831, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8567/10000, Loss: 0.6831, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8568/10000, Loss: 0.6830, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8569/10000, Loss: 0.6830, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8570/10000, Loss: 0.6830, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8571/10000, Loss: 0.6830, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8572/10000, Loss: 0.6830, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8573/10000, Loss: 0.6829, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8574/10000, Loss: 0.6829, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8575/10000, Loss: 0.6829, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8576/10000, Loss: 0.6829, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8577/10000, Loss: 0.6829, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8578/10000, Loss: 0.6829, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8579/10000, Loss: 0.6828, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8580/10000, Loss: 0.6828, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8581/10000, Loss: 0.6828, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8582/10000, Loss: 0.6828, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8583/10000, Loss: 0.6828, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8584/10000, Loss: 0.6828, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8585/10000, Loss: 0.6827, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8586/10000, Loss: 0.6827, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8587/10000, Loss: 0.6827, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8588/10000, Loss: 0.6827, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8589/10000, Loss: 0.6827, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8590/10000, Loss: 0.6827, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8591/10000, Loss: 0.6826, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8592/10000, Loss: 0.6826, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8593/10000, Loss: 0.6826, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8594/10000, Loss: 0.6826, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8595/10000, Loss: 0.6826, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8596/10000, Loss: 0.6826, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8597/10000, Loss: 0.6825, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8598/10000, Loss: 0.6825, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8599/10000, Loss: 0.6825, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8600/10000, Loss: 0.6825, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8601/10000, Loss: 0.6825, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8602/10000, Loss: 0.6824, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8603/10000, Loss: 0.6824, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8604/10000, Loss: 0.6824, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8605/10000, Loss: 0.6824, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8606/10000, Loss: 0.6824, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8607/10000, Loss: 0.6824, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8608/10000, Loss: 0.6823, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8609/10000, Loss: 0.6823, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8610/10000, Loss: 0.6823, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8611/10000, Loss: 0.6823, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8612/10000, Loss: 0.6823, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8613/10000, Loss: 0.6823, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8614/10000, Loss: 0.6822, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8615/10000, Loss: 0.6822, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8616/10000, Loss: 0.6822, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8617/10000, Loss: 0.6822, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8618/10000, Loss: 0.6822, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8619/10000, Loss: 0.6822, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8620/10000, Loss: 0.6821, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8621/10000, Loss: 0.6821, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8622/10000, Loss: 0.6821, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8623/10000, Loss: 0.6821, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8624/10000, Loss: 0.6821, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8625/10000, Loss: 0.6821, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8626/10000, Loss: 0.6820, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8627/10000, Loss: 0.6820, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8628/10000, Loss: 0.6820, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8629/10000, Loss: 0.6820, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8630/10000, Loss: 0.6820, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8631/10000, Loss: 0.6820, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8632/10000, Loss: 0.6819, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8633/10000, Loss: 0.6819, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8634/10000, Loss: 0.6819, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8635/10000, Loss: 0.6819, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8636/10000, Loss: 0.6819, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8637/10000, Loss: 0.6819, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8638/10000, Loss: 0.6818, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8639/10000, Loss: 0.6818, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8640/10000, Loss: 0.6818, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8641/10000, Loss: 0.6818, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8642/10000, Loss: 0.6818, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8643/10000, Loss: 0.6817, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8644/10000, Loss: 0.6817, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8645/10000, Loss: 0.6817, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8646/10000, Loss: 0.6817, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8647/10000, Loss: 0.6817, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8648/10000, Loss: 0.6817, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8649/10000, Loss: 0.6816, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8650/10000, Loss: 0.6816, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8651/10000, Loss: 0.6816, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8652/10000, Loss: 0.6816, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8653/10000, Loss: 0.6816, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8654/10000, Loss: 0.6816, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8655/10000, Loss: 0.6815, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8656/10000, Loss: 0.6815, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8657/10000, Loss: 0.6815, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8658/10000, Loss: 0.6815, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8659/10000, Loss: 0.6815, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8660/10000, Loss: 0.6815, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8661/10000, Loss: 0.6814, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8662/10000, Loss: 0.6814, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8663/10000, Loss: 0.6814, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8664/10000, Loss: 0.6814, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8665/10000, Loss: 0.6814, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8666/10000, Loss: 0.6814, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8667/10000, Loss: 0.6813, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8668/10000, Loss: 0.6813, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8669/10000, Loss: 0.6813, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8670/10000, Loss: 0.6813, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8671/10000, Loss: 0.6813, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8672/10000, Loss: 0.6813, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8673/10000, Loss: 0.6812, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8674/10000, Loss: 0.6812, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8675/10000, Loss: 0.6812, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8676/10000, Loss: 0.6812, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8677/10000, Loss: 0.6812, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8678/10000, Loss: 0.6812, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8679/10000, Loss: 0.6811, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8680/10000, Loss: 0.6811, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8681/10000, Loss: 0.6811, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8682/10000, Loss: 0.6811, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8683/10000, Loss: 0.6811, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8684/10000, Loss: 0.6811, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8685/10000, Loss: 0.6810, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8686/10000, Loss: 0.6810, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8687/10000, Loss: 0.6810, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8688/10000, Loss: 0.6810, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8689/10000, Loss: 0.6810, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8690/10000, Loss: 0.6810, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8691/10000, Loss: 0.6809, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8692/10000, Loss: 0.6809, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8693/10000, Loss: 0.6809, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8694/10000, Loss: 0.6809, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8695/10000, Loss: 0.6809, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8696/10000, Loss: 0.6808, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8697/10000, Loss: 0.6808, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8698/10000, Loss: 0.6808, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8699/10000, Loss: 0.6808, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8700/10000, Loss: 0.6808, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8701/10000, Loss: 0.6808, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8702/10000, Loss: 0.6807, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8703/10000, Loss: 0.6807, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8704/10000, Loss: 0.6807, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8705/10000, Loss: 0.6807, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8706/10000, Loss: 0.6807, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8707/10000, Loss: 0.6807, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8708/10000, Loss: 0.6806, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8709/10000, Loss: 0.6806, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8710/10000, Loss: 0.6806, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8711/10000, Loss: 0.6806, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8712/10000, Loss: 0.6806, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8713/10000, Loss: 0.6806, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8714/10000, Loss: 0.6805, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8715/10000, Loss: 0.6805, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8716/10000, Loss: 0.6805, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8717/10000, Loss: 0.6805, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8718/10000, Loss: 0.6805, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8719/10000, Loss: 0.6805, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8720/10000, Loss: 0.6804, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8721/10000, Loss: 0.6804, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8722/10000, Loss: 0.6804, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8723/10000, Loss: 0.6804, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8724/10000, Loss: 0.6804, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8725/10000, Loss: 0.6804, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8726/10000, Loss: 0.6803, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8727/10000, Loss: 0.6803, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8728/10000, Loss: 0.6803, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8729/10000, Loss: 0.6803, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8730/10000, Loss: 0.6803, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8731/10000, Loss: 0.6803, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8732/10000, Loss: 0.6802, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8733/10000, Loss: 0.6802, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8734/10000, Loss: 0.6802, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8735/10000, Loss: 0.6802, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8736/10000, Loss: 0.6802, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8737/10000, Loss: 0.6802, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8738/10000, Loss: 0.6801, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8739/10000, Loss: 0.6801, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8740/10000, Loss: 0.6801, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8741/10000, Loss: 0.6801, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8742/10000, Loss: 0.6801, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8743/10000, Loss: 0.6801, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8744/10000, Loss: 0.6800, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8745/10000, Loss: 0.6800, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8746/10000, Loss: 0.6800, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8747/10000, Loss: 0.6800, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8748/10000, Loss: 0.6800, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8749/10000, Loss: 0.6800, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8750/10000, Loss: 0.6799, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8751/10000, Loss: 0.6799, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8752/10000, Loss: 0.6799, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8753/10000, Loss: 0.6799, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8754/10000, Loss: 0.6799, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8755/10000, Loss: 0.6799, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8756/10000, Loss: 0.6798, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8757/10000, Loss: 0.6798, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8758/10000, Loss: 0.6798, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8759/10000, Loss: 0.6798, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8760/10000, Loss: 0.6798, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8761/10000, Loss: 0.6798, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8762/10000, Loss: 0.6797, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8763/10000, Loss: 0.6797, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8764/10000, Loss: 0.6797, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8765/10000, Loss: 0.6797, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8766/10000, Loss: 0.6797, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8767/10000, Loss: 0.6797, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8768/10000, Loss: 0.6796, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8769/10000, Loss: 0.6796, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8770/10000, Loss: 0.6796, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8771/10000, Loss: 0.6796, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8772/10000, Loss: 0.6796, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8773/10000, Loss: 0.6796, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8774/10000, Loss: 0.6795, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8775/10000, Loss: 0.6795, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8776/10000, Loss: 0.6795, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8777/10000, Loss: 0.6795, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8778/10000, Loss: 0.6795, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8779/10000, Loss: 0.6795, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8780/10000, Loss: 0.6794, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8781/10000, Loss: 0.6794, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8782/10000, Loss: 0.6794, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8783/10000, Loss: 0.6794, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8784/10000, Loss: 0.6794, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8785/10000, Loss: 0.6794, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8786/10000, Loss: 0.6793, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8787/10000, Loss: 0.6793, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8788/10000, Loss: 0.6793, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8789/10000, Loss: 0.6793, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8790/10000, Loss: 0.6793, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8791/10000, Loss: 0.6793, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8792/10000, Loss: 0.6792, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8793/10000, Loss: 0.6792, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8794/10000, Loss: 0.6792, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8795/10000, Loss: 0.6792, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8796/10000, Loss: 0.6792, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8797/10000, Loss: 0.6792, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8798/10000, Loss: 0.6791, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8799/10000, Loss: 0.6791, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8800/10000, Loss: 0.6791, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8801/10000, Loss: 0.6791, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8802/10000, Loss: 0.6791, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8803/10000, Loss: 0.6791, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8804/10000, Loss: 0.6790, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8805/10000, Loss: 0.6790, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8806/10000, Loss: 0.6790, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8807/10000, Loss: 0.6790, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8808/10000, Loss: 0.6790, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8809/10000, Loss: 0.6790, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8810/10000, Loss: 0.6789, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8811/10000, Loss: 0.6789, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8812/10000, Loss: 0.6789, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8813/10000, Loss: 0.6789, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8814/10000, Loss: 0.6789, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8815/10000, Loss: 0.6789, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8816/10000, Loss: 0.6788, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8817/10000, Loss: 0.6788, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8818/10000, Loss: 0.6788, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8819/10000, Loss: 0.6788, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8820/10000, Loss: 0.6788, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8821/10000, Loss: 0.6788, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8822/10000, Loss: 0.6787, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8823/10000, Loss: 0.6787, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8824/10000, Loss: 0.6787, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8825/10000, Loss: 0.6787, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8826/10000, Loss: 0.6787, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8827/10000, Loss: 0.6787, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8828/10000, Loss: 0.6786, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8829/10000, Loss: 0.6786, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8830/10000, Loss: 0.6786, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8831/10000, Loss: 0.6786, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8832/10000, Loss: 0.6786, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8833/10000, Loss: 0.6786, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8834/10000, Loss: 0.6785, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8835/10000, Loss: 0.6785, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8836/10000, Loss: 0.6785, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8837/10000, Loss: 0.6785, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8838/10000, Loss: 0.6785, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8839/10000, Loss: 0.6785, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8840/10000, Loss: 0.6784, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8841/10000, Loss: 0.6784, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8842/10000, Loss: 0.6784, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8843/10000, Loss: 0.6784, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8844/10000, Loss: 0.6784, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8845/10000, Loss: 0.6784, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8846/10000, Loss: 0.6783, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8847/10000, Loss: 0.6783, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8848/10000, Loss: 0.6783, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8849/10000, Loss: 0.6783, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8850/10000, Loss: 0.6783, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8851/10000, Loss: 0.6783, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8852/10000, Loss: 0.6782, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8853/10000, Loss: 0.6782, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8854/10000, Loss: 0.6782, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8855/10000, Loss: 0.6782, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8856/10000, Loss: 0.6782, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8857/10000, Loss: 0.6782, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8858/10000, Loss: 0.6781, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8859/10000, Loss: 0.6781, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8860/10000, Loss: 0.6781, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8861/10000, Loss: 0.6781, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8862/10000, Loss: 0.6781, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8863/10000, Loss: 0.6781, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8864/10000, Loss: 0.6781, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8865/10000, Loss: 0.6780, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8866/10000, Loss: 0.6780, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8867/10000, Loss: 0.6780, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8868/10000, Loss: 0.6780, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8869/10000, Loss: 0.6780, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8870/10000, Loss: 0.6780, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8871/10000, Loss: 0.6779, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8872/10000, Loss: 0.6779, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8873/10000, Loss: 0.6779, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8874/10000, Loss: 0.6779, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8875/10000, Loss: 0.6779, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8876/10000, Loss: 0.6779, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8877/10000, Loss: 0.6778, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8878/10000, Loss: 0.6778, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8879/10000, Loss: 0.6778, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8880/10000, Loss: 0.6778, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8881/10000, Loss: 0.6778, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8882/10000, Loss: 0.6778, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8883/10000, Loss: 0.6777, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8884/10000, Loss: 0.6777, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8885/10000, Loss: 0.6777, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8886/10000, Loss: 0.6777, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8887/10000, Loss: 0.6777, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8888/10000, Loss: 0.6777, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8889/10000, Loss: 0.6776, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8890/10000, Loss: 0.6776, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8891/10000, Loss: 0.6776, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8892/10000, Loss: 0.6776, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8893/10000, Loss: 0.6776, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8894/10000, Loss: 0.6776, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8895/10000, Loss: 0.6775, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8896/10000, Loss: 0.6775, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8897/10000, Loss: 0.6775, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8898/10000, Loss: 0.6775, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8899/10000, Loss: 0.6775, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8900/10000, Loss: 0.6775, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8901/10000, Loss: 0.6774, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8902/10000, Loss: 0.6774, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8903/10000, Loss: 0.6774, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8904/10000, Loss: 0.6774, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8905/10000, Loss: 0.6774, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8906/10000, Loss: 0.6774, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8907/10000, Loss: 0.6773, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8908/10000, Loss: 0.6773, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8909/10000, Loss: 0.6773, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8910/10000, Loss: 0.6773, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8911/10000, Loss: 0.6773, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8912/10000, Loss: 0.6773, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8913/10000, Loss: 0.6772, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8914/10000, Loss: 0.6772, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8915/10000, Loss: 0.6772, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8916/10000, Loss: 0.6772, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8917/10000, Loss: 0.6772, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8918/10000, Loss: 0.6772, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8919/10000, Loss: 0.6772, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8920/10000, Loss: 0.6771, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8921/10000, Loss: 0.6771, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8922/10000, Loss: 0.6771, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8923/10000, Loss: 0.6771, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8924/10000, Loss: 0.6771, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8925/10000, Loss: 0.6771, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8926/10000, Loss: 0.6770, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8927/10000, Loss: 0.6770, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8928/10000, Loss: 0.6770, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8929/10000, Loss: 0.6770, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8930/10000, Loss: 0.6770, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8931/10000, Loss: 0.6770, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8932/10000, Loss: 0.6769, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8933/10000, Loss: 0.6769, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8934/10000, Loss: 0.6769, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8935/10000, Loss: 0.6769, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8936/10000, Loss: 0.6769, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8937/10000, Loss: 0.6769, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8938/10000, Loss: 0.6768, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8939/10000, Loss: 0.6768, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8940/10000, Loss: 0.6768, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8941/10000, Loss: 0.6768, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8942/10000, Loss: 0.6768, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8943/10000, Loss: 0.6768, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8944/10000, Loss: 0.6767, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8945/10000, Loss: 0.6767, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8946/10000, Loss: 0.6767, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8947/10000, Loss: 0.6767, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8948/10000, Loss: 0.6767, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8949/10000, Loss: 0.6767, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8950/10000, Loss: 0.6766, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8951/10000, Loss: 0.6766, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8952/10000, Loss: 0.6766, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8953/10000, Loss: 0.6766, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8954/10000, Loss: 0.6766, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8955/10000, Loss: 0.6766, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8956/10000, Loss: 0.6765, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8957/10000, Loss: 0.6765, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8958/10000, Loss: 0.6765, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8959/10000, Loss: 0.6765, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8960/10000, Loss: 0.6765, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8961/10000, Loss: 0.6765, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8962/10000, Loss: 0.6765, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8963/10000, Loss: 0.6764, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8964/10000, Loss: 0.6764, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8965/10000, Loss: 0.6764, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8966/10000, Loss: 0.6764, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8967/10000, Loss: 0.6764, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8968/10000, Loss: 0.6764, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8969/10000, Loss: 0.6763, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8970/10000, Loss: 0.6763, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8971/10000, Loss: 0.6763, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8972/10000, Loss: 0.6763, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8973/10000, Loss: 0.6763, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8974/10000, Loss: 0.6763, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8975/10000, Loss: 0.6762, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8976/10000, Loss: 0.6762, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8977/10000, Loss: 0.6762, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8978/10000, Loss: 0.6762, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8979/10000, Loss: 0.6762, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8980/10000, Loss: 0.6762, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8981/10000, Loss: 0.6761, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8982/10000, Loss: 0.6761, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8983/10000, Loss: 0.6761, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8984/10000, Loss: 0.6761, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8985/10000, Loss: 0.6761, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8986/10000, Loss: 0.6761, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8987/10000, Loss: 0.6760, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8988/10000, Loss: 0.6760, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8989/10000, Loss: 0.6760, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8990/10000, Loss: 0.6760, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8991/10000, Loss: 0.6760, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8992/10000, Loss: 0.6760, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8993/10000, Loss: 0.6760, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8994/10000, Loss: 0.6759, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8995/10000, Loss: 0.6759, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8996/10000, Loss: 0.6759, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8997/10000, Loss: 0.6759, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8998/10000, Loss: 0.6759, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8999/10000, Loss: 0.6759, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9000/10000, Loss: 0.6758, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9001/10000, Loss: 0.6758, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9002/10000, Loss: 0.6758, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9003/10000, Loss: 0.6758, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9004/10000, Loss: 0.6758, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9005/10000, Loss: 0.6758, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9006/10000, Loss: 0.6757, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9007/10000, Loss: 0.6757, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9008/10000, Loss: 0.6757, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9009/10000, Loss: 0.6757, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9010/10000, Loss: 0.6757, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9011/10000, Loss: 0.6757, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9012/10000, Loss: 0.6756, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9013/10000, Loss: 0.6756, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9014/10000, Loss: 0.6756, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9015/10000, Loss: 0.6756, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9016/10000, Loss: 0.6756, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9017/10000, Loss: 0.6756, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9018/10000, Loss: 0.6755, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9019/10000, Loss: 0.6755, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9020/10000, Loss: 0.6755, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9021/10000, Loss: 0.6755, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9022/10000, Loss: 0.6755, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9023/10000, Loss: 0.6755, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9024/10000, Loss: 0.6755, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9025/10000, Loss: 0.6754, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9026/10000, Loss: 0.6754, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9027/10000, Loss: 0.6754, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9028/10000, Loss: 0.6754, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9029/10000, Loss: 0.6754, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9030/10000, Loss: 0.6754, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9031/10000, Loss: 0.6753, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9032/10000, Loss: 0.6753, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9033/10000, Loss: 0.6753, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9034/10000, Loss: 0.6753, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9035/10000, Loss: 0.6753, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9036/10000, Loss: 0.6753, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9037/10000, Loss: 0.6752, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9038/10000, Loss: 0.6752, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9039/10000, Loss: 0.6752, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9040/10000, Loss: 0.6752, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9041/10000, Loss: 0.6752, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9042/10000, Loss: 0.6752, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9043/10000, Loss: 0.6751, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9044/10000, Loss: 0.6751, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9045/10000, Loss: 0.6751, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9046/10000, Loss: 0.6751, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9047/10000, Loss: 0.6751, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9048/10000, Loss: 0.6751, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9049/10000, Loss: 0.6751, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9050/10000, Loss: 0.6750, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9051/10000, Loss: 0.6750, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9052/10000, Loss: 0.6750, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9053/10000, Loss: 0.6750, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9054/10000, Loss: 0.6750, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9055/10000, Loss: 0.6750, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9056/10000, Loss: 0.6749, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9057/10000, Loss: 0.6749, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9058/10000, Loss: 0.6749, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9059/10000, Loss: 0.6749, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9060/10000, Loss: 0.6749, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9061/10000, Loss: 0.6749, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9062/10000, Loss: 0.6748, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9063/10000, Loss: 0.6748, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9064/10000, Loss: 0.6748, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9065/10000, Loss: 0.6748, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9066/10000, Loss: 0.6748, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9067/10000, Loss: 0.6748, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9068/10000, Loss: 0.6748, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9069/10000, Loss: 0.6747, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9070/10000, Loss: 0.6747, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9071/10000, Loss: 0.6747, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9072/10000, Loss: 0.6747, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9073/10000, Loss: 0.6747, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9074/10000, Loss: 0.6747, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9075/10000, Loss: 0.6746, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9076/10000, Loss: 0.6746, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9077/10000, Loss: 0.6746, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9078/10000, Loss: 0.6746, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9079/10000, Loss: 0.6746, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9080/10000, Loss: 0.6746, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9081/10000, Loss: 0.6745, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9082/10000, Loss: 0.6745, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9083/10000, Loss: 0.6745, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9084/10000, Loss: 0.6745, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9085/10000, Loss: 0.6745, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9086/10000, Loss: 0.6745, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9087/10000, Loss: 0.6744, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9088/10000, Loss: 0.6744, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9089/10000, Loss: 0.6744, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9090/10000, Loss: 0.6744, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9091/10000, Loss: 0.6744, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9092/10000, Loss: 0.6744, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9093/10000, Loss: 0.6744, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9094/10000, Loss: 0.6743, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9095/10000, Loss: 0.6743, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9096/10000, Loss: 0.6743, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9097/10000, Loss: 0.6743, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9098/10000, Loss: 0.6743, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9099/10000, Loss: 0.6743, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9100/10000, Loss: 0.6742, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9101/10000, Loss: 0.6742, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9102/10000, Loss: 0.6742, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9103/10000, Loss: 0.6742, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9104/10000, Loss: 0.6742, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9105/10000, Loss: 0.6742, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9106/10000, Loss: 0.6741, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9107/10000, Loss: 0.6741, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9108/10000, Loss: 0.6741, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9109/10000, Loss: 0.6741, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9110/10000, Loss: 0.6741, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9111/10000, Loss: 0.6741, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9112/10000, Loss: 0.6741, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9113/10000, Loss: 0.6740, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9114/10000, Loss: 0.6740, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9115/10000, Loss: 0.6740, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9116/10000, Loss: 0.6740, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9117/10000, Loss: 0.6740, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9118/10000, Loss: 0.6740, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9119/10000, Loss: 0.6739, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9120/10000, Loss: 0.6739, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9121/10000, Loss: 0.6739, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9122/10000, Loss: 0.6739, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9123/10000, Loss: 0.6739, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9124/10000, Loss: 0.6739, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9125/10000, Loss: 0.6738, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9126/10000, Loss: 0.6738, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9127/10000, Loss: 0.6738, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9128/10000, Loss: 0.6738, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9129/10000, Loss: 0.6738, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9130/10000, Loss: 0.6738, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9131/10000, Loss: 0.6738, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9132/10000, Loss: 0.6737, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9133/10000, Loss: 0.6737, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9134/10000, Loss: 0.6737, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9135/10000, Loss: 0.6737, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9136/10000, Loss: 0.6737, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9137/10000, Loss: 0.6737, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9138/10000, Loss: 0.6736, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9139/10000, Loss: 0.6736, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9140/10000, Loss: 0.6736, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9141/10000, Loss: 0.6736, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9142/10000, Loss: 0.6736, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9143/10000, Loss: 0.6736, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9144/10000, Loss: 0.6735, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9145/10000, Loss: 0.6735, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9146/10000, Loss: 0.6735, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9147/10000, Loss: 0.6735, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9148/10000, Loss: 0.6735, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9149/10000, Loss: 0.6735, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9150/10000, Loss: 0.6735, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9151/10000, Loss: 0.6734, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9152/10000, Loss: 0.6734, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9153/10000, Loss: 0.6734, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9154/10000, Loss: 0.6734, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9155/10000, Loss: 0.6734, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9156/10000, Loss: 0.6734, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9157/10000, Loss: 0.6733, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9158/10000, Loss: 0.6733, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9159/10000, Loss: 0.6733, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9160/10000, Loss: 0.6733, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9161/10000, Loss: 0.6733, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9162/10000, Loss: 0.6733, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9163/10000, Loss: 0.6733, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9164/10000, Loss: 0.6732, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9165/10000, Loss: 0.6732, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9166/10000, Loss: 0.6732, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9167/10000, Loss: 0.6732, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9168/10000, Loss: 0.6732, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9169/10000, Loss: 0.6732, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9170/10000, Loss: 0.6731, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9171/10000, Loss: 0.6731, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9172/10000, Loss: 0.6731, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9173/10000, Loss: 0.6731, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9174/10000, Loss: 0.6731, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9175/10000, Loss: 0.6731, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9176/10000, Loss: 0.6730, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9177/10000, Loss: 0.6730, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9178/10000, Loss: 0.6730, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9179/10000, Loss: 0.6730, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9180/10000, Loss: 0.6730, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9181/10000, Loss: 0.6730, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9182/10000, Loss: 0.6730, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9183/10000, Loss: 0.6729, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9184/10000, Loss: 0.6729, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9185/10000, Loss: 0.6729, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9186/10000, Loss: 0.6729, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9187/10000, Loss: 0.6729, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9188/10000, Loss: 0.6729, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9189/10000, Loss: 0.6728, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9190/10000, Loss: 0.6728, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9191/10000, Loss: 0.6728, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9192/10000, Loss: 0.6728, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9193/10000, Loss: 0.6728, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9194/10000, Loss: 0.6728, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9195/10000, Loss: 0.6728, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9196/10000, Loss: 0.6727, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9197/10000, Loss: 0.6727, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9198/10000, Loss: 0.6727, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9199/10000, Loss: 0.6727, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9200/10000, Loss: 0.6727, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9201/10000, Loss: 0.6727, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9202/10000, Loss: 0.6726, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9203/10000, Loss: 0.6726, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9204/10000, Loss: 0.6726, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9205/10000, Loss: 0.6726, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9206/10000, Loss: 0.6726, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9207/10000, Loss: 0.6726, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9208/10000, Loss: 0.6725, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9209/10000, Loss: 0.6725, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9210/10000, Loss: 0.6725, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9211/10000, Loss: 0.6725, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9212/10000, Loss: 0.6725, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9213/10000, Loss: 0.6725, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9214/10000, Loss: 0.6725, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9215/10000, Loss: 0.6724, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9216/10000, Loss: 0.6724, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9217/10000, Loss: 0.6724, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9218/10000, Loss: 0.6724, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9219/10000, Loss: 0.6724, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9220/10000, Loss: 0.6724, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9221/10000, Loss: 0.6723, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9222/10000, Loss: 0.6723, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9223/10000, Loss: 0.6723, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9224/10000, Loss: 0.6723, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9225/10000, Loss: 0.6723, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9226/10000, Loss: 0.6723, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9227/10000, Loss: 0.6723, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9228/10000, Loss: 0.6722, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9229/10000, Loss: 0.6722, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9230/10000, Loss: 0.6722, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9231/10000, Loss: 0.6722, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9232/10000, Loss: 0.6722, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9233/10000, Loss: 0.6722, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9234/10000, Loss: 0.6721, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9235/10000, Loss: 0.6721, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9236/10000, Loss: 0.6721, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9237/10000, Loss: 0.6721, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9238/10000, Loss: 0.6721, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9239/10000, Loss: 0.6721, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9240/10000, Loss: 0.6721, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9241/10000, Loss: 0.6720, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9242/10000, Loss: 0.6720, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9243/10000, Loss: 0.6720, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9244/10000, Loss: 0.6720, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9245/10000, Loss: 0.6720, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9246/10000, Loss: 0.6720, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9247/10000, Loss: 0.6719, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9248/10000, Loss: 0.6719, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9249/10000, Loss: 0.6719, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9250/10000, Loss: 0.6719, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9251/10000, Loss: 0.6719, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9252/10000, Loss: 0.6719, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9253/10000, Loss: 0.6719, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9254/10000, Loss: 0.6718, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9255/10000, Loss: 0.6718, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9256/10000, Loss: 0.6718, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9257/10000, Loss: 0.6718, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9258/10000, Loss: 0.6718, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9259/10000, Loss: 0.6718, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9260/10000, Loss: 0.6717, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9261/10000, Loss: 0.6717, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9262/10000, Loss: 0.6717, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9263/10000, Loss: 0.6717, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9264/10000, Loss: 0.6717, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9265/10000, Loss: 0.6717, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9266/10000, Loss: 0.6717, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9267/10000, Loss: 0.6716, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9268/10000, Loss: 0.6716, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9269/10000, Loss: 0.6716, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9270/10000, Loss: 0.6716, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9271/10000, Loss: 0.6716, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9272/10000, Loss: 0.6716, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9273/10000, Loss: 0.6715, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9274/10000, Loss: 0.6715, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9275/10000, Loss: 0.6715, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9276/10000, Loss: 0.6715, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9277/10000, Loss: 0.6715, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9278/10000, Loss: 0.6715, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9279/10000, Loss: 0.6715, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9280/10000, Loss: 0.6714, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9281/10000, Loss: 0.6714, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9282/10000, Loss: 0.6714, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9283/10000, Loss: 0.6714, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9284/10000, Loss: 0.6714, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9285/10000, Loss: 0.6714, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9286/10000, Loss: 0.6713, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9287/10000, Loss: 0.6713, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9288/10000, Loss: 0.6713, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9289/10000, Loss: 0.6713, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9290/10000, Loss: 0.6713, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9291/10000, Loss: 0.6713, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9292/10000, Loss: 0.6713, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9293/10000, Loss: 0.6712, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9294/10000, Loss: 0.6712, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9295/10000, Loss: 0.6712, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9296/10000, Loss: 0.6712, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9297/10000, Loss: 0.6712, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9298/10000, Loss: 0.6712, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9299/10000, Loss: 0.6711, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9300/10000, Loss: 0.6711, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9301/10000, Loss: 0.6711, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9302/10000, Loss: 0.6711, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9303/10000, Loss: 0.6711, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9304/10000, Loss: 0.6711, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9305/10000, Loss: 0.6711, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9306/10000, Loss: 0.6710, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9307/10000, Loss: 0.6710, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9308/10000, Loss: 0.6710, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9309/10000, Loss: 0.6710, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9310/10000, Loss: 0.6710, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9311/10000, Loss: 0.6710, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9312/10000, Loss: 0.6709, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9313/10000, Loss: 0.6709, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9314/10000, Loss: 0.6709, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9315/10000, Loss: 0.6709, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9316/10000, Loss: 0.6709, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9317/10000, Loss: 0.6709, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9318/10000, Loss: 0.6709, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9319/10000, Loss: 0.6708, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9320/10000, Loss: 0.6708, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9321/10000, Loss: 0.6708, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9322/10000, Loss: 0.6708, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9323/10000, Loss: 0.6708, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9324/10000, Loss: 0.6708, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9325/10000, Loss: 0.6707, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9326/10000, Loss: 0.6707, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9327/10000, Loss: 0.6707, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9328/10000, Loss: 0.6707, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9329/10000, Loss: 0.6707, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9330/10000, Loss: 0.6707, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9331/10000, Loss: 0.6707, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9332/10000, Loss: 0.6706, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9333/10000, Loss: 0.6706, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9334/10000, Loss: 0.6706, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9335/10000, Loss: 0.6706, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9336/10000, Loss: 0.6706, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9337/10000, Loss: 0.6706, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9338/10000, Loss: 0.6705, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9339/10000, Loss: 0.6705, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9340/10000, Loss: 0.6705, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9341/10000, Loss: 0.6705, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9342/10000, Loss: 0.6705, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9343/10000, Loss: 0.6705, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9344/10000, Loss: 0.6705, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9345/10000, Loss: 0.6704, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9346/10000, Loss: 0.6704, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9347/10000, Loss: 0.6704, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9348/10000, Loss: 0.6704, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9349/10000, Loss: 0.6704, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9350/10000, Loss: 0.6704, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9351/10000, Loss: 0.6703, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9352/10000, Loss: 0.6703, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9353/10000, Loss: 0.6703, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9354/10000, Loss: 0.6703, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9355/10000, Loss: 0.6703, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9356/10000, Loss: 0.6703, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9357/10000, Loss: 0.6703, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9358/10000, Loss: 0.6702, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9359/10000, Loss: 0.6702, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9360/10000, Loss: 0.6702, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9361/10000, Loss: 0.6702, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9362/10000, Loss: 0.6702, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9363/10000, Loss: 0.6702, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9364/10000, Loss: 0.6702, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9365/10000, Loss: 0.6701, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9366/10000, Loss: 0.6701, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9367/10000, Loss: 0.6701, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9368/10000, Loss: 0.6701, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9369/10000, Loss: 0.6701, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9370/10000, Loss: 0.6701, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9371/10000, Loss: 0.6700, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9372/10000, Loss: 0.6700, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9373/10000, Loss: 0.6700, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9374/10000, Loss: 0.6700, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9375/10000, Loss: 0.6700, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9376/10000, Loss: 0.6700, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9377/10000, Loss: 0.6700, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9378/10000, Loss: 0.6699, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9379/10000, Loss: 0.6699, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9380/10000, Loss: 0.6699, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9381/10000, Loss: 0.6699, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9382/10000, Loss: 0.6699, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9383/10000, Loss: 0.6699, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9384/10000, Loss: 0.6698, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9385/10000, Loss: 0.6698, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9386/10000, Loss: 0.6698, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9387/10000, Loss: 0.6698, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9388/10000, Loss: 0.6698, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9389/10000, Loss: 0.6698, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9390/10000, Loss: 0.6698, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9391/10000, Loss: 0.6697, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9392/10000, Loss: 0.6697, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9393/10000, Loss: 0.6697, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9394/10000, Loss: 0.6697, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9395/10000, Loss: 0.6697, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9396/10000, Loss: 0.6697, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9397/10000, Loss: 0.6697, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9398/10000, Loss: 0.6696, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9399/10000, Loss: 0.6696, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9400/10000, Loss: 0.6696, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9401/10000, Loss: 0.6696, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9402/10000, Loss: 0.6696, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9403/10000, Loss: 0.6696, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9404/10000, Loss: 0.6695, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9405/10000, Loss: 0.6695, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9406/10000, Loss: 0.6695, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9407/10000, Loss: 0.6695, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9408/10000, Loss: 0.6695, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9409/10000, Loss: 0.6695, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9410/10000, Loss: 0.6695, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9411/10000, Loss: 0.6694, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9412/10000, Loss: 0.6694, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9413/10000, Loss: 0.6694, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9414/10000, Loss: 0.6694, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9415/10000, Loss: 0.6694, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9416/10000, Loss: 0.6694, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9417/10000, Loss: 0.6694, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9418/10000, Loss: 0.6693, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9419/10000, Loss: 0.6693, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9420/10000, Loss: 0.6693, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9421/10000, Loss: 0.6693, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9422/10000, Loss: 0.6693, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9423/10000, Loss: 0.6693, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9424/10000, Loss: 0.6692, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9425/10000, Loss: 0.6692, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9426/10000, Loss: 0.6692, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9427/10000, Loss: 0.6692, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9428/10000, Loss: 0.6692, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9429/10000, Loss: 0.6692, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9430/10000, Loss: 0.6692, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9431/10000, Loss: 0.6691, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9432/10000, Loss: 0.6691, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9433/10000, Loss: 0.6691, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9434/10000, Loss: 0.6691, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9435/10000, Loss: 0.6691, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9436/10000, Loss: 0.6691, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9437/10000, Loss: 0.6691, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9438/10000, Loss: 0.6690, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9439/10000, Loss: 0.6690, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9440/10000, Loss: 0.6690, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9441/10000, Loss: 0.6690, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9442/10000, Loss: 0.6690, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9443/10000, Loss: 0.6690, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9444/10000, Loss: 0.6689, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9445/10000, Loss: 0.6689, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9446/10000, Loss: 0.6689, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9447/10000, Loss: 0.6689, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9448/10000, Loss: 0.6689, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9449/10000, Loss: 0.6689, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9450/10000, Loss: 0.6689, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9451/10000, Loss: 0.6688, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9452/10000, Loss: 0.6688, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9453/10000, Loss: 0.6688, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9454/10000, Loss: 0.6688, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9455/10000, Loss: 0.6688, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9456/10000, Loss: 0.6688, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9457/10000, Loss: 0.6688, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9458/10000, Loss: 0.6687, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9459/10000, Loss: 0.6687, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9460/10000, Loss: 0.6687, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9461/10000, Loss: 0.6687, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9462/10000, Loss: 0.6687, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9463/10000, Loss: 0.6687, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9464/10000, Loss: 0.6686, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9465/10000, Loss: 0.6686, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9466/10000, Loss: 0.6686, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9467/10000, Loss: 0.6686, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9468/10000, Loss: 0.6686, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9469/10000, Loss: 0.6686, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9470/10000, Loss: 0.6686, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9471/10000, Loss: 0.6685, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9472/10000, Loss: 0.6685, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9473/10000, Loss: 0.6685, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9474/10000, Loss: 0.6685, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9475/10000, Loss: 0.6685, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9476/10000, Loss: 0.6685, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9477/10000, Loss: 0.6685, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9478/10000, Loss: 0.6684, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9479/10000, Loss: 0.6684, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9480/10000, Loss: 0.6684, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9481/10000, Loss: 0.6684, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9482/10000, Loss: 0.6684, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9483/10000, Loss: 0.6684, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9484/10000, Loss: 0.6684, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9485/10000, Loss: 0.6683, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9486/10000, Loss: 0.6683, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9487/10000, Loss: 0.6683, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9488/10000, Loss: 0.6683, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9489/10000, Loss: 0.6683, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9490/10000, Loss: 0.6683, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9491/10000, Loss: 0.6682, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9492/10000, Loss: 0.6682, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9493/10000, Loss: 0.6682, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9494/10000, Loss: 0.6682, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9495/10000, Loss: 0.6682, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9496/10000, Loss: 0.6682, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9497/10000, Loss: 0.6682, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9498/10000, Loss: 0.6681, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9499/10000, Loss: 0.6681, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9500/10000, Loss: 0.6681, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9501/10000, Loss: 0.6681, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9502/10000, Loss: 0.6681, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9503/10000, Loss: 0.6681, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9504/10000, Loss: 0.6681, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9505/10000, Loss: 0.6680, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9506/10000, Loss: 0.6680, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9507/10000, Loss: 0.6680, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9508/10000, Loss: 0.6680, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9509/10000, Loss: 0.6680, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9510/10000, Loss: 0.6680, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9511/10000, Loss: 0.6680, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9512/10000, Loss: 0.6679, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9513/10000, Loss: 0.6679, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9514/10000, Loss: 0.6679, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9515/10000, Loss: 0.6679, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9516/10000, Loss: 0.6679, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9517/10000, Loss: 0.6679, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9518/10000, Loss: 0.6678, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9519/10000, Loss: 0.6678, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9520/10000, Loss: 0.6678, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9521/10000, Loss: 0.6678, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9522/10000, Loss: 0.6678, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9523/10000, Loss: 0.6678, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9524/10000, Loss: 0.6678, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9525/10000, Loss: 0.6677, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9526/10000, Loss: 0.6677, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9527/10000, Loss: 0.6677, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9528/10000, Loss: 0.6677, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9529/10000, Loss: 0.6677, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9530/10000, Loss: 0.6677, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9531/10000, Loss: 0.6677, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9532/10000, Loss: 0.6676, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9533/10000, Loss: 0.6676, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9534/10000, Loss: 0.6676, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9535/10000, Loss: 0.6676, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9536/10000, Loss: 0.6676, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9537/10000, Loss: 0.6676, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9538/10000, Loss: 0.6676, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9539/10000, Loss: 0.6675, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9540/10000, Loss: 0.6675, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9541/10000, Loss: 0.6675, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9542/10000, Loss: 0.6675, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9543/10000, Loss: 0.6675, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9544/10000, Loss: 0.6675, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9545/10000, Loss: 0.6674, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9546/10000, Loss: 0.6674, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9547/10000, Loss: 0.6674, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9548/10000, Loss: 0.6674, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9549/10000, Loss: 0.6674, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9550/10000, Loss: 0.6674, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9551/10000, Loss: 0.6674, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9552/10000, Loss: 0.6673, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9553/10000, Loss: 0.6673, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9554/10000, Loss: 0.6673, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9555/10000, Loss: 0.6673, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9556/10000, Loss: 0.6673, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9557/10000, Loss: 0.6673, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9558/10000, Loss: 0.6673, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9559/10000, Loss: 0.6672, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9560/10000, Loss: 0.6672, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9561/10000, Loss: 0.6672, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9562/10000, Loss: 0.6672, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9563/10000, Loss: 0.6672, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9564/10000, Loss: 0.6672, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9565/10000, Loss: 0.6672, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9566/10000, Loss: 0.6671, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9567/10000, Loss: 0.6671, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9568/10000, Loss: 0.6671, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9569/10000, Loss: 0.6671, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9570/10000, Loss: 0.6671, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9571/10000, Loss: 0.6671, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9572/10000, Loss: 0.6671, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9573/10000, Loss: 0.6670, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9574/10000, Loss: 0.6670, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9575/10000, Loss: 0.6670, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9576/10000, Loss: 0.6670, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9577/10000, Loss: 0.6670, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9578/10000, Loss: 0.6670, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9579/10000, Loss: 0.6669, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9580/10000, Loss: 0.6669, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9581/10000, Loss: 0.6669, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9582/10000, Loss: 0.6669, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9583/10000, Loss: 0.6669, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9584/10000, Loss: 0.6669, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9585/10000, Loss: 0.6669, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9586/10000, Loss: 0.6668, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9587/10000, Loss: 0.6668, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9588/10000, Loss: 0.6668, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9589/10000, Loss: 0.6668, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9590/10000, Loss: 0.6668, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9591/10000, Loss: 0.6668, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9592/10000, Loss: 0.6668, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9593/10000, Loss: 0.6667, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9594/10000, Loss: 0.6667, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9595/10000, Loss: 0.6667, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9596/10000, Loss: 0.6667, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9597/10000, Loss: 0.6667, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9598/10000, Loss: 0.6667, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9599/10000, Loss: 0.6667, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9600/10000, Loss: 0.6666, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9601/10000, Loss: 0.6666, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9602/10000, Loss: 0.6666, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9603/10000, Loss: 0.6666, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9604/10000, Loss: 0.6666, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9605/10000, Loss: 0.6666, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9606/10000, Loss: 0.6666, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9607/10000, Loss: 0.6665, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9608/10000, Loss: 0.6665, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9609/10000, Loss: 0.6665, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9610/10000, Loss: 0.6665, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9611/10000, Loss: 0.6665, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9612/10000, Loss: 0.6665, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9613/10000, Loss: 0.6665, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9614/10000, Loss: 0.6664, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9615/10000, Loss: 0.6664, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9616/10000, Loss: 0.6664, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9617/10000, Loss: 0.6664, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9618/10000, Loss: 0.6664, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9619/10000, Loss: 0.6664, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9620/10000, Loss: 0.6664, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9621/10000, Loss: 0.6663, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9622/10000, Loss: 0.6663, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9623/10000, Loss: 0.6663, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9624/10000, Loss: 0.6663, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9625/10000, Loss: 0.6663, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9626/10000, Loss: 0.6663, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9627/10000, Loss: 0.6663, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9628/10000, Loss: 0.6662, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9629/10000, Loss: 0.6662, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9630/10000, Loss: 0.6662, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9631/10000, Loss: 0.6662, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9632/10000, Loss: 0.6662, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9633/10000, Loss: 0.6662, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9634/10000, Loss: 0.6661, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9635/10000, Loss: 0.6661, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9636/10000, Loss: 0.6661, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9637/10000, Loss: 0.6661, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9638/10000, Loss: 0.6661, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9639/10000, Loss: 0.6661, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9640/10000, Loss: 0.6661, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9641/10000, Loss: 0.6660, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9642/10000, Loss: 0.6660, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9643/10000, Loss: 0.6660, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9644/10000, Loss: 0.6660, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9645/10000, Loss: 0.6660, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9646/10000, Loss: 0.6660, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9647/10000, Loss: 0.6660, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9648/10000, Loss: 0.6659, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9649/10000, Loss: 0.6659, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9650/10000, Loss: 0.6659, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9651/10000, Loss: 0.6659, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9652/10000, Loss: 0.6659, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9653/10000, Loss: 0.6659, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9654/10000, Loss: 0.6659, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9655/10000, Loss: 0.6658, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9656/10000, Loss: 0.6658, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9657/10000, Loss: 0.6658, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9658/10000, Loss: 0.6658, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9659/10000, Loss: 0.6658, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9660/10000, Loss: 0.6658, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9661/10000, Loss: 0.6658, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9662/10000, Loss: 0.6657, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9663/10000, Loss: 0.6657, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9664/10000, Loss: 0.6657, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9665/10000, Loss: 0.6657, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9666/10000, Loss: 0.6657, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9667/10000, Loss: 0.6657, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9668/10000, Loss: 0.6657, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9669/10000, Loss: 0.6656, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9670/10000, Loss: 0.6656, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9671/10000, Loss: 0.6656, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9672/10000, Loss: 0.6656, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9673/10000, Loss: 0.6656, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9674/10000, Loss: 0.6656, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9675/10000, Loss: 0.6656, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9676/10000, Loss: 0.6655, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9677/10000, Loss: 0.6655, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9678/10000, Loss: 0.6655, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9679/10000, Loss: 0.6655, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9680/10000, Loss: 0.6655, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9681/10000, Loss: 0.6655, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9682/10000, Loss: 0.6655, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9683/10000, Loss: 0.6654, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9684/10000, Loss: 0.6654, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9685/10000, Loss: 0.6654, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9686/10000, Loss: 0.6654, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9687/10000, Loss: 0.6654, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9688/10000, Loss: 0.6654, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9689/10000, Loss: 0.6654, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9690/10000, Loss: 0.6653, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9691/10000, Loss: 0.6653, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9692/10000, Loss: 0.6653, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9693/10000, Loss: 0.6653, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9694/10000, Loss: 0.6653, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9695/10000, Loss: 0.6653, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9696/10000, Loss: 0.6653, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9697/10000, Loss: 0.6652, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9698/10000, Loss: 0.6652, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9699/10000, Loss: 0.6652, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9700/10000, Loss: 0.6652, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9701/10000, Loss: 0.6652, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9702/10000, Loss: 0.6652, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9703/10000, Loss: 0.6652, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9704/10000, Loss: 0.6651, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9705/10000, Loss: 0.6651, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9706/10000, Loss: 0.6651, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9707/10000, Loss: 0.6651, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9708/10000, Loss: 0.6651, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9709/10000, Loss: 0.6651, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9710/10000, Loss: 0.6651, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9711/10000, Loss: 0.6650, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9712/10000, Loss: 0.6650, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9713/10000, Loss: 0.6650, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9714/10000, Loss: 0.6650, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9715/10000, Loss: 0.6650, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9716/10000, Loss: 0.6650, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9717/10000, Loss: 0.6650, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9718/10000, Loss: 0.6649, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9719/10000, Loss: 0.6649, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9720/10000, Loss: 0.6649, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9721/10000, Loss: 0.6649, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9722/10000, Loss: 0.6649, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9723/10000, Loss: 0.6649, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9724/10000, Loss: 0.6649, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9725/10000, Loss: 0.6648, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9726/10000, Loss: 0.6648, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9727/10000, Loss: 0.6648, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9728/10000, Loss: 0.6648, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9729/10000, Loss: 0.6648, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9730/10000, Loss: 0.6648, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9731/10000, Loss: 0.6648, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9732/10000, Loss: 0.6647, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9733/10000, Loss: 0.6647, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9734/10000, Loss: 0.6647, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9735/10000, Loss: 0.6647, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9736/10000, Loss: 0.6647, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9737/10000, Loss: 0.6647, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9738/10000, Loss: 0.6647, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9739/10000, Loss: 0.6646, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9740/10000, Loss: 0.6646, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9741/10000, Loss: 0.6646, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9742/10000, Loss: 0.6646, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9743/10000, Loss: 0.6646, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9744/10000, Loss: 0.6646, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9745/10000, Loss: 0.6646, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9746/10000, Loss: 0.6645, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9747/10000, Loss: 0.6645, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9748/10000, Loss: 0.6645, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9749/10000, Loss: 0.6645, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9750/10000, Loss: 0.6645, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9751/10000, Loss: 0.6645, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9752/10000, Loss: 0.6645, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9753/10000, Loss: 0.6644, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9754/10000, Loss: 0.6644, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9755/10000, Loss: 0.6644, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9756/10000, Loss: 0.6644, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9757/10000, Loss: 0.6644, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9758/10000, Loss: 0.6644, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9759/10000, Loss: 0.6644, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9760/10000, Loss: 0.6643, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9761/10000, Loss: 0.6643, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9762/10000, Loss: 0.6643, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9763/10000, Loss: 0.6643, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9764/10000, Loss: 0.6643, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9765/10000, Loss: 0.6643, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9766/10000, Loss: 0.6643, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9767/10000, Loss: 0.6642, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9768/10000, Loss: 0.6642, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9769/10000, Loss: 0.6642, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9770/10000, Loss: 0.6642, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9771/10000, Loss: 0.6642, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9772/10000, Loss: 0.6642, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9773/10000, Loss: 0.6642, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9774/10000, Loss: 0.6641, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9775/10000, Loss: 0.6641, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9776/10000, Loss: 0.6641, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9777/10000, Loss: 0.6641, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9778/10000, Loss: 0.6641, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9779/10000, Loss: 0.6641, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9780/10000, Loss: 0.6641, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9781/10000, Loss: 0.6640, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9782/10000, Loss: 0.6640, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9783/10000, Loss: 0.6640, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9784/10000, Loss: 0.6640, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9785/10000, Loss: 0.6640, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9786/10000, Loss: 0.6640, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9787/10000, Loss: 0.6640, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9788/10000, Loss: 0.6639, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9789/10000, Loss: 0.6639, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9790/10000, Loss: 0.6639, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9791/10000, Loss: 0.6639, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9792/10000, Loss: 0.6639, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9793/10000, Loss: 0.6639, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9794/10000, Loss: 0.6639, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9795/10000, Loss: 0.6638, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9796/10000, Loss: 0.6638, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9797/10000, Loss: 0.6638, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9798/10000, Loss: 0.6638, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9799/10000, Loss: 0.6638, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9800/10000, Loss: 0.6638, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9801/10000, Loss: 0.6638, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9802/10000, Loss: 0.6637, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9803/10000, Loss: 0.6637, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9804/10000, Loss: 0.6637, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9805/10000, Loss: 0.6637, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9806/10000, Loss: 0.6637, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9807/10000, Loss: 0.6637, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9808/10000, Loss: 0.6637, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9809/10000, Loss: 0.6636, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9810/10000, Loss: 0.6636, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9811/10000, Loss: 0.6636, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9812/10000, Loss: 0.6636, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9813/10000, Loss: 0.6636, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9814/10000, Loss: 0.6636, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9815/10000, Loss: 0.6636, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9816/10000, Loss: 0.6636, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9817/10000, Loss: 0.6635, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9818/10000, Loss: 0.6635, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9819/10000, Loss: 0.6635, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9820/10000, Loss: 0.6635, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9821/10000, Loss: 0.6635, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9822/10000, Loss: 0.6635, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9823/10000, Loss: 0.6635, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9824/10000, Loss: 0.6634, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9825/10000, Loss: 0.6634, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9826/10000, Loss: 0.6634, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9827/10000, Loss: 0.6634, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9828/10000, Loss: 0.6634, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9829/10000, Loss: 0.6634, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9830/10000, Loss: 0.6634, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9831/10000, Loss: 0.6633, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9832/10000, Loss: 0.6633, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9833/10000, Loss: 0.6633, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9834/10000, Loss: 0.6633, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9835/10000, Loss: 0.6633, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9836/10000, Loss: 0.6633, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9837/10000, Loss: 0.6633, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9838/10000, Loss: 0.6632, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9839/10000, Loss: 0.6632, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9840/10000, Loss: 0.6632, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9841/10000, Loss: 0.6632, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9842/10000, Loss: 0.6632, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9843/10000, Loss: 0.6632, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9844/10000, Loss: 0.6632, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9845/10000, Loss: 0.6631, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9846/10000, Loss: 0.6631, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9847/10000, Loss: 0.6631, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9848/10000, Loss: 0.6631, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9849/10000, Loss: 0.6631, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9850/10000, Loss: 0.6631, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9851/10000, Loss: 0.6631, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9852/10000, Loss: 0.6630, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9853/10000, Loss: 0.6630, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9854/10000, Loss: 0.6630, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9855/10000, Loss: 0.6630, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9856/10000, Loss: 0.6630, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9857/10000, Loss: 0.6630, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9858/10000, Loss: 0.6630, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9859/10000, Loss: 0.6629, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9860/10000, Loss: 0.6629, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9861/10000, Loss: 0.6629, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9862/10000, Loss: 0.6629, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9863/10000, Loss: 0.6629, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9864/10000, Loss: 0.6629, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9865/10000, Loss: 0.6629, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9866/10000, Loss: 0.6629, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9867/10000, Loss: 0.6628, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9868/10000, Loss: 0.6628, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9869/10000, Loss: 0.6628, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9870/10000, Loss: 0.6628, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9871/10000, Loss: 0.6628, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9872/10000, Loss: 0.6628, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9873/10000, Loss: 0.6628, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9874/10000, Loss: 0.6627, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9875/10000, Loss: 0.6627, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9876/10000, Loss: 0.6627, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9877/10000, Loss: 0.6627, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9878/10000, Loss: 0.6627, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9879/10000, Loss: 0.6627, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9880/10000, Loss: 0.6627, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9881/10000, Loss: 0.6626, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9882/10000, Loss: 0.6626, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9883/10000, Loss: 0.6626, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9884/10000, Loss: 0.6626, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9885/10000, Loss: 0.6626, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9886/10000, Loss: 0.6626, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9887/10000, Loss: 0.6626, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9888/10000, Loss: 0.6625, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9889/10000, Loss: 0.6625, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9890/10000, Loss: 0.6625, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9891/10000, Loss: 0.6625, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9892/10000, Loss: 0.6625, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9893/10000, Loss: 0.6625, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9894/10000, Loss: 0.6625, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9895/10000, Loss: 0.6624, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9896/10000, Loss: 0.6624, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9897/10000, Loss: 0.6624, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9898/10000, Loss: 0.6624, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9899/10000, Loss: 0.6624, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9900/10000, Loss: 0.6624, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9901/10000, Loss: 0.6624, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9902/10000, Loss: 0.6624, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9903/10000, Loss: 0.6623, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9904/10000, Loss: 0.6623, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9905/10000, Loss: 0.6623, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9906/10000, Loss: 0.6623, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9907/10000, Loss: 0.6623, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9908/10000, Loss: 0.6623, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9909/10000, Loss: 0.6623, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9910/10000, Loss: 0.6622, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9911/10000, Loss: 0.6622, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9912/10000, Loss: 0.6622, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9913/10000, Loss: 0.6622, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9914/10000, Loss: 0.6622, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9915/10000, Loss: 0.6622, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9916/10000, Loss: 0.6622, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9917/10000, Loss: 0.6621, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9918/10000, Loss: 0.6621, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9919/10000, Loss: 0.6621, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9920/10000, Loss: 0.6621, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9921/10000, Loss: 0.6621, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9922/10000, Loss: 0.6621, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9923/10000, Loss: 0.6621, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9924/10000, Loss: 0.6620, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9925/10000, Loss: 0.6620, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9926/10000, Loss: 0.6620, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9927/10000, Loss: 0.6620, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9928/10000, Loss: 0.6620, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9929/10000, Loss: 0.6620, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9930/10000, Loss: 0.6620, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9931/10000, Loss: 0.6620, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9932/10000, Loss: 0.6619, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9933/10000, Loss: 0.6619, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9934/10000, Loss: 0.6619, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9935/10000, Loss: 0.6619, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9936/10000, Loss: 0.6619, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9937/10000, Loss: 0.6619, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9938/10000, Loss: 0.6619, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9939/10000, Loss: 0.6618, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9940/10000, Loss: 0.6618, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9941/10000, Loss: 0.6618, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9942/10000, Loss: 0.6618, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9943/10000, Loss: 0.6618, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9944/10000, Loss: 0.6618, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9945/10000, Loss: 0.6618, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9946/10000, Loss: 0.6617, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9947/10000, Loss: 0.6617, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9948/10000, Loss: 0.6617, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9949/10000, Loss: 0.6617, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9950/10000, Loss: 0.6617, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9951/10000, Loss: 0.6617, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9952/10000, Loss: 0.6617, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9953/10000, Loss: 0.6616, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9954/10000, Loss: 0.6616, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9955/10000, Loss: 0.6616, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9956/10000, Loss: 0.6616, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9957/10000, Loss: 0.6616, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9958/10000, Loss: 0.6616, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9959/10000, Loss: 0.6616, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9960/10000, Loss: 0.6616, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9961/10000, Loss: 0.6615, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9962/10000, Loss: 0.6615, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9963/10000, Loss: 0.6615, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9964/10000, Loss: 0.6615, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9965/10000, Loss: 0.6615, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9966/10000, Loss: 0.6615, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9967/10000, Loss: 0.6615, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9968/10000, Loss: 0.6614, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9969/10000, Loss: 0.6614, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9970/10000, Loss: 0.6614, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9971/10000, Loss: 0.6614, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9972/10000, Loss: 0.6614, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9973/10000, Loss: 0.6614, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9974/10000, Loss: 0.6614, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9975/10000, Loss: 0.6613, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9976/10000, Loss: 0.6613, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9977/10000, Loss: 0.6613, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9978/10000, Loss: 0.6613, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9979/10000, Loss: 0.6613, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9980/10000, Loss: 0.6613, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9981/10000, Loss: 0.6613, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9982/10000, Loss: 0.6613, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9983/10000, Loss: 0.6612, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9984/10000, Loss: 0.6612, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9985/10000, Loss: 0.6612, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9986/10000, Loss: 0.6612, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9987/10000, Loss: 0.6612, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9988/10000, Loss: 0.6612, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9989/10000, Loss: 0.6612, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9990/10000, Loss: 0.6611, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9991/10000, Loss: 0.6611, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9992/10000, Loss: 0.6611, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9993/10000, Loss: 0.6611, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9994/10000, Loss: 0.6611, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9995/10000, Loss: 0.6611, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9996/10000, Loss: 0.6611, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9997/10000, Loss: 0.6610, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9998/10000, Loss: 0.6610, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9999/10000, Loss: 0.6610, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 10000/10000, Loss: 0.6610, Accuracy: 0.6890, Learning Rate: 0.000100\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(0.0001,10000,'l2',0.05)\n",
    "\n",
    "model.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "711fdeba-c8d6-42d4-bcc2-abbe17e471c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "425f2df8-de76-47fc-ad58-3d0e30f57e1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000, Loss: 0.8053, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 2/10000, Loss: 0.7980, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3/10000, Loss: 0.7942, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 4/10000, Loss: 0.7916, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5/10000, Loss: 0.7896, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6/10000, Loss: 0.7881, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7/10000, Loss: 0.7870, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 8/10000, Loss: 0.7861, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9/10000, Loss: 0.7854, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 10/10000, Loss: 0.7848, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 11/10000, Loss: 0.7843, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 12/10000, Loss: 0.7839, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 13/10000, Loss: 0.7835, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 14/10000, Loss: 0.7832, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 15/10000, Loss: 0.7829, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 16/10000, Loss: 0.7826, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 17/10000, Loss: 0.7824, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 18/10000, Loss: 0.7821, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 19/10000, Loss: 0.7819, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 20/10000, Loss: 0.7816, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 21/10000, Loss: 0.7814, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 22/10000, Loss: 0.7812, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 23/10000, Loss: 0.7809, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 24/10000, Loss: 0.7807, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 25/10000, Loss: 0.7805, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 26/10000, Loss: 0.7803, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 27/10000, Loss: 0.7801, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 28/10000, Loss: 0.7799, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 29/10000, Loss: 0.7796, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 30/10000, Loss: 0.7794, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 31/10000, Loss: 0.7792, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 32/10000, Loss: 0.7790, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 33/10000, Loss: 0.7788, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 34/10000, Loss: 0.7786, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 35/10000, Loss: 0.7784, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 36/10000, Loss: 0.7782, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 37/10000, Loss: 0.7780, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 38/10000, Loss: 0.7778, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 39/10000, Loss: 0.7776, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 40/10000, Loss: 0.7774, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 41/10000, Loss: 0.7772, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 42/10000, Loss: 0.7770, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 43/10000, Loss: 0.7768, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 44/10000, Loss: 0.7766, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 45/10000, Loss: 0.7764, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 46/10000, Loss: 0.7762, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 47/10000, Loss: 0.7760, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 48/10000, Loss: 0.7759, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 49/10000, Loss: 0.7757, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 50/10000, Loss: 0.7755, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 51/10000, Loss: 0.7753, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 52/10000, Loss: 0.7751, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 53/10000, Loss: 0.7749, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 54/10000, Loss: 0.7747, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 55/10000, Loss: 0.7745, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 56/10000, Loss: 0.7744, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 57/10000, Loss: 0.7742, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 58/10000, Loss: 0.7740, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 59/10000, Loss: 0.7738, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 60/10000, Loss: 0.7736, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 61/10000, Loss: 0.7735, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 62/10000, Loss: 0.7733, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 63/10000, Loss: 0.7731, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 64/10000, Loss: 0.7729, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 65/10000, Loss: 0.7728, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 66/10000, Loss: 0.7726, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 67/10000, Loss: 0.7724, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 68/10000, Loss: 0.7722, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 69/10000, Loss: 0.7721, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 70/10000, Loss: 0.7719, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 71/10000, Loss: 0.7717, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 72/10000, Loss: 0.7716, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 73/10000, Loss: 0.7714, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 74/10000, Loss: 0.7712, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 75/10000, Loss: 0.7711, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 76/10000, Loss: 0.7709, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 77/10000, Loss: 0.7707, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 78/10000, Loss: 0.7706, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 79/10000, Loss: 0.7704, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 80/10000, Loss: 0.7702, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 81/10000, Loss: 0.7701, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 82/10000, Loss: 0.7699, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 83/10000, Loss: 0.7697, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 84/10000, Loss: 0.7696, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 85/10000, Loss: 0.7694, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 86/10000, Loss: 0.7693, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 87/10000, Loss: 0.7691, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 88/10000, Loss: 0.7690, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 89/10000, Loss: 0.7688, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 90/10000, Loss: 0.7686, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 91/10000, Loss: 0.7685, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 92/10000, Loss: 0.7683, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 93/10000, Loss: 0.7682, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 94/10000, Loss: 0.7680, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 95/10000, Loss: 0.7679, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 96/10000, Loss: 0.7677, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 97/10000, Loss: 0.7676, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 98/10000, Loss: 0.7674, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 99/10000, Loss: 0.7673, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 100/10000, Loss: 0.7671, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 101/10000, Loss: 0.7670, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 102/10000, Loss: 0.7668, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 103/10000, Loss: 0.7667, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 104/10000, Loss: 0.7665, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 105/10000, Loss: 0.7664, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 106/10000, Loss: 0.7662, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 107/10000, Loss: 0.7661, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 108/10000, Loss: 0.7659, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 109/10000, Loss: 0.7658, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 110/10000, Loss: 0.7656, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 111/10000, Loss: 0.7655, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 112/10000, Loss: 0.7653, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 113/10000, Loss: 0.7652, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 114/10000, Loss: 0.7651, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 115/10000, Loss: 0.7649, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 116/10000, Loss: 0.7648, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 117/10000, Loss: 0.7646, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 118/10000, Loss: 0.7645, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 119/10000, Loss: 0.7643, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 120/10000, Loss: 0.7642, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 121/10000, Loss: 0.7641, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 122/10000, Loss: 0.7639, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 123/10000, Loss: 0.7638, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 124/10000, Loss: 0.7636, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 125/10000, Loss: 0.7635, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 126/10000, Loss: 0.7634, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 127/10000, Loss: 0.7632, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 128/10000, Loss: 0.7631, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 129/10000, Loss: 0.7630, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 130/10000, Loss: 0.7628, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 131/10000, Loss: 0.7627, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 132/10000, Loss: 0.7626, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 133/10000, Loss: 0.7624, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 134/10000, Loss: 0.7623, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 135/10000, Loss: 0.7622, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 136/10000, Loss: 0.7620, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 137/10000, Loss: 0.7619, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 138/10000, Loss: 0.7618, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 139/10000, Loss: 0.7616, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 140/10000, Loss: 0.7615, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 141/10000, Loss: 0.7614, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 142/10000, Loss: 0.7612, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 143/10000, Loss: 0.7611, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 144/10000, Loss: 0.7610, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 145/10000, Loss: 0.7608, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 146/10000, Loss: 0.7607, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 147/10000, Loss: 0.7606, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 148/10000, Loss: 0.7605, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 149/10000, Loss: 0.7603, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 150/10000, Loss: 0.7602, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 151/10000, Loss: 0.7601, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 152/10000, Loss: 0.7599, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 153/10000, Loss: 0.7598, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 154/10000, Loss: 0.7597, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 155/10000, Loss: 0.7596, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 156/10000, Loss: 0.7594, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 157/10000, Loss: 0.7593, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 158/10000, Loss: 0.7592, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 159/10000, Loss: 0.7591, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 160/10000, Loss: 0.7589, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 161/10000, Loss: 0.7588, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 162/10000, Loss: 0.7587, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 163/10000, Loss: 0.7586, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 164/10000, Loss: 0.7584, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 165/10000, Loss: 0.7583, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 166/10000, Loss: 0.7582, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 167/10000, Loss: 0.7581, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 168/10000, Loss: 0.7580, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 169/10000, Loss: 0.7578, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 170/10000, Loss: 0.7577, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 171/10000, Loss: 0.7576, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 172/10000, Loss: 0.7575, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 173/10000, Loss: 0.7574, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 174/10000, Loss: 0.7572, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 175/10000, Loss: 0.7571, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 176/10000, Loss: 0.7570, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 177/10000, Loss: 0.7569, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 178/10000, Loss: 0.7568, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 179/10000, Loss: 0.7566, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 180/10000, Loss: 0.7565, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 181/10000, Loss: 0.7564, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 182/10000, Loss: 0.7563, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 183/10000, Loss: 0.7562, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 184/10000, Loss: 0.7561, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 185/10000, Loss: 0.7559, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 186/10000, Loss: 0.7558, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 187/10000, Loss: 0.7557, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 188/10000, Loss: 0.7556, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 189/10000, Loss: 0.7555, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 190/10000, Loss: 0.7554, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 191/10000, Loss: 0.7552, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 192/10000, Loss: 0.7551, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 193/10000, Loss: 0.7550, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 194/10000, Loss: 0.7549, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 195/10000, Loss: 0.7548, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 196/10000, Loss: 0.7547, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 197/10000, Loss: 0.7546, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 198/10000, Loss: 0.7545, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 199/10000, Loss: 0.7543, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 200/10000, Loss: 0.7542, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 201/10000, Loss: 0.7541, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 202/10000, Loss: 0.7540, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 203/10000, Loss: 0.7539, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 204/10000, Loss: 0.7538, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 205/10000, Loss: 0.7537, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 206/10000, Loss: 0.7536, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 207/10000, Loss: 0.7535, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 208/10000, Loss: 0.7533, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 209/10000, Loss: 0.7532, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 210/10000, Loss: 0.7531, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 211/10000, Loss: 0.7530, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 212/10000, Loss: 0.7529, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 213/10000, Loss: 0.7528, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 214/10000, Loss: 0.7527, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 215/10000, Loss: 0.7526, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 216/10000, Loss: 0.7525, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 217/10000, Loss: 0.7524, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 218/10000, Loss: 0.7523, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 219/10000, Loss: 0.7521, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 220/10000, Loss: 0.7520, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 221/10000, Loss: 0.7519, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 222/10000, Loss: 0.7518, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 223/10000, Loss: 0.7517, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 224/10000, Loss: 0.7516, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 225/10000, Loss: 0.7515, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 226/10000, Loss: 0.7514, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 227/10000, Loss: 0.7513, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 228/10000, Loss: 0.7512, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 229/10000, Loss: 0.7511, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 230/10000, Loss: 0.7510, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 231/10000, Loss: 0.7509, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 232/10000, Loss: 0.7508, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 233/10000, Loss: 0.7507, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 234/10000, Loss: 0.7506, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 235/10000, Loss: 0.7505, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 236/10000, Loss: 0.7504, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 237/10000, Loss: 0.7502, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 238/10000, Loss: 0.7501, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 239/10000, Loss: 0.7500, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 240/10000, Loss: 0.7499, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 241/10000, Loss: 0.7498, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 242/10000, Loss: 0.7497, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 243/10000, Loss: 0.7496, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 244/10000, Loss: 0.7495, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 245/10000, Loss: 0.7494, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 246/10000, Loss: 0.7493, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 247/10000, Loss: 0.7492, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 248/10000, Loss: 0.7491, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 249/10000, Loss: 0.7490, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 250/10000, Loss: 0.7489, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 251/10000, Loss: 0.7488, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 252/10000, Loss: 0.7487, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 253/10000, Loss: 0.7486, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 254/10000, Loss: 0.7485, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 255/10000, Loss: 0.7484, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 256/10000, Loss: 0.7483, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 257/10000, Loss: 0.7482, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 258/10000, Loss: 0.7481, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 259/10000, Loss: 0.7480, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 260/10000, Loss: 0.7479, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 261/10000, Loss: 0.7478, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 262/10000, Loss: 0.7477, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 263/10000, Loss: 0.7476, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 264/10000, Loss: 0.7475, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 265/10000, Loss: 0.7474, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 266/10000, Loss: 0.7473, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 267/10000, Loss: 0.7472, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 268/10000, Loss: 0.7471, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 269/10000, Loss: 0.7470, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 270/10000, Loss: 0.7469, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 271/10000, Loss: 0.7468, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 272/10000, Loss: 0.7467, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 273/10000, Loss: 0.7466, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 274/10000, Loss: 0.7466, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 275/10000, Loss: 0.7465, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 276/10000, Loss: 0.7464, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 277/10000, Loss: 0.7463, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 278/10000, Loss: 0.7462, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 279/10000, Loss: 0.7461, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 280/10000, Loss: 0.7460, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 281/10000, Loss: 0.7459, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 282/10000, Loss: 0.7458, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 283/10000, Loss: 0.7457, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 284/10000, Loss: 0.7456, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 285/10000, Loss: 0.7455, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 286/10000, Loss: 0.7454, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 287/10000, Loss: 0.7453, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 288/10000, Loss: 0.7452, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 289/10000, Loss: 0.7451, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 290/10000, Loss: 0.7450, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 291/10000, Loss: 0.7449, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 292/10000, Loss: 0.7448, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 293/10000, Loss: 0.7448, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 294/10000, Loss: 0.7447, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 295/10000, Loss: 0.7446, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 296/10000, Loss: 0.7445, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 297/10000, Loss: 0.7444, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 298/10000, Loss: 0.7443, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 299/10000, Loss: 0.7442, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 300/10000, Loss: 0.7441, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 301/10000, Loss: 0.7440, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 302/10000, Loss: 0.7439, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 303/10000, Loss: 0.7438, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 304/10000, Loss: 0.7437, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 305/10000, Loss: 0.7436, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 306/10000, Loss: 0.7436, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 307/10000, Loss: 0.7435, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 308/10000, Loss: 0.7434, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 309/10000, Loss: 0.7433, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 310/10000, Loss: 0.7432, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 311/10000, Loss: 0.7431, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 312/10000, Loss: 0.7430, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 313/10000, Loss: 0.7429, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 314/10000, Loss: 0.7428, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 315/10000, Loss: 0.7427, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 316/10000, Loss: 0.7426, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 317/10000, Loss: 0.7426, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 318/10000, Loss: 0.7425, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 319/10000, Loss: 0.7424, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 320/10000, Loss: 0.7423, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 321/10000, Loss: 0.7422, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 322/10000, Loss: 0.7421, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 323/10000, Loss: 0.7420, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 324/10000, Loss: 0.7419, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 325/10000, Loss: 0.7418, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 326/10000, Loss: 0.7418, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 327/10000, Loss: 0.7417, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 328/10000, Loss: 0.7416, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 329/10000, Loss: 0.7415, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 330/10000, Loss: 0.7414, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 331/10000, Loss: 0.7413, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 332/10000, Loss: 0.7412, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 333/10000, Loss: 0.7411, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 334/10000, Loss: 0.7411, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 335/10000, Loss: 0.7410, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 336/10000, Loss: 0.7409, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 337/10000, Loss: 0.7408, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 338/10000, Loss: 0.7407, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 339/10000, Loss: 0.7406, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 340/10000, Loss: 0.7405, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 341/10000, Loss: 0.7404, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 342/10000, Loss: 0.7404, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 343/10000, Loss: 0.7403, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 344/10000, Loss: 0.7402, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 345/10000, Loss: 0.7401, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 346/10000, Loss: 0.7400, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 347/10000, Loss: 0.7399, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 348/10000, Loss: 0.7398, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 349/10000, Loss: 0.7398, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 350/10000, Loss: 0.7397, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 351/10000, Loss: 0.7396, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 352/10000, Loss: 0.7395, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 353/10000, Loss: 0.7394, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 354/10000, Loss: 0.7393, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 355/10000, Loss: 0.7393, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 356/10000, Loss: 0.7392, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 357/10000, Loss: 0.7391, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 358/10000, Loss: 0.7390, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 359/10000, Loss: 0.7389, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 360/10000, Loss: 0.7388, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 361/10000, Loss: 0.7387, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 362/10000, Loss: 0.7387, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 363/10000, Loss: 0.7386, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 364/10000, Loss: 0.7385, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 365/10000, Loss: 0.7384, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 366/10000, Loss: 0.7383, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 367/10000, Loss: 0.7382, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 368/10000, Loss: 0.7382, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 369/10000, Loss: 0.7381, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 370/10000, Loss: 0.7380, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 371/10000, Loss: 0.7379, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 372/10000, Loss: 0.7378, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 373/10000, Loss: 0.7378, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 374/10000, Loss: 0.7377, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 375/10000, Loss: 0.7376, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 376/10000, Loss: 0.7375, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 377/10000, Loss: 0.7374, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 378/10000, Loss: 0.7373, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 379/10000, Loss: 0.7373, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 380/10000, Loss: 0.7372, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 381/10000, Loss: 0.7371, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 382/10000, Loss: 0.7370, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 383/10000, Loss: 0.7369, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 384/10000, Loss: 0.7369, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 385/10000, Loss: 0.7368, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 386/10000, Loss: 0.7367, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 387/10000, Loss: 0.7366, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 388/10000, Loss: 0.7365, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 389/10000, Loss: 0.7364, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 390/10000, Loss: 0.7364, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 391/10000, Loss: 0.7363, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 392/10000, Loss: 0.7362, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 393/10000, Loss: 0.7361, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 394/10000, Loss: 0.7360, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 395/10000, Loss: 0.7360, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 396/10000, Loss: 0.7359, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 397/10000, Loss: 0.7358, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 398/10000, Loss: 0.7357, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 399/10000, Loss: 0.7357, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 400/10000, Loss: 0.7356, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 401/10000, Loss: 0.7355, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 402/10000, Loss: 0.7354, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 403/10000, Loss: 0.7353, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 404/10000, Loss: 0.7353, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 405/10000, Loss: 0.7352, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 406/10000, Loss: 0.7351, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 407/10000, Loss: 0.7350, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 408/10000, Loss: 0.7349, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 409/10000, Loss: 0.7349, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 410/10000, Loss: 0.7348, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 411/10000, Loss: 0.7347, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 412/10000, Loss: 0.7346, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 413/10000, Loss: 0.7346, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 414/10000, Loss: 0.7345, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 415/10000, Loss: 0.7344, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 416/10000, Loss: 0.7343, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 417/10000, Loss: 0.7342, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 418/10000, Loss: 0.7342, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 419/10000, Loss: 0.7341, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 420/10000, Loss: 0.7340, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 421/10000, Loss: 0.7339, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 422/10000, Loss: 0.7339, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 423/10000, Loss: 0.7338, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 424/10000, Loss: 0.7337, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 425/10000, Loss: 0.7336, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 426/10000, Loss: 0.7335, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 427/10000, Loss: 0.7335, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 428/10000, Loss: 0.7334, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 429/10000, Loss: 0.7333, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 430/10000, Loss: 0.7332, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 431/10000, Loss: 0.7332, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 432/10000, Loss: 0.7331, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 433/10000, Loss: 0.7330, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 434/10000, Loss: 0.7329, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 435/10000, Loss: 0.7329, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 436/10000, Loss: 0.7328, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 437/10000, Loss: 0.7327, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 438/10000, Loss: 0.7326, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 439/10000, Loss: 0.7326, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 440/10000, Loss: 0.7325, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 441/10000, Loss: 0.7324, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 442/10000, Loss: 0.7323, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 443/10000, Loss: 0.7323, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 444/10000, Loss: 0.7322, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 445/10000, Loss: 0.7321, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 446/10000, Loss: 0.7320, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 447/10000, Loss: 0.7320, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 448/10000, Loss: 0.7319, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 449/10000, Loss: 0.7318, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 450/10000, Loss: 0.7317, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 451/10000, Loss: 0.7317, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 452/10000, Loss: 0.7316, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 453/10000, Loss: 0.7315, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 454/10000, Loss: 0.7314, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 455/10000, Loss: 0.7314, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 456/10000, Loss: 0.7313, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 457/10000, Loss: 0.7312, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 458/10000, Loss: 0.7312, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 459/10000, Loss: 0.7311, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 460/10000, Loss: 0.7310, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 461/10000, Loss: 0.7309, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 462/10000, Loss: 0.7309, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 463/10000, Loss: 0.7308, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 464/10000, Loss: 0.7307, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 465/10000, Loss: 0.7306, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 466/10000, Loss: 0.7306, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 467/10000, Loss: 0.7305, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 468/10000, Loss: 0.7304, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 469/10000, Loss: 0.7304, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 470/10000, Loss: 0.7303, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 471/10000, Loss: 0.7302, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 472/10000, Loss: 0.7301, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 473/10000, Loss: 0.7301, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 474/10000, Loss: 0.7300, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 475/10000, Loss: 0.7299, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 476/10000, Loss: 0.7298, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 477/10000, Loss: 0.7298, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 478/10000, Loss: 0.7297, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 479/10000, Loss: 0.7296, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 480/10000, Loss: 0.7296, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 481/10000, Loss: 0.7295, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 482/10000, Loss: 0.7294, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 483/10000, Loss: 0.7293, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 484/10000, Loss: 0.7293, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 485/10000, Loss: 0.7292, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 486/10000, Loss: 0.7291, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 487/10000, Loss: 0.7291, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 488/10000, Loss: 0.7290, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 489/10000, Loss: 0.7289, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 490/10000, Loss: 0.7289, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 491/10000, Loss: 0.7288, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 492/10000, Loss: 0.7287, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 493/10000, Loss: 0.7286, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 494/10000, Loss: 0.7286, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 495/10000, Loss: 0.7285, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 496/10000, Loss: 0.7284, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 497/10000, Loss: 0.7284, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 498/10000, Loss: 0.7283, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 499/10000, Loss: 0.7282, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 500/10000, Loss: 0.7282, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 501/10000, Loss: 0.7281, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 502/10000, Loss: 0.7280, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 503/10000, Loss: 0.7279, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 504/10000, Loss: 0.7279, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 505/10000, Loss: 0.7278, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 506/10000, Loss: 0.7277, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 507/10000, Loss: 0.7277, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 508/10000, Loss: 0.7276, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 509/10000, Loss: 0.7275, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 510/10000, Loss: 0.7275, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 511/10000, Loss: 0.7274, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 512/10000, Loss: 0.7273, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 513/10000, Loss: 0.7273, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 514/10000, Loss: 0.7272, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 515/10000, Loss: 0.7271, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 516/10000, Loss: 0.7270, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 517/10000, Loss: 0.7270, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 518/10000, Loss: 0.7269, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 519/10000, Loss: 0.7268, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 520/10000, Loss: 0.7268, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 521/10000, Loss: 0.7267, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 522/10000, Loss: 0.7266, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 523/10000, Loss: 0.7266, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 524/10000, Loss: 0.7265, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 525/10000, Loss: 0.7264, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 526/10000, Loss: 0.7264, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 527/10000, Loss: 0.7263, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 528/10000, Loss: 0.7262, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 529/10000, Loss: 0.7262, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 530/10000, Loss: 0.7261, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 531/10000, Loss: 0.7260, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 532/10000, Loss: 0.7260, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 533/10000, Loss: 0.7259, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 534/10000, Loss: 0.7258, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 535/10000, Loss: 0.7258, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 536/10000, Loss: 0.7257, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 537/10000, Loss: 0.7256, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 538/10000, Loss: 0.7256, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 539/10000, Loss: 0.7255, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 540/10000, Loss: 0.7254, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 541/10000, Loss: 0.7254, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 542/10000, Loss: 0.7253, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 543/10000, Loss: 0.7252, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 544/10000, Loss: 0.7252, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 545/10000, Loss: 0.7251, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 546/10000, Loss: 0.7250, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 547/10000, Loss: 0.7250, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 548/10000, Loss: 0.7249, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 549/10000, Loss: 0.7248, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 550/10000, Loss: 0.7248, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 551/10000, Loss: 0.7247, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 552/10000, Loss: 0.7246, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 553/10000, Loss: 0.7246, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 554/10000, Loss: 0.7245, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 555/10000, Loss: 0.7244, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 556/10000, Loss: 0.7244, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 557/10000, Loss: 0.7243, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 558/10000, Loss: 0.7242, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 559/10000, Loss: 0.7242, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 560/10000, Loss: 0.7241, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 561/10000, Loss: 0.7241, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 562/10000, Loss: 0.7240, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 563/10000, Loss: 0.7239, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 564/10000, Loss: 0.7239, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 565/10000, Loss: 0.7238, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 566/10000, Loss: 0.7237, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 567/10000, Loss: 0.7237, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 568/10000, Loss: 0.7236, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 569/10000, Loss: 0.7235, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 570/10000, Loss: 0.7235, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 571/10000, Loss: 0.7234, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 572/10000, Loss: 0.7233, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 573/10000, Loss: 0.7233, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 574/10000, Loss: 0.7232, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 575/10000, Loss: 0.7231, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 576/10000, Loss: 0.7231, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 577/10000, Loss: 0.7230, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 578/10000, Loss: 0.7230, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 579/10000, Loss: 0.7229, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 580/10000, Loss: 0.7228, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 581/10000, Loss: 0.7228, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 582/10000, Loss: 0.7227, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 583/10000, Loss: 0.7226, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 584/10000, Loss: 0.7226, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 585/10000, Loss: 0.7225, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 586/10000, Loss: 0.7224, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 587/10000, Loss: 0.7224, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 588/10000, Loss: 0.7223, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 589/10000, Loss: 0.7223, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 590/10000, Loss: 0.7222, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 591/10000, Loss: 0.7221, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 592/10000, Loss: 0.7221, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 593/10000, Loss: 0.7220, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 594/10000, Loss: 0.7219, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 595/10000, Loss: 0.7219, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 596/10000, Loss: 0.7218, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 597/10000, Loss: 0.7218, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 598/10000, Loss: 0.7217, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 599/10000, Loss: 0.7216, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 600/10000, Loss: 0.7216, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 601/10000, Loss: 0.7215, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 602/10000, Loss: 0.7214, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 603/10000, Loss: 0.7214, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 604/10000, Loss: 0.7213, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 605/10000, Loss: 0.7213, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 606/10000, Loss: 0.7212, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 607/10000, Loss: 0.7211, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 608/10000, Loss: 0.7211, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 609/10000, Loss: 0.7210, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 610/10000, Loss: 0.7210, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 611/10000, Loss: 0.7209, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 612/10000, Loss: 0.7208, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 613/10000, Loss: 0.7208, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 614/10000, Loss: 0.7207, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 615/10000, Loss: 0.7206, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 616/10000, Loss: 0.7206, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 617/10000, Loss: 0.7205, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 618/10000, Loss: 0.7205, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 619/10000, Loss: 0.7204, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 620/10000, Loss: 0.7203, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 621/10000, Loss: 0.7203, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 622/10000, Loss: 0.7202, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 623/10000, Loss: 0.7202, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 624/10000, Loss: 0.7201, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 625/10000, Loss: 0.7200, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 626/10000, Loss: 0.7200, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 627/10000, Loss: 0.7199, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 628/10000, Loss: 0.7199, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 629/10000, Loss: 0.7198, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 630/10000, Loss: 0.7197, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 631/10000, Loss: 0.7197, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 632/10000, Loss: 0.7196, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 633/10000, Loss: 0.7196, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 634/10000, Loss: 0.7195, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 635/10000, Loss: 0.7194, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 636/10000, Loss: 0.7194, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 637/10000, Loss: 0.7193, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 638/10000, Loss: 0.7193, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 639/10000, Loss: 0.7192, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 640/10000, Loss: 0.7191, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 641/10000, Loss: 0.7191, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 642/10000, Loss: 0.7190, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 643/10000, Loss: 0.7190, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 644/10000, Loss: 0.7189, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 645/10000, Loss: 0.7188, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 646/10000, Loss: 0.7188, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 647/10000, Loss: 0.7187, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 648/10000, Loss: 0.7187, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 649/10000, Loss: 0.7186, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 650/10000, Loss: 0.7185, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 651/10000, Loss: 0.7185, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 652/10000, Loss: 0.7184, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 653/10000, Loss: 0.7184, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 654/10000, Loss: 0.7183, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 655/10000, Loss: 0.7182, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 656/10000, Loss: 0.7182, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 657/10000, Loss: 0.7181, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 658/10000, Loss: 0.7181, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 659/10000, Loss: 0.7180, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 660/10000, Loss: 0.7180, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 661/10000, Loss: 0.7179, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 662/10000, Loss: 0.7178, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 663/10000, Loss: 0.7178, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 664/10000, Loss: 0.7177, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 665/10000, Loss: 0.7177, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 666/10000, Loss: 0.7176, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 667/10000, Loss: 0.7175, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 668/10000, Loss: 0.7175, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 669/10000, Loss: 0.7174, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 670/10000, Loss: 0.7174, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 671/10000, Loss: 0.7173, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 672/10000, Loss: 0.7173, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 673/10000, Loss: 0.7172, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 674/10000, Loss: 0.7171, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 675/10000, Loss: 0.7171, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 676/10000, Loss: 0.7170, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 677/10000, Loss: 0.7170, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 678/10000, Loss: 0.7169, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 679/10000, Loss: 0.7169, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 680/10000, Loss: 0.7168, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 681/10000, Loss: 0.7167, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 682/10000, Loss: 0.7167, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 683/10000, Loss: 0.7166, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 684/10000, Loss: 0.7166, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 685/10000, Loss: 0.7165, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 686/10000, Loss: 0.7165, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 687/10000, Loss: 0.7164, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 688/10000, Loss: 0.7163, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 689/10000, Loss: 0.7163, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 690/10000, Loss: 0.7162, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 691/10000, Loss: 0.7162, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 692/10000, Loss: 0.7161, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 693/10000, Loss: 0.7161, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 694/10000, Loss: 0.7160, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 695/10000, Loss: 0.7159, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 696/10000, Loss: 0.7159, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 697/10000, Loss: 0.7158, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 698/10000, Loss: 0.7158, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 699/10000, Loss: 0.7157, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 700/10000, Loss: 0.7157, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 701/10000, Loss: 0.7156, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 702/10000, Loss: 0.7155, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 703/10000, Loss: 0.7155, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 704/10000, Loss: 0.7154, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 705/10000, Loss: 0.7154, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 706/10000, Loss: 0.7153, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 707/10000, Loss: 0.7153, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 708/10000, Loss: 0.7152, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 709/10000, Loss: 0.7152, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 710/10000, Loss: 0.7151, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 711/10000, Loss: 0.7150, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 712/10000, Loss: 0.7150, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 713/10000, Loss: 0.7149, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 714/10000, Loss: 0.7149, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 715/10000, Loss: 0.7148, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 716/10000, Loss: 0.7148, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 717/10000, Loss: 0.7147, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 718/10000, Loss: 0.7147, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 719/10000, Loss: 0.7146, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 720/10000, Loss: 0.7145, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 721/10000, Loss: 0.7145, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 722/10000, Loss: 0.7144, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 723/10000, Loss: 0.7144, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 724/10000, Loss: 0.7143, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 725/10000, Loss: 0.7143, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 726/10000, Loss: 0.7142, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 727/10000, Loss: 0.7142, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 728/10000, Loss: 0.7141, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 729/10000, Loss: 0.7141, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 730/10000, Loss: 0.7140, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 731/10000, Loss: 0.7139, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 732/10000, Loss: 0.7139, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 733/10000, Loss: 0.7138, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 734/10000, Loss: 0.7138, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 735/10000, Loss: 0.7137, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 736/10000, Loss: 0.7137, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 737/10000, Loss: 0.7136, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 738/10000, Loss: 0.7136, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 739/10000, Loss: 0.7135, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 740/10000, Loss: 0.7135, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 741/10000, Loss: 0.7134, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 742/10000, Loss: 0.7133, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 743/10000, Loss: 0.7133, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 744/10000, Loss: 0.7132, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 745/10000, Loss: 0.7132, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 746/10000, Loss: 0.7131, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 747/10000, Loss: 0.7131, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 748/10000, Loss: 0.7130, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 749/10000, Loss: 0.7130, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 750/10000, Loss: 0.7129, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 751/10000, Loss: 0.7129, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 752/10000, Loss: 0.7128, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 753/10000, Loss: 0.7128, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 754/10000, Loss: 0.7127, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 755/10000, Loss: 0.7126, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 756/10000, Loss: 0.7126, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 757/10000, Loss: 0.7125, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 758/10000, Loss: 0.7125, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 759/10000, Loss: 0.7124, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 760/10000, Loss: 0.7124, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 761/10000, Loss: 0.7123, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 762/10000, Loss: 0.7123, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 763/10000, Loss: 0.7122, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 764/10000, Loss: 0.7122, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 765/10000, Loss: 0.7121, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 766/10000, Loss: 0.7121, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 767/10000, Loss: 0.7120, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 768/10000, Loss: 0.7120, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 769/10000, Loss: 0.7119, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 770/10000, Loss: 0.7118, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 771/10000, Loss: 0.7118, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 772/10000, Loss: 0.7117, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 773/10000, Loss: 0.7117, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 774/10000, Loss: 0.7116, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 775/10000, Loss: 0.7116, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 776/10000, Loss: 0.7115, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 777/10000, Loss: 0.7115, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 778/10000, Loss: 0.7114, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 779/10000, Loss: 0.7114, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 780/10000, Loss: 0.7113, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 781/10000, Loss: 0.7113, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 782/10000, Loss: 0.7112, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 783/10000, Loss: 0.7112, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 784/10000, Loss: 0.7111, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 785/10000, Loss: 0.7111, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 786/10000, Loss: 0.7110, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 787/10000, Loss: 0.7110, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 788/10000, Loss: 0.7109, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 789/10000, Loss: 0.7109, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 790/10000, Loss: 0.7108, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 791/10000, Loss: 0.7108, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 792/10000, Loss: 0.7107, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 793/10000, Loss: 0.7106, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 794/10000, Loss: 0.7106, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 795/10000, Loss: 0.7105, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 796/10000, Loss: 0.7105, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 797/10000, Loss: 0.7104, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 798/10000, Loss: 0.7104, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 799/10000, Loss: 0.7103, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 800/10000, Loss: 0.7103, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 801/10000, Loss: 0.7102, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 802/10000, Loss: 0.7102, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 803/10000, Loss: 0.7101, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 804/10000, Loss: 0.7101, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 805/10000, Loss: 0.7100, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 806/10000, Loss: 0.7100, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 807/10000, Loss: 0.7099, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 808/10000, Loss: 0.7099, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 809/10000, Loss: 0.7098, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 810/10000, Loss: 0.7098, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 811/10000, Loss: 0.7097, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 812/10000, Loss: 0.7097, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 813/10000, Loss: 0.7096, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 814/10000, Loss: 0.7096, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 815/10000, Loss: 0.7095, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 816/10000, Loss: 0.7095, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 817/10000, Loss: 0.7094, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 818/10000, Loss: 0.7094, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 819/10000, Loss: 0.7093, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 820/10000, Loss: 0.7093, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 821/10000, Loss: 0.7092, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 822/10000, Loss: 0.7092, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 823/10000, Loss: 0.7091, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 824/10000, Loss: 0.7091, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 825/10000, Loss: 0.7090, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 826/10000, Loss: 0.7090, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 827/10000, Loss: 0.7089, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 828/10000, Loss: 0.7089, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 829/10000, Loss: 0.7088, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 830/10000, Loss: 0.7088, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 831/10000, Loss: 0.7087, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 832/10000, Loss: 0.7087, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 833/10000, Loss: 0.7086, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 834/10000, Loss: 0.7086, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 835/10000, Loss: 0.7085, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 836/10000, Loss: 0.7085, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 837/10000, Loss: 0.7084, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 838/10000, Loss: 0.7084, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 839/10000, Loss: 0.7083, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 840/10000, Loss: 0.7083, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 841/10000, Loss: 0.7082, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 842/10000, Loss: 0.7082, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 843/10000, Loss: 0.7081, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 844/10000, Loss: 0.7081, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 845/10000, Loss: 0.7080, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 846/10000, Loss: 0.7080, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 847/10000, Loss: 0.7079, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 848/10000, Loss: 0.7079, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 849/10000, Loss: 0.7078, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 850/10000, Loss: 0.7078, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 851/10000, Loss: 0.7077, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 852/10000, Loss: 0.7077, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 853/10000, Loss: 0.7076, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 854/10000, Loss: 0.7076, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 855/10000, Loss: 0.7075, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 856/10000, Loss: 0.7075, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 857/10000, Loss: 0.7074, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 858/10000, Loss: 0.7074, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 859/10000, Loss: 0.7073, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 860/10000, Loss: 0.7073, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 861/10000, Loss: 0.7072, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 862/10000, Loss: 0.7072, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 863/10000, Loss: 0.7071, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 864/10000, Loss: 0.7071, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 865/10000, Loss: 0.7070, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 866/10000, Loss: 0.7070, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 867/10000, Loss: 0.7069, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 868/10000, Loss: 0.7069, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 869/10000, Loss: 0.7068, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 870/10000, Loss: 0.7068, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 871/10000, Loss: 0.7067, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 872/10000, Loss: 0.7067, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 873/10000, Loss: 0.7067, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 874/10000, Loss: 0.7066, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 875/10000, Loss: 0.7066, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 876/10000, Loss: 0.7065, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 877/10000, Loss: 0.7065, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 878/10000, Loss: 0.7064, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 879/10000, Loss: 0.7064, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 880/10000, Loss: 0.7063, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 881/10000, Loss: 0.7063, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 882/10000, Loss: 0.7062, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 883/10000, Loss: 0.7062, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 884/10000, Loss: 0.7061, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 885/10000, Loss: 0.7061, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 886/10000, Loss: 0.7060, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 887/10000, Loss: 0.7060, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 888/10000, Loss: 0.7059, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 889/10000, Loss: 0.7059, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 890/10000, Loss: 0.7058, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 891/10000, Loss: 0.7058, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 892/10000, Loss: 0.7057, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 893/10000, Loss: 0.7057, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 894/10000, Loss: 0.7056, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 895/10000, Loss: 0.7056, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 896/10000, Loss: 0.7055, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 897/10000, Loss: 0.7055, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 898/10000, Loss: 0.7055, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 899/10000, Loss: 0.7054, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 900/10000, Loss: 0.7054, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 901/10000, Loss: 0.7053, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 902/10000, Loss: 0.7053, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 903/10000, Loss: 0.7052, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 904/10000, Loss: 0.7052, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 905/10000, Loss: 0.7051, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 906/10000, Loss: 0.7051, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 907/10000, Loss: 0.7050, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 908/10000, Loss: 0.7050, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 909/10000, Loss: 0.7049, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 910/10000, Loss: 0.7049, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 911/10000, Loss: 0.7048, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 912/10000, Loss: 0.7048, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 913/10000, Loss: 0.7047, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 914/10000, Loss: 0.7047, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 915/10000, Loss: 0.7047, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 916/10000, Loss: 0.7046, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 917/10000, Loss: 0.7046, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 918/10000, Loss: 0.7045, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 919/10000, Loss: 0.7045, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 920/10000, Loss: 0.7044, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 921/10000, Loss: 0.7044, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 922/10000, Loss: 0.7043, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 923/10000, Loss: 0.7043, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 924/10000, Loss: 0.7042, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 925/10000, Loss: 0.7042, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 926/10000, Loss: 0.7041, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 927/10000, Loss: 0.7041, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 928/10000, Loss: 0.7040, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 929/10000, Loss: 0.7040, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 930/10000, Loss: 0.7040, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 931/10000, Loss: 0.7039, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 932/10000, Loss: 0.7039, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 933/10000, Loss: 0.7038, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 934/10000, Loss: 0.7038, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 935/10000, Loss: 0.7037, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 936/10000, Loss: 0.7037, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 937/10000, Loss: 0.7036, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 938/10000, Loss: 0.7036, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 939/10000, Loss: 0.7035, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 940/10000, Loss: 0.7035, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 941/10000, Loss: 0.7034, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 942/10000, Loss: 0.7034, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 943/10000, Loss: 0.7034, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 944/10000, Loss: 0.7033, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 945/10000, Loss: 0.7033, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 946/10000, Loss: 0.7032, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 947/10000, Loss: 0.7032, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 948/10000, Loss: 0.7031, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 949/10000, Loss: 0.7031, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 950/10000, Loss: 0.7030, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 951/10000, Loss: 0.7030, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 952/10000, Loss: 0.7029, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 953/10000, Loss: 0.7029, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 954/10000, Loss: 0.7029, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 955/10000, Loss: 0.7028, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 956/10000, Loss: 0.7028, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 957/10000, Loss: 0.7027, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 958/10000, Loss: 0.7027, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 959/10000, Loss: 0.7026, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 960/10000, Loss: 0.7026, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 961/10000, Loss: 0.7025, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 962/10000, Loss: 0.7025, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 963/10000, Loss: 0.7024, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 964/10000, Loss: 0.7024, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 965/10000, Loss: 0.7024, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 966/10000, Loss: 0.7023, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 967/10000, Loss: 0.7023, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 968/10000, Loss: 0.7022, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 969/10000, Loss: 0.7022, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 970/10000, Loss: 0.7021, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 971/10000, Loss: 0.7021, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 972/10000, Loss: 0.7020, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 973/10000, Loss: 0.7020, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 974/10000, Loss: 0.7020, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 975/10000, Loss: 0.7019, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 976/10000, Loss: 0.7019, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 977/10000, Loss: 0.7018, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 978/10000, Loss: 0.7018, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 979/10000, Loss: 0.7017, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 980/10000, Loss: 0.7017, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 981/10000, Loss: 0.7016, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 982/10000, Loss: 0.7016, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 983/10000, Loss: 0.7016, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 984/10000, Loss: 0.7015, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 985/10000, Loss: 0.7015, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 986/10000, Loss: 0.7014, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 987/10000, Loss: 0.7014, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 988/10000, Loss: 0.7013, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 989/10000, Loss: 0.7013, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 990/10000, Loss: 0.7012, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 991/10000, Loss: 0.7012, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 992/10000, Loss: 0.7012, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 993/10000, Loss: 0.7011, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 994/10000, Loss: 0.7011, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 995/10000, Loss: 0.7010, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 996/10000, Loss: 0.7010, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 997/10000, Loss: 0.7009, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 998/10000, Loss: 0.7009, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 999/10000, Loss: 0.7008, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1000/10000, Loss: 0.7008, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1001/10000, Loss: 0.7008, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1002/10000, Loss: 0.7007, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1003/10000, Loss: 0.7007, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1004/10000, Loss: 0.7006, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1005/10000, Loss: 0.7006, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1006/10000, Loss: 0.7005, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1007/10000, Loss: 0.7005, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1008/10000, Loss: 0.7005, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1009/10000, Loss: 0.7004, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1010/10000, Loss: 0.7004, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1011/10000, Loss: 0.7003, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1012/10000, Loss: 0.7003, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1013/10000, Loss: 0.7002, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1014/10000, Loss: 0.7002, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1015/10000, Loss: 0.7001, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1016/10000, Loss: 0.7001, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1017/10000, Loss: 0.7001, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1018/10000, Loss: 0.7000, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1019/10000, Loss: 0.7000, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1020/10000, Loss: 0.6999, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1021/10000, Loss: 0.6999, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1022/10000, Loss: 0.6998, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1023/10000, Loss: 0.6998, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1024/10000, Loss: 0.6998, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1025/10000, Loss: 0.6997, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1026/10000, Loss: 0.6997, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1027/10000, Loss: 0.6996, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1028/10000, Loss: 0.6996, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1029/10000, Loss: 0.6995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1030/10000, Loss: 0.6995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1031/10000, Loss: 0.6995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1032/10000, Loss: 0.6994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1033/10000, Loss: 0.6994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1034/10000, Loss: 0.6993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1035/10000, Loss: 0.6993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1036/10000, Loss: 0.6992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1037/10000, Loss: 0.6992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1038/10000, Loss: 0.6992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1039/10000, Loss: 0.6991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1040/10000, Loss: 0.6991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1041/10000, Loss: 0.6990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1042/10000, Loss: 0.6990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1043/10000, Loss: 0.6989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1044/10000, Loss: 0.6989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1045/10000, Loss: 0.6989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1046/10000, Loss: 0.6988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1047/10000, Loss: 0.6988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1048/10000, Loss: 0.6987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1049/10000, Loss: 0.6987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1050/10000, Loss: 0.6986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1051/10000, Loss: 0.6986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1052/10000, Loss: 0.6986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1053/10000, Loss: 0.6985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1054/10000, Loss: 0.6985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1055/10000, Loss: 0.6984, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1056/10000, Loss: 0.6984, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1057/10000, Loss: 0.6983, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1058/10000, Loss: 0.6983, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1059/10000, Loss: 0.6983, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1060/10000, Loss: 0.6982, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1061/10000, Loss: 0.6982, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1062/10000, Loss: 0.6981, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1063/10000, Loss: 0.6981, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1064/10000, Loss: 0.6981, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1065/10000, Loss: 0.6980, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1066/10000, Loss: 0.6980, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1067/10000, Loss: 0.6979, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1068/10000, Loss: 0.6979, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1069/10000, Loss: 0.6978, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1070/10000, Loss: 0.6978, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1071/10000, Loss: 0.6978, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1072/10000, Loss: 0.6977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1073/10000, Loss: 0.6977, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1074/10000, Loss: 0.6976, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1075/10000, Loss: 0.6976, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1076/10000, Loss: 0.6976, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1077/10000, Loss: 0.6975, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1078/10000, Loss: 0.6975, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1079/10000, Loss: 0.6974, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1080/10000, Loss: 0.6974, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1081/10000, Loss: 0.6973, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1082/10000, Loss: 0.6973, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1083/10000, Loss: 0.6973, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1084/10000, Loss: 0.6972, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1085/10000, Loss: 0.6972, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1086/10000, Loss: 0.6971, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1087/10000, Loss: 0.6971, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1088/10000, Loss: 0.6971, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1089/10000, Loss: 0.6970, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1090/10000, Loss: 0.6970, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1091/10000, Loss: 0.6969, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1092/10000, Loss: 0.6969, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1093/10000, Loss: 0.6968, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1094/10000, Loss: 0.6968, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1095/10000, Loss: 0.6968, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1096/10000, Loss: 0.6967, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1097/10000, Loss: 0.6967, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1098/10000, Loss: 0.6966, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1099/10000, Loss: 0.6966, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1100/10000, Loss: 0.6966, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1101/10000, Loss: 0.6965, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1102/10000, Loss: 0.6965, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1103/10000, Loss: 0.6964, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1104/10000, Loss: 0.6964, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1105/10000, Loss: 0.6964, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1106/10000, Loss: 0.6963, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1107/10000, Loss: 0.6963, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1108/10000, Loss: 0.6962, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1109/10000, Loss: 0.6962, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1110/10000, Loss: 0.6962, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1111/10000, Loss: 0.6961, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1112/10000, Loss: 0.6961, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1113/10000, Loss: 0.6960, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1114/10000, Loss: 0.6960, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1115/10000, Loss: 0.6959, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1116/10000, Loss: 0.6959, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1117/10000, Loss: 0.6959, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1118/10000, Loss: 0.6958, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1119/10000, Loss: 0.6958, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1120/10000, Loss: 0.6957, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1121/10000, Loss: 0.6957, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1122/10000, Loss: 0.6957, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1123/10000, Loss: 0.6956, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1124/10000, Loss: 0.6956, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1125/10000, Loss: 0.6955, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1126/10000, Loss: 0.6955, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1127/10000, Loss: 0.6955, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1128/10000, Loss: 0.6954, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1129/10000, Loss: 0.6954, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1130/10000, Loss: 0.6953, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1131/10000, Loss: 0.6953, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1132/10000, Loss: 0.6953, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1133/10000, Loss: 0.6952, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1134/10000, Loss: 0.6952, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1135/10000, Loss: 0.6951, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1136/10000, Loss: 0.6951, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1137/10000, Loss: 0.6951, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1138/10000, Loss: 0.6950, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1139/10000, Loss: 0.6950, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1140/10000, Loss: 0.6949, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1141/10000, Loss: 0.6949, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1142/10000, Loss: 0.6949, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1143/10000, Loss: 0.6948, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1144/10000, Loss: 0.6948, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1145/10000, Loss: 0.6947, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1146/10000, Loss: 0.6947, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1147/10000, Loss: 0.6947, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1148/10000, Loss: 0.6946, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1149/10000, Loss: 0.6946, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1150/10000, Loss: 0.6945, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1151/10000, Loss: 0.6945, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1152/10000, Loss: 0.6945, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1153/10000, Loss: 0.6944, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1154/10000, Loss: 0.6944, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1155/10000, Loss: 0.6943, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1156/10000, Loss: 0.6943, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1157/10000, Loss: 0.6943, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1158/10000, Loss: 0.6942, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1159/10000, Loss: 0.6942, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1160/10000, Loss: 0.6941, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1161/10000, Loss: 0.6941, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1162/10000, Loss: 0.6941, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1163/10000, Loss: 0.6940, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1164/10000, Loss: 0.6940, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1165/10000, Loss: 0.6939, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1166/10000, Loss: 0.6939, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1167/10000, Loss: 0.6939, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1168/10000, Loss: 0.6938, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1169/10000, Loss: 0.6938, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1170/10000, Loss: 0.6938, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1171/10000, Loss: 0.6937, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1172/10000, Loss: 0.6937, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1173/10000, Loss: 0.6936, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1174/10000, Loss: 0.6936, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1175/10000, Loss: 0.6936, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1176/10000, Loss: 0.6935, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1177/10000, Loss: 0.6935, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1178/10000, Loss: 0.6934, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1179/10000, Loss: 0.6934, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1180/10000, Loss: 0.6934, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1181/10000, Loss: 0.6933, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1182/10000, Loss: 0.6933, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1183/10000, Loss: 0.6932, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1184/10000, Loss: 0.6932, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1185/10000, Loss: 0.6932, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1186/10000, Loss: 0.6931, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1187/10000, Loss: 0.6931, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1188/10000, Loss: 0.6930, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1189/10000, Loss: 0.6930, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1190/10000, Loss: 0.6930, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1191/10000, Loss: 0.6929, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1192/10000, Loss: 0.6929, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1193/10000, Loss: 0.6929, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1194/10000, Loss: 0.6928, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1195/10000, Loss: 0.6928, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1196/10000, Loss: 0.6927, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1197/10000, Loss: 0.6927, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1198/10000, Loss: 0.6927, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1199/10000, Loss: 0.6926, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1200/10000, Loss: 0.6926, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1201/10000, Loss: 0.6925, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1202/10000, Loss: 0.6925, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1203/10000, Loss: 0.6925, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1204/10000, Loss: 0.6924, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1205/10000, Loss: 0.6924, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1206/10000, Loss: 0.6924, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1207/10000, Loss: 0.6923, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1208/10000, Loss: 0.6923, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1209/10000, Loss: 0.6922, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1210/10000, Loss: 0.6922, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1211/10000, Loss: 0.6922, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1212/10000, Loss: 0.6921, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1213/10000, Loss: 0.6921, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1214/10000, Loss: 0.6920, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1215/10000, Loss: 0.6920, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1216/10000, Loss: 0.6920, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1217/10000, Loss: 0.6919, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1218/10000, Loss: 0.6919, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1219/10000, Loss: 0.6919, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1220/10000, Loss: 0.6918, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1221/10000, Loss: 0.6918, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1222/10000, Loss: 0.6917, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1223/10000, Loss: 0.6917, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1224/10000, Loss: 0.6917, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1225/10000, Loss: 0.6916, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1226/10000, Loss: 0.6916, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1227/10000, Loss: 0.6916, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1228/10000, Loss: 0.6915, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1229/10000, Loss: 0.6915, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 1230/10000, Loss: 0.6914, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1231/10000, Loss: 0.6914, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1232/10000, Loss: 0.6914, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1233/10000, Loss: 0.6913, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1234/10000, Loss: 0.6913, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1235/10000, Loss: 0.6913, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1236/10000, Loss: 0.6912, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1237/10000, Loss: 0.6912, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1238/10000, Loss: 0.6911, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1239/10000, Loss: 0.6911, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1240/10000, Loss: 0.6911, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1241/10000, Loss: 0.6910, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1242/10000, Loss: 0.6910, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1243/10000, Loss: 0.6910, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1244/10000, Loss: 0.6909, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1245/10000, Loss: 0.6909, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1246/10000, Loss: 0.6908, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1247/10000, Loss: 0.6908, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1248/10000, Loss: 0.6908, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1249/10000, Loss: 0.6907, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1250/10000, Loss: 0.6907, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1251/10000, Loss: 0.6907, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1252/10000, Loss: 0.6906, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1253/10000, Loss: 0.6906, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1254/10000, Loss: 0.6905, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1255/10000, Loss: 0.6905, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1256/10000, Loss: 0.6905, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1257/10000, Loss: 0.6904, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1258/10000, Loss: 0.6904, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1259/10000, Loss: 0.6904, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1260/10000, Loss: 0.6903, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1261/10000, Loss: 0.6903, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1262/10000, Loss: 0.6902, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1263/10000, Loss: 0.6902, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1264/10000, Loss: 0.6902, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1265/10000, Loss: 0.6901, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1266/10000, Loss: 0.6901, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1267/10000, Loss: 0.6901, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1268/10000, Loss: 0.6900, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1269/10000, Loss: 0.6900, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1270/10000, Loss: 0.6899, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1271/10000, Loss: 0.6899, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1272/10000, Loss: 0.6899, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1273/10000, Loss: 0.6898, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1274/10000, Loss: 0.6898, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1275/10000, Loss: 0.6898, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1276/10000, Loss: 0.6897, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1277/10000, Loss: 0.6897, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1278/10000, Loss: 0.6897, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1279/10000, Loss: 0.6896, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1280/10000, Loss: 0.6896, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1281/10000, Loss: 0.6895, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1282/10000, Loss: 0.6895, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1283/10000, Loss: 0.6895, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1284/10000, Loss: 0.6894, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1285/10000, Loss: 0.6894, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1286/10000, Loss: 0.6894, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1287/10000, Loss: 0.6893, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1288/10000, Loss: 0.6893, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1289/10000, Loss: 0.6892, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1290/10000, Loss: 0.6892, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1291/10000, Loss: 0.6892, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1292/10000, Loss: 0.6891, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1293/10000, Loss: 0.6891, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1294/10000, Loss: 0.6891, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1295/10000, Loss: 0.6890, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1296/10000, Loss: 0.6890, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1297/10000, Loss: 0.6890, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1298/10000, Loss: 0.6889, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1299/10000, Loss: 0.6889, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1300/10000, Loss: 0.6888, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1301/10000, Loss: 0.6888, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1302/10000, Loss: 0.6888, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1303/10000, Loss: 0.6887, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1304/10000, Loss: 0.6887, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1305/10000, Loss: 0.6887, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1306/10000, Loss: 0.6886, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1307/10000, Loss: 0.6886, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1308/10000, Loss: 0.6886, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1309/10000, Loss: 0.6885, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1310/10000, Loss: 0.6885, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1311/10000, Loss: 0.6885, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1312/10000, Loss: 0.6884, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1313/10000, Loss: 0.6884, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1314/10000, Loss: 0.6883, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1315/10000, Loss: 0.6883, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1316/10000, Loss: 0.6883, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1317/10000, Loss: 0.6882, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1318/10000, Loss: 0.6882, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1319/10000, Loss: 0.6882, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1320/10000, Loss: 0.6881, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1321/10000, Loss: 0.6881, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1322/10000, Loss: 0.6881, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1323/10000, Loss: 0.6880, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1324/10000, Loss: 0.6880, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1325/10000, Loss: 0.6879, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1326/10000, Loss: 0.6879, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1327/10000, Loss: 0.6879, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1328/10000, Loss: 0.6878, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1329/10000, Loss: 0.6878, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1330/10000, Loss: 0.6878, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1331/10000, Loss: 0.6877, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1332/10000, Loss: 0.6877, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1333/10000, Loss: 0.6877, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1334/10000, Loss: 0.6876, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1335/10000, Loss: 0.6876, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1336/10000, Loss: 0.6876, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1337/10000, Loss: 0.6875, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1338/10000, Loss: 0.6875, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1339/10000, Loss: 0.6874, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1340/10000, Loss: 0.6874, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1341/10000, Loss: 0.6874, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1342/10000, Loss: 0.6873, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1343/10000, Loss: 0.6873, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1344/10000, Loss: 0.6873, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1345/10000, Loss: 0.6872, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1346/10000, Loss: 0.6872, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1347/10000, Loss: 0.6872, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1348/10000, Loss: 0.6871, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1349/10000, Loss: 0.6871, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1350/10000, Loss: 0.6871, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1351/10000, Loss: 0.6870, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1352/10000, Loss: 0.6870, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1353/10000, Loss: 0.6870, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1354/10000, Loss: 0.6869, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1355/10000, Loss: 0.6869, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1356/10000, Loss: 0.6868, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1357/10000, Loss: 0.6868, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1358/10000, Loss: 0.6868, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1359/10000, Loss: 0.6867, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1360/10000, Loss: 0.6867, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1361/10000, Loss: 0.6867, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1362/10000, Loss: 0.6866, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1363/10000, Loss: 0.6866, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1364/10000, Loss: 0.6866, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1365/10000, Loss: 0.6865, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1366/10000, Loss: 0.6865, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1367/10000, Loss: 0.6865, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1368/10000, Loss: 0.6864, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1369/10000, Loss: 0.6864, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1370/10000, Loss: 0.6864, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1371/10000, Loss: 0.6863, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1372/10000, Loss: 0.6863, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1373/10000, Loss: 0.6863, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1374/10000, Loss: 0.6862, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1375/10000, Loss: 0.6862, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1376/10000, Loss: 0.6861, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1377/10000, Loss: 0.6861, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1378/10000, Loss: 0.6861, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1379/10000, Loss: 0.6860, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1380/10000, Loss: 0.6860, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1381/10000, Loss: 0.6860, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1382/10000, Loss: 0.6859, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1383/10000, Loss: 0.6859, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1384/10000, Loss: 0.6859, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1385/10000, Loss: 0.6858, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1386/10000, Loss: 0.6858, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1387/10000, Loss: 0.6858, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1388/10000, Loss: 0.6857, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1389/10000, Loss: 0.6857, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1390/10000, Loss: 0.6857, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1391/10000, Loss: 0.6856, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1392/10000, Loss: 0.6856, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1393/10000, Loss: 0.6856, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1394/10000, Loss: 0.6855, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1395/10000, Loss: 0.6855, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1396/10000, Loss: 0.6855, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1397/10000, Loss: 0.6854, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1398/10000, Loss: 0.6854, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1399/10000, Loss: 0.6854, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1400/10000, Loss: 0.6853, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1401/10000, Loss: 0.6853, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1402/10000, Loss: 0.6852, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1403/10000, Loss: 0.6852, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1404/10000, Loss: 0.6852, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1405/10000, Loss: 0.6851, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1406/10000, Loss: 0.6851, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1407/10000, Loss: 0.6851, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1408/10000, Loss: 0.6850, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1409/10000, Loss: 0.6850, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1410/10000, Loss: 0.6850, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1411/10000, Loss: 0.6849, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1412/10000, Loss: 0.6849, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1413/10000, Loss: 0.6849, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1414/10000, Loss: 0.6848, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1415/10000, Loss: 0.6848, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1416/10000, Loss: 0.6848, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1417/10000, Loss: 0.6847, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1418/10000, Loss: 0.6847, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1419/10000, Loss: 0.6847, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1420/10000, Loss: 0.6846, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1421/10000, Loss: 0.6846, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1422/10000, Loss: 0.6846, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1423/10000, Loss: 0.6845, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1424/10000, Loss: 0.6845, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1425/10000, Loss: 0.6845, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1426/10000, Loss: 0.6844, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1427/10000, Loss: 0.6844, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1428/10000, Loss: 0.6844, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1429/10000, Loss: 0.6843, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1430/10000, Loss: 0.6843, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1431/10000, Loss: 0.6843, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1432/10000, Loss: 0.6842, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1433/10000, Loss: 0.6842, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1434/10000, Loss: 0.6842, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1435/10000, Loss: 0.6841, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1436/10000, Loss: 0.6841, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1437/10000, Loss: 0.6841, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1438/10000, Loss: 0.6840, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1439/10000, Loss: 0.6840, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1440/10000, Loss: 0.6840, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1441/10000, Loss: 0.6839, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1442/10000, Loss: 0.6839, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1443/10000, Loss: 0.6839, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1444/10000, Loss: 0.6838, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1445/10000, Loss: 0.6838, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1446/10000, Loss: 0.6838, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1447/10000, Loss: 0.6837, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1448/10000, Loss: 0.6837, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1449/10000, Loss: 0.6837, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1450/10000, Loss: 0.6836, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1451/10000, Loss: 0.6836, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1452/10000, Loss: 0.6836, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1453/10000, Loss: 0.6835, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1454/10000, Loss: 0.6835, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1455/10000, Loss: 0.6835, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1456/10000, Loss: 0.6834, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1457/10000, Loss: 0.6834, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1458/10000, Loss: 0.6834, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1459/10000, Loss: 0.6833, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1460/10000, Loss: 0.6833, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1461/10000, Loss: 0.6833, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1462/10000, Loss: 0.6832, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1463/10000, Loss: 0.6832, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1464/10000, Loss: 0.6832, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1465/10000, Loss: 0.6831, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1466/10000, Loss: 0.6831, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1467/10000, Loss: 0.6831, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1468/10000, Loss: 0.6830, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1469/10000, Loss: 0.6830, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1470/10000, Loss: 0.6830, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1471/10000, Loss: 0.6829, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1472/10000, Loss: 0.6829, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1473/10000, Loss: 0.6829, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1474/10000, Loss: 0.6828, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1475/10000, Loss: 0.6828, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1476/10000, Loss: 0.6828, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1477/10000, Loss: 0.6827, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1478/10000, Loss: 0.6827, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1479/10000, Loss: 0.6827, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1480/10000, Loss: 0.6826, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1481/10000, Loss: 0.6826, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1482/10000, Loss: 0.6826, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1483/10000, Loss: 0.6825, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1484/10000, Loss: 0.6825, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1485/10000, Loss: 0.6825, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1486/10000, Loss: 0.6824, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1487/10000, Loss: 0.6824, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1488/10000, Loss: 0.6824, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1489/10000, Loss: 0.6823, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1490/10000, Loss: 0.6823, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1491/10000, Loss: 0.6823, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1492/10000, Loss: 0.6822, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1493/10000, Loss: 0.6822, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1494/10000, Loss: 0.6822, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1495/10000, Loss: 0.6821, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1496/10000, Loss: 0.6821, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1497/10000, Loss: 0.6821, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1498/10000, Loss: 0.6820, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1499/10000, Loss: 0.6820, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1500/10000, Loss: 0.6820, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1501/10000, Loss: 0.6819, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1502/10000, Loss: 0.6819, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1503/10000, Loss: 0.6819, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1504/10000, Loss: 0.6818, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1505/10000, Loss: 0.6818, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1506/10000, Loss: 0.6818, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1507/10000, Loss: 0.6817, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1508/10000, Loss: 0.6817, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1509/10000, Loss: 0.6817, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1510/10000, Loss: 0.6816, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1511/10000, Loss: 0.6816, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1512/10000, Loss: 0.6816, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1513/10000, Loss: 0.6815, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1514/10000, Loss: 0.6815, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1515/10000, Loss: 0.6815, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1516/10000, Loss: 0.6814, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1517/10000, Loss: 0.6814, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1518/10000, Loss: 0.6814, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1519/10000, Loss: 0.6814, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1520/10000, Loss: 0.6813, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1521/10000, Loss: 0.6813, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1522/10000, Loss: 0.6813, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1523/10000, Loss: 0.6812, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1524/10000, Loss: 0.6812, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1525/10000, Loss: 0.6812, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1526/10000, Loss: 0.6811, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1527/10000, Loss: 0.6811, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1528/10000, Loss: 0.6811, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1529/10000, Loss: 0.6810, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1530/10000, Loss: 0.6810, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1531/10000, Loss: 0.6810, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1532/10000, Loss: 0.6809, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1533/10000, Loss: 0.6809, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1534/10000, Loss: 0.6809, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1535/10000, Loss: 0.6808, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1536/10000, Loss: 0.6808, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1537/10000, Loss: 0.6808, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1538/10000, Loss: 0.6807, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1539/10000, Loss: 0.6807, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1540/10000, Loss: 0.6807, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1541/10000, Loss: 0.6806, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1542/10000, Loss: 0.6806, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1543/10000, Loss: 0.6806, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1544/10000, Loss: 0.6805, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1545/10000, Loss: 0.6805, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1546/10000, Loss: 0.6805, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1547/10000, Loss: 0.6805, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1548/10000, Loss: 0.6804, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1549/10000, Loss: 0.6804, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1550/10000, Loss: 0.6804, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1551/10000, Loss: 0.6803, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1552/10000, Loss: 0.6803, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1553/10000, Loss: 0.6803, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1554/10000, Loss: 0.6802, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1555/10000, Loss: 0.6802, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1556/10000, Loss: 0.6802, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1557/10000, Loss: 0.6801, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1558/10000, Loss: 0.6801, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1559/10000, Loss: 0.6801, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1560/10000, Loss: 0.6800, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1561/10000, Loss: 0.6800, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1562/10000, Loss: 0.6800, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1563/10000, Loss: 0.6799, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1564/10000, Loss: 0.6799, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1565/10000, Loss: 0.6799, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1566/10000, Loss: 0.6798, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1567/10000, Loss: 0.6798, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1568/10000, Loss: 0.6798, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1569/10000, Loss: 0.6798, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1570/10000, Loss: 0.6797, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1571/10000, Loss: 0.6797, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1572/10000, Loss: 0.6797, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1573/10000, Loss: 0.6796, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1574/10000, Loss: 0.6796, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1575/10000, Loss: 0.6796, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1576/10000, Loss: 0.6795, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1577/10000, Loss: 0.6795, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1578/10000, Loss: 0.6795, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1579/10000, Loss: 0.6794, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1580/10000, Loss: 0.6794, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1581/10000, Loss: 0.6794, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1582/10000, Loss: 0.6793, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1583/10000, Loss: 0.6793, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1584/10000, Loss: 0.6793, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1585/10000, Loss: 0.6793, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1586/10000, Loss: 0.6792, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1587/10000, Loss: 0.6792, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1588/10000, Loss: 0.6792, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1589/10000, Loss: 0.6791, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1590/10000, Loss: 0.6791, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1591/10000, Loss: 0.6791, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1592/10000, Loss: 0.6790, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1593/10000, Loss: 0.6790, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1594/10000, Loss: 0.6790, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1595/10000, Loss: 0.6789, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1596/10000, Loss: 0.6789, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1597/10000, Loss: 0.6789, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1598/10000, Loss: 0.6788, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1599/10000, Loss: 0.6788, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1600/10000, Loss: 0.6788, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1601/10000, Loss: 0.6788, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1602/10000, Loss: 0.6787, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1603/10000, Loss: 0.6787, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1604/10000, Loss: 0.6787, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1605/10000, Loss: 0.6786, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1606/10000, Loss: 0.6786, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1607/10000, Loss: 0.6786, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1608/10000, Loss: 0.6785, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1609/10000, Loss: 0.6785, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1610/10000, Loss: 0.6785, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1611/10000, Loss: 0.6784, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1612/10000, Loss: 0.6784, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1613/10000, Loss: 0.6784, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1614/10000, Loss: 0.6784, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1615/10000, Loss: 0.6783, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1616/10000, Loss: 0.6783, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1617/10000, Loss: 0.6783, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1618/10000, Loss: 0.6782, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1619/10000, Loss: 0.6782, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1620/10000, Loss: 0.6782, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1621/10000, Loss: 0.6781, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1622/10000, Loss: 0.6781, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1623/10000, Loss: 0.6781, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1624/10000, Loss: 0.6780, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1625/10000, Loss: 0.6780, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1626/10000, Loss: 0.6780, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1627/10000, Loss: 0.6779, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1628/10000, Loss: 0.6779, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1629/10000, Loss: 0.6779, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1630/10000, Loss: 0.6779, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1631/10000, Loss: 0.6778, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1632/10000, Loss: 0.6778, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1633/10000, Loss: 0.6778, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1634/10000, Loss: 0.6777, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1635/10000, Loss: 0.6777, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1636/10000, Loss: 0.6777, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1637/10000, Loss: 0.6776, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1638/10000, Loss: 0.6776, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1639/10000, Loss: 0.6776, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1640/10000, Loss: 0.6776, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1641/10000, Loss: 0.6775, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1642/10000, Loss: 0.6775, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1643/10000, Loss: 0.6775, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1644/10000, Loss: 0.6774, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1645/10000, Loss: 0.6774, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1646/10000, Loss: 0.6774, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1647/10000, Loss: 0.6773, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1648/10000, Loss: 0.6773, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1649/10000, Loss: 0.6773, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1650/10000, Loss: 0.6772, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1651/10000, Loss: 0.6772, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1652/10000, Loss: 0.6772, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1653/10000, Loss: 0.6772, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1654/10000, Loss: 0.6771, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1655/10000, Loss: 0.6771, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1656/10000, Loss: 0.6771, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1657/10000, Loss: 0.6770, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1658/10000, Loss: 0.6770, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1659/10000, Loss: 0.6770, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1660/10000, Loss: 0.6769, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1661/10000, Loss: 0.6769, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1662/10000, Loss: 0.6769, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1663/10000, Loss: 0.6769, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1664/10000, Loss: 0.6768, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1665/10000, Loss: 0.6768, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1666/10000, Loss: 0.6768, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1667/10000, Loss: 0.6767, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1668/10000, Loss: 0.6767, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1669/10000, Loss: 0.6767, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1670/10000, Loss: 0.6766, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1671/10000, Loss: 0.6766, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1672/10000, Loss: 0.6766, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1673/10000, Loss: 0.6766, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1674/10000, Loss: 0.6765, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1675/10000, Loss: 0.6765, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1676/10000, Loss: 0.6765, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1677/10000, Loss: 0.6764, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1678/10000, Loss: 0.6764, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1679/10000, Loss: 0.6764, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1680/10000, Loss: 0.6763, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1681/10000, Loss: 0.6763, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1682/10000, Loss: 0.6763, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 1683/10000, Loss: 0.6763, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1684/10000, Loss: 0.6762, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1685/10000, Loss: 0.6762, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1686/10000, Loss: 0.6762, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1687/10000, Loss: 0.6761, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1688/10000, Loss: 0.6761, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1689/10000, Loss: 0.6761, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1690/10000, Loss: 0.6760, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1691/10000, Loss: 0.6760, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1692/10000, Loss: 0.6760, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1693/10000, Loss: 0.6760, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1694/10000, Loss: 0.6759, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1695/10000, Loss: 0.6759, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1696/10000, Loss: 0.6759, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1697/10000, Loss: 0.6758, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1698/10000, Loss: 0.6758, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1699/10000, Loss: 0.6758, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1700/10000, Loss: 0.6757, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1701/10000, Loss: 0.6757, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1702/10000, Loss: 0.6757, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1703/10000, Loss: 0.6757, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1704/10000, Loss: 0.6756, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1705/10000, Loss: 0.6756, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1706/10000, Loss: 0.6756, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1707/10000, Loss: 0.6755, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1708/10000, Loss: 0.6755, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1709/10000, Loss: 0.6755, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1710/10000, Loss: 0.6755, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1711/10000, Loss: 0.6754, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1712/10000, Loss: 0.6754, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1713/10000, Loss: 0.6754, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1714/10000, Loss: 0.6753, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1715/10000, Loss: 0.6753, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1716/10000, Loss: 0.6753, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1717/10000, Loss: 0.6752, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1718/10000, Loss: 0.6752, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1719/10000, Loss: 0.6752, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1720/10000, Loss: 0.6752, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1721/10000, Loss: 0.6751, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1722/10000, Loss: 0.6751, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1723/10000, Loss: 0.6751, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1724/10000, Loss: 0.6750, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1725/10000, Loss: 0.6750, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1726/10000, Loss: 0.6750, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1727/10000, Loss: 0.6750, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1728/10000, Loss: 0.6749, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1729/10000, Loss: 0.6749, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1730/10000, Loss: 0.6749, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1731/10000, Loss: 0.6748, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1732/10000, Loss: 0.6748, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1733/10000, Loss: 0.6748, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1734/10000, Loss: 0.6747, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1735/10000, Loss: 0.6747, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1736/10000, Loss: 0.6747, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1737/10000, Loss: 0.6747, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1738/10000, Loss: 0.6746, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1739/10000, Loss: 0.6746, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1740/10000, Loss: 0.6746, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1741/10000, Loss: 0.6745, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1742/10000, Loss: 0.6745, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1743/10000, Loss: 0.6745, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1744/10000, Loss: 0.6745, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1745/10000, Loss: 0.6744, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1746/10000, Loss: 0.6744, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1747/10000, Loss: 0.6744, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1748/10000, Loss: 0.6743, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1749/10000, Loss: 0.6743, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1750/10000, Loss: 0.6743, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1751/10000, Loss: 0.6743, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1752/10000, Loss: 0.6742, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1753/10000, Loss: 0.6742, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1754/10000, Loss: 0.6742, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1755/10000, Loss: 0.6741, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1756/10000, Loss: 0.6741, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1757/10000, Loss: 0.6741, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1758/10000, Loss: 0.6740, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1759/10000, Loss: 0.6740, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1760/10000, Loss: 0.6740, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1761/10000, Loss: 0.6740, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1762/10000, Loss: 0.6739, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1763/10000, Loss: 0.6739, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1764/10000, Loss: 0.6739, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1765/10000, Loss: 0.6738, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1766/10000, Loss: 0.6738, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1767/10000, Loss: 0.6738, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1768/10000, Loss: 0.6738, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1769/10000, Loss: 0.6737, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1770/10000, Loss: 0.6737, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1771/10000, Loss: 0.6737, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1772/10000, Loss: 0.6736, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1773/10000, Loss: 0.6736, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1774/10000, Loss: 0.6736, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1775/10000, Loss: 0.6736, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1776/10000, Loss: 0.6735, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1777/10000, Loss: 0.6735, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1778/10000, Loss: 0.6735, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1779/10000, Loss: 0.6734, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1780/10000, Loss: 0.6734, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1781/10000, Loss: 0.6734, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1782/10000, Loss: 0.6734, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1783/10000, Loss: 0.6733, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1784/10000, Loss: 0.6733, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1785/10000, Loss: 0.6733, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1786/10000, Loss: 0.6732, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1787/10000, Loss: 0.6732, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1788/10000, Loss: 0.6732, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1789/10000, Loss: 0.6732, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1790/10000, Loss: 0.6731, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1791/10000, Loss: 0.6731, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1792/10000, Loss: 0.6731, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1793/10000, Loss: 0.6730, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1794/10000, Loss: 0.6730, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1795/10000, Loss: 0.6730, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1796/10000, Loss: 0.6730, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1797/10000, Loss: 0.6729, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1798/10000, Loss: 0.6729, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1799/10000, Loss: 0.6729, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1800/10000, Loss: 0.6728, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1801/10000, Loss: 0.6728, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1802/10000, Loss: 0.6728, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1803/10000, Loss: 0.6728, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1804/10000, Loss: 0.6727, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1805/10000, Loss: 0.6727, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1806/10000, Loss: 0.6727, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1807/10000, Loss: 0.6726, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1808/10000, Loss: 0.6726, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1809/10000, Loss: 0.6726, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1810/10000, Loss: 0.6726, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1811/10000, Loss: 0.6725, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1812/10000, Loss: 0.6725, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1813/10000, Loss: 0.6725, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1814/10000, Loss: 0.6724, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1815/10000, Loss: 0.6724, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1816/10000, Loss: 0.6724, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1817/10000, Loss: 0.6724, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1818/10000, Loss: 0.6723, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1819/10000, Loss: 0.6723, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1820/10000, Loss: 0.6723, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1821/10000, Loss: 0.6723, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1822/10000, Loss: 0.6722, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1823/10000, Loss: 0.6722, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1824/10000, Loss: 0.6722, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1825/10000, Loss: 0.6721, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1826/10000, Loss: 0.6721, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1827/10000, Loss: 0.6721, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1828/10000, Loss: 0.6721, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1829/10000, Loss: 0.6720, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1830/10000, Loss: 0.6720, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1831/10000, Loss: 0.6720, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1832/10000, Loss: 0.6719, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1833/10000, Loss: 0.6719, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1834/10000, Loss: 0.6719, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1835/10000, Loss: 0.6719, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1836/10000, Loss: 0.6718, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1837/10000, Loss: 0.6718, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1838/10000, Loss: 0.6718, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1839/10000, Loss: 0.6717, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1840/10000, Loss: 0.6717, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1841/10000, Loss: 0.6717, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1842/10000, Loss: 0.6717, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1843/10000, Loss: 0.6716, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1844/10000, Loss: 0.6716, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1845/10000, Loss: 0.6716, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1846/10000, Loss: 0.6716, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1847/10000, Loss: 0.6715, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1848/10000, Loss: 0.6715, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1849/10000, Loss: 0.6715, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1850/10000, Loss: 0.6714, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1851/10000, Loss: 0.6714, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1852/10000, Loss: 0.6714, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1853/10000, Loss: 0.6714, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1854/10000, Loss: 0.6713, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1855/10000, Loss: 0.6713, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1856/10000, Loss: 0.6713, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1857/10000, Loss: 0.6712, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1858/10000, Loss: 0.6712, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1859/10000, Loss: 0.6712, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1860/10000, Loss: 0.6712, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1861/10000, Loss: 0.6711, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1862/10000, Loss: 0.6711, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1863/10000, Loss: 0.6711, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1864/10000, Loss: 0.6711, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1865/10000, Loss: 0.6710, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1866/10000, Loss: 0.6710, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1867/10000, Loss: 0.6710, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1868/10000, Loss: 0.6709, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1869/10000, Loss: 0.6709, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1870/10000, Loss: 0.6709, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1871/10000, Loss: 0.6709, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1872/10000, Loss: 0.6708, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1873/10000, Loss: 0.6708, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1874/10000, Loss: 0.6708, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1875/10000, Loss: 0.6707, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1876/10000, Loss: 0.6707, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1877/10000, Loss: 0.6707, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1878/10000, Loss: 0.6707, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1879/10000, Loss: 0.6706, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1880/10000, Loss: 0.6706, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1881/10000, Loss: 0.6706, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1882/10000, Loss: 0.6706, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1883/10000, Loss: 0.6705, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1884/10000, Loss: 0.6705, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1885/10000, Loss: 0.6705, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1886/10000, Loss: 0.6704, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1887/10000, Loss: 0.6704, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1888/10000, Loss: 0.6704, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1889/10000, Loss: 0.6704, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1890/10000, Loss: 0.6703, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1891/10000, Loss: 0.6703, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1892/10000, Loss: 0.6703, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1893/10000, Loss: 0.6703, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1894/10000, Loss: 0.6702, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1895/10000, Loss: 0.6702, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1896/10000, Loss: 0.6702, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1897/10000, Loss: 0.6701, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1898/10000, Loss: 0.6701, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1899/10000, Loss: 0.6701, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1900/10000, Loss: 0.6701, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1901/10000, Loss: 0.6700, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1902/10000, Loss: 0.6700, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1903/10000, Loss: 0.6700, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1904/10000, Loss: 0.6700, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1905/10000, Loss: 0.6699, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1906/10000, Loss: 0.6699, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1907/10000, Loss: 0.6699, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1908/10000, Loss: 0.6698, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1909/10000, Loss: 0.6698, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1910/10000, Loss: 0.6698, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1911/10000, Loss: 0.6698, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1912/10000, Loss: 0.6697, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1913/10000, Loss: 0.6697, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1914/10000, Loss: 0.6697, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1915/10000, Loss: 0.6697, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1916/10000, Loss: 0.6696, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1917/10000, Loss: 0.6696, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1918/10000, Loss: 0.6696, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1919/10000, Loss: 0.6695, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1920/10000, Loss: 0.6695, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1921/10000, Loss: 0.6695, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1922/10000, Loss: 0.6695, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1923/10000, Loss: 0.6694, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1924/10000, Loss: 0.6694, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1925/10000, Loss: 0.6694, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1926/10000, Loss: 0.6694, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1927/10000, Loss: 0.6693, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1928/10000, Loss: 0.6693, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1929/10000, Loss: 0.6693, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1930/10000, Loss: 0.6693, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1931/10000, Loss: 0.6692, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1932/10000, Loss: 0.6692, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1933/10000, Loss: 0.6692, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1934/10000, Loss: 0.6691, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1935/10000, Loss: 0.6691, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1936/10000, Loss: 0.6691, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1937/10000, Loss: 0.6691, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1938/10000, Loss: 0.6690, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1939/10000, Loss: 0.6690, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1940/10000, Loss: 0.6690, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1941/10000, Loss: 0.6690, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1942/10000, Loss: 0.6689, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1943/10000, Loss: 0.6689, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1944/10000, Loss: 0.6689, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1945/10000, Loss: 0.6689, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1946/10000, Loss: 0.6688, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1947/10000, Loss: 0.6688, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1948/10000, Loss: 0.6688, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1949/10000, Loss: 0.6687, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1950/10000, Loss: 0.6687, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1951/10000, Loss: 0.6687, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1952/10000, Loss: 0.6687, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1953/10000, Loss: 0.6686, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1954/10000, Loss: 0.6686, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1955/10000, Loss: 0.6686, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1956/10000, Loss: 0.6686, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1957/10000, Loss: 0.6685, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1958/10000, Loss: 0.6685, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1959/10000, Loss: 0.6685, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1960/10000, Loss: 0.6685, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1961/10000, Loss: 0.6684, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1962/10000, Loss: 0.6684, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1963/10000, Loss: 0.6684, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1964/10000, Loss: 0.6683, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1965/10000, Loss: 0.6683, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1966/10000, Loss: 0.6683, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1967/10000, Loss: 0.6683, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1968/10000, Loss: 0.6682, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1969/10000, Loss: 0.6682, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1970/10000, Loss: 0.6682, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1971/10000, Loss: 0.6682, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1972/10000, Loss: 0.6681, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1973/10000, Loss: 0.6681, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1974/10000, Loss: 0.6681, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1975/10000, Loss: 0.6681, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1976/10000, Loss: 0.6680, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1977/10000, Loss: 0.6680, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1978/10000, Loss: 0.6680, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1979/10000, Loss: 0.6679, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1980/10000, Loss: 0.6679, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1981/10000, Loss: 0.6679, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1982/10000, Loss: 0.6679, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1983/10000, Loss: 0.6678, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1984/10000, Loss: 0.6678, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1985/10000, Loss: 0.6678, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1986/10000, Loss: 0.6678, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1987/10000, Loss: 0.6677, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1988/10000, Loss: 0.6677, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1989/10000, Loss: 0.6677, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1990/10000, Loss: 0.6677, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1991/10000, Loss: 0.6676, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1992/10000, Loss: 0.6676, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1993/10000, Loss: 0.6676, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1994/10000, Loss: 0.6676, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1995/10000, Loss: 0.6675, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1996/10000, Loss: 0.6675, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1997/10000, Loss: 0.6675, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1998/10000, Loss: 0.6674, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 1999/10000, Loss: 0.6674, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2000/10000, Loss: 0.6674, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2001/10000, Loss: 0.6674, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2002/10000, Loss: 0.6673, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2003/10000, Loss: 0.6673, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2004/10000, Loss: 0.6673, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2005/10000, Loss: 0.6673, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2006/10000, Loss: 0.6672, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2007/10000, Loss: 0.6672, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2008/10000, Loss: 0.6672, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2009/10000, Loss: 0.6672, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2010/10000, Loss: 0.6671, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2011/10000, Loss: 0.6671, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2012/10000, Loss: 0.6671, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2013/10000, Loss: 0.6671, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2014/10000, Loss: 0.6670, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2015/10000, Loss: 0.6670, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2016/10000, Loss: 0.6670, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2017/10000, Loss: 0.6670, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2018/10000, Loss: 0.6669, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2019/10000, Loss: 0.6669, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2020/10000, Loss: 0.6669, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2021/10000, Loss: 0.6669, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2022/10000, Loss: 0.6668, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2023/10000, Loss: 0.6668, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2024/10000, Loss: 0.6668, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2025/10000, Loss: 0.6667, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2026/10000, Loss: 0.6667, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2027/10000, Loss: 0.6667, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2028/10000, Loss: 0.6667, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2029/10000, Loss: 0.6666, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2030/10000, Loss: 0.6666, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2031/10000, Loss: 0.6666, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2032/10000, Loss: 0.6666, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2033/10000, Loss: 0.6665, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2034/10000, Loss: 0.6665, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2035/10000, Loss: 0.6665, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2036/10000, Loss: 0.6665, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2037/10000, Loss: 0.6664, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2038/10000, Loss: 0.6664, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2039/10000, Loss: 0.6664, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2040/10000, Loss: 0.6664, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2041/10000, Loss: 0.6663, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2042/10000, Loss: 0.6663, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2043/10000, Loss: 0.6663, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2044/10000, Loss: 0.6663, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2045/10000, Loss: 0.6662, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2046/10000, Loss: 0.6662, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2047/10000, Loss: 0.6662, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2048/10000, Loss: 0.6662, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2049/10000, Loss: 0.6661, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2050/10000, Loss: 0.6661, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2051/10000, Loss: 0.6661, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2052/10000, Loss: 0.6661, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2053/10000, Loss: 0.6660, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2054/10000, Loss: 0.6660, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2055/10000, Loss: 0.6660, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2056/10000, Loss: 0.6659, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2057/10000, Loss: 0.6659, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2058/10000, Loss: 0.6659, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2059/10000, Loss: 0.6659, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2060/10000, Loss: 0.6658, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2061/10000, Loss: 0.6658, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2062/10000, Loss: 0.6658, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2063/10000, Loss: 0.6658, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2064/10000, Loss: 0.6657, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2065/10000, Loss: 0.6657, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2066/10000, Loss: 0.6657, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2067/10000, Loss: 0.6657, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2068/10000, Loss: 0.6656, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2069/10000, Loss: 0.6656, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2070/10000, Loss: 0.6656, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2071/10000, Loss: 0.6656, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2072/10000, Loss: 0.6655, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2073/10000, Loss: 0.6655, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2074/10000, Loss: 0.6655, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2075/10000, Loss: 0.6655, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2076/10000, Loss: 0.6654, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2077/10000, Loss: 0.6654, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2078/10000, Loss: 0.6654, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2079/10000, Loss: 0.6654, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2080/10000, Loss: 0.6653, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2081/10000, Loss: 0.6653, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2082/10000, Loss: 0.6653, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2083/10000, Loss: 0.6653, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2084/10000, Loss: 0.6652, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2085/10000, Loss: 0.6652, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2086/10000, Loss: 0.6652, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2087/10000, Loss: 0.6652, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2088/10000, Loss: 0.6651, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2089/10000, Loss: 0.6651, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2090/10000, Loss: 0.6651, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2091/10000, Loss: 0.6651, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2092/10000, Loss: 0.6650, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2093/10000, Loss: 0.6650, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2094/10000, Loss: 0.6650, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2095/10000, Loss: 0.6650, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2096/10000, Loss: 0.6649, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2097/10000, Loss: 0.6649, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2098/10000, Loss: 0.6649, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2099/10000, Loss: 0.6649, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2100/10000, Loss: 0.6648, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2101/10000, Loss: 0.6648, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2102/10000, Loss: 0.6648, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2103/10000, Loss: 0.6648, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2104/10000, Loss: 0.6647, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2105/10000, Loss: 0.6647, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2106/10000, Loss: 0.6647, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2107/10000, Loss: 0.6647, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2108/10000, Loss: 0.6646, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2109/10000, Loss: 0.6646, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2110/10000, Loss: 0.6646, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2111/10000, Loss: 0.6646, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2112/10000, Loss: 0.6645, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2113/10000, Loss: 0.6645, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2114/10000, Loss: 0.6645, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2115/10000, Loss: 0.6645, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2116/10000, Loss: 0.6644, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2117/10000, Loss: 0.6644, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2118/10000, Loss: 0.6644, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2119/10000, Loss: 0.6644, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2120/10000, Loss: 0.6643, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2121/10000, Loss: 0.6643, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2122/10000, Loss: 0.6643, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2123/10000, Loss: 0.6643, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2124/10000, Loss: 0.6642, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2125/10000, Loss: 0.6642, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2126/10000, Loss: 0.6642, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2127/10000, Loss: 0.6642, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2128/10000, Loss: 0.6641, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2129/10000, Loss: 0.6641, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2130/10000, Loss: 0.6641, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2131/10000, Loss: 0.6641, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2132/10000, Loss: 0.6640, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2133/10000, Loss: 0.6640, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2134/10000, Loss: 0.6640, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2135/10000, Loss: 0.6640, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2136/10000, Loss: 0.6639, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2137/10000, Loss: 0.6639, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2138/10000, Loss: 0.6639, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2139/10000, Loss: 0.6639, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2140/10000, Loss: 0.6638, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2141/10000, Loss: 0.6638, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2142/10000, Loss: 0.6638, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2143/10000, Loss: 0.6638, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2144/10000, Loss: 0.6637, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2145/10000, Loss: 0.6637, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2146/10000, Loss: 0.6637, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2147/10000, Loss: 0.6637, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2148/10000, Loss: 0.6636, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2149/10000, Loss: 0.6636, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2150/10000, Loss: 0.6636, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2151/10000, Loss: 0.6636, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2152/10000, Loss: 0.6635, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2153/10000, Loss: 0.6635, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2154/10000, Loss: 0.6635, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2155/10000, Loss: 0.6635, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2156/10000, Loss: 0.6634, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2157/10000, Loss: 0.6634, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2158/10000, Loss: 0.6634, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2159/10000, Loss: 0.6634, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2160/10000, Loss: 0.6633, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2161/10000, Loss: 0.6633, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2162/10000, Loss: 0.6633, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2163/10000, Loss: 0.6633, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2164/10000, Loss: 0.6632, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2165/10000, Loss: 0.6632, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2166/10000, Loss: 0.6632, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2167/10000, Loss: 0.6632, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2168/10000, Loss: 0.6631, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2169/10000, Loss: 0.6631, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2170/10000, Loss: 0.6631, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2171/10000, Loss: 0.6631, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2172/10000, Loss: 0.6631, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2173/10000, Loss: 0.6630, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2174/10000, Loss: 0.6630, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2175/10000, Loss: 0.6630, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2176/10000, Loss: 0.6630, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2177/10000, Loss: 0.6629, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2178/10000, Loss: 0.6629, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2179/10000, Loss: 0.6629, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2180/10000, Loss: 0.6629, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2181/10000, Loss: 0.6628, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2182/10000, Loss: 0.6628, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2183/10000, Loss: 0.6628, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2184/10000, Loss: 0.6628, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2185/10000, Loss: 0.6627, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2186/10000, Loss: 0.6627, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2187/10000, Loss: 0.6627, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2188/10000, Loss: 0.6627, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2189/10000, Loss: 0.6626, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2190/10000, Loss: 0.6626, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2191/10000, Loss: 0.6626, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2192/10000, Loss: 0.6626, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2193/10000, Loss: 0.6625, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2194/10000, Loss: 0.6625, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2195/10000, Loss: 0.6625, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2196/10000, Loss: 0.6625, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2197/10000, Loss: 0.6624, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2198/10000, Loss: 0.6624, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2199/10000, Loss: 0.6624, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2200/10000, Loss: 0.6624, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2201/10000, Loss: 0.6623, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2202/10000, Loss: 0.6623, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2203/10000, Loss: 0.6623, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2204/10000, Loss: 0.6623, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2205/10000, Loss: 0.6622, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2206/10000, Loss: 0.6622, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2207/10000, Loss: 0.6622, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2208/10000, Loss: 0.6622, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2209/10000, Loss: 0.6622, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2210/10000, Loss: 0.6621, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2211/10000, Loss: 0.6621, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2212/10000, Loss: 0.6621, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2213/10000, Loss: 0.6621, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2214/10000, Loss: 0.6620, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2215/10000, Loss: 0.6620, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2216/10000, Loss: 0.6620, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2217/10000, Loss: 0.6620, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2218/10000, Loss: 0.6619, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2219/10000, Loss: 0.6619, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2220/10000, Loss: 0.6619, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2221/10000, Loss: 0.6619, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2222/10000, Loss: 0.6618, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2223/10000, Loss: 0.6618, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2224/10000, Loss: 0.6618, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2225/10000, Loss: 0.6618, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2226/10000, Loss: 0.6617, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2227/10000, Loss: 0.6617, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2228/10000, Loss: 0.6617, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2229/10000, Loss: 0.6617, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2230/10000, Loss: 0.6616, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2231/10000, Loss: 0.6616, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2232/10000, Loss: 0.6616, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2233/10000, Loss: 0.6616, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2234/10000, Loss: 0.6616, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2235/10000, Loss: 0.6615, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2236/10000, Loss: 0.6615, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2237/10000, Loss: 0.6615, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2238/10000, Loss: 0.6615, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2239/10000, Loss: 0.6614, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2240/10000, Loss: 0.6614, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2241/10000, Loss: 0.6614, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2242/10000, Loss: 0.6614, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2243/10000, Loss: 0.6613, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2244/10000, Loss: 0.6613, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2245/10000, Loss: 0.6613, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2246/10000, Loss: 0.6613, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2247/10000, Loss: 0.6612, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2248/10000, Loss: 0.6612, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2249/10000, Loss: 0.6612, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2250/10000, Loss: 0.6612, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2251/10000, Loss: 0.6611, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2252/10000, Loss: 0.6611, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2253/10000, Loss: 0.6611, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2254/10000, Loss: 0.6611, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2255/10000, Loss: 0.6611, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2256/10000, Loss: 0.6610, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2257/10000, Loss: 0.6610, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2258/10000, Loss: 0.6610, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2259/10000, Loss: 0.6610, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2260/10000, Loss: 0.6609, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2261/10000, Loss: 0.6609, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2262/10000, Loss: 0.6609, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2263/10000, Loss: 0.6609, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2264/10000, Loss: 0.6608, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2265/10000, Loss: 0.6608, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2266/10000, Loss: 0.6608, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2267/10000, Loss: 0.6608, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2268/10000, Loss: 0.6607, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2269/10000, Loss: 0.6607, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2270/10000, Loss: 0.6607, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2271/10000, Loss: 0.6607, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2272/10000, Loss: 0.6607, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2273/10000, Loss: 0.6606, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2274/10000, Loss: 0.6606, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2275/10000, Loss: 0.6606, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2276/10000, Loss: 0.6606, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2277/10000, Loss: 0.6605, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2278/10000, Loss: 0.6605, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2279/10000, Loss: 0.6605, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2280/10000, Loss: 0.6605, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2281/10000, Loss: 0.6604, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2282/10000, Loss: 0.6604, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2283/10000, Loss: 0.6604, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2284/10000, Loss: 0.6604, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2285/10000, Loss: 0.6603, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2286/10000, Loss: 0.6603, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2287/10000, Loss: 0.6603, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2288/10000, Loss: 0.6603, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2289/10000, Loss: 0.6603, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2290/10000, Loss: 0.6602, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2291/10000, Loss: 0.6602, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2292/10000, Loss: 0.6602, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2293/10000, Loss: 0.6602, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2294/10000, Loss: 0.6601, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2295/10000, Loss: 0.6601, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2296/10000, Loss: 0.6601, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2297/10000, Loss: 0.6601, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2298/10000, Loss: 0.6600, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2299/10000, Loss: 0.6600, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2300/10000, Loss: 0.6600, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2301/10000, Loss: 0.6600, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2302/10000, Loss: 0.6599, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2303/10000, Loss: 0.6599, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2304/10000, Loss: 0.6599, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2305/10000, Loss: 0.6599, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2306/10000, Loss: 0.6599, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2307/10000, Loss: 0.6598, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2308/10000, Loss: 0.6598, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2309/10000, Loss: 0.6598, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2310/10000, Loss: 0.6598, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2311/10000, Loss: 0.6597, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2312/10000, Loss: 0.6597, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2313/10000, Loss: 0.6597, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2314/10000, Loss: 0.6597, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2315/10000, Loss: 0.6596, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2316/10000, Loss: 0.6596, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2317/10000, Loss: 0.6596, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2318/10000, Loss: 0.6596, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2319/10000, Loss: 0.6596, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2320/10000, Loss: 0.6595, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2321/10000, Loss: 0.6595, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2322/10000, Loss: 0.6595, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2323/10000, Loss: 0.6595, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2324/10000, Loss: 0.6594, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2325/10000, Loss: 0.6594, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2326/10000, Loss: 0.6594, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2327/10000, Loss: 0.6594, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2328/10000, Loss: 0.6593, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2329/10000, Loss: 0.6593, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2330/10000, Loss: 0.6593, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2331/10000, Loss: 0.6593, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2332/10000, Loss: 0.6593, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2333/10000, Loss: 0.6592, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2334/10000, Loss: 0.6592, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2335/10000, Loss: 0.6592, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2336/10000, Loss: 0.6592, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2337/10000, Loss: 0.6591, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2338/10000, Loss: 0.6591, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2339/10000, Loss: 0.6591, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2340/10000, Loss: 0.6591, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2341/10000, Loss: 0.6590, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2342/10000, Loss: 0.6590, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2343/10000, Loss: 0.6590, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2344/10000, Loss: 0.6590, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2345/10000, Loss: 0.6590, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2346/10000, Loss: 0.6589, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2347/10000, Loss: 0.6589, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2348/10000, Loss: 0.6589, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2349/10000, Loss: 0.6589, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2350/10000, Loss: 0.6588, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2351/10000, Loss: 0.6588, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2352/10000, Loss: 0.6588, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2353/10000, Loss: 0.6588, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2354/10000, Loss: 0.6587, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2355/10000, Loss: 0.6587, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2356/10000, Loss: 0.6587, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2357/10000, Loss: 0.6587, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2358/10000, Loss: 0.6587, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2359/10000, Loss: 0.6586, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2360/10000, Loss: 0.6586, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2361/10000, Loss: 0.6586, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2362/10000, Loss: 0.6586, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2363/10000, Loss: 0.6585, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2364/10000, Loss: 0.6585, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2365/10000, Loss: 0.6585, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2366/10000, Loss: 0.6585, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2367/10000, Loss: 0.6585, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2368/10000, Loss: 0.6584, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2369/10000, Loss: 0.6584, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2370/10000, Loss: 0.6584, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2371/10000, Loss: 0.6584, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2372/10000, Loss: 0.6583, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2373/10000, Loss: 0.6583, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2374/10000, Loss: 0.6583, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2375/10000, Loss: 0.6583, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2376/10000, Loss: 0.6582, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2377/10000, Loss: 0.6582, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2378/10000, Loss: 0.6582, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2379/10000, Loss: 0.6582, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2380/10000, Loss: 0.6582, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2381/10000, Loss: 0.6581, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2382/10000, Loss: 0.6581, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2383/10000, Loss: 0.6581, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2384/10000, Loss: 0.6581, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2385/10000, Loss: 0.6580, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2386/10000, Loss: 0.6580, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2387/10000, Loss: 0.6580, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2388/10000, Loss: 0.6580, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2389/10000, Loss: 0.6580, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2390/10000, Loss: 0.6579, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2391/10000, Loss: 0.6579, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2392/10000, Loss: 0.6579, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2393/10000, Loss: 0.6579, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2394/10000, Loss: 0.6578, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2395/10000, Loss: 0.6578, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2396/10000, Loss: 0.6578, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2397/10000, Loss: 0.6578, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2398/10000, Loss: 0.6577, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2399/10000, Loss: 0.6577, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2400/10000, Loss: 0.6577, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2401/10000, Loss: 0.6577, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2402/10000, Loss: 0.6577, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2403/10000, Loss: 0.6576, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2404/10000, Loss: 0.6576, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2405/10000, Loss: 0.6576, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2406/10000, Loss: 0.6576, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2407/10000, Loss: 0.6575, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2408/10000, Loss: 0.6575, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2409/10000, Loss: 0.6575, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2410/10000, Loss: 0.6575, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2411/10000, Loss: 0.6575, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2412/10000, Loss: 0.6574, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2413/10000, Loss: 0.6574, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2414/10000, Loss: 0.6574, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2415/10000, Loss: 0.6574, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2416/10000, Loss: 0.6573, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2417/10000, Loss: 0.6573, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2418/10000, Loss: 0.6573, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2419/10000, Loss: 0.6573, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2420/10000, Loss: 0.6573, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2421/10000, Loss: 0.6572, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2422/10000, Loss: 0.6572, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2423/10000, Loss: 0.6572, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2424/10000, Loss: 0.6572, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2425/10000, Loss: 0.6571, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2426/10000, Loss: 0.6571, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2427/10000, Loss: 0.6571, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2428/10000, Loss: 0.6571, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2429/10000, Loss: 0.6571, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2430/10000, Loss: 0.6570, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2431/10000, Loss: 0.6570, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2432/10000, Loss: 0.6570, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2433/10000, Loss: 0.6570, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2434/10000, Loss: 0.6569, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2435/10000, Loss: 0.6569, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2436/10000, Loss: 0.6569, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2437/10000, Loss: 0.6569, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2438/10000, Loss: 0.6569, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2439/10000, Loss: 0.6568, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2440/10000, Loss: 0.6568, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2441/10000, Loss: 0.6568, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2442/10000, Loss: 0.6568, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2443/10000, Loss: 0.6567, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2444/10000, Loss: 0.6567, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2445/10000, Loss: 0.6567, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2446/10000, Loss: 0.6567, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2447/10000, Loss: 0.6567, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2448/10000, Loss: 0.6566, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2449/10000, Loss: 0.6566, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2450/10000, Loss: 0.6566, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2451/10000, Loss: 0.6566, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2452/10000, Loss: 0.6565, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2453/10000, Loss: 0.6565, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2454/10000, Loss: 0.6565, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2455/10000, Loss: 0.6565, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2456/10000, Loss: 0.6565, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2457/10000, Loss: 0.6564, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2458/10000, Loss: 0.6564, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2459/10000, Loss: 0.6564, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2460/10000, Loss: 0.6564, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2461/10000, Loss: 0.6563, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2462/10000, Loss: 0.6563, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2463/10000, Loss: 0.6563, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2464/10000, Loss: 0.6563, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2465/10000, Loss: 0.6563, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2466/10000, Loss: 0.6562, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2467/10000, Loss: 0.6562, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2468/10000, Loss: 0.6562, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2469/10000, Loss: 0.6562, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2470/10000, Loss: 0.6561, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2471/10000, Loss: 0.6561, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2472/10000, Loss: 0.6561, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2473/10000, Loss: 0.6561, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2474/10000, Loss: 0.6561, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2475/10000, Loss: 0.6560, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2476/10000, Loss: 0.6560, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2477/10000, Loss: 0.6560, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2478/10000, Loss: 0.6560, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2479/10000, Loss: 0.6560, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2480/10000, Loss: 0.6559, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2481/10000, Loss: 0.6559, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2482/10000, Loss: 0.6559, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2483/10000, Loss: 0.6559, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2484/10000, Loss: 0.6558, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2485/10000, Loss: 0.6558, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2486/10000, Loss: 0.6558, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2487/10000, Loss: 0.6558, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2488/10000, Loss: 0.6558, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2489/10000, Loss: 0.6557, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2490/10000, Loss: 0.6557, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2491/10000, Loss: 0.6557, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2492/10000, Loss: 0.6557, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2493/10000, Loss: 0.6556, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2494/10000, Loss: 0.6556, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2495/10000, Loss: 0.6556, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2496/10000, Loss: 0.6556, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2497/10000, Loss: 0.6556, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2498/10000, Loss: 0.6555, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2499/10000, Loss: 0.6555, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2500/10000, Loss: 0.6555, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2501/10000, Loss: 0.6555, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2502/10000, Loss: 0.6554, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2503/10000, Loss: 0.6554, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2504/10000, Loss: 0.6554, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2505/10000, Loss: 0.6554, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2506/10000, Loss: 0.6554, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2507/10000, Loss: 0.6553, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2508/10000, Loss: 0.6553, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2509/10000, Loss: 0.6553, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2510/10000, Loss: 0.6553, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2511/10000, Loss: 0.6553, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2512/10000, Loss: 0.6552, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2513/10000, Loss: 0.6552, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2514/10000, Loss: 0.6552, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2515/10000, Loss: 0.6552, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2516/10000, Loss: 0.6551, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2517/10000, Loss: 0.6551, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2518/10000, Loss: 0.6551, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2519/10000, Loss: 0.6551, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2520/10000, Loss: 0.6551, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2521/10000, Loss: 0.6550, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2522/10000, Loss: 0.6550, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2523/10000, Loss: 0.6550, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2524/10000, Loss: 0.6550, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2525/10000, Loss: 0.6550, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2526/10000, Loss: 0.6549, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2527/10000, Loss: 0.6549, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2528/10000, Loss: 0.6549, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2529/10000, Loss: 0.6549, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2530/10000, Loss: 0.6548, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2531/10000, Loss: 0.6548, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2532/10000, Loss: 0.6548, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2533/10000, Loss: 0.6548, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2534/10000, Loss: 0.6548, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2535/10000, Loss: 0.6547, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2536/10000, Loss: 0.6547, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2537/10000, Loss: 0.6547, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2538/10000, Loss: 0.6547, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2539/10000, Loss: 0.6547, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2540/10000, Loss: 0.6546, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2541/10000, Loss: 0.6546, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2542/10000, Loss: 0.6546, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2543/10000, Loss: 0.6546, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2544/10000, Loss: 0.6545, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2545/10000, Loss: 0.6545, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2546/10000, Loss: 0.6545, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2547/10000, Loss: 0.6545, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2548/10000, Loss: 0.6545, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2549/10000, Loss: 0.6544, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2550/10000, Loss: 0.6544, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2551/10000, Loss: 0.6544, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2552/10000, Loss: 0.6544, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2553/10000, Loss: 0.6544, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2554/10000, Loss: 0.6543, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2555/10000, Loss: 0.6543, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2556/10000, Loss: 0.6543, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2557/10000, Loss: 0.6543, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2558/10000, Loss: 0.6542, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2559/10000, Loss: 0.6542, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2560/10000, Loss: 0.6542, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2561/10000, Loss: 0.6542, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2562/10000, Loss: 0.6542, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2563/10000, Loss: 0.6541, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2564/10000, Loss: 0.6541, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2565/10000, Loss: 0.6541, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2566/10000, Loss: 0.6541, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2567/10000, Loss: 0.6541, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2568/10000, Loss: 0.6540, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2569/10000, Loss: 0.6540, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2570/10000, Loss: 0.6540, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2571/10000, Loss: 0.6540, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2572/10000, Loss: 0.6539, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2573/10000, Loss: 0.6539, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2574/10000, Loss: 0.6539, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2575/10000, Loss: 0.6539, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2576/10000, Loss: 0.6539, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2577/10000, Loss: 0.6538, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2578/10000, Loss: 0.6538, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2579/10000, Loss: 0.6538, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2580/10000, Loss: 0.6538, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2581/10000, Loss: 0.6538, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2582/10000, Loss: 0.6537, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2583/10000, Loss: 0.6537, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2584/10000, Loss: 0.6537, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2585/10000, Loss: 0.6537, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2586/10000, Loss: 0.6537, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2587/10000, Loss: 0.6536, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2588/10000, Loss: 0.6536, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2589/10000, Loss: 0.6536, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2590/10000, Loss: 0.6536, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2591/10000, Loss: 0.6535, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2592/10000, Loss: 0.6535, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2593/10000, Loss: 0.6535, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2594/10000, Loss: 0.6535, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2595/10000, Loss: 0.6535, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2596/10000, Loss: 0.6534, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2597/10000, Loss: 0.6534, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2598/10000, Loss: 0.6534, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2599/10000, Loss: 0.6534, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2600/10000, Loss: 0.6534, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2601/10000, Loss: 0.6533, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2602/10000, Loss: 0.6533, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2603/10000, Loss: 0.6533, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2604/10000, Loss: 0.6533, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2605/10000, Loss: 0.6533, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2606/10000, Loss: 0.6532, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2607/10000, Loss: 0.6532, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2608/10000, Loss: 0.6532, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2609/10000, Loss: 0.6532, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2610/10000, Loss: 0.6531, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2611/10000, Loss: 0.6531, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2612/10000, Loss: 0.6531, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2613/10000, Loss: 0.6531, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2614/10000, Loss: 0.6531, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2615/10000, Loss: 0.6530, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2616/10000, Loss: 0.6530, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2617/10000, Loss: 0.6530, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2618/10000, Loss: 0.6530, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2619/10000, Loss: 0.6530, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2620/10000, Loss: 0.6529, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2621/10000, Loss: 0.6529, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2622/10000, Loss: 0.6529, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2623/10000, Loss: 0.6529, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2624/10000, Loss: 0.6529, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2625/10000, Loss: 0.6528, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2626/10000, Loss: 0.6528, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2627/10000, Loss: 0.6528, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2628/10000, Loss: 0.6528, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2629/10000, Loss: 0.6528, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2630/10000, Loss: 0.6527, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2631/10000, Loss: 0.6527, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2632/10000, Loss: 0.6527, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2633/10000, Loss: 0.6527, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2634/10000, Loss: 0.6526, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2635/10000, Loss: 0.6526, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2636/10000, Loss: 0.6526, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2637/10000, Loss: 0.6526, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2638/10000, Loss: 0.6526, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2639/10000, Loss: 0.6525, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2640/10000, Loss: 0.6525, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2641/10000, Loss: 0.6525, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2642/10000, Loss: 0.6525, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2643/10000, Loss: 0.6525, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2644/10000, Loss: 0.6524, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2645/10000, Loss: 0.6524, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2646/10000, Loss: 0.6524, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2647/10000, Loss: 0.6524, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2648/10000, Loss: 0.6524, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2649/10000, Loss: 0.6523, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2650/10000, Loss: 0.6523, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2651/10000, Loss: 0.6523, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2652/10000, Loss: 0.6523, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2653/10000, Loss: 0.6523, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2654/10000, Loss: 0.6522, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2655/10000, Loss: 0.6522, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2656/10000, Loss: 0.6522, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2657/10000, Loss: 0.6522, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2658/10000, Loss: 0.6522, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2659/10000, Loss: 0.6521, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2660/10000, Loss: 0.6521, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2661/10000, Loss: 0.6521, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2662/10000, Loss: 0.6521, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2663/10000, Loss: 0.6520, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2664/10000, Loss: 0.6520, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2665/10000, Loss: 0.6520, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2666/10000, Loss: 0.6520, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2667/10000, Loss: 0.6520, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2668/10000, Loss: 0.6519, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2669/10000, Loss: 0.6519, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2670/10000, Loss: 0.6519, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2671/10000, Loss: 0.6519, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2672/10000, Loss: 0.6519, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2673/10000, Loss: 0.6518, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2674/10000, Loss: 0.6518, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2675/10000, Loss: 0.6518, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2676/10000, Loss: 0.6518, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2677/10000, Loss: 0.6518, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2678/10000, Loss: 0.6517, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2679/10000, Loss: 0.6517, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2680/10000, Loss: 0.6517, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2681/10000, Loss: 0.6517, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2682/10000, Loss: 0.6517, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2683/10000, Loss: 0.6516, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2684/10000, Loss: 0.6516, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2685/10000, Loss: 0.6516, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2686/10000, Loss: 0.6516, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2687/10000, Loss: 0.6516, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2688/10000, Loss: 0.6515, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2689/10000, Loss: 0.6515, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2690/10000, Loss: 0.6515, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2691/10000, Loss: 0.6515, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2692/10000, Loss: 0.6515, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2693/10000, Loss: 0.6514, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2694/10000, Loss: 0.6514, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2695/10000, Loss: 0.6514, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2696/10000, Loss: 0.6514, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2697/10000, Loss: 0.6514, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2698/10000, Loss: 0.6513, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2699/10000, Loss: 0.6513, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2700/10000, Loss: 0.6513, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2701/10000, Loss: 0.6513, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2702/10000, Loss: 0.6513, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2703/10000, Loss: 0.6512, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2704/10000, Loss: 0.6512, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2705/10000, Loss: 0.6512, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2706/10000, Loss: 0.6512, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2707/10000, Loss: 0.6512, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2708/10000, Loss: 0.6511, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2709/10000, Loss: 0.6511, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2710/10000, Loss: 0.6511, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2711/10000, Loss: 0.6511, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2712/10000, Loss: 0.6511, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2713/10000, Loss: 0.6510, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2714/10000, Loss: 0.6510, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2715/10000, Loss: 0.6510, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2716/10000, Loss: 0.6510, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2717/10000, Loss: 0.6510, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2718/10000, Loss: 0.6509, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2719/10000, Loss: 0.6509, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2720/10000, Loss: 0.6509, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2721/10000, Loss: 0.6509, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2722/10000, Loss: 0.6508, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2723/10000, Loss: 0.6508, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2724/10000, Loss: 0.6508, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2725/10000, Loss: 0.6508, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2726/10000, Loss: 0.6508, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2727/10000, Loss: 0.6507, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2728/10000, Loss: 0.6507, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2729/10000, Loss: 0.6507, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2730/10000, Loss: 0.6507, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2731/10000, Loss: 0.6507, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2732/10000, Loss: 0.6506, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2733/10000, Loss: 0.6506, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2734/10000, Loss: 0.6506, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2735/10000, Loss: 0.6506, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2736/10000, Loss: 0.6506, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2737/10000, Loss: 0.6505, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2738/10000, Loss: 0.6505, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2739/10000, Loss: 0.6505, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2740/10000, Loss: 0.6505, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2741/10000, Loss: 0.6505, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2742/10000, Loss: 0.6504, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2743/10000, Loss: 0.6504, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2744/10000, Loss: 0.6504, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2745/10000, Loss: 0.6504, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2746/10000, Loss: 0.6504, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2747/10000, Loss: 0.6503, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2748/10000, Loss: 0.6503, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2749/10000, Loss: 0.6503, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2750/10000, Loss: 0.6503, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2751/10000, Loss: 0.6503, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2752/10000, Loss: 0.6502, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2753/10000, Loss: 0.6502, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2754/10000, Loss: 0.6502, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2755/10000, Loss: 0.6502, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2756/10000, Loss: 0.6502, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2757/10000, Loss: 0.6501, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2758/10000, Loss: 0.6501, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2759/10000, Loss: 0.6501, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2760/10000, Loss: 0.6501, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2761/10000, Loss: 0.6501, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2762/10000, Loss: 0.6500, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2763/10000, Loss: 0.6500, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2764/10000, Loss: 0.6500, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2765/10000, Loss: 0.6500, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2766/10000, Loss: 0.6500, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2767/10000, Loss: 0.6499, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2768/10000, Loss: 0.6499, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2769/10000, Loss: 0.6499, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2770/10000, Loss: 0.6499, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2771/10000, Loss: 0.6499, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2772/10000, Loss: 0.6499, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2773/10000, Loss: 0.6498, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2774/10000, Loss: 0.6498, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2775/10000, Loss: 0.6498, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2776/10000, Loss: 0.6498, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2777/10000, Loss: 0.6498, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2778/10000, Loss: 0.6497, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2779/10000, Loss: 0.6497, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2780/10000, Loss: 0.6497, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2781/10000, Loss: 0.6497, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2782/10000, Loss: 0.6497, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2783/10000, Loss: 0.6496, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2784/10000, Loss: 0.6496, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2785/10000, Loss: 0.6496, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2786/10000, Loss: 0.6496, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2787/10000, Loss: 0.6496, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2788/10000, Loss: 0.6495, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2789/10000, Loss: 0.6495, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2790/10000, Loss: 0.6495, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2791/10000, Loss: 0.6495, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2792/10000, Loss: 0.6495, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2793/10000, Loss: 0.6494, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2794/10000, Loss: 0.6494, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2795/10000, Loss: 0.6494, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2796/10000, Loss: 0.6494, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2797/10000, Loss: 0.6494, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2798/10000, Loss: 0.6493, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2799/10000, Loss: 0.6493, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2800/10000, Loss: 0.6493, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2801/10000, Loss: 0.6493, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2802/10000, Loss: 0.6493, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2803/10000, Loss: 0.6492, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2804/10000, Loss: 0.6492, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2805/10000, Loss: 0.6492, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2806/10000, Loss: 0.6492, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2807/10000, Loss: 0.6492, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2808/10000, Loss: 0.6491, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2809/10000, Loss: 0.6491, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2810/10000, Loss: 0.6491, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2811/10000, Loss: 0.6491, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2812/10000, Loss: 0.6491, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2813/10000, Loss: 0.6490, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2814/10000, Loss: 0.6490, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2815/10000, Loss: 0.6490, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2816/10000, Loss: 0.6490, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2817/10000, Loss: 0.6490, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2818/10000, Loss: 0.6489, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2819/10000, Loss: 0.6489, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2820/10000, Loss: 0.6489, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2821/10000, Loss: 0.6489, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2822/10000, Loss: 0.6489, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2823/10000, Loss: 0.6488, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2824/10000, Loss: 0.6488, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2825/10000, Loss: 0.6488, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2826/10000, Loss: 0.6488, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2827/10000, Loss: 0.6488, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2828/10000, Loss: 0.6488, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2829/10000, Loss: 0.6487, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2830/10000, Loss: 0.6487, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2831/10000, Loss: 0.6487, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2832/10000, Loss: 0.6487, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2833/10000, Loss: 0.6487, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2834/10000, Loss: 0.6486, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2835/10000, Loss: 0.6486, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2836/10000, Loss: 0.6486, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2837/10000, Loss: 0.6486, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2838/10000, Loss: 0.6486, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2839/10000, Loss: 0.6485, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2840/10000, Loss: 0.6485, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2841/10000, Loss: 0.6485, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2842/10000, Loss: 0.6485, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2843/10000, Loss: 0.6485, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2844/10000, Loss: 0.6484, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2845/10000, Loss: 0.6484, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2846/10000, Loss: 0.6484, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2847/10000, Loss: 0.6484, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2848/10000, Loss: 0.6484, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2849/10000, Loss: 0.6483, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2850/10000, Loss: 0.6483, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2851/10000, Loss: 0.6483, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2852/10000, Loss: 0.6483, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2853/10000, Loss: 0.6483, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2854/10000, Loss: 0.6482, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2855/10000, Loss: 0.6482, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2856/10000, Loss: 0.6482, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2857/10000, Loss: 0.6482, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2858/10000, Loss: 0.6482, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2859/10000, Loss: 0.6482, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2860/10000, Loss: 0.6481, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2861/10000, Loss: 0.6481, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2862/10000, Loss: 0.6481, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2863/10000, Loss: 0.6481, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2864/10000, Loss: 0.6481, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2865/10000, Loss: 0.6480, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2866/10000, Loss: 0.6480, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2867/10000, Loss: 0.6480, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2868/10000, Loss: 0.6480, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2869/10000, Loss: 0.6480, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2870/10000, Loss: 0.6479, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2871/10000, Loss: 0.6479, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2872/10000, Loss: 0.6479, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2873/10000, Loss: 0.6479, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2874/10000, Loss: 0.6479, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2875/10000, Loss: 0.6478, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2876/10000, Loss: 0.6478, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2877/10000, Loss: 0.6478, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2878/10000, Loss: 0.6478, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2879/10000, Loss: 0.6478, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2880/10000, Loss: 0.6477, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2881/10000, Loss: 0.6477, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2882/10000, Loss: 0.6477, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2883/10000, Loss: 0.6477, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2884/10000, Loss: 0.6477, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2885/10000, Loss: 0.6477, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2886/10000, Loss: 0.6476, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2887/10000, Loss: 0.6476, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2888/10000, Loss: 0.6476, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2889/10000, Loss: 0.6476, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2890/10000, Loss: 0.6476, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2891/10000, Loss: 0.6475, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2892/10000, Loss: 0.6475, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2893/10000, Loss: 0.6475, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2894/10000, Loss: 0.6475, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2895/10000, Loss: 0.6475, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2896/10000, Loss: 0.6474, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2897/10000, Loss: 0.6474, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2898/10000, Loss: 0.6474, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2899/10000, Loss: 0.6474, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2900/10000, Loss: 0.6474, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2901/10000, Loss: 0.6473, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2902/10000, Loss: 0.6473, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2903/10000, Loss: 0.6473, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2904/10000, Loss: 0.6473, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2905/10000, Loss: 0.6473, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2906/10000, Loss: 0.6473, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2907/10000, Loss: 0.6472, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2908/10000, Loss: 0.6472, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2909/10000, Loss: 0.6472, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2910/10000, Loss: 0.6472, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2911/10000, Loss: 0.6472, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2912/10000, Loss: 0.6471, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2913/10000, Loss: 0.6471, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2914/10000, Loss: 0.6471, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2915/10000, Loss: 0.6471, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2916/10000, Loss: 0.6471, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2917/10000, Loss: 0.6470, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2918/10000, Loss: 0.6470, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2919/10000, Loss: 0.6470, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2920/10000, Loss: 0.6470, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2921/10000, Loss: 0.6470, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2922/10000, Loss: 0.6470, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2923/10000, Loss: 0.6469, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2924/10000, Loss: 0.6469, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2925/10000, Loss: 0.6469, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2926/10000, Loss: 0.6469, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2927/10000, Loss: 0.6469, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2928/10000, Loss: 0.6468, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2929/10000, Loss: 0.6468, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2930/10000, Loss: 0.6468, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2931/10000, Loss: 0.6468, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2932/10000, Loss: 0.6468, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2933/10000, Loss: 0.6467, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2934/10000, Loss: 0.6467, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2935/10000, Loss: 0.6467, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2936/10000, Loss: 0.6467, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2937/10000, Loss: 0.6467, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2938/10000, Loss: 0.6466, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2939/10000, Loss: 0.6466, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2940/10000, Loss: 0.6466, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2941/10000, Loss: 0.6466, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2942/10000, Loss: 0.6466, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2943/10000, Loss: 0.6466, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2944/10000, Loss: 0.6465, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2945/10000, Loss: 0.6465, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2946/10000, Loss: 0.6465, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2947/10000, Loss: 0.6465, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2948/10000, Loss: 0.6465, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2949/10000, Loss: 0.6464, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2950/10000, Loss: 0.6464, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2951/10000, Loss: 0.6464, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2952/10000, Loss: 0.6464, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2953/10000, Loss: 0.6464, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2954/10000, Loss: 0.6463, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2955/10000, Loss: 0.6463, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2956/10000, Loss: 0.6463, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2957/10000, Loss: 0.6463, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2958/10000, Loss: 0.6463, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2959/10000, Loss: 0.6463, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2960/10000, Loss: 0.6462, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2961/10000, Loss: 0.6462, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2962/10000, Loss: 0.6462, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2963/10000, Loss: 0.6462, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2964/10000, Loss: 0.6462, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2965/10000, Loss: 0.6461, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2966/10000, Loss: 0.6461, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2967/10000, Loss: 0.6461, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2968/10000, Loss: 0.6461, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2969/10000, Loss: 0.6461, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2970/10000, Loss: 0.6461, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2971/10000, Loss: 0.6460, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2972/10000, Loss: 0.6460, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2973/10000, Loss: 0.6460, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2974/10000, Loss: 0.6460, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2975/10000, Loss: 0.6460, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2976/10000, Loss: 0.6459, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2977/10000, Loss: 0.6459, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2978/10000, Loss: 0.6459, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2979/10000, Loss: 0.6459, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2980/10000, Loss: 0.6459, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2981/10000, Loss: 0.6458, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2982/10000, Loss: 0.6458, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2983/10000, Loss: 0.6458, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2984/10000, Loss: 0.6458, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2985/10000, Loss: 0.6458, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2986/10000, Loss: 0.6458, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2987/10000, Loss: 0.6457, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2988/10000, Loss: 0.6457, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2989/10000, Loss: 0.6457, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2990/10000, Loss: 0.6457, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2991/10000, Loss: 0.6457, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2992/10000, Loss: 0.6456, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2993/10000, Loss: 0.6456, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2994/10000, Loss: 0.6456, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2995/10000, Loss: 0.6456, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2996/10000, Loss: 0.6456, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2997/10000, Loss: 0.6456, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2998/10000, Loss: 0.6455, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 2999/10000, Loss: 0.6455, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3000/10000, Loss: 0.6455, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3001/10000, Loss: 0.6455, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3002/10000, Loss: 0.6455, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3003/10000, Loss: 0.6454, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3004/10000, Loss: 0.6454, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3005/10000, Loss: 0.6454, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3006/10000, Loss: 0.6454, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3007/10000, Loss: 0.6454, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3008/10000, Loss: 0.6454, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3009/10000, Loss: 0.6453, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3010/10000, Loss: 0.6453, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3011/10000, Loss: 0.6453, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3012/10000, Loss: 0.6453, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3013/10000, Loss: 0.6453, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3014/10000, Loss: 0.6452, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3015/10000, Loss: 0.6452, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3016/10000, Loss: 0.6452, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3017/10000, Loss: 0.6452, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3018/10000, Loss: 0.6452, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3019/10000, Loss: 0.6451, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3020/10000, Loss: 0.6451, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3021/10000, Loss: 0.6451, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3022/10000, Loss: 0.6451, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3023/10000, Loss: 0.6451, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3024/10000, Loss: 0.6451, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3025/10000, Loss: 0.6450, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3026/10000, Loss: 0.6450, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3027/10000, Loss: 0.6450, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3028/10000, Loss: 0.6450, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3029/10000, Loss: 0.6450, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3030/10000, Loss: 0.6449, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3031/10000, Loss: 0.6449, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3032/10000, Loss: 0.6449, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3033/10000, Loss: 0.6449, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3034/10000, Loss: 0.6449, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3035/10000, Loss: 0.6449, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3036/10000, Loss: 0.6448, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3037/10000, Loss: 0.6448, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3038/10000, Loss: 0.6448, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3039/10000, Loss: 0.6448, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3040/10000, Loss: 0.6448, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3041/10000, Loss: 0.6447, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3042/10000, Loss: 0.6447, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3043/10000, Loss: 0.6447, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3044/10000, Loss: 0.6447, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3045/10000, Loss: 0.6447, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3046/10000, Loss: 0.6447, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3047/10000, Loss: 0.6446, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3048/10000, Loss: 0.6446, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3049/10000, Loss: 0.6446, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3050/10000, Loss: 0.6446, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3051/10000, Loss: 0.6446, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3052/10000, Loss: 0.6445, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3053/10000, Loss: 0.6445, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3054/10000, Loss: 0.6445, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3055/10000, Loss: 0.6445, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3056/10000, Loss: 0.6445, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3057/10000, Loss: 0.6445, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3058/10000, Loss: 0.6444, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3059/10000, Loss: 0.6444, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3060/10000, Loss: 0.6444, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3061/10000, Loss: 0.6444, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3062/10000, Loss: 0.6444, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3063/10000, Loss: 0.6443, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3064/10000, Loss: 0.6443, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3065/10000, Loss: 0.6443, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3066/10000, Loss: 0.6443, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3067/10000, Loss: 0.6443, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3068/10000, Loss: 0.6443, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3069/10000, Loss: 0.6442, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3070/10000, Loss: 0.6442, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3071/10000, Loss: 0.6442, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3072/10000, Loss: 0.6442, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3073/10000, Loss: 0.6442, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3074/10000, Loss: 0.6442, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3075/10000, Loss: 0.6441, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3076/10000, Loss: 0.6441, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3077/10000, Loss: 0.6441, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3078/10000, Loss: 0.6441, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3079/10000, Loss: 0.6441, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3080/10000, Loss: 0.6440, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3081/10000, Loss: 0.6440, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3082/10000, Loss: 0.6440, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3083/10000, Loss: 0.6440, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3084/10000, Loss: 0.6440, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3085/10000, Loss: 0.6440, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3086/10000, Loss: 0.6439, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3087/10000, Loss: 0.6439, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3088/10000, Loss: 0.6439, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3089/10000, Loss: 0.6439, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3090/10000, Loss: 0.6439, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3091/10000, Loss: 0.6438, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3092/10000, Loss: 0.6438, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3093/10000, Loss: 0.6438, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3094/10000, Loss: 0.6438, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3095/10000, Loss: 0.6438, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3096/10000, Loss: 0.6438, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3097/10000, Loss: 0.6437, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3098/10000, Loss: 0.6437, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3099/10000, Loss: 0.6437, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3100/10000, Loss: 0.6437, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3101/10000, Loss: 0.6437, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3102/10000, Loss: 0.6437, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3103/10000, Loss: 0.6436, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3104/10000, Loss: 0.6436, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3105/10000, Loss: 0.6436, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3106/10000, Loss: 0.6436, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3107/10000, Loss: 0.6436, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3108/10000, Loss: 0.6435, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3109/10000, Loss: 0.6435, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3110/10000, Loss: 0.6435, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3111/10000, Loss: 0.6435, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3112/10000, Loss: 0.6435, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3113/10000, Loss: 0.6435, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3114/10000, Loss: 0.6434, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3115/10000, Loss: 0.6434, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3116/10000, Loss: 0.6434, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3117/10000, Loss: 0.6434, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3118/10000, Loss: 0.6434, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3119/10000, Loss: 0.6433, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3120/10000, Loss: 0.6433, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3121/10000, Loss: 0.6433, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3122/10000, Loss: 0.6433, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3123/10000, Loss: 0.6433, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3124/10000, Loss: 0.6433, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3125/10000, Loss: 0.6432, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3126/10000, Loss: 0.6432, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3127/10000, Loss: 0.6432, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3128/10000, Loss: 0.6432, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3129/10000, Loss: 0.6432, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3130/10000, Loss: 0.6432, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3131/10000, Loss: 0.6431, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3132/10000, Loss: 0.6431, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3133/10000, Loss: 0.6431, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3134/10000, Loss: 0.6431, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3135/10000, Loss: 0.6431, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3136/10000, Loss: 0.6430, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3137/10000, Loss: 0.6430, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3138/10000, Loss: 0.6430, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3139/10000, Loss: 0.6430, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3140/10000, Loss: 0.6430, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3141/10000, Loss: 0.6430, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3142/10000, Loss: 0.6429, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3143/10000, Loss: 0.6429, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3144/10000, Loss: 0.6429, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3145/10000, Loss: 0.6429, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3146/10000, Loss: 0.6429, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3147/10000, Loss: 0.6429, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3148/10000, Loss: 0.6428, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3149/10000, Loss: 0.6428, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3150/10000, Loss: 0.6428, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3151/10000, Loss: 0.6428, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3152/10000, Loss: 0.6428, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3153/10000, Loss: 0.6428, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3154/10000, Loss: 0.6427, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3155/10000, Loss: 0.6427, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3156/10000, Loss: 0.6427, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3157/10000, Loss: 0.6427, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3158/10000, Loss: 0.6427, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3159/10000, Loss: 0.6426, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3160/10000, Loss: 0.6426, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3161/10000, Loss: 0.6426, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3162/10000, Loss: 0.6426, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3163/10000, Loss: 0.6426, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3164/10000, Loss: 0.6426, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3165/10000, Loss: 0.6425, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3166/10000, Loss: 0.6425, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3167/10000, Loss: 0.6425, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3168/10000, Loss: 0.6425, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3169/10000, Loss: 0.6425, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3170/10000, Loss: 0.6425, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3171/10000, Loss: 0.6424, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3172/10000, Loss: 0.6424, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3173/10000, Loss: 0.6424, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3174/10000, Loss: 0.6424, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3175/10000, Loss: 0.6424, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3176/10000, Loss: 0.6423, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3177/10000, Loss: 0.6423, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3178/10000, Loss: 0.6423, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3179/10000, Loss: 0.6423, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3180/10000, Loss: 0.6423, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3181/10000, Loss: 0.6423, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3182/10000, Loss: 0.6422, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3183/10000, Loss: 0.6422, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3184/10000, Loss: 0.6422, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3185/10000, Loss: 0.6422, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3186/10000, Loss: 0.6422, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3187/10000, Loss: 0.6422, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3188/10000, Loss: 0.6421, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3189/10000, Loss: 0.6421, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3190/10000, Loss: 0.6421, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3191/10000, Loss: 0.6421, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3192/10000, Loss: 0.6421, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3193/10000, Loss: 0.6421, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3194/10000, Loss: 0.6420, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3195/10000, Loss: 0.6420, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3196/10000, Loss: 0.6420, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3197/10000, Loss: 0.6420, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3198/10000, Loss: 0.6420, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3199/10000, Loss: 0.6420, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3200/10000, Loss: 0.6419, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3201/10000, Loss: 0.6419, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3202/10000, Loss: 0.6419, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3203/10000, Loss: 0.6419, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3204/10000, Loss: 0.6419, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3205/10000, Loss: 0.6418, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3206/10000, Loss: 0.6418, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3207/10000, Loss: 0.6418, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3208/10000, Loss: 0.6418, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3209/10000, Loss: 0.6418, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3210/10000, Loss: 0.6418, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3211/10000, Loss: 0.6417, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3212/10000, Loss: 0.6417, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3213/10000, Loss: 0.6417, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3214/10000, Loss: 0.6417, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3215/10000, Loss: 0.6417, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3216/10000, Loss: 0.6417, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3217/10000, Loss: 0.6416, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3218/10000, Loss: 0.6416, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3219/10000, Loss: 0.6416, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3220/10000, Loss: 0.6416, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3221/10000, Loss: 0.6416, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3222/10000, Loss: 0.6416, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3223/10000, Loss: 0.6415, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3224/10000, Loss: 0.6415, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3225/10000, Loss: 0.6415, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3226/10000, Loss: 0.6415, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3227/10000, Loss: 0.6415, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3228/10000, Loss: 0.6415, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3229/10000, Loss: 0.6414, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3230/10000, Loss: 0.6414, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3231/10000, Loss: 0.6414, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3232/10000, Loss: 0.6414, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3233/10000, Loss: 0.6414, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3234/10000, Loss: 0.6413, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3235/10000, Loss: 0.6413, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3236/10000, Loss: 0.6413, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3237/10000, Loss: 0.6413, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3238/10000, Loss: 0.6413, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3239/10000, Loss: 0.6413, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3240/10000, Loss: 0.6412, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3241/10000, Loss: 0.6412, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3242/10000, Loss: 0.6412, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3243/10000, Loss: 0.6412, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3244/10000, Loss: 0.6412, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3245/10000, Loss: 0.6412, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3246/10000, Loss: 0.6411, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3247/10000, Loss: 0.6411, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3248/10000, Loss: 0.6411, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3249/10000, Loss: 0.6411, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3250/10000, Loss: 0.6411, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3251/10000, Loss: 0.6411, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3252/10000, Loss: 0.6410, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3253/10000, Loss: 0.6410, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3254/10000, Loss: 0.6410, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3255/10000, Loss: 0.6410, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3256/10000, Loss: 0.6410, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3257/10000, Loss: 0.6410, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3258/10000, Loss: 0.6409, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3259/10000, Loss: 0.6409, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3260/10000, Loss: 0.6409, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3261/10000, Loss: 0.6409, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3262/10000, Loss: 0.6409, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3263/10000, Loss: 0.6409, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3264/10000, Loss: 0.6408, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3265/10000, Loss: 0.6408, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3266/10000, Loss: 0.6408, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3267/10000, Loss: 0.6408, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3268/10000, Loss: 0.6408, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3269/10000, Loss: 0.6408, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3270/10000, Loss: 0.6407, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3271/10000, Loss: 0.6407, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3272/10000, Loss: 0.6407, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3273/10000, Loss: 0.6407, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3274/10000, Loss: 0.6407, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3275/10000, Loss: 0.6407, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3276/10000, Loss: 0.6406, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3277/10000, Loss: 0.6406, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3278/10000, Loss: 0.6406, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3279/10000, Loss: 0.6406, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3280/10000, Loss: 0.6406, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3281/10000, Loss: 0.6406, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3282/10000, Loss: 0.6405, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3283/10000, Loss: 0.6405, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3284/10000, Loss: 0.6405, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3285/10000, Loss: 0.6405, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3286/10000, Loss: 0.6405, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3287/10000, Loss: 0.6405, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3288/10000, Loss: 0.6404, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3289/10000, Loss: 0.6404, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3290/10000, Loss: 0.6404, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3291/10000, Loss: 0.6404, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3292/10000, Loss: 0.6404, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3293/10000, Loss: 0.6404, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3294/10000, Loss: 0.6403, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3295/10000, Loss: 0.6403, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3296/10000, Loss: 0.6403, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3297/10000, Loss: 0.6403, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3298/10000, Loss: 0.6403, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3299/10000, Loss: 0.6403, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3300/10000, Loss: 0.6402, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3301/10000, Loss: 0.6402, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3302/10000, Loss: 0.6402, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3303/10000, Loss: 0.6402, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3304/10000, Loss: 0.6402, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3305/10000, Loss: 0.6401, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3306/10000, Loss: 0.6401, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3307/10000, Loss: 0.6401, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3308/10000, Loss: 0.6401, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3309/10000, Loss: 0.6401, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3310/10000, Loss: 0.6401, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3311/10000, Loss: 0.6400, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3312/10000, Loss: 0.6400, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3313/10000, Loss: 0.6400, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3314/10000, Loss: 0.6400, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3315/10000, Loss: 0.6400, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3316/10000, Loss: 0.6400, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3317/10000, Loss: 0.6399, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3318/10000, Loss: 0.6399, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3319/10000, Loss: 0.6399, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3320/10000, Loss: 0.6399, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3321/10000, Loss: 0.6399, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3322/10000, Loss: 0.6399, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3323/10000, Loss: 0.6399, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3324/10000, Loss: 0.6398, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3325/10000, Loss: 0.6398, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3326/10000, Loss: 0.6398, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3327/10000, Loss: 0.6398, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3328/10000, Loss: 0.6398, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3329/10000, Loss: 0.6398, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3330/10000, Loss: 0.6397, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3331/10000, Loss: 0.6397, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3332/10000, Loss: 0.6397, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3333/10000, Loss: 0.6397, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3334/10000, Loss: 0.6397, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3335/10000, Loss: 0.6397, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3336/10000, Loss: 0.6396, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3337/10000, Loss: 0.6396, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3338/10000, Loss: 0.6396, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3339/10000, Loss: 0.6396, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3340/10000, Loss: 0.6396, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3341/10000, Loss: 0.6396, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3342/10000, Loss: 0.6395, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3343/10000, Loss: 0.6395, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3344/10000, Loss: 0.6395, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3345/10000, Loss: 0.6395, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3346/10000, Loss: 0.6395, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3347/10000, Loss: 0.6395, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3348/10000, Loss: 0.6394, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3349/10000, Loss: 0.6394, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3350/10000, Loss: 0.6394, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3351/10000, Loss: 0.6394, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3352/10000, Loss: 0.6394, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3353/10000, Loss: 0.6394, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3354/10000, Loss: 0.6393, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3355/10000, Loss: 0.6393, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3356/10000, Loss: 0.6393, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3357/10000, Loss: 0.6393, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3358/10000, Loss: 0.6393, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3359/10000, Loss: 0.6393, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3360/10000, Loss: 0.6392, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3361/10000, Loss: 0.6392, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3362/10000, Loss: 0.6392, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3363/10000, Loss: 0.6392, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3364/10000, Loss: 0.6392, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3365/10000, Loss: 0.6392, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3366/10000, Loss: 0.6391, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3367/10000, Loss: 0.6391, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3368/10000, Loss: 0.6391, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3369/10000, Loss: 0.6391, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3370/10000, Loss: 0.6391, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3371/10000, Loss: 0.6391, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3372/10000, Loss: 0.6390, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3373/10000, Loss: 0.6390, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3374/10000, Loss: 0.6390, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3375/10000, Loss: 0.6390, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3376/10000, Loss: 0.6390, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3377/10000, Loss: 0.6390, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3378/10000, Loss: 0.6389, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3379/10000, Loss: 0.6389, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3380/10000, Loss: 0.6389, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3381/10000, Loss: 0.6389, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3382/10000, Loss: 0.6389, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3383/10000, Loss: 0.6389, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3384/10000, Loss: 0.6388, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3385/10000, Loss: 0.6388, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3386/10000, Loss: 0.6388, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3387/10000, Loss: 0.6388, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3388/10000, Loss: 0.6388, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3389/10000, Loss: 0.6388, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3390/10000, Loss: 0.6387, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3391/10000, Loss: 0.6387, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3392/10000, Loss: 0.6387, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3393/10000, Loss: 0.6387, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3394/10000, Loss: 0.6387, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3395/10000, Loss: 0.6387, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3396/10000, Loss: 0.6387, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3397/10000, Loss: 0.6386, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3398/10000, Loss: 0.6386, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3399/10000, Loss: 0.6386, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3400/10000, Loss: 0.6386, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 3401/10000, Loss: 0.6386, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3402/10000, Loss: 0.6386, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3403/10000, Loss: 0.6385, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3404/10000, Loss: 0.6385, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3405/10000, Loss: 0.6385, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3406/10000, Loss: 0.6385, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3407/10000, Loss: 0.6385, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3408/10000, Loss: 0.6385, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3409/10000, Loss: 0.6384, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3410/10000, Loss: 0.6384, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3411/10000, Loss: 0.6384, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3412/10000, Loss: 0.6384, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3413/10000, Loss: 0.6384, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3414/10000, Loss: 0.6384, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3415/10000, Loss: 0.6383, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3416/10000, Loss: 0.6383, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3417/10000, Loss: 0.6383, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3418/10000, Loss: 0.6383, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3419/10000, Loss: 0.6383, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3420/10000, Loss: 0.6383, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3421/10000, Loss: 0.6382, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3422/10000, Loss: 0.6382, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3423/10000, Loss: 0.6382, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3424/10000, Loss: 0.6382, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3425/10000, Loss: 0.6382, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3426/10000, Loss: 0.6382, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3427/10000, Loss: 0.6382, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3428/10000, Loss: 0.6381, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3429/10000, Loss: 0.6381, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3430/10000, Loss: 0.6381, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3431/10000, Loss: 0.6381, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3432/10000, Loss: 0.6381, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3433/10000, Loss: 0.6381, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3434/10000, Loss: 0.6380, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3435/10000, Loss: 0.6380, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3436/10000, Loss: 0.6380, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3437/10000, Loss: 0.6380, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3438/10000, Loss: 0.6380, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3439/10000, Loss: 0.6380, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3440/10000, Loss: 0.6379, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3441/10000, Loss: 0.6379, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3442/10000, Loss: 0.6379, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3443/10000, Loss: 0.6379, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3444/10000, Loss: 0.6379, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3445/10000, Loss: 0.6379, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3446/10000, Loss: 0.6378, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3447/10000, Loss: 0.6378, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3448/10000, Loss: 0.6378, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3449/10000, Loss: 0.6378, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3450/10000, Loss: 0.6378, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3451/10000, Loss: 0.6378, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3452/10000, Loss: 0.6378, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3453/10000, Loss: 0.6377, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3454/10000, Loss: 0.6377, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3455/10000, Loss: 0.6377, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3456/10000, Loss: 0.6377, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3457/10000, Loss: 0.6377, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3458/10000, Loss: 0.6377, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3459/10000, Loss: 0.6376, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3460/10000, Loss: 0.6376, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3461/10000, Loss: 0.6376, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3462/10000, Loss: 0.6376, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3463/10000, Loss: 0.6376, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3464/10000, Loss: 0.6376, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3465/10000, Loss: 0.6375, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3466/10000, Loss: 0.6375, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3467/10000, Loss: 0.6375, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3468/10000, Loss: 0.6375, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3469/10000, Loss: 0.6375, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3470/10000, Loss: 0.6375, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3471/10000, Loss: 0.6374, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3472/10000, Loss: 0.6374, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3473/10000, Loss: 0.6374, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3474/10000, Loss: 0.6374, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3475/10000, Loss: 0.6374, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3476/10000, Loss: 0.6374, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3477/10000, Loss: 0.6374, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3478/10000, Loss: 0.6373, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3479/10000, Loss: 0.6373, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3480/10000, Loss: 0.6373, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3481/10000, Loss: 0.6373, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3482/10000, Loss: 0.6373, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3483/10000, Loss: 0.6373, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3484/10000, Loss: 0.6372, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3485/10000, Loss: 0.6372, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3486/10000, Loss: 0.6372, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3487/10000, Loss: 0.6372, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3488/10000, Loss: 0.6372, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3489/10000, Loss: 0.6372, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3490/10000, Loss: 0.6371, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3491/10000, Loss: 0.6371, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3492/10000, Loss: 0.6371, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3493/10000, Loss: 0.6371, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3494/10000, Loss: 0.6371, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3495/10000, Loss: 0.6371, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3496/10000, Loss: 0.6371, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3497/10000, Loss: 0.6370, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3498/10000, Loss: 0.6370, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3499/10000, Loss: 0.6370, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3500/10000, Loss: 0.6370, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3501/10000, Loss: 0.6370, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3502/10000, Loss: 0.6370, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3503/10000, Loss: 0.6369, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3504/10000, Loss: 0.6369, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3505/10000, Loss: 0.6369, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3506/10000, Loss: 0.6369, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3507/10000, Loss: 0.6369, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3508/10000, Loss: 0.6369, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3509/10000, Loss: 0.6368, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3510/10000, Loss: 0.6368, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3511/10000, Loss: 0.6368, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3512/10000, Loss: 0.6368, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3513/10000, Loss: 0.6368, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3514/10000, Loss: 0.6368, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3515/10000, Loss: 0.6368, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3516/10000, Loss: 0.6367, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3517/10000, Loss: 0.6367, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3518/10000, Loss: 0.6367, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3519/10000, Loss: 0.6367, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3520/10000, Loss: 0.6367, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3521/10000, Loss: 0.6367, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3522/10000, Loss: 0.6366, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3523/10000, Loss: 0.6366, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3524/10000, Loss: 0.6366, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3525/10000, Loss: 0.6366, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3526/10000, Loss: 0.6366, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3527/10000, Loss: 0.6366, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3528/10000, Loss: 0.6366, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3529/10000, Loss: 0.6365, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3530/10000, Loss: 0.6365, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3531/10000, Loss: 0.6365, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3532/10000, Loss: 0.6365, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3533/10000, Loss: 0.6365, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3534/10000, Loss: 0.6365, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3535/10000, Loss: 0.6364, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3536/10000, Loss: 0.6364, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3537/10000, Loss: 0.6364, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3538/10000, Loss: 0.6364, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3539/10000, Loss: 0.6364, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3540/10000, Loss: 0.6364, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3541/10000, Loss: 0.6364, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3542/10000, Loss: 0.6363, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3543/10000, Loss: 0.6363, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3544/10000, Loss: 0.6363, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3545/10000, Loss: 0.6363, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3546/10000, Loss: 0.6363, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3547/10000, Loss: 0.6363, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3548/10000, Loss: 0.6362, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3549/10000, Loss: 0.6362, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3550/10000, Loss: 0.6362, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3551/10000, Loss: 0.6362, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3552/10000, Loss: 0.6362, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3553/10000, Loss: 0.6362, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3554/10000, Loss: 0.6361, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3555/10000, Loss: 0.6361, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3556/10000, Loss: 0.6361, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3557/10000, Loss: 0.6361, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3558/10000, Loss: 0.6361, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3559/10000, Loss: 0.6361, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3560/10000, Loss: 0.6361, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3561/10000, Loss: 0.6360, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3562/10000, Loss: 0.6360, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3563/10000, Loss: 0.6360, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3564/10000, Loss: 0.6360, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3565/10000, Loss: 0.6360, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3566/10000, Loss: 0.6360, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3567/10000, Loss: 0.6359, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3568/10000, Loss: 0.6359, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3569/10000, Loss: 0.6359, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3570/10000, Loss: 0.6359, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3571/10000, Loss: 0.6359, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3572/10000, Loss: 0.6359, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3573/10000, Loss: 0.6359, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3574/10000, Loss: 0.6358, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3575/10000, Loss: 0.6358, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3576/10000, Loss: 0.6358, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3577/10000, Loss: 0.6358, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3578/10000, Loss: 0.6358, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3579/10000, Loss: 0.6358, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3580/10000, Loss: 0.6357, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3581/10000, Loss: 0.6357, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3582/10000, Loss: 0.6357, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3583/10000, Loss: 0.6357, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3584/10000, Loss: 0.6357, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3585/10000, Loss: 0.6357, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3586/10000, Loss: 0.6357, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3587/10000, Loss: 0.6356, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3588/10000, Loss: 0.6356, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3589/10000, Loss: 0.6356, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3590/10000, Loss: 0.6356, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3591/10000, Loss: 0.6356, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3592/10000, Loss: 0.6356, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3593/10000, Loss: 0.6356, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3594/10000, Loss: 0.6355, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3595/10000, Loss: 0.6355, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3596/10000, Loss: 0.6355, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3597/10000, Loss: 0.6355, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3598/10000, Loss: 0.6355, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3599/10000, Loss: 0.6355, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3600/10000, Loss: 0.6354, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3601/10000, Loss: 0.6354, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3602/10000, Loss: 0.6354, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3603/10000, Loss: 0.6354, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3604/10000, Loss: 0.6354, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3605/10000, Loss: 0.6354, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3606/10000, Loss: 0.6354, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3607/10000, Loss: 0.6353, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3608/10000, Loss: 0.6353, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3609/10000, Loss: 0.6353, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3610/10000, Loss: 0.6353, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3611/10000, Loss: 0.6353, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3612/10000, Loss: 0.6353, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3613/10000, Loss: 0.6352, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3614/10000, Loss: 0.6352, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3615/10000, Loss: 0.6352, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3616/10000, Loss: 0.6352, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3617/10000, Loss: 0.6352, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3618/10000, Loss: 0.6352, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3619/10000, Loss: 0.6352, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3620/10000, Loss: 0.6351, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3621/10000, Loss: 0.6351, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3622/10000, Loss: 0.6351, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3623/10000, Loss: 0.6351, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3624/10000, Loss: 0.6351, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3625/10000, Loss: 0.6351, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3626/10000, Loss: 0.6350, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3627/10000, Loss: 0.6350, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3628/10000, Loss: 0.6350, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3629/10000, Loss: 0.6350, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3630/10000, Loss: 0.6350, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3631/10000, Loss: 0.6350, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3632/10000, Loss: 0.6350, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3633/10000, Loss: 0.6349, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3634/10000, Loss: 0.6349, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3635/10000, Loss: 0.6349, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3636/10000, Loss: 0.6349, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3637/10000, Loss: 0.6349, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3638/10000, Loss: 0.6349, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3639/10000, Loss: 0.6349, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3640/10000, Loss: 0.6348, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3641/10000, Loss: 0.6348, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3642/10000, Loss: 0.6348, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3643/10000, Loss: 0.6348, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3644/10000, Loss: 0.6348, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3645/10000, Loss: 0.6348, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3646/10000, Loss: 0.6347, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3647/10000, Loss: 0.6347, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3648/10000, Loss: 0.6347, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3649/10000, Loss: 0.6347, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3650/10000, Loss: 0.6347, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3651/10000, Loss: 0.6347, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3652/10000, Loss: 0.6347, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3653/10000, Loss: 0.6346, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3654/10000, Loss: 0.6346, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3655/10000, Loss: 0.6346, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3656/10000, Loss: 0.6346, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3657/10000, Loss: 0.6346, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3658/10000, Loss: 0.6346, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3659/10000, Loss: 0.6346, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3660/10000, Loss: 0.6345, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3661/10000, Loss: 0.6345, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3662/10000, Loss: 0.6345, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3663/10000, Loss: 0.6345, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3664/10000, Loss: 0.6345, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3665/10000, Loss: 0.6345, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3666/10000, Loss: 0.6344, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3667/10000, Loss: 0.6344, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3668/10000, Loss: 0.6344, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3669/10000, Loss: 0.6344, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3670/10000, Loss: 0.6344, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3671/10000, Loss: 0.6344, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3672/10000, Loss: 0.6344, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3673/10000, Loss: 0.6343, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3674/10000, Loss: 0.6343, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3675/10000, Loss: 0.6343, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3676/10000, Loss: 0.6343, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3677/10000, Loss: 0.6343, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3678/10000, Loss: 0.6343, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3679/10000, Loss: 0.6343, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3680/10000, Loss: 0.6342, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3681/10000, Loss: 0.6342, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3682/10000, Loss: 0.6342, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3683/10000, Loss: 0.6342, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3684/10000, Loss: 0.6342, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3685/10000, Loss: 0.6342, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3686/10000, Loss: 0.6342, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3687/10000, Loss: 0.6341, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3688/10000, Loss: 0.6341, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3689/10000, Loss: 0.6341, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3690/10000, Loss: 0.6341, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3691/10000, Loss: 0.6341, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3692/10000, Loss: 0.6341, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3693/10000, Loss: 0.6340, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3694/10000, Loss: 0.6340, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3695/10000, Loss: 0.6340, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3696/10000, Loss: 0.6340, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3697/10000, Loss: 0.6340, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3698/10000, Loss: 0.6340, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3699/10000, Loss: 0.6340, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3700/10000, Loss: 0.6339, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3701/10000, Loss: 0.6339, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3702/10000, Loss: 0.6339, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3703/10000, Loss: 0.6339, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3704/10000, Loss: 0.6339, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3705/10000, Loss: 0.6339, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3706/10000, Loss: 0.6339, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3707/10000, Loss: 0.6338, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3708/10000, Loss: 0.6338, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3709/10000, Loss: 0.6338, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3710/10000, Loss: 0.6338, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3711/10000, Loss: 0.6338, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3712/10000, Loss: 0.6338, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3713/10000, Loss: 0.6338, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3714/10000, Loss: 0.6337, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3715/10000, Loss: 0.6337, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3716/10000, Loss: 0.6337, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3717/10000, Loss: 0.6337, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3718/10000, Loss: 0.6337, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3719/10000, Loss: 0.6337, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3720/10000, Loss: 0.6336, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3721/10000, Loss: 0.6336, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3722/10000, Loss: 0.6336, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3723/10000, Loss: 0.6336, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3724/10000, Loss: 0.6336, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3725/10000, Loss: 0.6336, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3726/10000, Loss: 0.6336, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3727/10000, Loss: 0.6335, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3728/10000, Loss: 0.6335, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3729/10000, Loss: 0.6335, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3730/10000, Loss: 0.6335, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3731/10000, Loss: 0.6335, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3732/10000, Loss: 0.6335, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3733/10000, Loss: 0.6335, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3734/10000, Loss: 0.6334, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3735/10000, Loss: 0.6334, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3736/10000, Loss: 0.6334, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3737/10000, Loss: 0.6334, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3738/10000, Loss: 0.6334, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3739/10000, Loss: 0.6334, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3740/10000, Loss: 0.6334, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3741/10000, Loss: 0.6333, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3742/10000, Loss: 0.6333, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3743/10000, Loss: 0.6333, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3744/10000, Loss: 0.6333, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3745/10000, Loss: 0.6333, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3746/10000, Loss: 0.6333, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3747/10000, Loss: 0.6333, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3748/10000, Loss: 0.6332, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3749/10000, Loss: 0.6332, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3750/10000, Loss: 0.6332, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3751/10000, Loss: 0.6332, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3752/10000, Loss: 0.6332, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3753/10000, Loss: 0.6332, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3754/10000, Loss: 0.6332, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3755/10000, Loss: 0.6331, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3756/10000, Loss: 0.6331, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3757/10000, Loss: 0.6331, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3758/10000, Loss: 0.6331, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3759/10000, Loss: 0.6331, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3760/10000, Loss: 0.6331, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3761/10000, Loss: 0.6331, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3762/10000, Loss: 0.6330, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3763/10000, Loss: 0.6330, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3764/10000, Loss: 0.6330, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3765/10000, Loss: 0.6330, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3766/10000, Loss: 0.6330, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3767/10000, Loss: 0.6330, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3768/10000, Loss: 0.6329, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3769/10000, Loss: 0.6329, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3770/10000, Loss: 0.6329, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3771/10000, Loss: 0.6329, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3772/10000, Loss: 0.6329, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3773/10000, Loss: 0.6329, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3774/10000, Loss: 0.6329, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3775/10000, Loss: 0.6328, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3776/10000, Loss: 0.6328, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3777/10000, Loss: 0.6328, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3778/10000, Loss: 0.6328, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3779/10000, Loss: 0.6328, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3780/10000, Loss: 0.6328, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3781/10000, Loss: 0.6328, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3782/10000, Loss: 0.6327, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3783/10000, Loss: 0.6327, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3784/10000, Loss: 0.6327, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3785/10000, Loss: 0.6327, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3786/10000, Loss: 0.6327, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3787/10000, Loss: 0.6327, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3788/10000, Loss: 0.6327, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3789/10000, Loss: 0.6326, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3790/10000, Loss: 0.6326, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3791/10000, Loss: 0.6326, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3792/10000, Loss: 0.6326, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3793/10000, Loss: 0.6326, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3794/10000, Loss: 0.6326, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3795/10000, Loss: 0.6326, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3796/10000, Loss: 0.6325, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3797/10000, Loss: 0.6325, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3798/10000, Loss: 0.6325, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3799/10000, Loss: 0.6325, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3800/10000, Loss: 0.6325, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3801/10000, Loss: 0.6325, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3802/10000, Loss: 0.6325, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3803/10000, Loss: 0.6324, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3804/10000, Loss: 0.6324, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3805/10000, Loss: 0.6324, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3806/10000, Loss: 0.6324, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3807/10000, Loss: 0.6324, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3808/10000, Loss: 0.6324, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3809/10000, Loss: 0.6324, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3810/10000, Loss: 0.6323, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3811/10000, Loss: 0.6323, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3812/10000, Loss: 0.6323, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3813/10000, Loss: 0.6323, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3814/10000, Loss: 0.6323, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3815/10000, Loss: 0.6323, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3816/10000, Loss: 0.6323, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3817/10000, Loss: 0.6322, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3818/10000, Loss: 0.6322, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3819/10000, Loss: 0.6322, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3820/10000, Loss: 0.6322, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3821/10000, Loss: 0.6322, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3822/10000, Loss: 0.6322, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3823/10000, Loss: 0.6322, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3824/10000, Loss: 0.6321, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3825/10000, Loss: 0.6321, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3826/10000, Loss: 0.6321, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3827/10000, Loss: 0.6321, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3828/10000, Loss: 0.6321, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3829/10000, Loss: 0.6321, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3830/10000, Loss: 0.6321, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3831/10000, Loss: 0.6320, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3832/10000, Loss: 0.6320, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3833/10000, Loss: 0.6320, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3834/10000, Loss: 0.6320, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3835/10000, Loss: 0.6320, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3836/10000, Loss: 0.6320, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3837/10000, Loss: 0.6320, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3838/10000, Loss: 0.6319, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3839/10000, Loss: 0.6319, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3840/10000, Loss: 0.6319, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3841/10000, Loss: 0.6319, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3842/10000, Loss: 0.6319, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3843/10000, Loss: 0.6319, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3844/10000, Loss: 0.6319, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3845/10000, Loss: 0.6318, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3846/10000, Loss: 0.6318, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3847/10000, Loss: 0.6318, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3848/10000, Loss: 0.6318, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3849/10000, Loss: 0.6318, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3850/10000, Loss: 0.6318, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3851/10000, Loss: 0.6318, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3852/10000, Loss: 0.6318, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3853/10000, Loss: 0.6317, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3854/10000, Loss: 0.6317, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3855/10000, Loss: 0.6317, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3856/10000, Loss: 0.6317, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3857/10000, Loss: 0.6317, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3858/10000, Loss: 0.6317, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3859/10000, Loss: 0.6317, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3860/10000, Loss: 0.6316, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3861/10000, Loss: 0.6316, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3862/10000, Loss: 0.6316, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3863/10000, Loss: 0.6316, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3864/10000, Loss: 0.6316, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3865/10000, Loss: 0.6316, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3866/10000, Loss: 0.6316, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3867/10000, Loss: 0.6315, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3868/10000, Loss: 0.6315, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3869/10000, Loss: 0.6315, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3870/10000, Loss: 0.6315, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3871/10000, Loss: 0.6315, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3872/10000, Loss: 0.6315, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3873/10000, Loss: 0.6315, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3874/10000, Loss: 0.6314, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3875/10000, Loss: 0.6314, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3876/10000, Loss: 0.6314, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3877/10000, Loss: 0.6314, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3878/10000, Loss: 0.6314, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3879/10000, Loss: 0.6314, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3880/10000, Loss: 0.6314, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3881/10000, Loss: 0.6313, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3882/10000, Loss: 0.6313, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3883/10000, Loss: 0.6313, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3884/10000, Loss: 0.6313, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3885/10000, Loss: 0.6313, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3886/10000, Loss: 0.6313, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3887/10000, Loss: 0.6313, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3888/10000, Loss: 0.6312, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3889/10000, Loss: 0.6312, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3890/10000, Loss: 0.6312, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3891/10000, Loss: 0.6312, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3892/10000, Loss: 0.6312, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3893/10000, Loss: 0.6312, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3894/10000, Loss: 0.6312, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3895/10000, Loss: 0.6311, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3896/10000, Loss: 0.6311, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3897/10000, Loss: 0.6311, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3898/10000, Loss: 0.6311, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3899/10000, Loss: 0.6311, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3900/10000, Loss: 0.6311, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3901/10000, Loss: 0.6311, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3902/10000, Loss: 0.6311, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3903/10000, Loss: 0.6310, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3904/10000, Loss: 0.6310, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3905/10000, Loss: 0.6310, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3906/10000, Loss: 0.6310, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3907/10000, Loss: 0.6310, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3908/10000, Loss: 0.6310, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3909/10000, Loss: 0.6310, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3910/10000, Loss: 0.6309, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3911/10000, Loss: 0.6309, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3912/10000, Loss: 0.6309, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3913/10000, Loss: 0.6309, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3914/10000, Loss: 0.6309, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3915/10000, Loss: 0.6309, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3916/10000, Loss: 0.6309, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3917/10000, Loss: 0.6308, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3918/10000, Loss: 0.6308, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3919/10000, Loss: 0.6308, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3920/10000, Loss: 0.6308, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3921/10000, Loss: 0.6308, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3922/10000, Loss: 0.6308, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3923/10000, Loss: 0.6308, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3924/10000, Loss: 0.6307, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3925/10000, Loss: 0.6307, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3926/10000, Loss: 0.6307, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3927/10000, Loss: 0.6307, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3928/10000, Loss: 0.6307, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3929/10000, Loss: 0.6307, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3930/10000, Loss: 0.6307, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3931/10000, Loss: 0.6307, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3932/10000, Loss: 0.6306, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3933/10000, Loss: 0.6306, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3934/10000, Loss: 0.6306, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3935/10000, Loss: 0.6306, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3936/10000, Loss: 0.6306, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3937/10000, Loss: 0.6306, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3938/10000, Loss: 0.6306, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3939/10000, Loss: 0.6305, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3940/10000, Loss: 0.6305, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3941/10000, Loss: 0.6305, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3942/10000, Loss: 0.6305, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3943/10000, Loss: 0.6305, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3944/10000, Loss: 0.6305, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3945/10000, Loss: 0.6305, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3946/10000, Loss: 0.6304, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3947/10000, Loss: 0.6304, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3948/10000, Loss: 0.6304, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3949/10000, Loss: 0.6304, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3950/10000, Loss: 0.6304, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3951/10000, Loss: 0.6304, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3952/10000, Loss: 0.6304, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3953/10000, Loss: 0.6304, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3954/10000, Loss: 0.6303, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3955/10000, Loss: 0.6303, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3956/10000, Loss: 0.6303, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3957/10000, Loss: 0.6303, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3958/10000, Loss: 0.6303, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3959/10000, Loss: 0.6303, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3960/10000, Loss: 0.6303, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3961/10000, Loss: 0.6302, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3962/10000, Loss: 0.6302, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3963/10000, Loss: 0.6302, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3964/10000, Loss: 0.6302, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3965/10000, Loss: 0.6302, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3966/10000, Loss: 0.6302, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3967/10000, Loss: 0.6302, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3968/10000, Loss: 0.6301, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3969/10000, Loss: 0.6301, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3970/10000, Loss: 0.6301, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3971/10000, Loss: 0.6301, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3972/10000, Loss: 0.6301, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3973/10000, Loss: 0.6301, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3974/10000, Loss: 0.6301, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3975/10000, Loss: 0.6301, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3976/10000, Loss: 0.6300, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3977/10000, Loss: 0.6300, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3978/10000, Loss: 0.6300, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3979/10000, Loss: 0.6300, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3980/10000, Loss: 0.6300, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3981/10000, Loss: 0.6300, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3982/10000, Loss: 0.6300, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3983/10000, Loss: 0.6299, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3984/10000, Loss: 0.6299, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3985/10000, Loss: 0.6299, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3986/10000, Loss: 0.6299, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3987/10000, Loss: 0.6299, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3988/10000, Loss: 0.6299, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3989/10000, Loss: 0.6299, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3990/10000, Loss: 0.6298, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3991/10000, Loss: 0.6298, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3992/10000, Loss: 0.6298, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3993/10000, Loss: 0.6298, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3994/10000, Loss: 0.6298, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3995/10000, Loss: 0.6298, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3996/10000, Loss: 0.6298, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3997/10000, Loss: 0.6298, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3998/10000, Loss: 0.6297, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 3999/10000, Loss: 0.6297, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4000/10000, Loss: 0.6297, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4001/10000, Loss: 0.6297, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4002/10000, Loss: 0.6297, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4003/10000, Loss: 0.6297, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4004/10000, Loss: 0.6297, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4005/10000, Loss: 0.6296, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4006/10000, Loss: 0.6296, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4007/10000, Loss: 0.6296, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4008/10000, Loss: 0.6296, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4009/10000, Loss: 0.6296, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4010/10000, Loss: 0.6296, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4011/10000, Loss: 0.6296, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4012/10000, Loss: 0.6296, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4013/10000, Loss: 0.6295, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4014/10000, Loss: 0.6295, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4015/10000, Loss: 0.6295, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4016/10000, Loss: 0.6295, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4017/10000, Loss: 0.6295, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4018/10000, Loss: 0.6295, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4019/10000, Loss: 0.6295, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4020/10000, Loss: 0.6294, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4021/10000, Loss: 0.6294, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4022/10000, Loss: 0.6294, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4023/10000, Loss: 0.6294, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4024/10000, Loss: 0.6294, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4025/10000, Loss: 0.6294, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4026/10000, Loss: 0.6294, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4027/10000, Loss: 0.6294, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4028/10000, Loss: 0.6293, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4029/10000, Loss: 0.6293, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4030/10000, Loss: 0.6293, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4031/10000, Loss: 0.6293, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4032/10000, Loss: 0.6293, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4033/10000, Loss: 0.6293, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4034/10000, Loss: 0.6293, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4035/10000, Loss: 0.6292, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4036/10000, Loss: 0.6292, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4037/10000, Loss: 0.6292, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4038/10000, Loss: 0.6292, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4039/10000, Loss: 0.6292, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4040/10000, Loss: 0.6292, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4041/10000, Loss: 0.6292, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4042/10000, Loss: 0.6292, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4043/10000, Loss: 0.6291, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4044/10000, Loss: 0.6291, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4045/10000, Loss: 0.6291, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4046/10000, Loss: 0.6291, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4047/10000, Loss: 0.6291, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4048/10000, Loss: 0.6291, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4049/10000, Loss: 0.6291, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4050/10000, Loss: 0.6290, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4051/10000, Loss: 0.6290, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4052/10000, Loss: 0.6290, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4053/10000, Loss: 0.6290, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4054/10000, Loss: 0.6290, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4055/10000, Loss: 0.6290, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4056/10000, Loss: 0.6290, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4057/10000, Loss: 0.6290, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4058/10000, Loss: 0.6289, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4059/10000, Loss: 0.6289, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4060/10000, Loss: 0.6289, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4061/10000, Loss: 0.6289, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4062/10000, Loss: 0.6289, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4063/10000, Loss: 0.6289, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4064/10000, Loss: 0.6289, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4065/10000, Loss: 0.6288, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4066/10000, Loss: 0.6288, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4067/10000, Loss: 0.6288, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4068/10000, Loss: 0.6288, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4069/10000, Loss: 0.6288, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4070/10000, Loss: 0.6288, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4071/10000, Loss: 0.6288, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4072/10000, Loss: 0.6288, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4073/10000, Loss: 0.6287, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4074/10000, Loss: 0.6287, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4075/10000, Loss: 0.6287, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4076/10000, Loss: 0.6287, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4077/10000, Loss: 0.6287, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4078/10000, Loss: 0.6287, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4079/10000, Loss: 0.6287, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4080/10000, Loss: 0.6287, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4081/10000, Loss: 0.6286, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4082/10000, Loss: 0.6286, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4083/10000, Loss: 0.6286, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4084/10000, Loss: 0.6286, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4085/10000, Loss: 0.6286, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4086/10000, Loss: 0.6286, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4087/10000, Loss: 0.6286, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4088/10000, Loss: 0.6285, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4089/10000, Loss: 0.6285, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4090/10000, Loss: 0.6285, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4091/10000, Loss: 0.6285, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4092/10000, Loss: 0.6285, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4093/10000, Loss: 0.6285, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4094/10000, Loss: 0.6285, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4095/10000, Loss: 0.6285, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4096/10000, Loss: 0.6284, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4097/10000, Loss: 0.6284, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4098/10000, Loss: 0.6284, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4099/10000, Loss: 0.6284, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4100/10000, Loss: 0.6284, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4101/10000, Loss: 0.6284, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4102/10000, Loss: 0.6284, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4103/10000, Loss: 0.6283, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4104/10000, Loss: 0.6283, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4105/10000, Loss: 0.6283, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4106/10000, Loss: 0.6283, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4107/10000, Loss: 0.6283, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4108/10000, Loss: 0.6283, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4109/10000, Loss: 0.6283, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4110/10000, Loss: 0.6283, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4111/10000, Loss: 0.6282, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4112/10000, Loss: 0.6282, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4113/10000, Loss: 0.6282, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4114/10000, Loss: 0.6282, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4115/10000, Loss: 0.6282, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4116/10000, Loss: 0.6282, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4117/10000, Loss: 0.6282, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4118/10000, Loss: 0.6282, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4119/10000, Loss: 0.6281, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4120/10000, Loss: 0.6281, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4121/10000, Loss: 0.6281, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4122/10000, Loss: 0.6281, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4123/10000, Loss: 0.6281, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4124/10000, Loss: 0.6281, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4125/10000, Loss: 0.6281, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4126/10000, Loss: 0.6281, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4127/10000, Loss: 0.6280, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4128/10000, Loss: 0.6280, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4129/10000, Loss: 0.6280, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4130/10000, Loss: 0.6280, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4131/10000, Loss: 0.6280, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4132/10000, Loss: 0.6280, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4133/10000, Loss: 0.6280, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4134/10000, Loss: 0.6279, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4135/10000, Loss: 0.6279, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4136/10000, Loss: 0.6279, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4137/10000, Loss: 0.6279, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4138/10000, Loss: 0.6279, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4139/10000, Loss: 0.6279, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4140/10000, Loss: 0.6279, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4141/10000, Loss: 0.6279, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4142/10000, Loss: 0.6278, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4143/10000, Loss: 0.6278, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4144/10000, Loss: 0.6278, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4145/10000, Loss: 0.6278, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4146/10000, Loss: 0.6278, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4147/10000, Loss: 0.6278, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4148/10000, Loss: 0.6278, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4149/10000, Loss: 0.6278, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4150/10000, Loss: 0.6277, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4151/10000, Loss: 0.6277, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4152/10000, Loss: 0.6277, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4153/10000, Loss: 0.6277, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4154/10000, Loss: 0.6277, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4155/10000, Loss: 0.6277, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4156/10000, Loss: 0.6277, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4157/10000, Loss: 0.6277, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4158/10000, Loss: 0.6276, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4159/10000, Loss: 0.6276, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4160/10000, Loss: 0.6276, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4161/10000, Loss: 0.6276, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4162/10000, Loss: 0.6276, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4163/10000, Loss: 0.6276, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4164/10000, Loss: 0.6276, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4165/10000, Loss: 0.6275, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4166/10000, Loss: 0.6275, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4167/10000, Loss: 0.6275, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4168/10000, Loss: 0.6275, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4169/10000, Loss: 0.6275, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4170/10000, Loss: 0.6275, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4171/10000, Loss: 0.6275, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4172/10000, Loss: 0.6275, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4173/10000, Loss: 0.6274, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4174/10000, Loss: 0.6274, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4175/10000, Loss: 0.6274, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4176/10000, Loss: 0.6274, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4177/10000, Loss: 0.6274, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4178/10000, Loss: 0.6274, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4179/10000, Loss: 0.6274, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4180/10000, Loss: 0.6274, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4181/10000, Loss: 0.6273, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4182/10000, Loss: 0.6273, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4183/10000, Loss: 0.6273, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4184/10000, Loss: 0.6273, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4185/10000, Loss: 0.6273, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4186/10000, Loss: 0.6273, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4187/10000, Loss: 0.6273, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4188/10000, Loss: 0.6273, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4189/10000, Loss: 0.6272, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4190/10000, Loss: 0.6272, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4191/10000, Loss: 0.6272, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4192/10000, Loss: 0.6272, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4193/10000, Loss: 0.6272, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4194/10000, Loss: 0.6272, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4195/10000, Loss: 0.6272, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4196/10000, Loss: 0.6272, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4197/10000, Loss: 0.6271, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4198/10000, Loss: 0.6271, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4199/10000, Loss: 0.6271, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4200/10000, Loss: 0.6271, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4201/10000, Loss: 0.6271, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4202/10000, Loss: 0.6271, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4203/10000, Loss: 0.6271, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4204/10000, Loss: 0.6271, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4205/10000, Loss: 0.6270, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4206/10000, Loss: 0.6270, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4207/10000, Loss: 0.6270, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4208/10000, Loss: 0.6270, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4209/10000, Loss: 0.6270, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4210/10000, Loss: 0.6270, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4211/10000, Loss: 0.6270, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4212/10000, Loss: 0.6270, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4213/10000, Loss: 0.6269, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4214/10000, Loss: 0.6269, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4215/10000, Loss: 0.6269, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4216/10000, Loss: 0.6269, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4217/10000, Loss: 0.6269, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4218/10000, Loss: 0.6269, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4219/10000, Loss: 0.6269, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4220/10000, Loss: 0.6269, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4221/10000, Loss: 0.6268, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4222/10000, Loss: 0.6268, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4223/10000, Loss: 0.6268, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4224/10000, Loss: 0.6268, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4225/10000, Loss: 0.6268, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4226/10000, Loss: 0.6268, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4227/10000, Loss: 0.6268, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4228/10000, Loss: 0.6268, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4229/10000, Loss: 0.6267, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4230/10000, Loss: 0.6267, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4231/10000, Loss: 0.6267, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4232/10000, Loss: 0.6267, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4233/10000, Loss: 0.6267, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4234/10000, Loss: 0.6267, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4235/10000, Loss: 0.6267, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4236/10000, Loss: 0.6267, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4237/10000, Loss: 0.6266, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4238/10000, Loss: 0.6266, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4239/10000, Loss: 0.6266, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4240/10000, Loss: 0.6266, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4241/10000, Loss: 0.6266, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4242/10000, Loss: 0.6266, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4243/10000, Loss: 0.6266, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4244/10000, Loss: 0.6266, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4245/10000, Loss: 0.6265, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4246/10000, Loss: 0.6265, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4247/10000, Loss: 0.6265, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4248/10000, Loss: 0.6265, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4249/10000, Loss: 0.6265, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4250/10000, Loss: 0.6265, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4251/10000, Loss: 0.6265, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4252/10000, Loss: 0.6265, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4253/10000, Loss: 0.6264, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4254/10000, Loss: 0.6264, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4255/10000, Loss: 0.6264, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4256/10000, Loss: 0.6264, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4257/10000, Loss: 0.6264, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4258/10000, Loss: 0.6264, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4259/10000, Loss: 0.6264, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4260/10000, Loss: 0.6264, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4261/10000, Loss: 0.6263, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4262/10000, Loss: 0.6263, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4263/10000, Loss: 0.6263, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4264/10000, Loss: 0.6263, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4265/10000, Loss: 0.6263, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4266/10000, Loss: 0.6263, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4267/10000, Loss: 0.6263, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4268/10000, Loss: 0.6263, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4269/10000, Loss: 0.6262, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4270/10000, Loss: 0.6262, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4271/10000, Loss: 0.6262, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4272/10000, Loss: 0.6262, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4273/10000, Loss: 0.6262, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4274/10000, Loss: 0.6262, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4275/10000, Loss: 0.6262, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4276/10000, Loss: 0.6262, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4277/10000, Loss: 0.6261, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4278/10000, Loss: 0.6261, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4279/10000, Loss: 0.6261, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4280/10000, Loss: 0.6261, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4281/10000, Loss: 0.6261, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4282/10000, Loss: 0.6261, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4283/10000, Loss: 0.6261, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4284/10000, Loss: 0.6261, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4285/10000, Loss: 0.6260, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4286/10000, Loss: 0.6260, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4287/10000, Loss: 0.6260, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4288/10000, Loss: 0.6260, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4289/10000, Loss: 0.6260, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4290/10000, Loss: 0.6260, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4291/10000, Loss: 0.6260, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4292/10000, Loss: 0.6260, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4293/10000, Loss: 0.6259, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4294/10000, Loss: 0.6259, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4295/10000, Loss: 0.6259, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4296/10000, Loss: 0.6259, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4297/10000, Loss: 0.6259, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4298/10000, Loss: 0.6259, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4299/10000, Loss: 0.6259, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4300/10000, Loss: 0.6259, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4301/10000, Loss: 0.6258, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4302/10000, Loss: 0.6258, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4303/10000, Loss: 0.6258, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4304/10000, Loss: 0.6258, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4305/10000, Loss: 0.6258, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4306/10000, Loss: 0.6258, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4307/10000, Loss: 0.6258, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4308/10000, Loss: 0.6258, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4309/10000, Loss: 0.6257, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4310/10000, Loss: 0.6257, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4311/10000, Loss: 0.6257, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4312/10000, Loss: 0.6257, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4313/10000, Loss: 0.6257, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4314/10000, Loss: 0.6257, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4315/10000, Loss: 0.6257, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4316/10000, Loss: 0.6257, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4317/10000, Loss: 0.6257, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4318/10000, Loss: 0.6256, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4319/10000, Loss: 0.6256, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4320/10000, Loss: 0.6256, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4321/10000, Loss: 0.6256, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4322/10000, Loss: 0.6256, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4323/10000, Loss: 0.6256, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4324/10000, Loss: 0.6256, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4325/10000, Loss: 0.6256, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4326/10000, Loss: 0.6255, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4327/10000, Loss: 0.6255, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4328/10000, Loss: 0.6255, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4329/10000, Loss: 0.6255, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4330/10000, Loss: 0.6255, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4331/10000, Loss: 0.6255, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4332/10000, Loss: 0.6255, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4333/10000, Loss: 0.6255, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4334/10000, Loss: 0.6254, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4335/10000, Loss: 0.6254, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4336/10000, Loss: 0.6254, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4337/10000, Loss: 0.6254, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4338/10000, Loss: 0.6254, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4339/10000, Loss: 0.6254, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4340/10000, Loss: 0.6254, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4341/10000, Loss: 0.6254, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4342/10000, Loss: 0.6253, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4343/10000, Loss: 0.6253, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4344/10000, Loss: 0.6253, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4345/10000, Loss: 0.6253, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4346/10000, Loss: 0.6253, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4347/10000, Loss: 0.6253, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4348/10000, Loss: 0.6253, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4349/10000, Loss: 0.6253, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4350/10000, Loss: 0.6253, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4351/10000, Loss: 0.6252, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4352/10000, Loss: 0.6252, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4353/10000, Loss: 0.6252, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4354/10000, Loss: 0.6252, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4355/10000, Loss: 0.6252, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4356/10000, Loss: 0.6252, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4357/10000, Loss: 0.6252, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4358/10000, Loss: 0.6252, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4359/10000, Loss: 0.6251, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4360/10000, Loss: 0.6251, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4361/10000, Loss: 0.6251, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4362/10000, Loss: 0.6251, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4363/10000, Loss: 0.6251, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4364/10000, Loss: 0.6251, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4365/10000, Loss: 0.6251, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4366/10000, Loss: 0.6251, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4367/10000, Loss: 0.6250, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4368/10000, Loss: 0.6250, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4369/10000, Loss: 0.6250, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4370/10000, Loss: 0.6250, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4371/10000, Loss: 0.6250, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4372/10000, Loss: 0.6250, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4373/10000, Loss: 0.6250, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4374/10000, Loss: 0.6250, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4375/10000, Loss: 0.6250, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4376/10000, Loss: 0.6249, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4377/10000, Loss: 0.6249, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4378/10000, Loss: 0.6249, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4379/10000, Loss: 0.6249, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4380/10000, Loss: 0.6249, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4381/10000, Loss: 0.6249, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4382/10000, Loss: 0.6249, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4383/10000, Loss: 0.6249, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4384/10000, Loss: 0.6248, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4385/10000, Loss: 0.6248, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4386/10000, Loss: 0.6248, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4387/10000, Loss: 0.6248, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4388/10000, Loss: 0.6248, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4389/10000, Loss: 0.6248, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4390/10000, Loss: 0.6248, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4391/10000, Loss: 0.6248, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4392/10000, Loss: 0.6247, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4393/10000, Loss: 0.6247, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4394/10000, Loss: 0.6247, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4395/10000, Loss: 0.6247, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4396/10000, Loss: 0.6247, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4397/10000, Loss: 0.6247, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4398/10000, Loss: 0.6247, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4399/10000, Loss: 0.6247, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4400/10000, Loss: 0.6247, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4401/10000, Loss: 0.6246, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4402/10000, Loss: 0.6246, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4403/10000, Loss: 0.6246, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4404/10000, Loss: 0.6246, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4405/10000, Loss: 0.6246, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4406/10000, Loss: 0.6246, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4407/10000, Loss: 0.6246, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4408/10000, Loss: 0.6246, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4409/10000, Loss: 0.6245, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4410/10000, Loss: 0.6245, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4411/10000, Loss: 0.6245, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4412/10000, Loss: 0.6245, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4413/10000, Loss: 0.6245, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4414/10000, Loss: 0.6245, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4415/10000, Loss: 0.6245, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4416/10000, Loss: 0.6245, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4417/10000, Loss: 0.6245, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4418/10000, Loss: 0.6244, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4419/10000, Loss: 0.6244, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4420/10000, Loss: 0.6244, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4421/10000, Loss: 0.6244, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4422/10000, Loss: 0.6244, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4423/10000, Loss: 0.6244, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4424/10000, Loss: 0.6244, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4425/10000, Loss: 0.6244, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4426/10000, Loss: 0.6243, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4427/10000, Loss: 0.6243, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4428/10000, Loss: 0.6243, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4429/10000, Loss: 0.6243, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4430/10000, Loss: 0.6243, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4431/10000, Loss: 0.6243, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4432/10000, Loss: 0.6243, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4433/10000, Loss: 0.6243, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4434/10000, Loss: 0.6243, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4435/10000, Loss: 0.6242, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4436/10000, Loss: 0.6242, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4437/10000, Loss: 0.6242, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4438/10000, Loss: 0.6242, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4439/10000, Loss: 0.6242, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4440/10000, Loss: 0.6242, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4441/10000, Loss: 0.6242, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4442/10000, Loss: 0.6242, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4443/10000, Loss: 0.6241, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4444/10000, Loss: 0.6241, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4445/10000, Loss: 0.6241, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4446/10000, Loss: 0.6241, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4447/10000, Loss: 0.6241, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4448/10000, Loss: 0.6241, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4449/10000, Loss: 0.6241, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4450/10000, Loss: 0.6241, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4451/10000, Loss: 0.6241, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4452/10000, Loss: 0.6240, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4453/10000, Loss: 0.6240, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4454/10000, Loss: 0.6240, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4455/10000, Loss: 0.6240, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4456/10000, Loss: 0.6240, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4457/10000, Loss: 0.6240, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4458/10000, Loss: 0.6240, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4459/10000, Loss: 0.6240, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4460/10000, Loss: 0.6239, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4461/10000, Loss: 0.6239, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4462/10000, Loss: 0.6239, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4463/10000, Loss: 0.6239, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4464/10000, Loss: 0.6239, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4465/10000, Loss: 0.6239, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4466/10000, Loss: 0.6239, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4467/10000, Loss: 0.6239, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4468/10000, Loss: 0.6239, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4469/10000, Loss: 0.6238, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4470/10000, Loss: 0.6238, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4471/10000, Loss: 0.6238, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4472/10000, Loss: 0.6238, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4473/10000, Loss: 0.6238, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4474/10000, Loss: 0.6238, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4475/10000, Loss: 0.6238, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4476/10000, Loss: 0.6238, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4477/10000, Loss: 0.6237, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4478/10000, Loss: 0.6237, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4479/10000, Loss: 0.6237, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4480/10000, Loss: 0.6237, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4481/10000, Loss: 0.6237, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4482/10000, Loss: 0.6237, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4483/10000, Loss: 0.6237, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4484/10000, Loss: 0.6237, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4485/10000, Loss: 0.6237, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4486/10000, Loss: 0.6236, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4487/10000, Loss: 0.6236, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4488/10000, Loss: 0.6236, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4489/10000, Loss: 0.6236, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4490/10000, Loss: 0.6236, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4491/10000, Loss: 0.6236, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4492/10000, Loss: 0.6236, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4493/10000, Loss: 0.6236, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4494/10000, Loss: 0.6236, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4495/10000, Loss: 0.6235, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4496/10000, Loss: 0.6235, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4497/10000, Loss: 0.6235, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4498/10000, Loss: 0.6235, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 4499/10000, Loss: 0.6235, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 4500/10000, Loss: 0.6235, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 4501/10000, Loss: 0.6235, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 4502/10000, Loss: 0.6235, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 4503/10000, Loss: 0.6234, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 4504/10000, Loss: 0.6234, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 4505/10000, Loss: 0.6234, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 4506/10000, Loss: 0.6234, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 4507/10000, Loss: 0.6234, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 4508/10000, Loss: 0.6234, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 4509/10000, Loss: 0.6234, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 4510/10000, Loss: 0.6234, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 4511/10000, Loss: 0.6234, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 4512/10000, Loss: 0.6233, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4513/10000, Loss: 0.6233, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4514/10000, Loss: 0.6233, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4515/10000, Loss: 0.6233, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4516/10000, Loss: 0.6233, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4517/10000, Loss: 0.6233, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4518/10000, Loss: 0.6233, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4519/10000, Loss: 0.6233, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4520/10000, Loss: 0.6233, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4521/10000, Loss: 0.6232, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4522/10000, Loss: 0.6232, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4523/10000, Loss: 0.6232, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4524/10000, Loss: 0.6232, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4525/10000, Loss: 0.6232, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4526/10000, Loss: 0.6232, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4527/10000, Loss: 0.6232, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4528/10000, Loss: 0.6232, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4529/10000, Loss: 0.6232, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4530/10000, Loss: 0.6231, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4531/10000, Loss: 0.6231, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4532/10000, Loss: 0.6231, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4533/10000, Loss: 0.6231, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4534/10000, Loss: 0.6231, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4535/10000, Loss: 0.6231, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4536/10000, Loss: 0.6231, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4537/10000, Loss: 0.6231, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4538/10000, Loss: 0.6230, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4539/10000, Loss: 0.6230, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4540/10000, Loss: 0.6230, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4541/10000, Loss: 0.6230, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4542/10000, Loss: 0.6230, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4543/10000, Loss: 0.6230, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4544/10000, Loss: 0.6230, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4545/10000, Loss: 0.6230, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4546/10000, Loss: 0.6230, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4547/10000, Loss: 0.6229, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4548/10000, Loss: 0.6229, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4549/10000, Loss: 0.6229, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4550/10000, Loss: 0.6229, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4551/10000, Loss: 0.6229, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4552/10000, Loss: 0.6229, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4553/10000, Loss: 0.6229, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4554/10000, Loss: 0.6229, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4555/10000, Loss: 0.6229, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4556/10000, Loss: 0.6228, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4557/10000, Loss: 0.6228, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4558/10000, Loss: 0.6228, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4559/10000, Loss: 0.6228, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4560/10000, Loss: 0.6228, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4561/10000, Loss: 0.6228, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4562/10000, Loss: 0.6228, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4563/10000, Loss: 0.6228, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4564/10000, Loss: 0.6228, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4565/10000, Loss: 0.6227, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4566/10000, Loss: 0.6227, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4567/10000, Loss: 0.6227, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4568/10000, Loss: 0.6227, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4569/10000, Loss: 0.6227, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4570/10000, Loss: 0.6227, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4571/10000, Loss: 0.6227, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4572/10000, Loss: 0.6227, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4573/10000, Loss: 0.6227, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4574/10000, Loss: 0.6226, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4575/10000, Loss: 0.6226, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4576/10000, Loss: 0.6226, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4577/10000, Loss: 0.6226, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4578/10000, Loss: 0.6226, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4579/10000, Loss: 0.6226, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4580/10000, Loss: 0.6226, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4581/10000, Loss: 0.6226, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4582/10000, Loss: 0.6226, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4583/10000, Loss: 0.6225, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4584/10000, Loss: 0.6225, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4585/10000, Loss: 0.6225, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4586/10000, Loss: 0.6225, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4587/10000, Loss: 0.6225, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4588/10000, Loss: 0.6225, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4589/10000, Loss: 0.6225, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4590/10000, Loss: 0.6225, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4591/10000, Loss: 0.6225, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4592/10000, Loss: 0.6224, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4593/10000, Loss: 0.6224, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4594/10000, Loss: 0.6224, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4595/10000, Loss: 0.6224, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4596/10000, Loss: 0.6224, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4597/10000, Loss: 0.6224, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4598/10000, Loss: 0.6224, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4599/10000, Loss: 0.6224, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4600/10000, Loss: 0.6224, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4601/10000, Loss: 0.6223, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4602/10000, Loss: 0.6223, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4603/10000, Loss: 0.6223, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4604/10000, Loss: 0.6223, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4605/10000, Loss: 0.6223, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4606/10000, Loss: 0.6223, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4607/10000, Loss: 0.6223, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4608/10000, Loss: 0.6223, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4609/10000, Loss: 0.6223, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4610/10000, Loss: 0.6222, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4611/10000, Loss: 0.6222, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4612/10000, Loss: 0.6222, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4613/10000, Loss: 0.6222, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4614/10000, Loss: 0.6222, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4615/10000, Loss: 0.6222, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4616/10000, Loss: 0.6222, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4617/10000, Loss: 0.6222, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4618/10000, Loss: 0.6222, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4619/10000, Loss: 0.6221, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4620/10000, Loss: 0.6221, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4621/10000, Loss: 0.6221, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4622/10000, Loss: 0.6221, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4623/10000, Loss: 0.6221, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4624/10000, Loss: 0.6221, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4625/10000, Loss: 0.6221, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4626/10000, Loss: 0.6221, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4627/10000, Loss: 0.6221, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4628/10000, Loss: 0.6220, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4629/10000, Loss: 0.6220, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4630/10000, Loss: 0.6220, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4631/10000, Loss: 0.6220, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4632/10000, Loss: 0.6220, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4633/10000, Loss: 0.6220, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4634/10000, Loss: 0.6220, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4635/10000, Loss: 0.6220, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4636/10000, Loss: 0.6220, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4637/10000, Loss: 0.6219, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4638/10000, Loss: 0.6219, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4639/10000, Loss: 0.6219, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4640/10000, Loss: 0.6219, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4641/10000, Loss: 0.6219, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4642/10000, Loss: 0.6219, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4643/10000, Loss: 0.6219, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4644/10000, Loss: 0.6219, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4645/10000, Loss: 0.6219, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4646/10000, Loss: 0.6218, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4647/10000, Loss: 0.6218, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4648/10000, Loss: 0.6218, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4649/10000, Loss: 0.6218, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4650/10000, Loss: 0.6218, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4651/10000, Loss: 0.6218, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4652/10000, Loss: 0.6218, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4653/10000, Loss: 0.6218, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4654/10000, Loss: 0.6218, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4655/10000, Loss: 0.6217, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4656/10000, Loss: 0.6217, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4657/10000, Loss: 0.6217, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4658/10000, Loss: 0.6217, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4659/10000, Loss: 0.6217, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4660/10000, Loss: 0.6217, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4661/10000, Loss: 0.6217, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4662/10000, Loss: 0.6217, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4663/10000, Loss: 0.6217, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4664/10000, Loss: 0.6216, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4665/10000, Loss: 0.6216, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4666/10000, Loss: 0.6216, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4667/10000, Loss: 0.6216, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4668/10000, Loss: 0.6216, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4669/10000, Loss: 0.6216, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4670/10000, Loss: 0.6216, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4671/10000, Loss: 0.6216, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4672/10000, Loss: 0.6216, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4673/10000, Loss: 0.6215, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4674/10000, Loss: 0.6215, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4675/10000, Loss: 0.6215, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4676/10000, Loss: 0.6215, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4677/10000, Loss: 0.6215, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4678/10000, Loss: 0.6215, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4679/10000, Loss: 0.6215, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4680/10000, Loss: 0.6215, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4681/10000, Loss: 0.6215, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4682/10000, Loss: 0.6214, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4683/10000, Loss: 0.6214, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4684/10000, Loss: 0.6214, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4685/10000, Loss: 0.6214, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4686/10000, Loss: 0.6214, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4687/10000, Loss: 0.6214, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4688/10000, Loss: 0.6214, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4689/10000, Loss: 0.6214, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4690/10000, Loss: 0.6214, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4691/10000, Loss: 0.6214, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4692/10000, Loss: 0.6213, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4693/10000, Loss: 0.6213, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4694/10000, Loss: 0.6213, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4695/10000, Loss: 0.6213, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4696/10000, Loss: 0.6213, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4697/10000, Loss: 0.6213, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4698/10000, Loss: 0.6213, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4699/10000, Loss: 0.6213, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4700/10000, Loss: 0.6213, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4701/10000, Loss: 0.6212, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4702/10000, Loss: 0.6212, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4703/10000, Loss: 0.6212, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4704/10000, Loss: 0.6212, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4705/10000, Loss: 0.6212, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4706/10000, Loss: 0.6212, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4707/10000, Loss: 0.6212, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4708/10000, Loss: 0.6212, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4709/10000, Loss: 0.6212, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4710/10000, Loss: 0.6211, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4711/10000, Loss: 0.6211, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4712/10000, Loss: 0.6211, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4713/10000, Loss: 0.6211, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4714/10000, Loss: 0.6211, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4715/10000, Loss: 0.6211, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4716/10000, Loss: 0.6211, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4717/10000, Loss: 0.6211, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4718/10000, Loss: 0.6211, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4719/10000, Loss: 0.6210, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4720/10000, Loss: 0.6210, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4721/10000, Loss: 0.6210, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4722/10000, Loss: 0.6210, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4723/10000, Loss: 0.6210, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4724/10000, Loss: 0.6210, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4725/10000, Loss: 0.6210, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4726/10000, Loss: 0.6210, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4727/10000, Loss: 0.6210, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4728/10000, Loss: 0.6210, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4729/10000, Loss: 0.6209, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4730/10000, Loss: 0.6209, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4731/10000, Loss: 0.6209, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4732/10000, Loss: 0.6209, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4733/10000, Loss: 0.6209, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4734/10000, Loss: 0.6209, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4735/10000, Loss: 0.6209, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4736/10000, Loss: 0.6209, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4737/10000, Loss: 0.6209, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4738/10000, Loss: 0.6208, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4739/10000, Loss: 0.6208, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4740/10000, Loss: 0.6208, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4741/10000, Loss: 0.6208, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4742/10000, Loss: 0.6208, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4743/10000, Loss: 0.6208, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4744/10000, Loss: 0.6208, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4745/10000, Loss: 0.6208, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4746/10000, Loss: 0.6208, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4747/10000, Loss: 0.6207, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4748/10000, Loss: 0.6207, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4749/10000, Loss: 0.6207, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4750/10000, Loss: 0.6207, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4751/10000, Loss: 0.6207, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4752/10000, Loss: 0.6207, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4753/10000, Loss: 0.6207, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4754/10000, Loss: 0.6207, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4755/10000, Loss: 0.6207, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4756/10000, Loss: 0.6207, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4757/10000, Loss: 0.6206, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4758/10000, Loss: 0.6206, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4759/10000, Loss: 0.6206, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4760/10000, Loss: 0.6206, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4761/10000, Loss: 0.6206, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4762/10000, Loss: 0.6206, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4763/10000, Loss: 0.6206, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4764/10000, Loss: 0.6206, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4765/10000, Loss: 0.6206, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4766/10000, Loss: 0.6205, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4767/10000, Loss: 0.6205, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4768/10000, Loss: 0.6205, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4769/10000, Loss: 0.6205, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4770/10000, Loss: 0.6205, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4771/10000, Loss: 0.6205, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4772/10000, Loss: 0.6205, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4773/10000, Loss: 0.6205, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4774/10000, Loss: 0.6205, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4775/10000, Loss: 0.6205, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4776/10000, Loss: 0.6204, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4777/10000, Loss: 0.6204, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4778/10000, Loss: 0.6204, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4779/10000, Loss: 0.6204, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4780/10000, Loss: 0.6204, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4781/10000, Loss: 0.6204, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4782/10000, Loss: 0.6204, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4783/10000, Loss: 0.6204, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4784/10000, Loss: 0.6204, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4785/10000, Loss: 0.6203, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4786/10000, Loss: 0.6203, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4787/10000, Loss: 0.6203, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4788/10000, Loss: 0.6203, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4789/10000, Loss: 0.6203, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4790/10000, Loss: 0.6203, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4791/10000, Loss: 0.6203, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4792/10000, Loss: 0.6203, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4793/10000, Loss: 0.6203, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4794/10000, Loss: 0.6203, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4795/10000, Loss: 0.6202, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4796/10000, Loss: 0.6202, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4797/10000, Loss: 0.6202, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4798/10000, Loss: 0.6202, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4799/10000, Loss: 0.6202, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4800/10000, Loss: 0.6202, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4801/10000, Loss: 0.6202, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4802/10000, Loss: 0.6202, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4803/10000, Loss: 0.6202, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4804/10000, Loss: 0.6201, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4805/10000, Loss: 0.6201, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4806/10000, Loss: 0.6201, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4807/10000, Loss: 0.6201, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4808/10000, Loss: 0.6201, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4809/10000, Loss: 0.6201, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4810/10000, Loss: 0.6201, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4811/10000, Loss: 0.6201, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4812/10000, Loss: 0.6201, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4813/10000, Loss: 0.6201, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4814/10000, Loss: 0.6200, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4815/10000, Loss: 0.6200, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4816/10000, Loss: 0.6200, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4817/10000, Loss: 0.6200, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4818/10000, Loss: 0.6200, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4819/10000, Loss: 0.6200, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4820/10000, Loss: 0.6200, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4821/10000, Loss: 0.6200, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4822/10000, Loss: 0.6200, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4823/10000, Loss: 0.6199, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4824/10000, Loss: 0.6199, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4825/10000, Loss: 0.6199, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4826/10000, Loss: 0.6199, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4827/10000, Loss: 0.6199, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4828/10000, Loss: 0.6199, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4829/10000, Loss: 0.6199, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4830/10000, Loss: 0.6199, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4831/10000, Loss: 0.6199, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4832/10000, Loss: 0.6199, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4833/10000, Loss: 0.6198, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4834/10000, Loss: 0.6198, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4835/10000, Loss: 0.6198, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4836/10000, Loss: 0.6198, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4837/10000, Loss: 0.6198, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4838/10000, Loss: 0.6198, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4839/10000, Loss: 0.6198, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4840/10000, Loss: 0.6198, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4841/10000, Loss: 0.6198, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4842/10000, Loss: 0.6198, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4843/10000, Loss: 0.6197, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4844/10000, Loss: 0.6197, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4845/10000, Loss: 0.6197, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4846/10000, Loss: 0.6197, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4847/10000, Loss: 0.6197, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4848/10000, Loss: 0.6197, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4849/10000, Loss: 0.6197, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4850/10000, Loss: 0.6197, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4851/10000, Loss: 0.6197, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4852/10000, Loss: 0.6196, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4853/10000, Loss: 0.6196, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4854/10000, Loss: 0.6196, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4855/10000, Loss: 0.6196, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4856/10000, Loss: 0.6196, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4857/10000, Loss: 0.6196, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4858/10000, Loss: 0.6196, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4859/10000, Loss: 0.6196, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4860/10000, Loss: 0.6196, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4861/10000, Loss: 0.6196, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4862/10000, Loss: 0.6195, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4863/10000, Loss: 0.6195, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4864/10000, Loss: 0.6195, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4865/10000, Loss: 0.6195, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4866/10000, Loss: 0.6195, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4867/10000, Loss: 0.6195, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4868/10000, Loss: 0.6195, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4869/10000, Loss: 0.6195, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4870/10000, Loss: 0.6195, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4871/10000, Loss: 0.6195, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4872/10000, Loss: 0.6194, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4873/10000, Loss: 0.6194, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4874/10000, Loss: 0.6194, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4875/10000, Loss: 0.6194, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4876/10000, Loss: 0.6194, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4877/10000, Loss: 0.6194, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4878/10000, Loss: 0.6194, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4879/10000, Loss: 0.6194, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4880/10000, Loss: 0.6194, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4881/10000, Loss: 0.6194, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4882/10000, Loss: 0.6193, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4883/10000, Loss: 0.6193, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4884/10000, Loss: 0.6193, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4885/10000, Loss: 0.6193, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4886/10000, Loss: 0.6193, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4887/10000, Loss: 0.6193, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4888/10000, Loss: 0.6193, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4889/10000, Loss: 0.6193, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4890/10000, Loss: 0.6193, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4891/10000, Loss: 0.6193, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4892/10000, Loss: 0.6192, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4893/10000, Loss: 0.6192, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4894/10000, Loss: 0.6192, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4895/10000, Loss: 0.6192, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4896/10000, Loss: 0.6192, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4897/10000, Loss: 0.6192, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4898/10000, Loss: 0.6192, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4899/10000, Loss: 0.6192, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4900/10000, Loss: 0.6192, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4901/10000, Loss: 0.6191, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4902/10000, Loss: 0.6191, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4903/10000, Loss: 0.6191, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4904/10000, Loss: 0.6191, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4905/10000, Loss: 0.6191, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4906/10000, Loss: 0.6191, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4907/10000, Loss: 0.6191, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4908/10000, Loss: 0.6191, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4909/10000, Loss: 0.6191, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4910/10000, Loss: 0.6191, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4911/10000, Loss: 0.6190, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4912/10000, Loss: 0.6190, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4913/10000, Loss: 0.6190, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4914/10000, Loss: 0.6190, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4915/10000, Loss: 0.6190, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4916/10000, Loss: 0.6190, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4917/10000, Loss: 0.6190, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4918/10000, Loss: 0.6190, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4919/10000, Loss: 0.6190, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4920/10000, Loss: 0.6190, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4921/10000, Loss: 0.6189, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4922/10000, Loss: 0.6189, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4923/10000, Loss: 0.6189, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4924/10000, Loss: 0.6189, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4925/10000, Loss: 0.6189, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4926/10000, Loss: 0.6189, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4927/10000, Loss: 0.6189, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4928/10000, Loss: 0.6189, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4929/10000, Loss: 0.6189, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4930/10000, Loss: 0.6189, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4931/10000, Loss: 0.6188, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4932/10000, Loss: 0.6188, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4933/10000, Loss: 0.6188, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4934/10000, Loss: 0.6188, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4935/10000, Loss: 0.6188, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4936/10000, Loss: 0.6188, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4937/10000, Loss: 0.6188, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4938/10000, Loss: 0.6188, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4939/10000, Loss: 0.6188, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4940/10000, Loss: 0.6188, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4941/10000, Loss: 0.6187, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4942/10000, Loss: 0.6187, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4943/10000, Loss: 0.6187, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4944/10000, Loss: 0.6187, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4945/10000, Loss: 0.6187, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4946/10000, Loss: 0.6187, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4947/10000, Loss: 0.6187, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4948/10000, Loss: 0.6187, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4949/10000, Loss: 0.6187, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4950/10000, Loss: 0.6187, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4951/10000, Loss: 0.6186, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4952/10000, Loss: 0.6186, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4953/10000, Loss: 0.6186, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4954/10000, Loss: 0.6186, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4955/10000, Loss: 0.6186, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4956/10000, Loss: 0.6186, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4957/10000, Loss: 0.6186, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4958/10000, Loss: 0.6186, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4959/10000, Loss: 0.6186, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4960/10000, Loss: 0.6186, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4961/10000, Loss: 0.6185, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4962/10000, Loss: 0.6185, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4963/10000, Loss: 0.6185, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4964/10000, Loss: 0.6185, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4965/10000, Loss: 0.6185, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4966/10000, Loss: 0.6185, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4967/10000, Loss: 0.6185, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4968/10000, Loss: 0.6185, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4969/10000, Loss: 0.6185, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4970/10000, Loss: 0.6185, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4971/10000, Loss: 0.6184, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4972/10000, Loss: 0.6184, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4973/10000, Loss: 0.6184, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4974/10000, Loss: 0.6184, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4975/10000, Loss: 0.6184, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4976/10000, Loss: 0.6184, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4977/10000, Loss: 0.6184, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4978/10000, Loss: 0.6184, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4979/10000, Loss: 0.6184, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4980/10000, Loss: 0.6184, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4981/10000, Loss: 0.6183, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4982/10000, Loss: 0.6183, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4983/10000, Loss: 0.6183, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4984/10000, Loss: 0.6183, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4985/10000, Loss: 0.6183, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4986/10000, Loss: 0.6183, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4987/10000, Loss: 0.6183, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4988/10000, Loss: 0.6183, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4989/10000, Loss: 0.6183, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4990/10000, Loss: 0.6183, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4991/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4992/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4993/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4994/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4995/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4996/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4997/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4998/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 4999/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5000/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5001/10000, Loss: 0.6182, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5002/10000, Loss: 0.6181, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5003/10000, Loss: 0.6181, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5004/10000, Loss: 0.6181, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5005/10000, Loss: 0.6181, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5006/10000, Loss: 0.6181, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5007/10000, Loss: 0.6181, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5008/10000, Loss: 0.6181, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5009/10000, Loss: 0.6181, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5010/10000, Loss: 0.6181, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5011/10000, Loss: 0.6181, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5012/10000, Loss: 0.6180, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5013/10000, Loss: 0.6180, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5014/10000, Loss: 0.6180, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5015/10000, Loss: 0.6180, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5016/10000, Loss: 0.6180, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5017/10000, Loss: 0.6180, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5018/10000, Loss: 0.6180, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5019/10000, Loss: 0.6180, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5020/10000, Loss: 0.6180, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5021/10000, Loss: 0.6180, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5022/10000, Loss: 0.6179, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5023/10000, Loss: 0.6179, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5024/10000, Loss: 0.6179, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5025/10000, Loss: 0.6179, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5026/10000, Loss: 0.6179, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5027/10000, Loss: 0.6179, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5028/10000, Loss: 0.6179, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5029/10000, Loss: 0.6179, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5030/10000, Loss: 0.6179, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5031/10000, Loss: 0.6179, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5032/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5033/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5034/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5035/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5036/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5037/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5038/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5039/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5040/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5041/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5042/10000, Loss: 0.6178, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5043/10000, Loss: 0.6177, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5044/10000, Loss: 0.6177, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5045/10000, Loss: 0.6177, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5046/10000, Loss: 0.6177, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5047/10000, Loss: 0.6177, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5048/10000, Loss: 0.6177, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5049/10000, Loss: 0.6177, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5050/10000, Loss: 0.6177, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5051/10000, Loss: 0.6177, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5052/10000, Loss: 0.6177, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5053/10000, Loss: 0.6176, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5054/10000, Loss: 0.6176, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5055/10000, Loss: 0.6176, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5056/10000, Loss: 0.6176, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5057/10000, Loss: 0.6176, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5058/10000, Loss: 0.6176, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5059/10000, Loss: 0.6176, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5060/10000, Loss: 0.6176, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5061/10000, Loss: 0.6176, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5062/10000, Loss: 0.6176, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5063/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5064/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5065/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5066/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5067/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5068/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5069/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5070/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5071/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5072/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5073/10000, Loss: 0.6175, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5074/10000, Loss: 0.6174, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5075/10000, Loss: 0.6174, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5076/10000, Loss: 0.6174, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5077/10000, Loss: 0.6174, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5078/10000, Loss: 0.6174, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5079/10000, Loss: 0.6174, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5080/10000, Loss: 0.6174, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5081/10000, Loss: 0.6174, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5082/10000, Loss: 0.6174, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5083/10000, Loss: 0.6174, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5084/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5085/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5086/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5087/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5088/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5089/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5090/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5091/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5092/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5093/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5094/10000, Loss: 0.6173, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5095/10000, Loss: 0.6172, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5096/10000, Loss: 0.6172, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5097/10000, Loss: 0.6172, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5098/10000, Loss: 0.6172, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5099/10000, Loss: 0.6172, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5100/10000, Loss: 0.6172, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5101/10000, Loss: 0.6172, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5102/10000, Loss: 0.6172, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5103/10000, Loss: 0.6172, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5104/10000, Loss: 0.6172, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5105/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5106/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5107/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5108/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5109/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5110/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5111/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5112/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5113/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5114/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5115/10000, Loss: 0.6171, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5116/10000, Loss: 0.6170, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5117/10000, Loss: 0.6170, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5118/10000, Loss: 0.6170, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5119/10000, Loss: 0.6170, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5120/10000, Loss: 0.6170, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5121/10000, Loss: 0.6170, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5122/10000, Loss: 0.6170, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5123/10000, Loss: 0.6170, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5124/10000, Loss: 0.6170, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5125/10000, Loss: 0.6170, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5126/10000, Loss: 0.6169, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5127/10000, Loss: 0.6169, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5128/10000, Loss: 0.6169, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5129/10000, Loss: 0.6169, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5130/10000, Loss: 0.6169, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5131/10000, Loss: 0.6169, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5132/10000, Loss: 0.6169, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5133/10000, Loss: 0.6169, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5134/10000, Loss: 0.6169, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5135/10000, Loss: 0.6169, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5136/10000, Loss: 0.6169, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5137/10000, Loss: 0.6168, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5138/10000, Loss: 0.6168, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5139/10000, Loss: 0.6168, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5140/10000, Loss: 0.6168, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5141/10000, Loss: 0.6168, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5142/10000, Loss: 0.6168, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5143/10000, Loss: 0.6168, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5144/10000, Loss: 0.6168, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5145/10000, Loss: 0.6168, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5146/10000, Loss: 0.6168, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5147/10000, Loss: 0.6168, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5148/10000, Loss: 0.6167, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5149/10000, Loss: 0.6167, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5150/10000, Loss: 0.6167, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5151/10000, Loss: 0.6167, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5152/10000, Loss: 0.6167, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5153/10000, Loss: 0.6167, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5154/10000, Loss: 0.6167, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5155/10000, Loss: 0.6167, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5156/10000, Loss: 0.6167, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5157/10000, Loss: 0.6167, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5158/10000, Loss: 0.6166, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5159/10000, Loss: 0.6166, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5160/10000, Loss: 0.6166, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5161/10000, Loss: 0.6166, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5162/10000, Loss: 0.6166, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5163/10000, Loss: 0.6166, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5164/10000, Loss: 0.6166, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5165/10000, Loss: 0.6166, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5166/10000, Loss: 0.6166, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5167/10000, Loss: 0.6166, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5168/10000, Loss: 0.6166, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5169/10000, Loss: 0.6165, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5170/10000, Loss: 0.6165, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5171/10000, Loss: 0.6165, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5172/10000, Loss: 0.6165, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5173/10000, Loss: 0.6165, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5174/10000, Loss: 0.6165, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5175/10000, Loss: 0.6165, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5176/10000, Loss: 0.6165, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5177/10000, Loss: 0.6165, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5178/10000, Loss: 0.6165, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5179/10000, Loss: 0.6165, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5180/10000, Loss: 0.6164, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5181/10000, Loss: 0.6164, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5182/10000, Loss: 0.6164, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5183/10000, Loss: 0.6164, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5184/10000, Loss: 0.6164, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5185/10000, Loss: 0.6164, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5186/10000, Loss: 0.6164, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5187/10000, Loss: 0.6164, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5188/10000, Loss: 0.6164, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5189/10000, Loss: 0.6164, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5190/10000, Loss: 0.6164, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5191/10000, Loss: 0.6163, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5192/10000, Loss: 0.6163, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5193/10000, Loss: 0.6163, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5194/10000, Loss: 0.6163, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5195/10000, Loss: 0.6163, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5196/10000, Loss: 0.6163, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5197/10000, Loss: 0.6163, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5198/10000, Loss: 0.6163, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5199/10000, Loss: 0.6163, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5200/10000, Loss: 0.6163, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5201/10000, Loss: 0.6162, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5202/10000, Loss: 0.6162, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5203/10000, Loss: 0.6162, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5204/10000, Loss: 0.6162, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5205/10000, Loss: 0.6162, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5206/10000, Loss: 0.6162, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5207/10000, Loss: 0.6162, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5208/10000, Loss: 0.6162, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5209/10000, Loss: 0.6162, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5210/10000, Loss: 0.6162, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5211/10000, Loss: 0.6162, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5212/10000, Loss: 0.6161, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5213/10000, Loss: 0.6161, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5214/10000, Loss: 0.6161, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5215/10000, Loss: 0.6161, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5216/10000, Loss: 0.6161, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5217/10000, Loss: 0.6161, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5218/10000, Loss: 0.6161, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5219/10000, Loss: 0.6161, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5220/10000, Loss: 0.6161, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5221/10000, Loss: 0.6161, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5222/10000, Loss: 0.6161, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5223/10000, Loss: 0.6160, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5224/10000, Loss: 0.6160, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5225/10000, Loss: 0.6160, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5226/10000, Loss: 0.6160, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5227/10000, Loss: 0.6160, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5228/10000, Loss: 0.6160, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5229/10000, Loss: 0.6160, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5230/10000, Loss: 0.6160, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5231/10000, Loss: 0.6160, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5232/10000, Loss: 0.6160, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5233/10000, Loss: 0.6160, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5234/10000, Loss: 0.6159, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5235/10000, Loss: 0.6159, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5236/10000, Loss: 0.6159, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5237/10000, Loss: 0.6159, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5238/10000, Loss: 0.6159, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5239/10000, Loss: 0.6159, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5240/10000, Loss: 0.6159, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5241/10000, Loss: 0.6159, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5242/10000, Loss: 0.6159, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5243/10000, Loss: 0.6159, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5244/10000, Loss: 0.6159, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5245/10000, Loss: 0.6158, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5246/10000, Loss: 0.6158, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5247/10000, Loss: 0.6158, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5248/10000, Loss: 0.6158, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5249/10000, Loss: 0.6158, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5250/10000, Loss: 0.6158, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5251/10000, Loss: 0.6158, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5252/10000, Loss: 0.6158, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5253/10000, Loss: 0.6158, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5254/10000, Loss: 0.6158, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5255/10000, Loss: 0.6158, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5256/10000, Loss: 0.6157, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5257/10000, Loss: 0.6157, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5258/10000, Loss: 0.6157, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5259/10000, Loss: 0.6157, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5260/10000, Loss: 0.6157, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5261/10000, Loss: 0.6157, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5262/10000, Loss: 0.6157, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5263/10000, Loss: 0.6157, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5264/10000, Loss: 0.6157, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5265/10000, Loss: 0.6157, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5266/10000, Loss: 0.6157, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5267/10000, Loss: 0.6156, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5268/10000, Loss: 0.6156, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5269/10000, Loss: 0.6156, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5270/10000, Loss: 0.6156, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5271/10000, Loss: 0.6156, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5272/10000, Loss: 0.6156, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5273/10000, Loss: 0.6156, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5274/10000, Loss: 0.6156, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5275/10000, Loss: 0.6156, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5276/10000, Loss: 0.6156, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5277/10000, Loss: 0.6156, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5278/10000, Loss: 0.6155, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5279/10000, Loss: 0.6155, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5280/10000, Loss: 0.6155, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5281/10000, Loss: 0.6155, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5282/10000, Loss: 0.6155, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5283/10000, Loss: 0.6155, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5284/10000, Loss: 0.6155, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5285/10000, Loss: 0.6155, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5286/10000, Loss: 0.6155, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5287/10000, Loss: 0.6155, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5288/10000, Loss: 0.6155, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5289/10000, Loss: 0.6155, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5290/10000, Loss: 0.6154, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5291/10000, Loss: 0.6154, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5292/10000, Loss: 0.6154, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5293/10000, Loss: 0.6154, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5294/10000, Loss: 0.6154, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5295/10000, Loss: 0.6154, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5296/10000, Loss: 0.6154, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5297/10000, Loss: 0.6154, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5298/10000, Loss: 0.6154, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5299/10000, Loss: 0.6154, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5300/10000, Loss: 0.6154, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5301/10000, Loss: 0.6153, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5302/10000, Loss: 0.6153, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5303/10000, Loss: 0.6153, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5304/10000, Loss: 0.6153, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5305/10000, Loss: 0.6153, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5306/10000, Loss: 0.6153, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5307/10000, Loss: 0.6153, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5308/10000, Loss: 0.6153, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5309/10000, Loss: 0.6153, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5310/10000, Loss: 0.6153, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5311/10000, Loss: 0.6153, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5312/10000, Loss: 0.6152, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5313/10000, Loss: 0.6152, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5314/10000, Loss: 0.6152, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5315/10000, Loss: 0.6152, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5316/10000, Loss: 0.6152, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5317/10000, Loss: 0.6152, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5318/10000, Loss: 0.6152, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5319/10000, Loss: 0.6152, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5320/10000, Loss: 0.6152, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5321/10000, Loss: 0.6152, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5322/10000, Loss: 0.6152, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5323/10000, Loss: 0.6151, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5324/10000, Loss: 0.6151, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5325/10000, Loss: 0.6151, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5326/10000, Loss: 0.6151, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5327/10000, Loss: 0.6151, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5328/10000, Loss: 0.6151, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5329/10000, Loss: 0.6151, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5330/10000, Loss: 0.6151, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5331/10000, Loss: 0.6151, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5332/10000, Loss: 0.6151, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5333/10000, Loss: 0.6151, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5334/10000, Loss: 0.6151, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5335/10000, Loss: 0.6150, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5336/10000, Loss: 0.6150, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5337/10000, Loss: 0.6150, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5338/10000, Loss: 0.6150, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5339/10000, Loss: 0.6150, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5340/10000, Loss: 0.6150, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5341/10000, Loss: 0.6150, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5342/10000, Loss: 0.6150, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5343/10000, Loss: 0.6150, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5344/10000, Loss: 0.6150, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5345/10000, Loss: 0.6150, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5346/10000, Loss: 0.6149, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5347/10000, Loss: 0.6149, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5348/10000, Loss: 0.6149, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5349/10000, Loss: 0.6149, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5350/10000, Loss: 0.6149, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5351/10000, Loss: 0.6149, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5352/10000, Loss: 0.6149, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5353/10000, Loss: 0.6149, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5354/10000, Loss: 0.6149, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5355/10000, Loss: 0.6149, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5356/10000, Loss: 0.6149, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5357/10000, Loss: 0.6148, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5358/10000, Loss: 0.6148, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5359/10000, Loss: 0.6148, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5360/10000, Loss: 0.6148, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5361/10000, Loss: 0.6148, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5362/10000, Loss: 0.6148, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5363/10000, Loss: 0.6148, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5364/10000, Loss: 0.6148, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5365/10000, Loss: 0.6148, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5366/10000, Loss: 0.6148, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5367/10000, Loss: 0.6148, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5368/10000, Loss: 0.6148, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5369/10000, Loss: 0.6147, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5370/10000, Loss: 0.6147, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5371/10000, Loss: 0.6147, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5372/10000, Loss: 0.6147, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5373/10000, Loss: 0.6147, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5374/10000, Loss: 0.6147, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5375/10000, Loss: 0.6147, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5376/10000, Loss: 0.6147, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5377/10000, Loss: 0.6147, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5378/10000, Loss: 0.6147, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5379/10000, Loss: 0.6147, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5380/10000, Loss: 0.6146, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5381/10000, Loss: 0.6146, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5382/10000, Loss: 0.6146, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5383/10000, Loss: 0.6146, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5384/10000, Loss: 0.6146, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5385/10000, Loss: 0.6146, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5386/10000, Loss: 0.6146, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5387/10000, Loss: 0.6146, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5388/10000, Loss: 0.6146, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5389/10000, Loss: 0.6146, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5390/10000, Loss: 0.6146, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5391/10000, Loss: 0.6146, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5392/10000, Loss: 0.6145, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5393/10000, Loss: 0.6145, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5394/10000, Loss: 0.6145, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5395/10000, Loss: 0.6145, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5396/10000, Loss: 0.6145, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5397/10000, Loss: 0.6145, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5398/10000, Loss: 0.6145, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5399/10000, Loss: 0.6145, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5400/10000, Loss: 0.6145, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5401/10000, Loss: 0.6145, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5402/10000, Loss: 0.6145, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5403/10000, Loss: 0.6144, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5404/10000, Loss: 0.6144, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5405/10000, Loss: 0.6144, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5406/10000, Loss: 0.6144, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5407/10000, Loss: 0.6144, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5408/10000, Loss: 0.6144, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5409/10000, Loss: 0.6144, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5410/10000, Loss: 0.6144, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5411/10000, Loss: 0.6144, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5412/10000, Loss: 0.6144, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5413/10000, Loss: 0.6144, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5414/10000, Loss: 0.6144, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5415/10000, Loss: 0.6143, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5416/10000, Loss: 0.6143, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5417/10000, Loss: 0.6143, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5418/10000, Loss: 0.6143, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5419/10000, Loss: 0.6143, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5420/10000, Loss: 0.6143, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5421/10000, Loss: 0.6143, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5422/10000, Loss: 0.6143, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5423/10000, Loss: 0.6143, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5424/10000, Loss: 0.6143, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5425/10000, Loss: 0.6143, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5426/10000, Loss: 0.6143, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5427/10000, Loss: 0.6142, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5428/10000, Loss: 0.6142, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5429/10000, Loss: 0.6142, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5430/10000, Loss: 0.6142, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5431/10000, Loss: 0.6142, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5432/10000, Loss: 0.6142, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5433/10000, Loss: 0.6142, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5434/10000, Loss: 0.6142, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5435/10000, Loss: 0.6142, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5436/10000, Loss: 0.6142, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5437/10000, Loss: 0.6142, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5438/10000, Loss: 0.6141, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5439/10000, Loss: 0.6141, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5440/10000, Loss: 0.6141, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5441/10000, Loss: 0.6141, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5442/10000, Loss: 0.6141, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5443/10000, Loss: 0.6141, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5444/10000, Loss: 0.6141, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5445/10000, Loss: 0.6141, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5446/10000, Loss: 0.6141, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5447/10000, Loss: 0.6141, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5448/10000, Loss: 0.6141, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5449/10000, Loss: 0.6141, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5450/10000, Loss: 0.6140, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5451/10000, Loss: 0.6140, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5452/10000, Loss: 0.6140, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5453/10000, Loss: 0.6140, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5454/10000, Loss: 0.6140, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5455/10000, Loss: 0.6140, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5456/10000, Loss: 0.6140, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5457/10000, Loss: 0.6140, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5458/10000, Loss: 0.6140, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5459/10000, Loss: 0.6140, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5460/10000, Loss: 0.6140, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5461/10000, Loss: 0.6140, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5462/10000, Loss: 0.6139, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5463/10000, Loss: 0.6139, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5464/10000, Loss: 0.6139, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5465/10000, Loss: 0.6139, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5466/10000, Loss: 0.6139, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5467/10000, Loss: 0.6139, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5468/10000, Loss: 0.6139, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5469/10000, Loss: 0.6139, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5470/10000, Loss: 0.6139, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5471/10000, Loss: 0.6139, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5472/10000, Loss: 0.6139, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5473/10000, Loss: 0.6139, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5474/10000, Loss: 0.6138, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5475/10000, Loss: 0.6138, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5476/10000, Loss: 0.6138, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5477/10000, Loss: 0.6138, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5478/10000, Loss: 0.6138, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5479/10000, Loss: 0.6138, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5480/10000, Loss: 0.6138, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5481/10000, Loss: 0.6138, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5482/10000, Loss: 0.6138, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5483/10000, Loss: 0.6138, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5484/10000, Loss: 0.6138, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5485/10000, Loss: 0.6138, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5486/10000, Loss: 0.6137, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5487/10000, Loss: 0.6137, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5488/10000, Loss: 0.6137, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5489/10000, Loss: 0.6137, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5490/10000, Loss: 0.6137, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5491/10000, Loss: 0.6137, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5492/10000, Loss: 0.6137, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5493/10000, Loss: 0.6137, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5494/10000, Loss: 0.6137, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5495/10000, Loss: 0.6137, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5496/10000, Loss: 0.6137, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5497/10000, Loss: 0.6137, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5498/10000, Loss: 0.6136, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5499/10000, Loss: 0.6136, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5500/10000, Loss: 0.6136, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5501/10000, Loss: 0.6136, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5502/10000, Loss: 0.6136, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5503/10000, Loss: 0.6136, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5504/10000, Loss: 0.6136, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5505/10000, Loss: 0.6136, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5506/10000, Loss: 0.6136, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5507/10000, Loss: 0.6136, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5508/10000, Loss: 0.6136, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5509/10000, Loss: 0.6136, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5510/10000, Loss: 0.6135, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5511/10000, Loss: 0.6135, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5512/10000, Loss: 0.6135, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5513/10000, Loss: 0.6135, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5514/10000, Loss: 0.6135, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5515/10000, Loss: 0.6135, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5516/10000, Loss: 0.6135, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5517/10000, Loss: 0.6135, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5518/10000, Loss: 0.6135, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5519/10000, Loss: 0.6135, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5520/10000, Loss: 0.6135, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5521/10000, Loss: 0.6135, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5522/10000, Loss: 0.6134, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5523/10000, Loss: 0.6134, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5524/10000, Loss: 0.6134, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5525/10000, Loss: 0.6134, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5526/10000, Loss: 0.6134, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5527/10000, Loss: 0.6134, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5528/10000, Loss: 0.6134, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5529/10000, Loss: 0.6134, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5530/10000, Loss: 0.6134, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5531/10000, Loss: 0.6134, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5532/10000, Loss: 0.6134, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5533/10000, Loss: 0.6134, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5534/10000, Loss: 0.6133, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5535/10000, Loss: 0.6133, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5536/10000, Loss: 0.6133, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5537/10000, Loss: 0.6133, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5538/10000, Loss: 0.6133, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5539/10000, Loss: 0.6133, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5540/10000, Loss: 0.6133, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5541/10000, Loss: 0.6133, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5542/10000, Loss: 0.6133, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5543/10000, Loss: 0.6133, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5544/10000, Loss: 0.6133, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5545/10000, Loss: 0.6133, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5546/10000, Loss: 0.6132, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5547/10000, Loss: 0.6132, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5548/10000, Loss: 0.6132, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5549/10000, Loss: 0.6132, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5550/10000, Loss: 0.6132, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5551/10000, Loss: 0.6132, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5552/10000, Loss: 0.6132, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5553/10000, Loss: 0.6132, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5554/10000, Loss: 0.6132, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5555/10000, Loss: 0.6132, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5556/10000, Loss: 0.6132, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5557/10000, Loss: 0.6132, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5558/10000, Loss: 0.6131, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5559/10000, Loss: 0.6131, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5560/10000, Loss: 0.6131, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5561/10000, Loss: 0.6131, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5562/10000, Loss: 0.6131, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5563/10000, Loss: 0.6131, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5564/10000, Loss: 0.6131, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5565/10000, Loss: 0.6131, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5566/10000, Loss: 0.6131, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5567/10000, Loss: 0.6131, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5568/10000, Loss: 0.6131, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5569/10000, Loss: 0.6131, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5570/10000, Loss: 0.6130, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5571/10000, Loss: 0.6130, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5572/10000, Loss: 0.6130, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5573/10000, Loss: 0.6130, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5574/10000, Loss: 0.6130, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5575/10000, Loss: 0.6130, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5576/10000, Loss: 0.6130, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5577/10000, Loss: 0.6130, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5578/10000, Loss: 0.6130, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5579/10000, Loss: 0.6130, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5580/10000, Loss: 0.6130, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5581/10000, Loss: 0.6130, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5582/10000, Loss: 0.6129, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5583/10000, Loss: 0.6129, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5584/10000, Loss: 0.6129, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5585/10000, Loss: 0.6129, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5586/10000, Loss: 0.6129, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5587/10000, Loss: 0.6129, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5588/10000, Loss: 0.6129, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5589/10000, Loss: 0.6129, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5590/10000, Loss: 0.6129, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5591/10000, Loss: 0.6129, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5592/10000, Loss: 0.6129, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5593/10000, Loss: 0.6129, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5594/10000, Loss: 0.6129, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5595/10000, Loss: 0.6128, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5596/10000, Loss: 0.6128, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5597/10000, Loss: 0.6128, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5598/10000, Loss: 0.6128, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5599/10000, Loss: 0.6128, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5600/10000, Loss: 0.6128, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5601/10000, Loss: 0.6128, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5602/10000, Loss: 0.6128, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5603/10000, Loss: 0.6128, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5604/10000, Loss: 0.6128, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5605/10000, Loss: 0.6128, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5606/10000, Loss: 0.6128, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5607/10000, Loss: 0.6127, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5608/10000, Loss: 0.6127, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5609/10000, Loss: 0.6127, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5610/10000, Loss: 0.6127, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5611/10000, Loss: 0.6127, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5612/10000, Loss: 0.6127, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5613/10000, Loss: 0.6127, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5614/10000, Loss: 0.6127, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5615/10000, Loss: 0.6127, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5616/10000, Loss: 0.6127, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5617/10000, Loss: 0.6127, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5618/10000, Loss: 0.6127, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5619/10000, Loss: 0.6127, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5620/10000, Loss: 0.6126, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5621/10000, Loss: 0.6126, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5622/10000, Loss: 0.6126, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5623/10000, Loss: 0.6126, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5624/10000, Loss: 0.6126, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5625/10000, Loss: 0.6126, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5626/10000, Loss: 0.6126, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5627/10000, Loss: 0.6126, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5628/10000, Loss: 0.6126, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5629/10000, Loss: 0.6126, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5630/10000, Loss: 0.6126, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5631/10000, Loss: 0.6126, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5632/10000, Loss: 0.6125, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5633/10000, Loss: 0.6125, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5634/10000, Loss: 0.6125, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5635/10000, Loss: 0.6125, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5636/10000, Loss: 0.6125, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5637/10000, Loss: 0.6125, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5638/10000, Loss: 0.6125, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5639/10000, Loss: 0.6125, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5640/10000, Loss: 0.6125, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5641/10000, Loss: 0.6125, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5642/10000, Loss: 0.6125, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5643/10000, Loss: 0.6125, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5644/10000, Loss: 0.6125, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5645/10000, Loss: 0.6124, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5646/10000, Loss: 0.6124, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5647/10000, Loss: 0.6124, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5648/10000, Loss: 0.6124, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5649/10000, Loss: 0.6124, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5650/10000, Loss: 0.6124, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5651/10000, Loss: 0.6124, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5652/10000, Loss: 0.6124, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5653/10000, Loss: 0.6124, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5654/10000, Loss: 0.6124, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5655/10000, Loss: 0.6124, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5656/10000, Loss: 0.6124, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5657/10000, Loss: 0.6123, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5658/10000, Loss: 0.6123, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5659/10000, Loss: 0.6123, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5660/10000, Loss: 0.6123, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5661/10000, Loss: 0.6123, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5662/10000, Loss: 0.6123, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5663/10000, Loss: 0.6123, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5664/10000, Loss: 0.6123, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5665/10000, Loss: 0.6123, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5666/10000, Loss: 0.6123, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5667/10000, Loss: 0.6123, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5668/10000, Loss: 0.6123, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5669/10000, Loss: 0.6123, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5670/10000, Loss: 0.6122, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5671/10000, Loss: 0.6122, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5672/10000, Loss: 0.6122, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5673/10000, Loss: 0.6122, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5674/10000, Loss: 0.6122, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5675/10000, Loss: 0.6122, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5676/10000, Loss: 0.6122, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5677/10000, Loss: 0.6122, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5678/10000, Loss: 0.6122, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5679/10000, Loss: 0.6122, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5680/10000, Loss: 0.6122, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5681/10000, Loss: 0.6122, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5682/10000, Loss: 0.6121, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5683/10000, Loss: 0.6121, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5684/10000, Loss: 0.6121, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5685/10000, Loss: 0.6121, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5686/10000, Loss: 0.6121, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5687/10000, Loss: 0.6121, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5688/10000, Loss: 0.6121, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5689/10000, Loss: 0.6121, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5690/10000, Loss: 0.6121, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5691/10000, Loss: 0.6121, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5692/10000, Loss: 0.6121, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5693/10000, Loss: 0.6121, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5694/10000, Loss: 0.6121, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5695/10000, Loss: 0.6120, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5696/10000, Loss: 0.6120, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5697/10000, Loss: 0.6120, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5698/10000, Loss: 0.6120, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5699/10000, Loss: 0.6120, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5700/10000, Loss: 0.6120, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5701/10000, Loss: 0.6120, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5702/10000, Loss: 0.6120, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5703/10000, Loss: 0.6120, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5704/10000, Loss: 0.6120, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5705/10000, Loss: 0.6120, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5706/10000, Loss: 0.6120, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5707/10000, Loss: 0.6120, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5708/10000, Loss: 0.6119, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5709/10000, Loss: 0.6119, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5710/10000, Loss: 0.6119, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5711/10000, Loss: 0.6119, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5712/10000, Loss: 0.6119, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5713/10000, Loss: 0.6119, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5714/10000, Loss: 0.6119, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5715/10000, Loss: 0.6119, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5716/10000, Loss: 0.6119, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5717/10000, Loss: 0.6119, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5718/10000, Loss: 0.6119, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5719/10000, Loss: 0.6119, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5720/10000, Loss: 0.6119, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5721/10000, Loss: 0.6118, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5722/10000, Loss: 0.6118, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5723/10000, Loss: 0.6118, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5724/10000, Loss: 0.6118, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5725/10000, Loss: 0.6118, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5726/10000, Loss: 0.6118, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5727/10000, Loss: 0.6118, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5728/10000, Loss: 0.6118, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5729/10000, Loss: 0.6118, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5730/10000, Loss: 0.6118, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5731/10000, Loss: 0.6118, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5732/10000, Loss: 0.6118, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5733/10000, Loss: 0.6118, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5734/10000, Loss: 0.6117, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5735/10000, Loss: 0.6117, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5736/10000, Loss: 0.6117, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5737/10000, Loss: 0.6117, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5738/10000, Loss: 0.6117, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5739/10000, Loss: 0.6117, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5740/10000, Loss: 0.6117, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5741/10000, Loss: 0.6117, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5742/10000, Loss: 0.6117, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5743/10000, Loss: 0.6117, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5744/10000, Loss: 0.6117, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5745/10000, Loss: 0.6117, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5746/10000, Loss: 0.6117, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5747/10000, Loss: 0.6116, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5748/10000, Loss: 0.6116, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5749/10000, Loss: 0.6116, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5750/10000, Loss: 0.6116, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5751/10000, Loss: 0.6116, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5752/10000, Loss: 0.6116, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5753/10000, Loss: 0.6116, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5754/10000, Loss: 0.6116, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5755/10000, Loss: 0.6116, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5756/10000, Loss: 0.6116, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5757/10000, Loss: 0.6116, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5758/10000, Loss: 0.6116, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5759/10000, Loss: 0.6116, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5760/10000, Loss: 0.6115, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5761/10000, Loss: 0.6115, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5762/10000, Loss: 0.6115, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5763/10000, Loss: 0.6115, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5764/10000, Loss: 0.6115, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5765/10000, Loss: 0.6115, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5766/10000, Loss: 0.6115, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5767/10000, Loss: 0.6115, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5768/10000, Loss: 0.6115, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5769/10000, Loss: 0.6115, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5770/10000, Loss: 0.6115, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5771/10000, Loss: 0.6115, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5772/10000, Loss: 0.6115, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5773/10000, Loss: 0.6114, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5774/10000, Loss: 0.6114, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5775/10000, Loss: 0.6114, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5776/10000, Loss: 0.6114, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5777/10000, Loss: 0.6114, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5778/10000, Loss: 0.6114, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5779/10000, Loss: 0.6114, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5780/10000, Loss: 0.6114, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5781/10000, Loss: 0.6114, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5782/10000, Loss: 0.6114, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5783/10000, Loss: 0.6114, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5784/10000, Loss: 0.6114, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5785/10000, Loss: 0.6114, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5786/10000, Loss: 0.6113, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5787/10000, Loss: 0.6113, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5788/10000, Loss: 0.6113, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5789/10000, Loss: 0.6113, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5790/10000, Loss: 0.6113, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5791/10000, Loss: 0.6113, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5792/10000, Loss: 0.6113, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5793/10000, Loss: 0.6113, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5794/10000, Loss: 0.6113, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5795/10000, Loss: 0.6113, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5796/10000, Loss: 0.6113, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5797/10000, Loss: 0.6113, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5798/10000, Loss: 0.6113, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5799/10000, Loss: 0.6112, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5800/10000, Loss: 0.6112, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5801/10000, Loss: 0.6112, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5802/10000, Loss: 0.6112, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5803/10000, Loss: 0.6112, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5804/10000, Loss: 0.6112, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5805/10000, Loss: 0.6112, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5806/10000, Loss: 0.6112, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5807/10000, Loss: 0.6112, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5808/10000, Loss: 0.6112, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5809/10000, Loss: 0.6112, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5810/10000, Loss: 0.6112, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5811/10000, Loss: 0.6112, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5812/10000, Loss: 0.6111, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5813/10000, Loss: 0.6111, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5814/10000, Loss: 0.6111, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5815/10000, Loss: 0.6111, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5816/10000, Loss: 0.6111, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5817/10000, Loss: 0.6111, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5818/10000, Loss: 0.6111, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5819/10000, Loss: 0.6111, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5820/10000, Loss: 0.6111, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5821/10000, Loss: 0.6111, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5822/10000, Loss: 0.6111, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5823/10000, Loss: 0.6111, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5824/10000, Loss: 0.6111, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5825/10000, Loss: 0.6110, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5826/10000, Loss: 0.6110, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5827/10000, Loss: 0.6110, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5828/10000, Loss: 0.6110, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5829/10000, Loss: 0.6110, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5830/10000, Loss: 0.6110, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5831/10000, Loss: 0.6110, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5832/10000, Loss: 0.6110, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5833/10000, Loss: 0.6110, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5834/10000, Loss: 0.6110, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5835/10000, Loss: 0.6110, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5836/10000, Loss: 0.6110, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5837/10000, Loss: 0.6110, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5838/10000, Loss: 0.6110, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5839/10000, Loss: 0.6109, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5840/10000, Loss: 0.6109, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5841/10000, Loss: 0.6109, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5842/10000, Loss: 0.6109, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5843/10000, Loss: 0.6109, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5844/10000, Loss: 0.6109, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5845/10000, Loss: 0.6109, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5846/10000, Loss: 0.6109, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5847/10000, Loss: 0.6109, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5848/10000, Loss: 0.6109, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5849/10000, Loss: 0.6109, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5850/10000, Loss: 0.6109, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5851/10000, Loss: 0.6109, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5852/10000, Loss: 0.6108, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5853/10000, Loss: 0.6108, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5854/10000, Loss: 0.6108, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5855/10000, Loss: 0.6108, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5856/10000, Loss: 0.6108, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5857/10000, Loss: 0.6108, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5858/10000, Loss: 0.6108, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5859/10000, Loss: 0.6108, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5860/10000, Loss: 0.6108, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5861/10000, Loss: 0.6108, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5862/10000, Loss: 0.6108, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5863/10000, Loss: 0.6108, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5864/10000, Loss: 0.6108, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5865/10000, Loss: 0.6108, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5866/10000, Loss: 0.6107, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5867/10000, Loss: 0.6107, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5868/10000, Loss: 0.6107, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5869/10000, Loss: 0.6107, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5870/10000, Loss: 0.6107, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5871/10000, Loss: 0.6107, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5872/10000, Loss: 0.6107, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5873/10000, Loss: 0.6107, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5874/10000, Loss: 0.6107, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5875/10000, Loss: 0.6107, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5876/10000, Loss: 0.6107, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5877/10000, Loss: 0.6107, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5878/10000, Loss: 0.6107, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5879/10000, Loss: 0.6106, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5880/10000, Loss: 0.6106, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5881/10000, Loss: 0.6106, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5882/10000, Loss: 0.6106, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5883/10000, Loss: 0.6106, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5884/10000, Loss: 0.6106, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5885/10000, Loss: 0.6106, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5886/10000, Loss: 0.6106, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5887/10000, Loss: 0.6106, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5888/10000, Loss: 0.6106, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5889/10000, Loss: 0.6106, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5890/10000, Loss: 0.6106, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5891/10000, Loss: 0.6106, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5892/10000, Loss: 0.6106, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5893/10000, Loss: 0.6105, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5894/10000, Loss: 0.6105, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5895/10000, Loss: 0.6105, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5896/10000, Loss: 0.6105, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5897/10000, Loss: 0.6105, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5898/10000, Loss: 0.6105, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5899/10000, Loss: 0.6105, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5900/10000, Loss: 0.6105, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5901/10000, Loss: 0.6105, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5902/10000, Loss: 0.6105, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5903/10000, Loss: 0.6105, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5904/10000, Loss: 0.6105, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5905/10000, Loss: 0.6105, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5906/10000, Loss: 0.6104, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5907/10000, Loss: 0.6104, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5908/10000, Loss: 0.6104, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5909/10000, Loss: 0.6104, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5910/10000, Loss: 0.6104, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5911/10000, Loss: 0.6104, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5912/10000, Loss: 0.6104, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5913/10000, Loss: 0.6104, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5914/10000, Loss: 0.6104, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5915/10000, Loss: 0.6104, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5916/10000, Loss: 0.6104, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5917/10000, Loss: 0.6104, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5918/10000, Loss: 0.6104, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5919/10000, Loss: 0.6104, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5920/10000, Loss: 0.6103, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5921/10000, Loss: 0.6103, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5922/10000, Loss: 0.6103, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5923/10000, Loss: 0.6103, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5924/10000, Loss: 0.6103, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5925/10000, Loss: 0.6103, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5926/10000, Loss: 0.6103, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5927/10000, Loss: 0.6103, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5928/10000, Loss: 0.6103, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5929/10000, Loss: 0.6103, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5930/10000, Loss: 0.6103, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5931/10000, Loss: 0.6103, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5932/10000, Loss: 0.6103, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5933/10000, Loss: 0.6103, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5934/10000, Loss: 0.6102, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5935/10000, Loss: 0.6102, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5936/10000, Loss: 0.6102, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5937/10000, Loss: 0.6102, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5938/10000, Loss: 0.6102, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5939/10000, Loss: 0.6102, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5940/10000, Loss: 0.6102, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5941/10000, Loss: 0.6102, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5942/10000, Loss: 0.6102, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5943/10000, Loss: 0.6102, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5944/10000, Loss: 0.6102, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5945/10000, Loss: 0.6102, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5946/10000, Loss: 0.6102, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5947/10000, Loss: 0.6102, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5948/10000, Loss: 0.6101, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5949/10000, Loss: 0.6101, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5950/10000, Loss: 0.6101, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5951/10000, Loss: 0.6101, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5952/10000, Loss: 0.6101, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5953/10000, Loss: 0.6101, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5954/10000, Loss: 0.6101, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5955/10000, Loss: 0.6101, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5956/10000, Loss: 0.6101, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5957/10000, Loss: 0.6101, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5958/10000, Loss: 0.6101, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5959/10000, Loss: 0.6101, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5960/10000, Loss: 0.6101, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5961/10000, Loss: 0.6101, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5962/10000, Loss: 0.6100, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5963/10000, Loss: 0.6100, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5964/10000, Loss: 0.6100, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5965/10000, Loss: 0.6100, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5966/10000, Loss: 0.6100, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5967/10000, Loss: 0.6100, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5968/10000, Loss: 0.6100, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5969/10000, Loss: 0.6100, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5970/10000, Loss: 0.6100, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5971/10000, Loss: 0.6100, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5972/10000, Loss: 0.6100, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5973/10000, Loss: 0.6100, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5974/10000, Loss: 0.6100, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5975/10000, Loss: 0.6100, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5976/10000, Loss: 0.6099, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5977/10000, Loss: 0.6099, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5978/10000, Loss: 0.6099, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5979/10000, Loss: 0.6099, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5980/10000, Loss: 0.6099, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5981/10000, Loss: 0.6099, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5982/10000, Loss: 0.6099, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5983/10000, Loss: 0.6099, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5984/10000, Loss: 0.6099, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5985/10000, Loss: 0.6099, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5986/10000, Loss: 0.6099, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5987/10000, Loss: 0.6099, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5988/10000, Loss: 0.6099, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5989/10000, Loss: 0.6099, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5990/10000, Loss: 0.6098, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5991/10000, Loss: 0.6098, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5992/10000, Loss: 0.6098, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5993/10000, Loss: 0.6098, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5994/10000, Loss: 0.6098, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5995/10000, Loss: 0.6098, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5996/10000, Loss: 0.6098, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5997/10000, Loss: 0.6098, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5998/10000, Loss: 0.6098, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 5999/10000, Loss: 0.6098, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6000/10000, Loss: 0.6098, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6001/10000, Loss: 0.6098, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6002/10000, Loss: 0.6098, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6003/10000, Loss: 0.6098, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6004/10000, Loss: 0.6097, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6005/10000, Loss: 0.6097, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6006/10000, Loss: 0.6097, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6007/10000, Loss: 0.6097, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6008/10000, Loss: 0.6097, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6009/10000, Loss: 0.6097, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6010/10000, Loss: 0.6097, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6011/10000, Loss: 0.6097, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6012/10000, Loss: 0.6097, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6013/10000, Loss: 0.6097, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6014/10000, Loss: 0.6097, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6015/10000, Loss: 0.6097, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6016/10000, Loss: 0.6097, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6017/10000, Loss: 0.6097, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6018/10000, Loss: 0.6096, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6019/10000, Loss: 0.6096, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6020/10000, Loss: 0.6096, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6021/10000, Loss: 0.6096, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6022/10000, Loss: 0.6096, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6023/10000, Loss: 0.6096, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6024/10000, Loss: 0.6096, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6025/10000, Loss: 0.6096, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6026/10000, Loss: 0.6096, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6027/10000, Loss: 0.6096, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6028/10000, Loss: 0.6096, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6029/10000, Loss: 0.6096, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6030/10000, Loss: 0.6096, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6031/10000, Loss: 0.6096, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6032/10000, Loss: 0.6095, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6033/10000, Loss: 0.6095, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6034/10000, Loss: 0.6095, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6035/10000, Loss: 0.6095, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6036/10000, Loss: 0.6095, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6037/10000, Loss: 0.6095, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6038/10000, Loss: 0.6095, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6039/10000, Loss: 0.6095, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6040/10000, Loss: 0.6095, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6041/10000, Loss: 0.6095, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6042/10000, Loss: 0.6095, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6043/10000, Loss: 0.6095, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6044/10000, Loss: 0.6095, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6045/10000, Loss: 0.6095, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6046/10000, Loss: 0.6094, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6047/10000, Loss: 0.6094, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6048/10000, Loss: 0.6094, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6049/10000, Loss: 0.6094, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6050/10000, Loss: 0.6094, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6051/10000, Loss: 0.6094, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6052/10000, Loss: 0.6094, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6053/10000, Loss: 0.6094, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6054/10000, Loss: 0.6094, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6055/10000, Loss: 0.6094, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6056/10000, Loss: 0.6094, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6057/10000, Loss: 0.6094, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6058/10000, Loss: 0.6094, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6059/10000, Loss: 0.6094, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6060/10000, Loss: 0.6094, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6061/10000, Loss: 0.6093, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6062/10000, Loss: 0.6093, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6063/10000, Loss: 0.6093, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6064/10000, Loss: 0.6093, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6065/10000, Loss: 0.6093, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6066/10000, Loss: 0.6093, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6067/10000, Loss: 0.6093, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6068/10000, Loss: 0.6093, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6069/10000, Loss: 0.6093, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6070/10000, Loss: 0.6093, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6071/10000, Loss: 0.6093, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6072/10000, Loss: 0.6093, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6073/10000, Loss: 0.6093, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6074/10000, Loss: 0.6093, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6075/10000, Loss: 0.6092, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6076/10000, Loss: 0.6092, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6077/10000, Loss: 0.6092, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6078/10000, Loss: 0.6092, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6079/10000, Loss: 0.6092, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6080/10000, Loss: 0.6092, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6081/10000, Loss: 0.6092, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6082/10000, Loss: 0.6092, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6083/10000, Loss: 0.6092, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6084/10000, Loss: 0.6092, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6085/10000, Loss: 0.6092, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6086/10000, Loss: 0.6092, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6087/10000, Loss: 0.6092, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6088/10000, Loss: 0.6092, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6089/10000, Loss: 0.6092, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6090/10000, Loss: 0.6091, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6091/10000, Loss: 0.6091, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6092/10000, Loss: 0.6091, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6093/10000, Loss: 0.6091, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6094/10000, Loss: 0.6091, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6095/10000, Loss: 0.6091, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6096/10000, Loss: 0.6091, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6097/10000, Loss: 0.6091, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6098/10000, Loss: 0.6091, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6099/10000, Loss: 0.6091, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6100/10000, Loss: 0.6091, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6101/10000, Loss: 0.6091, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6102/10000, Loss: 0.6091, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6103/10000, Loss: 0.6091, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6104/10000, Loss: 0.6090, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6105/10000, Loss: 0.6090, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6106/10000, Loss: 0.6090, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6107/10000, Loss: 0.6090, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6108/10000, Loss: 0.6090, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6109/10000, Loss: 0.6090, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6110/10000, Loss: 0.6090, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6111/10000, Loss: 0.6090, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6112/10000, Loss: 0.6090, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6113/10000, Loss: 0.6090, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6114/10000, Loss: 0.6090, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6115/10000, Loss: 0.6090, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6116/10000, Loss: 0.6090, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6117/10000, Loss: 0.6090, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6118/10000, Loss: 0.6090, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6119/10000, Loss: 0.6089, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6120/10000, Loss: 0.6089, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6121/10000, Loss: 0.6089, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6122/10000, Loss: 0.6089, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6123/10000, Loss: 0.6089, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6124/10000, Loss: 0.6089, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6125/10000, Loss: 0.6089, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6126/10000, Loss: 0.6089, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6127/10000, Loss: 0.6089, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6128/10000, Loss: 0.6089, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6129/10000, Loss: 0.6089, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6130/10000, Loss: 0.6089, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6131/10000, Loss: 0.6089, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6132/10000, Loss: 0.6089, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6133/10000, Loss: 0.6088, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6134/10000, Loss: 0.6088, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6135/10000, Loss: 0.6088, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6136/10000, Loss: 0.6088, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6137/10000, Loss: 0.6088, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6138/10000, Loss: 0.6088, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6139/10000, Loss: 0.6088, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6140/10000, Loss: 0.6088, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6141/10000, Loss: 0.6088, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6142/10000, Loss: 0.6088, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6143/10000, Loss: 0.6088, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6144/10000, Loss: 0.6088, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6145/10000, Loss: 0.6088, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6146/10000, Loss: 0.6088, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6147/10000, Loss: 0.6088, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6148/10000, Loss: 0.6087, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6149/10000, Loss: 0.6087, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6150/10000, Loss: 0.6087, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6151/10000, Loss: 0.6087, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6152/10000, Loss: 0.6087, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6153/10000, Loss: 0.6087, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6154/10000, Loss: 0.6087, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6155/10000, Loss: 0.6087, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6156/10000, Loss: 0.6087, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6157/10000, Loss: 0.6087, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6158/10000, Loss: 0.6087, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6159/10000, Loss: 0.6087, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6160/10000, Loss: 0.6087, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6161/10000, Loss: 0.6087, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6162/10000, Loss: 0.6087, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6163/10000, Loss: 0.6086, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6164/10000, Loss: 0.6086, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6165/10000, Loss: 0.6086, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6166/10000, Loss: 0.6086, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6167/10000, Loss: 0.6086, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6168/10000, Loss: 0.6086, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6169/10000, Loss: 0.6086, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6170/10000, Loss: 0.6086, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6171/10000, Loss: 0.6086, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6172/10000, Loss: 0.6086, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6173/10000, Loss: 0.6086, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6174/10000, Loss: 0.6086, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6175/10000, Loss: 0.6086, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6176/10000, Loss: 0.6086, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6177/10000, Loss: 0.6086, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6178/10000, Loss: 0.6085, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6179/10000, Loss: 0.6085, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6180/10000, Loss: 0.6085, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6181/10000, Loss: 0.6085, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6182/10000, Loss: 0.6085, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6183/10000, Loss: 0.6085, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6184/10000, Loss: 0.6085, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6185/10000, Loss: 0.6085, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6186/10000, Loss: 0.6085, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6187/10000, Loss: 0.6085, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6188/10000, Loss: 0.6085, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6189/10000, Loss: 0.6085, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6190/10000, Loss: 0.6085, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6191/10000, Loss: 0.6085, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6192/10000, Loss: 0.6085, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6193/10000, Loss: 0.6084, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6194/10000, Loss: 0.6084, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6195/10000, Loss: 0.6084, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6196/10000, Loss: 0.6084, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6197/10000, Loss: 0.6084, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6198/10000, Loss: 0.6084, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6199/10000, Loss: 0.6084, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6200/10000, Loss: 0.6084, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6201/10000, Loss: 0.6084, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6202/10000, Loss: 0.6084, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6203/10000, Loss: 0.6084, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6204/10000, Loss: 0.6084, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6205/10000, Loss: 0.6084, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6206/10000, Loss: 0.6084, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6207/10000, Loss: 0.6084, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6208/10000, Loss: 0.6083, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6209/10000, Loss: 0.6083, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6210/10000, Loss: 0.6083, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6211/10000, Loss: 0.6083, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6212/10000, Loss: 0.6083, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6213/10000, Loss: 0.6083, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6214/10000, Loss: 0.6083, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6215/10000, Loss: 0.6083, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6216/10000, Loss: 0.6083, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6217/10000, Loss: 0.6083, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6218/10000, Loss: 0.6083, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6219/10000, Loss: 0.6083, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6220/10000, Loss: 0.6083, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6221/10000, Loss: 0.6083, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6222/10000, Loss: 0.6083, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6223/10000, Loss: 0.6082, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6224/10000, Loss: 0.6082, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6225/10000, Loss: 0.6082, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6226/10000, Loss: 0.6082, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6227/10000, Loss: 0.6082, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6228/10000, Loss: 0.6082, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6229/10000, Loss: 0.6082, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6230/10000, Loss: 0.6082, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6231/10000, Loss: 0.6082, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6232/10000, Loss: 0.6082, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6233/10000, Loss: 0.6082, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6234/10000, Loss: 0.6082, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6235/10000, Loss: 0.6082, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6236/10000, Loss: 0.6082, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6237/10000, Loss: 0.6082, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6238/10000, Loss: 0.6082, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6239/10000, Loss: 0.6081, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6240/10000, Loss: 0.6081, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6241/10000, Loss: 0.6081, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6242/10000, Loss: 0.6081, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6243/10000, Loss: 0.6081, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6244/10000, Loss: 0.6081, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6245/10000, Loss: 0.6081, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6246/10000, Loss: 0.6081, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6247/10000, Loss: 0.6081, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6248/10000, Loss: 0.6081, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6249/10000, Loss: 0.6081, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6250/10000, Loss: 0.6081, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6251/10000, Loss: 0.6081, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6252/10000, Loss: 0.6081, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6253/10000, Loss: 0.6081, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6254/10000, Loss: 0.6080, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6255/10000, Loss: 0.6080, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6256/10000, Loss: 0.6080, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6257/10000, Loss: 0.6080, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6258/10000, Loss: 0.6080, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6259/10000, Loss: 0.6080, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6260/10000, Loss: 0.6080, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6261/10000, Loss: 0.6080, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6262/10000, Loss: 0.6080, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6263/10000, Loss: 0.6080, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6264/10000, Loss: 0.6080, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6265/10000, Loss: 0.6080, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6266/10000, Loss: 0.6080, Accuracy: 0.7051, Learning Rate: 0.000100\n",
      "Epoch 6267/10000, Loss: 0.6080, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6268/10000, Loss: 0.6080, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6269/10000, Loss: 0.6079, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6270/10000, Loss: 0.6079, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6271/10000, Loss: 0.6079, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6272/10000, Loss: 0.6079, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6273/10000, Loss: 0.6079, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6274/10000, Loss: 0.6079, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6275/10000, Loss: 0.6079, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6276/10000, Loss: 0.6079, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6277/10000, Loss: 0.6079, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6278/10000, Loss: 0.6079, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6279/10000, Loss: 0.6079, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6280/10000, Loss: 0.6079, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6281/10000, Loss: 0.6079, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6282/10000, Loss: 0.6079, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6283/10000, Loss: 0.6079, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6284/10000, Loss: 0.6079, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6285/10000, Loss: 0.6078, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6286/10000, Loss: 0.6078, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6287/10000, Loss: 0.6078, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6288/10000, Loss: 0.6078, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6289/10000, Loss: 0.6078, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6290/10000, Loss: 0.6078, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6291/10000, Loss: 0.6078, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6292/10000, Loss: 0.6078, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6293/10000, Loss: 0.6078, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6294/10000, Loss: 0.6078, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6295/10000, Loss: 0.6078, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6296/10000, Loss: 0.6078, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6297/10000, Loss: 0.6078, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6298/10000, Loss: 0.6078, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6299/10000, Loss: 0.6078, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6300/10000, Loss: 0.6077, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6301/10000, Loss: 0.6077, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6302/10000, Loss: 0.6077, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6303/10000, Loss: 0.6077, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6304/10000, Loss: 0.6077, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6305/10000, Loss: 0.6077, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6306/10000, Loss: 0.6077, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6307/10000, Loss: 0.6077, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6308/10000, Loss: 0.6077, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6309/10000, Loss: 0.6077, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6310/10000, Loss: 0.6077, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6311/10000, Loss: 0.6077, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6312/10000, Loss: 0.6077, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6313/10000, Loss: 0.6077, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6314/10000, Loss: 0.6077, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6315/10000, Loss: 0.6077, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6316/10000, Loss: 0.6076, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6317/10000, Loss: 0.6076, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6318/10000, Loss: 0.6076, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6319/10000, Loss: 0.6076, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6320/10000, Loss: 0.6076, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6321/10000, Loss: 0.6076, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6322/10000, Loss: 0.6076, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6323/10000, Loss: 0.6076, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6324/10000, Loss: 0.6076, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6325/10000, Loss: 0.6076, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6326/10000, Loss: 0.6076, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6327/10000, Loss: 0.6076, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6328/10000, Loss: 0.6076, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6329/10000, Loss: 0.6076, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6330/10000, Loss: 0.6076, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6331/10000, Loss: 0.6076, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6332/10000, Loss: 0.6075, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6333/10000, Loss: 0.6075, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6334/10000, Loss: 0.6075, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6335/10000, Loss: 0.6075, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6336/10000, Loss: 0.6075, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6337/10000, Loss: 0.6075, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6338/10000, Loss: 0.6075, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6339/10000, Loss: 0.6075, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6340/10000, Loss: 0.6075, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6341/10000, Loss: 0.6075, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6342/10000, Loss: 0.6075, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6343/10000, Loss: 0.6075, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6344/10000, Loss: 0.6075, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6345/10000, Loss: 0.6075, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6346/10000, Loss: 0.6075, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6347/10000, Loss: 0.6074, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6348/10000, Loss: 0.6074, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6349/10000, Loss: 0.6074, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6350/10000, Loss: 0.6074, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6351/10000, Loss: 0.6074, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6352/10000, Loss: 0.6074, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6353/10000, Loss: 0.6074, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6354/10000, Loss: 0.6074, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6355/10000, Loss: 0.6074, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6356/10000, Loss: 0.6074, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6357/10000, Loss: 0.6074, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6358/10000, Loss: 0.6074, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6359/10000, Loss: 0.6074, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6360/10000, Loss: 0.6074, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6361/10000, Loss: 0.6074, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6362/10000, Loss: 0.6074, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6363/10000, Loss: 0.6073, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6364/10000, Loss: 0.6073, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 6365/10000, Loss: 0.6073, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6366/10000, Loss: 0.6073, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6367/10000, Loss: 0.6073, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6368/10000, Loss: 0.6073, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6369/10000, Loss: 0.6073, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6370/10000, Loss: 0.6073, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6371/10000, Loss: 0.6073, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6372/10000, Loss: 0.6073, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6373/10000, Loss: 0.6073, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6374/10000, Loss: 0.6073, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6375/10000, Loss: 0.6073, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6376/10000, Loss: 0.6073, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6377/10000, Loss: 0.6073, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6378/10000, Loss: 0.6073, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6379/10000, Loss: 0.6072, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6380/10000, Loss: 0.6072, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6381/10000, Loss: 0.6072, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6382/10000, Loss: 0.6072, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6383/10000, Loss: 0.6072, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6384/10000, Loss: 0.6072, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6385/10000, Loss: 0.6072, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6386/10000, Loss: 0.6072, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6387/10000, Loss: 0.6072, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6388/10000, Loss: 0.6072, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6389/10000, Loss: 0.6072, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6390/10000, Loss: 0.6072, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6391/10000, Loss: 0.6072, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6392/10000, Loss: 0.6072, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6393/10000, Loss: 0.6072, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6394/10000, Loss: 0.6072, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6395/10000, Loss: 0.6071, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6396/10000, Loss: 0.6071, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6397/10000, Loss: 0.6071, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6398/10000, Loss: 0.6071, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6399/10000, Loss: 0.6071, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6400/10000, Loss: 0.6071, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6401/10000, Loss: 0.6071, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6402/10000, Loss: 0.6071, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6403/10000, Loss: 0.6071, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6404/10000, Loss: 0.6071, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6405/10000, Loss: 0.6071, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6406/10000, Loss: 0.6071, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6407/10000, Loss: 0.6071, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6408/10000, Loss: 0.6071, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6409/10000, Loss: 0.6071, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6410/10000, Loss: 0.6071, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6411/10000, Loss: 0.6070, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6412/10000, Loss: 0.6070, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6413/10000, Loss: 0.6070, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6414/10000, Loss: 0.6070, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6415/10000, Loss: 0.6070, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6416/10000, Loss: 0.6070, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6417/10000, Loss: 0.6070, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6418/10000, Loss: 0.6070, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6419/10000, Loss: 0.6070, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6420/10000, Loss: 0.6070, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6421/10000, Loss: 0.6070, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6422/10000, Loss: 0.6070, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6423/10000, Loss: 0.6070, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6424/10000, Loss: 0.6070, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6425/10000, Loss: 0.6070, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6426/10000, Loss: 0.6070, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6427/10000, Loss: 0.6070, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6428/10000, Loss: 0.6069, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6429/10000, Loss: 0.6069, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6430/10000, Loss: 0.6069, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6431/10000, Loss: 0.6069, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6432/10000, Loss: 0.6069, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6433/10000, Loss: 0.6069, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6434/10000, Loss: 0.6069, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6435/10000, Loss: 0.6069, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6436/10000, Loss: 0.6069, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6437/10000, Loss: 0.6069, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6438/10000, Loss: 0.6069, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6439/10000, Loss: 0.6069, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6440/10000, Loss: 0.6069, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6441/10000, Loss: 0.6069, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6442/10000, Loss: 0.6069, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6443/10000, Loss: 0.6069, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6444/10000, Loss: 0.6068, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6445/10000, Loss: 0.6068, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6446/10000, Loss: 0.6068, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6447/10000, Loss: 0.6068, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6448/10000, Loss: 0.6068, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6449/10000, Loss: 0.6068, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6450/10000, Loss: 0.6068, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6451/10000, Loss: 0.6068, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6452/10000, Loss: 0.6068, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6453/10000, Loss: 0.6068, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6454/10000, Loss: 0.6068, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6455/10000, Loss: 0.6068, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6456/10000, Loss: 0.6068, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6457/10000, Loss: 0.6068, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6458/10000, Loss: 0.6068, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6459/10000, Loss: 0.6068, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6460/10000, Loss: 0.6067, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6461/10000, Loss: 0.6067, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6462/10000, Loss: 0.6067, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6463/10000, Loss: 0.6067, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6464/10000, Loss: 0.6067, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6465/10000, Loss: 0.6067, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6466/10000, Loss: 0.6067, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6467/10000, Loss: 0.6067, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6468/10000, Loss: 0.6067, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6469/10000, Loss: 0.6067, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6470/10000, Loss: 0.6067, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6471/10000, Loss: 0.6067, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6472/10000, Loss: 0.6067, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6473/10000, Loss: 0.6067, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6474/10000, Loss: 0.6067, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6475/10000, Loss: 0.6067, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6476/10000, Loss: 0.6067, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6477/10000, Loss: 0.6066, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6478/10000, Loss: 0.6066, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6479/10000, Loss: 0.6066, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6480/10000, Loss: 0.6066, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6481/10000, Loss: 0.6066, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6482/10000, Loss: 0.6066, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6483/10000, Loss: 0.6066, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6484/10000, Loss: 0.6066, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6485/10000, Loss: 0.6066, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6486/10000, Loss: 0.6066, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6487/10000, Loss: 0.6066, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6488/10000, Loss: 0.6066, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6489/10000, Loss: 0.6066, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6490/10000, Loss: 0.6066, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6491/10000, Loss: 0.6066, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6492/10000, Loss: 0.6066, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6493/10000, Loss: 0.6066, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6494/10000, Loss: 0.6065, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6495/10000, Loss: 0.6065, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6496/10000, Loss: 0.6065, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6497/10000, Loss: 0.6065, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6498/10000, Loss: 0.6065, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6499/10000, Loss: 0.6065, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6500/10000, Loss: 0.6065, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6501/10000, Loss: 0.6065, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6502/10000, Loss: 0.6065, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6503/10000, Loss: 0.6065, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6504/10000, Loss: 0.6065, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6505/10000, Loss: 0.6065, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6506/10000, Loss: 0.6065, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6507/10000, Loss: 0.6065, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6508/10000, Loss: 0.6065, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6509/10000, Loss: 0.6065, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6510/10000, Loss: 0.6064, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6511/10000, Loss: 0.6064, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6512/10000, Loss: 0.6064, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6513/10000, Loss: 0.6064, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6514/10000, Loss: 0.6064, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6515/10000, Loss: 0.6064, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6516/10000, Loss: 0.6064, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6517/10000, Loss: 0.6064, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6518/10000, Loss: 0.6064, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6519/10000, Loss: 0.6064, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6520/10000, Loss: 0.6064, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6521/10000, Loss: 0.6064, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6522/10000, Loss: 0.6064, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6523/10000, Loss: 0.6064, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6524/10000, Loss: 0.6064, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6525/10000, Loss: 0.6064, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6526/10000, Loss: 0.6064, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6527/10000, Loss: 0.6063, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6528/10000, Loss: 0.6063, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6529/10000, Loss: 0.6063, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6530/10000, Loss: 0.6063, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6531/10000, Loss: 0.6063, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6532/10000, Loss: 0.6063, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6533/10000, Loss: 0.6063, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6534/10000, Loss: 0.6063, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6535/10000, Loss: 0.6063, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6536/10000, Loss: 0.6063, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6537/10000, Loss: 0.6063, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6538/10000, Loss: 0.6063, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6539/10000, Loss: 0.6063, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6540/10000, Loss: 0.6063, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6541/10000, Loss: 0.6063, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6542/10000, Loss: 0.6063, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6543/10000, Loss: 0.6063, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6544/10000, Loss: 0.6062, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6545/10000, Loss: 0.6062, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6546/10000, Loss: 0.6062, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6547/10000, Loss: 0.6062, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6548/10000, Loss: 0.6062, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6549/10000, Loss: 0.6062, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6550/10000, Loss: 0.6062, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6551/10000, Loss: 0.6062, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6552/10000, Loss: 0.6062, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6553/10000, Loss: 0.6062, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6554/10000, Loss: 0.6062, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6555/10000, Loss: 0.6062, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6556/10000, Loss: 0.6062, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6557/10000, Loss: 0.6062, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6558/10000, Loss: 0.6062, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6559/10000, Loss: 0.6062, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6560/10000, Loss: 0.6062, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6561/10000, Loss: 0.6061, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6562/10000, Loss: 0.6061, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6563/10000, Loss: 0.6061, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6564/10000, Loss: 0.6061, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6565/10000, Loss: 0.6061, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6566/10000, Loss: 0.6061, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6567/10000, Loss: 0.6061, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6568/10000, Loss: 0.6061, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6569/10000, Loss: 0.6061, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6570/10000, Loss: 0.6061, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6571/10000, Loss: 0.6061, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6572/10000, Loss: 0.6061, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6573/10000, Loss: 0.6061, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6574/10000, Loss: 0.6061, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6575/10000, Loss: 0.6061, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6576/10000, Loss: 0.6061, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6577/10000, Loss: 0.6061, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6578/10000, Loss: 0.6060, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6579/10000, Loss: 0.6060, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6580/10000, Loss: 0.6060, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6581/10000, Loss: 0.6060, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6582/10000, Loss: 0.6060, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6583/10000, Loss: 0.6060, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6584/10000, Loss: 0.6060, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6585/10000, Loss: 0.6060, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6586/10000, Loss: 0.6060, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6587/10000, Loss: 0.6060, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6588/10000, Loss: 0.6060, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6589/10000, Loss: 0.6060, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6590/10000, Loss: 0.6060, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6591/10000, Loss: 0.6060, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6592/10000, Loss: 0.6060, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6593/10000, Loss: 0.6060, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6594/10000, Loss: 0.6060, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6595/10000, Loss: 0.6059, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6596/10000, Loss: 0.6059, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6597/10000, Loss: 0.6059, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6598/10000, Loss: 0.6059, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6599/10000, Loss: 0.6059, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6600/10000, Loss: 0.6059, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6601/10000, Loss: 0.6059, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6602/10000, Loss: 0.6059, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6603/10000, Loss: 0.6059, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6604/10000, Loss: 0.6059, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6605/10000, Loss: 0.6059, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6606/10000, Loss: 0.6059, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6607/10000, Loss: 0.6059, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6608/10000, Loss: 0.6059, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6609/10000, Loss: 0.6059, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6610/10000, Loss: 0.6059, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6611/10000, Loss: 0.6059, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6612/10000, Loss: 0.6058, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6613/10000, Loss: 0.6058, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6614/10000, Loss: 0.6058, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6615/10000, Loss: 0.6058, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6616/10000, Loss: 0.6058, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6617/10000, Loss: 0.6058, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6618/10000, Loss: 0.6058, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6619/10000, Loss: 0.6058, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6620/10000, Loss: 0.6058, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6621/10000, Loss: 0.6058, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6622/10000, Loss: 0.6058, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6623/10000, Loss: 0.6058, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6624/10000, Loss: 0.6058, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6625/10000, Loss: 0.6058, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6626/10000, Loss: 0.6058, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6627/10000, Loss: 0.6058, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6628/10000, Loss: 0.6058, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6629/10000, Loss: 0.6058, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6630/10000, Loss: 0.6057, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6631/10000, Loss: 0.6057, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6632/10000, Loss: 0.6057, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6633/10000, Loss: 0.6057, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6634/10000, Loss: 0.6057, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6635/10000, Loss: 0.6057, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6636/10000, Loss: 0.6057, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6637/10000, Loss: 0.6057, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6638/10000, Loss: 0.6057, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6639/10000, Loss: 0.6057, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6640/10000, Loss: 0.6057, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6641/10000, Loss: 0.6057, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6642/10000, Loss: 0.6057, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6643/10000, Loss: 0.6057, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6644/10000, Loss: 0.6057, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6645/10000, Loss: 0.6057, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6646/10000, Loss: 0.6057, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6647/10000, Loss: 0.6056, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6648/10000, Loss: 0.6056, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6649/10000, Loss: 0.6056, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6650/10000, Loss: 0.6056, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6651/10000, Loss: 0.6056, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6652/10000, Loss: 0.6056, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6653/10000, Loss: 0.6056, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6654/10000, Loss: 0.6056, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6655/10000, Loss: 0.6056, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6656/10000, Loss: 0.6056, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6657/10000, Loss: 0.6056, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6658/10000, Loss: 0.6056, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6659/10000, Loss: 0.6056, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6660/10000, Loss: 0.6056, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6661/10000, Loss: 0.6056, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6662/10000, Loss: 0.6056, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6663/10000, Loss: 0.6056, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6664/10000, Loss: 0.6056, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6665/10000, Loss: 0.6055, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6666/10000, Loss: 0.6055, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6667/10000, Loss: 0.6055, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6668/10000, Loss: 0.6055, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6669/10000, Loss: 0.6055, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6670/10000, Loss: 0.6055, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6671/10000, Loss: 0.6055, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6672/10000, Loss: 0.6055, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6673/10000, Loss: 0.6055, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6674/10000, Loss: 0.6055, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6675/10000, Loss: 0.6055, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6676/10000, Loss: 0.6055, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6677/10000, Loss: 0.6055, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6678/10000, Loss: 0.6055, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6679/10000, Loss: 0.6055, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6680/10000, Loss: 0.6055, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6681/10000, Loss: 0.6055, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6682/10000, Loss: 0.6055, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6683/10000, Loss: 0.6054, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6684/10000, Loss: 0.6054, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6685/10000, Loss: 0.6054, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6686/10000, Loss: 0.6054, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6687/10000, Loss: 0.6054, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6688/10000, Loss: 0.6054, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6689/10000, Loss: 0.6054, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6690/10000, Loss: 0.6054, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6691/10000, Loss: 0.6054, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6692/10000, Loss: 0.6054, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6693/10000, Loss: 0.6054, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6694/10000, Loss: 0.6054, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6695/10000, Loss: 0.6054, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6696/10000, Loss: 0.6054, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6697/10000, Loss: 0.6054, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6698/10000, Loss: 0.6054, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6699/10000, Loss: 0.6054, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6700/10000, Loss: 0.6053, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6701/10000, Loss: 0.6053, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6702/10000, Loss: 0.6053, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6703/10000, Loss: 0.6053, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6704/10000, Loss: 0.6053, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6705/10000, Loss: 0.6053, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6706/10000, Loss: 0.6053, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6707/10000, Loss: 0.6053, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6708/10000, Loss: 0.6053, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6709/10000, Loss: 0.6053, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6710/10000, Loss: 0.6053, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6711/10000, Loss: 0.6053, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6712/10000, Loss: 0.6053, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6713/10000, Loss: 0.6053, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6714/10000, Loss: 0.6053, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6715/10000, Loss: 0.6053, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6716/10000, Loss: 0.6053, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6717/10000, Loss: 0.6053, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6718/10000, Loss: 0.6052, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6719/10000, Loss: 0.6052, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6720/10000, Loss: 0.6052, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6721/10000, Loss: 0.6052, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6722/10000, Loss: 0.6052, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6723/10000, Loss: 0.6052, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6724/10000, Loss: 0.6052, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6725/10000, Loss: 0.6052, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6726/10000, Loss: 0.6052, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6727/10000, Loss: 0.6052, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6728/10000, Loss: 0.6052, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6729/10000, Loss: 0.6052, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6730/10000, Loss: 0.6052, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6731/10000, Loss: 0.6052, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6732/10000, Loss: 0.6052, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6733/10000, Loss: 0.6052, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6734/10000, Loss: 0.6052, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6735/10000, Loss: 0.6052, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6736/10000, Loss: 0.6051, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6737/10000, Loss: 0.6051, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6738/10000, Loss: 0.6051, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6739/10000, Loss: 0.6051, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6740/10000, Loss: 0.6051, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6741/10000, Loss: 0.6051, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6742/10000, Loss: 0.6051, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6743/10000, Loss: 0.6051, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6744/10000, Loss: 0.6051, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6745/10000, Loss: 0.6051, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6746/10000, Loss: 0.6051, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6747/10000, Loss: 0.6051, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6748/10000, Loss: 0.6051, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6749/10000, Loss: 0.6051, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6750/10000, Loss: 0.6051, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6751/10000, Loss: 0.6051, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6752/10000, Loss: 0.6051, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6753/10000, Loss: 0.6051, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6754/10000, Loss: 0.6050, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6755/10000, Loss: 0.6050, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6756/10000, Loss: 0.6050, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6757/10000, Loss: 0.6050, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6758/10000, Loss: 0.6050, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6759/10000, Loss: 0.6050, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6760/10000, Loss: 0.6050, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6761/10000, Loss: 0.6050, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6762/10000, Loss: 0.6050, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6763/10000, Loss: 0.6050, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6764/10000, Loss: 0.6050, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6765/10000, Loss: 0.6050, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6766/10000, Loss: 0.6050, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6767/10000, Loss: 0.6050, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6768/10000, Loss: 0.6050, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6769/10000, Loss: 0.6050, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6770/10000, Loss: 0.6050, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6771/10000, Loss: 0.6050, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6772/10000, Loss: 0.6050, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6773/10000, Loss: 0.6049, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6774/10000, Loss: 0.6049, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6775/10000, Loss: 0.6049, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6776/10000, Loss: 0.6049, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6777/10000, Loss: 0.6049, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6778/10000, Loss: 0.6049, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6779/10000, Loss: 0.6049, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6780/10000, Loss: 0.6049, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6781/10000, Loss: 0.6049, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6782/10000, Loss: 0.6049, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6783/10000, Loss: 0.6049, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6784/10000, Loss: 0.6049, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6785/10000, Loss: 0.6049, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6786/10000, Loss: 0.6049, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6787/10000, Loss: 0.6049, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6788/10000, Loss: 0.6049, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6789/10000, Loss: 0.6049, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6790/10000, Loss: 0.6049, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6791/10000, Loss: 0.6048, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6792/10000, Loss: 0.6048, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6793/10000, Loss: 0.6048, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6794/10000, Loss: 0.6048, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6795/10000, Loss: 0.6048, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6796/10000, Loss: 0.6048, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6797/10000, Loss: 0.6048, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6798/10000, Loss: 0.6048, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6799/10000, Loss: 0.6048, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6800/10000, Loss: 0.6048, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6801/10000, Loss: 0.6048, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6802/10000, Loss: 0.6048, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6803/10000, Loss: 0.6048, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6804/10000, Loss: 0.6048, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6805/10000, Loss: 0.6048, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6806/10000, Loss: 0.6048, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6807/10000, Loss: 0.6048, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6808/10000, Loss: 0.6048, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6809/10000, Loss: 0.6047, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6810/10000, Loss: 0.6047, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6811/10000, Loss: 0.6047, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6812/10000, Loss: 0.6047, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6813/10000, Loss: 0.6047, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6814/10000, Loss: 0.6047, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6815/10000, Loss: 0.6047, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6816/10000, Loss: 0.6047, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6817/10000, Loss: 0.6047, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6818/10000, Loss: 0.6047, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6819/10000, Loss: 0.6047, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6820/10000, Loss: 0.6047, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6821/10000, Loss: 0.6047, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6822/10000, Loss: 0.6047, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6823/10000, Loss: 0.6047, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6824/10000, Loss: 0.6047, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6825/10000, Loss: 0.6047, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6826/10000, Loss: 0.6047, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6827/10000, Loss: 0.6047, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6828/10000, Loss: 0.6046, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6829/10000, Loss: 0.6046, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6830/10000, Loss: 0.6046, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6831/10000, Loss: 0.6046, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6832/10000, Loss: 0.6046, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6833/10000, Loss: 0.6046, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6834/10000, Loss: 0.6046, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6835/10000, Loss: 0.6046, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6836/10000, Loss: 0.6046, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6837/10000, Loss: 0.6046, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6838/10000, Loss: 0.6046, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6839/10000, Loss: 0.6046, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6840/10000, Loss: 0.6046, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6841/10000, Loss: 0.6046, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6842/10000, Loss: 0.6046, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6843/10000, Loss: 0.6046, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6844/10000, Loss: 0.6046, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6845/10000, Loss: 0.6046, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6846/10000, Loss: 0.6046, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6847/10000, Loss: 0.6045, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6848/10000, Loss: 0.6045, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6849/10000, Loss: 0.6045, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6850/10000, Loss: 0.6045, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6851/10000, Loss: 0.6045, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6852/10000, Loss: 0.6045, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6853/10000, Loss: 0.6045, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6854/10000, Loss: 0.6045, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6855/10000, Loss: 0.6045, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6856/10000, Loss: 0.6045, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6857/10000, Loss: 0.6045, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6858/10000, Loss: 0.6045, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6859/10000, Loss: 0.6045, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6860/10000, Loss: 0.6045, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6861/10000, Loss: 0.6045, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6862/10000, Loss: 0.6045, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6863/10000, Loss: 0.6045, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6864/10000, Loss: 0.6045, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6865/10000, Loss: 0.6045, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6866/10000, Loss: 0.6044, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6867/10000, Loss: 0.6044, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6868/10000, Loss: 0.6044, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6869/10000, Loss: 0.6044, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6870/10000, Loss: 0.6044, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6871/10000, Loss: 0.6044, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6872/10000, Loss: 0.6044, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6873/10000, Loss: 0.6044, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6874/10000, Loss: 0.6044, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6875/10000, Loss: 0.6044, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6876/10000, Loss: 0.6044, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6877/10000, Loss: 0.6044, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6878/10000, Loss: 0.6044, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6879/10000, Loss: 0.6044, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6880/10000, Loss: 0.6044, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6881/10000, Loss: 0.6044, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6882/10000, Loss: 0.6044, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6883/10000, Loss: 0.6044, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6884/10000, Loss: 0.6044, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6885/10000, Loss: 0.6043, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6886/10000, Loss: 0.6043, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6887/10000, Loss: 0.6043, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6888/10000, Loss: 0.6043, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6889/10000, Loss: 0.6043, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6890/10000, Loss: 0.6043, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6891/10000, Loss: 0.6043, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6892/10000, Loss: 0.6043, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6893/10000, Loss: 0.6043, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6894/10000, Loss: 0.6043, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6895/10000, Loss: 0.6043, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6896/10000, Loss: 0.6043, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6897/10000, Loss: 0.6043, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6898/10000, Loss: 0.6043, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6899/10000, Loss: 0.6043, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6900/10000, Loss: 0.6043, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6901/10000, Loss: 0.6043, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6902/10000, Loss: 0.6043, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6903/10000, Loss: 0.6043, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6904/10000, Loss: 0.6042, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6905/10000, Loss: 0.6042, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6906/10000, Loss: 0.6042, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6907/10000, Loss: 0.6042, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6908/10000, Loss: 0.6042, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6909/10000, Loss: 0.6042, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6910/10000, Loss: 0.6042, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6911/10000, Loss: 0.6042, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6912/10000, Loss: 0.6042, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6913/10000, Loss: 0.6042, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6914/10000, Loss: 0.6042, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6915/10000, Loss: 0.6042, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6916/10000, Loss: 0.6042, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6917/10000, Loss: 0.6042, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6918/10000, Loss: 0.6042, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6919/10000, Loss: 0.6042, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6920/10000, Loss: 0.6042, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6921/10000, Loss: 0.6042, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6922/10000, Loss: 0.6042, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6923/10000, Loss: 0.6041, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6924/10000, Loss: 0.6041, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6925/10000, Loss: 0.6041, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6926/10000, Loss: 0.6041, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6927/10000, Loss: 0.6041, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6928/10000, Loss: 0.6041, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6929/10000, Loss: 0.6041, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6930/10000, Loss: 0.6041, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6931/10000, Loss: 0.6041, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6932/10000, Loss: 0.6041, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6933/10000, Loss: 0.6041, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6934/10000, Loss: 0.6041, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6935/10000, Loss: 0.6041, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6936/10000, Loss: 0.6041, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6937/10000, Loss: 0.6041, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6938/10000, Loss: 0.6041, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6939/10000, Loss: 0.6041, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6940/10000, Loss: 0.6041, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6941/10000, Loss: 0.6041, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6942/10000, Loss: 0.6040, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6943/10000, Loss: 0.6040, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6944/10000, Loss: 0.6040, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6945/10000, Loss: 0.6040, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6946/10000, Loss: 0.6040, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6947/10000, Loss: 0.6040, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6948/10000, Loss: 0.6040, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6949/10000, Loss: 0.6040, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6950/10000, Loss: 0.6040, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6951/10000, Loss: 0.6040, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6952/10000, Loss: 0.6040, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6953/10000, Loss: 0.6040, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6954/10000, Loss: 0.6040, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6955/10000, Loss: 0.6040, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6956/10000, Loss: 0.6040, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6957/10000, Loss: 0.6040, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6958/10000, Loss: 0.6040, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6959/10000, Loss: 0.6040, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6960/10000, Loss: 0.6040, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6961/10000, Loss: 0.6040, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6962/10000, Loss: 0.6039, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6963/10000, Loss: 0.6039, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6964/10000, Loss: 0.6039, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6965/10000, Loss: 0.6039, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6966/10000, Loss: 0.6039, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6967/10000, Loss: 0.6039, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6968/10000, Loss: 0.6039, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6969/10000, Loss: 0.6039, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6970/10000, Loss: 0.6039, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6971/10000, Loss: 0.6039, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6972/10000, Loss: 0.6039, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6973/10000, Loss: 0.6039, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6974/10000, Loss: 0.6039, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6975/10000, Loss: 0.6039, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6976/10000, Loss: 0.6039, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6977/10000, Loss: 0.6039, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6978/10000, Loss: 0.6039, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6979/10000, Loss: 0.6039, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6980/10000, Loss: 0.6039, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6981/10000, Loss: 0.6038, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6982/10000, Loss: 0.6038, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6983/10000, Loss: 0.6038, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6984/10000, Loss: 0.6038, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6985/10000, Loss: 0.6038, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6986/10000, Loss: 0.6038, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6987/10000, Loss: 0.6038, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6988/10000, Loss: 0.6038, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6989/10000, Loss: 0.6038, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6990/10000, Loss: 0.6038, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6991/10000, Loss: 0.6038, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6992/10000, Loss: 0.6038, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6993/10000, Loss: 0.6038, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6994/10000, Loss: 0.6038, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6995/10000, Loss: 0.6038, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6996/10000, Loss: 0.6038, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6997/10000, Loss: 0.6038, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6998/10000, Loss: 0.6038, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6999/10000, Loss: 0.6038, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7000/10000, Loss: 0.6038, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7001/10000, Loss: 0.6037, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7002/10000, Loss: 0.6037, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7003/10000, Loss: 0.6037, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7004/10000, Loss: 0.6037, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7005/10000, Loss: 0.6037, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7006/10000, Loss: 0.6037, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7007/10000, Loss: 0.6037, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7008/10000, Loss: 0.6037, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7009/10000, Loss: 0.6037, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7010/10000, Loss: 0.6037, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7011/10000, Loss: 0.6037, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7012/10000, Loss: 0.6037, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7013/10000, Loss: 0.6037, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7014/10000, Loss: 0.6037, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7015/10000, Loss: 0.6037, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7016/10000, Loss: 0.6037, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7017/10000, Loss: 0.6037, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7018/10000, Loss: 0.6037, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7019/10000, Loss: 0.6037, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7020/10000, Loss: 0.6037, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7021/10000, Loss: 0.6036, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7022/10000, Loss: 0.6036, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7023/10000, Loss: 0.6036, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7024/10000, Loss: 0.6036, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7025/10000, Loss: 0.6036, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7026/10000, Loss: 0.6036, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7027/10000, Loss: 0.6036, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7028/10000, Loss: 0.6036, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7029/10000, Loss: 0.6036, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7030/10000, Loss: 0.6036, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7031/10000, Loss: 0.6036, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7032/10000, Loss: 0.6036, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7033/10000, Loss: 0.6036, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7034/10000, Loss: 0.6036, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7035/10000, Loss: 0.6036, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7036/10000, Loss: 0.6036, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7037/10000, Loss: 0.6036, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7038/10000, Loss: 0.6036, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7039/10000, Loss: 0.6036, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7040/10000, Loss: 0.6036, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7041/10000, Loss: 0.6035, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7042/10000, Loss: 0.6035, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7043/10000, Loss: 0.6035, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7044/10000, Loss: 0.6035, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7045/10000, Loss: 0.6035, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7046/10000, Loss: 0.6035, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7047/10000, Loss: 0.6035, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7048/10000, Loss: 0.6035, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7049/10000, Loss: 0.6035, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7050/10000, Loss: 0.6035, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7051/10000, Loss: 0.6035, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7052/10000, Loss: 0.6035, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7053/10000, Loss: 0.6035, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7054/10000, Loss: 0.6035, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7055/10000, Loss: 0.6035, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7056/10000, Loss: 0.6035, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7057/10000, Loss: 0.6035, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7058/10000, Loss: 0.6035, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7059/10000, Loss: 0.6035, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7060/10000, Loss: 0.6035, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7061/10000, Loss: 0.6034, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7062/10000, Loss: 0.6034, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7063/10000, Loss: 0.6034, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7064/10000, Loss: 0.6034, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7065/10000, Loss: 0.6034, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7066/10000, Loss: 0.6034, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7067/10000, Loss: 0.6034, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7068/10000, Loss: 0.6034, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7069/10000, Loss: 0.6034, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7070/10000, Loss: 0.6034, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7071/10000, Loss: 0.6034, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7072/10000, Loss: 0.6034, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7073/10000, Loss: 0.6034, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7074/10000, Loss: 0.6034, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7075/10000, Loss: 0.6034, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7076/10000, Loss: 0.6034, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7077/10000, Loss: 0.6034, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7078/10000, Loss: 0.6034, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7079/10000, Loss: 0.6034, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7080/10000, Loss: 0.6034, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7081/10000, Loss: 0.6033, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7082/10000, Loss: 0.6033, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7083/10000, Loss: 0.6033, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7084/10000, Loss: 0.6033, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7085/10000, Loss: 0.6033, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7086/10000, Loss: 0.6033, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7087/10000, Loss: 0.6033, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7088/10000, Loss: 0.6033, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7089/10000, Loss: 0.6033, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7090/10000, Loss: 0.6033, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7091/10000, Loss: 0.6033, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7092/10000, Loss: 0.6033, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7093/10000, Loss: 0.6033, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7094/10000, Loss: 0.6033, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7095/10000, Loss: 0.6033, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7096/10000, Loss: 0.6033, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7097/10000, Loss: 0.6033, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7098/10000, Loss: 0.6033, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7099/10000, Loss: 0.6033, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7100/10000, Loss: 0.6033, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7101/10000, Loss: 0.6033, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7102/10000, Loss: 0.6032, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7103/10000, Loss: 0.6032, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7104/10000, Loss: 0.6032, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7105/10000, Loss: 0.6032, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7106/10000, Loss: 0.6032, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7107/10000, Loss: 0.6032, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7108/10000, Loss: 0.6032, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7109/10000, Loss: 0.6032, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7110/10000, Loss: 0.6032, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7111/10000, Loss: 0.6032, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7112/10000, Loss: 0.6032, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7113/10000, Loss: 0.6032, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7114/10000, Loss: 0.6032, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7115/10000, Loss: 0.6032, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7116/10000, Loss: 0.6032, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7117/10000, Loss: 0.6032, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7118/10000, Loss: 0.6032, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7119/10000, Loss: 0.6032, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7120/10000, Loss: 0.6032, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7121/10000, Loss: 0.6032, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7122/10000, Loss: 0.6031, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7123/10000, Loss: 0.6031, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7124/10000, Loss: 0.6031, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7125/10000, Loss: 0.6031, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7126/10000, Loss: 0.6031, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7127/10000, Loss: 0.6031, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7128/10000, Loss: 0.6031, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7129/10000, Loss: 0.6031, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7130/10000, Loss: 0.6031, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7131/10000, Loss: 0.6031, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7132/10000, Loss: 0.6031, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7133/10000, Loss: 0.6031, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7134/10000, Loss: 0.6031, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7135/10000, Loss: 0.6031, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7136/10000, Loss: 0.6031, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7137/10000, Loss: 0.6031, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7138/10000, Loss: 0.6031, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7139/10000, Loss: 0.6031, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7140/10000, Loss: 0.6031, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7141/10000, Loss: 0.6031, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7142/10000, Loss: 0.6031, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7143/10000, Loss: 0.6030, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7144/10000, Loss: 0.6030, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7145/10000, Loss: 0.6030, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7146/10000, Loss: 0.6030, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7147/10000, Loss: 0.6030, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7148/10000, Loss: 0.6030, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7149/10000, Loss: 0.6030, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7150/10000, Loss: 0.6030, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7151/10000, Loss: 0.6030, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7152/10000, Loss: 0.6030, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7153/10000, Loss: 0.6030, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7154/10000, Loss: 0.6030, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7155/10000, Loss: 0.6030, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7156/10000, Loss: 0.6030, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7157/10000, Loss: 0.6030, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7158/10000, Loss: 0.6030, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7159/10000, Loss: 0.6030, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7160/10000, Loss: 0.6030, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7161/10000, Loss: 0.6030, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7162/10000, Loss: 0.6030, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7163/10000, Loss: 0.6030, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7164/10000, Loss: 0.6029, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7165/10000, Loss: 0.6029, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7166/10000, Loss: 0.6029, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7167/10000, Loss: 0.6029, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7168/10000, Loss: 0.6029, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7169/10000, Loss: 0.6029, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7170/10000, Loss: 0.6029, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7171/10000, Loss: 0.6029, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7172/10000, Loss: 0.6029, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7173/10000, Loss: 0.6029, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7174/10000, Loss: 0.6029, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7175/10000, Loss: 0.6029, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7176/10000, Loss: 0.6029, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7177/10000, Loss: 0.6029, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7178/10000, Loss: 0.6029, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7179/10000, Loss: 0.6029, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7180/10000, Loss: 0.6029, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7181/10000, Loss: 0.6029, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7182/10000, Loss: 0.6029, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7183/10000, Loss: 0.6029, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7184/10000, Loss: 0.6029, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7185/10000, Loss: 0.6028, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7186/10000, Loss: 0.6028, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7187/10000, Loss: 0.6028, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7188/10000, Loss: 0.6028, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7189/10000, Loss: 0.6028, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7190/10000, Loss: 0.6028, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7191/10000, Loss: 0.6028, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7192/10000, Loss: 0.6028, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7193/10000, Loss: 0.6028, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7194/10000, Loss: 0.6028, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7195/10000, Loss: 0.6028, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7196/10000, Loss: 0.6028, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7197/10000, Loss: 0.6028, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7198/10000, Loss: 0.6028, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7199/10000, Loss: 0.6028, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7200/10000, Loss: 0.6028, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7201/10000, Loss: 0.6028, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7202/10000, Loss: 0.6028, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7203/10000, Loss: 0.6028, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7204/10000, Loss: 0.6028, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7205/10000, Loss: 0.6028, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7206/10000, Loss: 0.6027, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7207/10000, Loss: 0.6027, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7208/10000, Loss: 0.6027, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7209/10000, Loss: 0.6027, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7210/10000, Loss: 0.6027, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7211/10000, Loss: 0.6027, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7212/10000, Loss: 0.6027, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7213/10000, Loss: 0.6027, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7214/10000, Loss: 0.6027, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7215/10000, Loss: 0.6027, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7216/10000, Loss: 0.6027, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7217/10000, Loss: 0.6027, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7218/10000, Loss: 0.6027, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7219/10000, Loss: 0.6027, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7220/10000, Loss: 0.6027, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7221/10000, Loss: 0.6027, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7222/10000, Loss: 0.6027, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7223/10000, Loss: 0.6027, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7224/10000, Loss: 0.6027, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7225/10000, Loss: 0.6027, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7226/10000, Loss: 0.6027, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7227/10000, Loss: 0.6026, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7228/10000, Loss: 0.6026, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7229/10000, Loss: 0.6026, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7230/10000, Loss: 0.6026, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7231/10000, Loss: 0.6026, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7232/10000, Loss: 0.6026, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7233/10000, Loss: 0.6026, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7234/10000, Loss: 0.6026, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7235/10000, Loss: 0.6026, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7236/10000, Loss: 0.6026, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7237/10000, Loss: 0.6026, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7238/10000, Loss: 0.6026, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7239/10000, Loss: 0.6026, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7240/10000, Loss: 0.6026, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7241/10000, Loss: 0.6026, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7242/10000, Loss: 0.6026, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7243/10000, Loss: 0.6026, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7244/10000, Loss: 0.6026, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7245/10000, Loss: 0.6026, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7246/10000, Loss: 0.6026, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7247/10000, Loss: 0.6026, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7248/10000, Loss: 0.6026, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7249/10000, Loss: 0.6025, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7250/10000, Loss: 0.6025, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7251/10000, Loss: 0.6025, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7252/10000, Loss: 0.6025, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7253/10000, Loss: 0.6025, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7254/10000, Loss: 0.6025, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7255/10000, Loss: 0.6025, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7256/10000, Loss: 0.6025, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7257/10000, Loss: 0.6025, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7258/10000, Loss: 0.6025, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7259/10000, Loss: 0.6025, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7260/10000, Loss: 0.6025, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7261/10000, Loss: 0.6025, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7262/10000, Loss: 0.6025, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7263/10000, Loss: 0.6025, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7264/10000, Loss: 0.6025, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7265/10000, Loss: 0.6025, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7266/10000, Loss: 0.6025, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7267/10000, Loss: 0.6025, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7268/10000, Loss: 0.6025, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7269/10000, Loss: 0.6025, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7270/10000, Loss: 0.6024, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7271/10000, Loss: 0.6024, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7272/10000, Loss: 0.6024, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7273/10000, Loss: 0.6024, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7274/10000, Loss: 0.6024, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7275/10000, Loss: 0.6024, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7276/10000, Loss: 0.6024, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7277/10000, Loss: 0.6024, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7278/10000, Loss: 0.6024, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7279/10000, Loss: 0.6024, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7280/10000, Loss: 0.6024, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7281/10000, Loss: 0.6024, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7282/10000, Loss: 0.6024, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7283/10000, Loss: 0.6024, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7284/10000, Loss: 0.6024, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7285/10000, Loss: 0.6024, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7286/10000, Loss: 0.6024, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7287/10000, Loss: 0.6024, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7288/10000, Loss: 0.6024, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7289/10000, Loss: 0.6024, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7290/10000, Loss: 0.6024, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7291/10000, Loss: 0.6024, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7292/10000, Loss: 0.6023, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7293/10000, Loss: 0.6023, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7294/10000, Loss: 0.6023, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7295/10000, Loss: 0.6023, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7296/10000, Loss: 0.6023, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7297/10000, Loss: 0.6023, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7298/10000, Loss: 0.6023, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7299/10000, Loss: 0.6023, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7300/10000, Loss: 0.6023, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7301/10000, Loss: 0.6023, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7302/10000, Loss: 0.6023, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7303/10000, Loss: 0.6023, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7304/10000, Loss: 0.6023, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7305/10000, Loss: 0.6023, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7306/10000, Loss: 0.6023, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7307/10000, Loss: 0.6023, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7308/10000, Loss: 0.6023, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7309/10000, Loss: 0.6023, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7310/10000, Loss: 0.6023, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7311/10000, Loss: 0.6023, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7312/10000, Loss: 0.6023, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7313/10000, Loss: 0.6023, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7314/10000, Loss: 0.6022, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7315/10000, Loss: 0.6022, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7316/10000, Loss: 0.6022, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7317/10000, Loss: 0.6022, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7318/10000, Loss: 0.6022, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7319/10000, Loss: 0.6022, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7320/10000, Loss: 0.6022, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7321/10000, Loss: 0.6022, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7322/10000, Loss: 0.6022, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7323/10000, Loss: 0.6022, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7324/10000, Loss: 0.6022, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7325/10000, Loss: 0.6022, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7326/10000, Loss: 0.6022, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7327/10000, Loss: 0.6022, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7328/10000, Loss: 0.6022, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7329/10000, Loss: 0.6022, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7330/10000, Loss: 0.6022, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7331/10000, Loss: 0.6022, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7332/10000, Loss: 0.6022, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7333/10000, Loss: 0.6022, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7334/10000, Loss: 0.6022, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7335/10000, Loss: 0.6022, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7336/10000, Loss: 0.6021, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7337/10000, Loss: 0.6021, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7338/10000, Loss: 0.6021, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7339/10000, Loss: 0.6021, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7340/10000, Loss: 0.6021, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7341/10000, Loss: 0.6021, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7342/10000, Loss: 0.6021, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7343/10000, Loss: 0.6021, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7344/10000, Loss: 0.6021, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7345/10000, Loss: 0.6021, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7346/10000, Loss: 0.6021, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7347/10000, Loss: 0.6021, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7348/10000, Loss: 0.6021, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7349/10000, Loss: 0.6021, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7350/10000, Loss: 0.6021, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7351/10000, Loss: 0.6021, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7352/10000, Loss: 0.6021, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7353/10000, Loss: 0.6021, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7354/10000, Loss: 0.6021, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7355/10000, Loss: 0.6021, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7356/10000, Loss: 0.6021, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7357/10000, Loss: 0.6021, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7358/10000, Loss: 0.6020, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7359/10000, Loss: 0.6020, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7360/10000, Loss: 0.6020, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7361/10000, Loss: 0.6020, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7362/10000, Loss: 0.6020, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7363/10000, Loss: 0.6020, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7364/10000, Loss: 0.6020, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7365/10000, Loss: 0.6020, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7366/10000, Loss: 0.6020, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7367/10000, Loss: 0.6020, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7368/10000, Loss: 0.6020, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7369/10000, Loss: 0.6020, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7370/10000, Loss: 0.6020, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7371/10000, Loss: 0.6020, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7372/10000, Loss: 0.6020, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7373/10000, Loss: 0.6020, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7374/10000, Loss: 0.6020, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7375/10000, Loss: 0.6020, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7376/10000, Loss: 0.6020, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7377/10000, Loss: 0.6020, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7378/10000, Loss: 0.6020, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7379/10000, Loss: 0.6020, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7380/10000, Loss: 0.6020, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7381/10000, Loss: 0.6019, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7382/10000, Loss: 0.6019, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7383/10000, Loss: 0.6019, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7384/10000, Loss: 0.6019, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7385/10000, Loss: 0.6019, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7386/10000, Loss: 0.6019, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7387/10000, Loss: 0.6019, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7388/10000, Loss: 0.6019, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7389/10000, Loss: 0.6019, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7390/10000, Loss: 0.6019, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7391/10000, Loss: 0.6019, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7392/10000, Loss: 0.6019, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7393/10000, Loss: 0.6019, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7394/10000, Loss: 0.6019, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7395/10000, Loss: 0.6019, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7396/10000, Loss: 0.6019, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7397/10000, Loss: 0.6019, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7398/10000, Loss: 0.6019, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7399/10000, Loss: 0.6019, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7400/10000, Loss: 0.6019, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7401/10000, Loss: 0.6019, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7402/10000, Loss: 0.6019, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7403/10000, Loss: 0.6018, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7404/10000, Loss: 0.6018, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7405/10000, Loss: 0.6018, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7406/10000, Loss: 0.6018, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7407/10000, Loss: 0.6018, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7408/10000, Loss: 0.6018, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7409/10000, Loss: 0.6018, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7410/10000, Loss: 0.6018, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7411/10000, Loss: 0.6018, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7412/10000, Loss: 0.6018, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7413/10000, Loss: 0.6018, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7414/10000, Loss: 0.6018, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7415/10000, Loss: 0.6018, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7416/10000, Loss: 0.6018, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7417/10000, Loss: 0.6018, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7418/10000, Loss: 0.6018, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7419/10000, Loss: 0.6018, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7420/10000, Loss: 0.6018, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7421/10000, Loss: 0.6018, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7422/10000, Loss: 0.6018, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7423/10000, Loss: 0.6018, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7424/10000, Loss: 0.6018, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7425/10000, Loss: 0.6018, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7426/10000, Loss: 0.6017, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7427/10000, Loss: 0.6017, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7428/10000, Loss: 0.6017, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7429/10000, Loss: 0.6017, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7430/10000, Loss: 0.6017, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7431/10000, Loss: 0.6017, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7432/10000, Loss: 0.6017, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7433/10000, Loss: 0.6017, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7434/10000, Loss: 0.6017, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7435/10000, Loss: 0.6017, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7436/10000, Loss: 0.6017, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7437/10000, Loss: 0.6017, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7438/10000, Loss: 0.6017, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7439/10000, Loss: 0.6017, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7440/10000, Loss: 0.6017, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7441/10000, Loss: 0.6017, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7442/10000, Loss: 0.6017, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7443/10000, Loss: 0.6017, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7444/10000, Loss: 0.6017, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7445/10000, Loss: 0.6017, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7446/10000, Loss: 0.6017, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7447/10000, Loss: 0.6017, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7448/10000, Loss: 0.6017, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7449/10000, Loss: 0.6016, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7450/10000, Loss: 0.6016, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7451/10000, Loss: 0.6016, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7452/10000, Loss: 0.6016, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7453/10000, Loss: 0.6016, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7454/10000, Loss: 0.6016, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7455/10000, Loss: 0.6016, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7456/10000, Loss: 0.6016, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7457/10000, Loss: 0.6016, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7458/10000, Loss: 0.6016, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7459/10000, Loss: 0.6016, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7460/10000, Loss: 0.6016, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7461/10000, Loss: 0.6016, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7462/10000, Loss: 0.6016, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7463/10000, Loss: 0.6016, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7464/10000, Loss: 0.6016, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7465/10000, Loss: 0.6016, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7466/10000, Loss: 0.6016, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7467/10000, Loss: 0.6016, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7468/10000, Loss: 0.6016, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7469/10000, Loss: 0.6016, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7470/10000, Loss: 0.6016, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7471/10000, Loss: 0.6016, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7472/10000, Loss: 0.6015, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7473/10000, Loss: 0.6015, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7474/10000, Loss: 0.6015, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7475/10000, Loss: 0.6015, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7476/10000, Loss: 0.6015, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7477/10000, Loss: 0.6015, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7478/10000, Loss: 0.6015, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7479/10000, Loss: 0.6015, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7480/10000, Loss: 0.6015, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7481/10000, Loss: 0.6015, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7482/10000, Loss: 0.6015, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7483/10000, Loss: 0.6015, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7484/10000, Loss: 0.6015, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7485/10000, Loss: 0.6015, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7486/10000, Loss: 0.6015, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7487/10000, Loss: 0.6015, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7488/10000, Loss: 0.6015, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7489/10000, Loss: 0.6015, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7490/10000, Loss: 0.6015, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7491/10000, Loss: 0.6015, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7492/10000, Loss: 0.6015, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7493/10000, Loss: 0.6015, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7494/10000, Loss: 0.6015, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7495/10000, Loss: 0.6015, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7496/10000, Loss: 0.6014, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7497/10000, Loss: 0.6014, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7498/10000, Loss: 0.6014, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7499/10000, Loss: 0.6014, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7500/10000, Loss: 0.6014, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7501/10000, Loss: 0.6014, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7502/10000, Loss: 0.6014, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7503/10000, Loss: 0.6014, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7504/10000, Loss: 0.6014, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7505/10000, Loss: 0.6014, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7506/10000, Loss: 0.6014, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7507/10000, Loss: 0.6014, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7508/10000, Loss: 0.6014, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7509/10000, Loss: 0.6014, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7510/10000, Loss: 0.6014, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7511/10000, Loss: 0.6014, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7512/10000, Loss: 0.6014, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7513/10000, Loss: 0.6014, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7514/10000, Loss: 0.6014, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7515/10000, Loss: 0.6014, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7516/10000, Loss: 0.6014, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7517/10000, Loss: 0.6014, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7518/10000, Loss: 0.6014, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7519/10000, Loss: 0.6013, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7520/10000, Loss: 0.6013, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7521/10000, Loss: 0.6013, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7522/10000, Loss: 0.6013, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7523/10000, Loss: 0.6013, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7524/10000, Loss: 0.6013, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7525/10000, Loss: 0.6013, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7526/10000, Loss: 0.6013, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7527/10000, Loss: 0.6013, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7528/10000, Loss: 0.6013, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7529/10000, Loss: 0.6013, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7530/10000, Loss: 0.6013, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7531/10000, Loss: 0.6013, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7532/10000, Loss: 0.6013, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7533/10000, Loss: 0.6013, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7534/10000, Loss: 0.6013, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7535/10000, Loss: 0.6013, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7536/10000, Loss: 0.6013, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7537/10000, Loss: 0.6013, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7538/10000, Loss: 0.6013, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7539/10000, Loss: 0.6013, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7540/10000, Loss: 0.6013, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7541/10000, Loss: 0.6013, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7542/10000, Loss: 0.6013, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7543/10000, Loss: 0.6012, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7544/10000, Loss: 0.6012, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7545/10000, Loss: 0.6012, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7546/10000, Loss: 0.6012, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7547/10000, Loss: 0.6012, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7548/10000, Loss: 0.6012, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7549/10000, Loss: 0.6012, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7550/10000, Loss: 0.6012, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7551/10000, Loss: 0.6012, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7552/10000, Loss: 0.6012, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7553/10000, Loss: 0.6012, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7554/10000, Loss: 0.6012, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7555/10000, Loss: 0.6012, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7556/10000, Loss: 0.6012, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7557/10000, Loss: 0.6012, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7558/10000, Loss: 0.6012, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7559/10000, Loss: 0.6012, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7560/10000, Loss: 0.6012, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7561/10000, Loss: 0.6012, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7562/10000, Loss: 0.6012, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7563/10000, Loss: 0.6012, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7564/10000, Loss: 0.6012, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7565/10000, Loss: 0.6012, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7566/10000, Loss: 0.6012, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7567/10000, Loss: 0.6011, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7568/10000, Loss: 0.6011, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7569/10000, Loss: 0.6011, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7570/10000, Loss: 0.6011, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7571/10000, Loss: 0.6011, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7572/10000, Loss: 0.6011, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7573/10000, Loss: 0.6011, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7574/10000, Loss: 0.6011, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7575/10000, Loss: 0.6011, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7576/10000, Loss: 0.6011, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7577/10000, Loss: 0.6011, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7578/10000, Loss: 0.6011, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7579/10000, Loss: 0.6011, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7580/10000, Loss: 0.6011, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7581/10000, Loss: 0.6011, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7582/10000, Loss: 0.6011, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7583/10000, Loss: 0.6011, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7584/10000, Loss: 0.6011, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7585/10000, Loss: 0.6011, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7586/10000, Loss: 0.6011, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7587/10000, Loss: 0.6011, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7588/10000, Loss: 0.6011, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7589/10000, Loss: 0.6011, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7590/10000, Loss: 0.6011, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7591/10000, Loss: 0.6010, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7592/10000, Loss: 0.6010, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7593/10000, Loss: 0.6010, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7594/10000, Loss: 0.6010, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7595/10000, Loss: 0.6010, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7596/10000, Loss: 0.6010, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7597/10000, Loss: 0.6010, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7598/10000, Loss: 0.6010, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7599/10000, Loss: 0.6010, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7600/10000, Loss: 0.6010, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7601/10000, Loss: 0.6010, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7602/10000, Loss: 0.6010, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7603/10000, Loss: 0.6010, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7604/10000, Loss: 0.6010, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7605/10000, Loss: 0.6010, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7606/10000, Loss: 0.6010, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7607/10000, Loss: 0.6010, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7608/10000, Loss: 0.6010, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7609/10000, Loss: 0.6010, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7610/10000, Loss: 0.6010, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7611/10000, Loss: 0.6010, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7612/10000, Loss: 0.6010, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7613/10000, Loss: 0.6010, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7614/10000, Loss: 0.6010, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7615/10000, Loss: 0.6010, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7616/10000, Loss: 0.6009, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7617/10000, Loss: 0.6009, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7618/10000, Loss: 0.6009, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7619/10000, Loss: 0.6009, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7620/10000, Loss: 0.6009, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7621/10000, Loss: 0.6009, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7622/10000, Loss: 0.6009, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7623/10000, Loss: 0.6009, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7624/10000, Loss: 0.6009, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7625/10000, Loss: 0.6009, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7626/10000, Loss: 0.6009, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7627/10000, Loss: 0.6009, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7628/10000, Loss: 0.6009, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7629/10000, Loss: 0.6009, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7630/10000, Loss: 0.6009, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7631/10000, Loss: 0.6009, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7632/10000, Loss: 0.6009, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7633/10000, Loss: 0.6009, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7634/10000, Loss: 0.6009, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7635/10000, Loss: 0.6009, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7636/10000, Loss: 0.6009, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7637/10000, Loss: 0.6009, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7638/10000, Loss: 0.6009, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7639/10000, Loss: 0.6009, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7640/10000, Loss: 0.6008, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7641/10000, Loss: 0.6008, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7642/10000, Loss: 0.6008, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7643/10000, Loss: 0.6008, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7644/10000, Loss: 0.6008, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7645/10000, Loss: 0.6008, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7646/10000, Loss: 0.6008, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7647/10000, Loss: 0.6008, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7648/10000, Loss: 0.6008, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7649/10000, Loss: 0.6008, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7650/10000, Loss: 0.6008, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7651/10000, Loss: 0.6008, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7652/10000, Loss: 0.6008, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7653/10000, Loss: 0.6008, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7654/10000, Loss: 0.6008, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7655/10000, Loss: 0.6008, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7656/10000, Loss: 0.6008, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7657/10000, Loss: 0.6008, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7658/10000, Loss: 0.6008, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7659/10000, Loss: 0.6008, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7660/10000, Loss: 0.6008, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7661/10000, Loss: 0.6008, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7662/10000, Loss: 0.6008, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7663/10000, Loss: 0.6008, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7664/10000, Loss: 0.6008, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7665/10000, Loss: 0.6007, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7666/10000, Loss: 0.6007, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7667/10000, Loss: 0.6007, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7668/10000, Loss: 0.6007, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7669/10000, Loss: 0.6007, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7670/10000, Loss: 0.6007, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7671/10000, Loss: 0.6007, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7672/10000, Loss: 0.6007, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7673/10000, Loss: 0.6007, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7674/10000, Loss: 0.6007, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7675/10000, Loss: 0.6007, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7676/10000, Loss: 0.6007, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7677/10000, Loss: 0.6007, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7678/10000, Loss: 0.6007, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7679/10000, Loss: 0.6007, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7680/10000, Loss: 0.6007, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7681/10000, Loss: 0.6007, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7682/10000, Loss: 0.6007, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7683/10000, Loss: 0.6007, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7684/10000, Loss: 0.6007, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7685/10000, Loss: 0.6007, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7686/10000, Loss: 0.6007, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7687/10000, Loss: 0.6007, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7688/10000, Loss: 0.6007, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7689/10000, Loss: 0.6007, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7690/10000, Loss: 0.6006, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7691/10000, Loss: 0.6006, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7692/10000, Loss: 0.6006, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7693/10000, Loss: 0.6006, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7694/10000, Loss: 0.6006, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7695/10000, Loss: 0.6006, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7696/10000, Loss: 0.6006, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7697/10000, Loss: 0.6006, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7698/10000, Loss: 0.6006, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7699/10000, Loss: 0.6006, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7700/10000, Loss: 0.6006, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7701/10000, Loss: 0.6006, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7702/10000, Loss: 0.6006, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7703/10000, Loss: 0.6006, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7704/10000, Loss: 0.6006, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7705/10000, Loss: 0.6006, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7706/10000, Loss: 0.6006, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7707/10000, Loss: 0.6006, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7708/10000, Loss: 0.6006, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7709/10000, Loss: 0.6006, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7710/10000, Loss: 0.6006, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7711/10000, Loss: 0.6006, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7712/10000, Loss: 0.6006, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7713/10000, Loss: 0.6006, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7714/10000, Loss: 0.6006, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7715/10000, Loss: 0.6005, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7716/10000, Loss: 0.6005, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7717/10000, Loss: 0.6005, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7718/10000, Loss: 0.6005, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7719/10000, Loss: 0.6005, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7720/10000, Loss: 0.6005, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7721/10000, Loss: 0.6005, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7722/10000, Loss: 0.6005, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7723/10000, Loss: 0.6005, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7724/10000, Loss: 0.6005, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7725/10000, Loss: 0.6005, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7726/10000, Loss: 0.6005, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7727/10000, Loss: 0.6005, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7728/10000, Loss: 0.6005, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7729/10000, Loss: 0.6005, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7730/10000, Loss: 0.6005, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7731/10000, Loss: 0.6005, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7732/10000, Loss: 0.6005, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7733/10000, Loss: 0.6005, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7734/10000, Loss: 0.6005, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7735/10000, Loss: 0.6005, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7736/10000, Loss: 0.6005, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7737/10000, Loss: 0.6005, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7738/10000, Loss: 0.6005, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7739/10000, Loss: 0.6005, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7740/10000, Loss: 0.6005, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7741/10000, Loss: 0.6004, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7742/10000, Loss: 0.6004, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7743/10000, Loss: 0.6004, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7744/10000, Loss: 0.6004, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7745/10000, Loss: 0.6004, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7746/10000, Loss: 0.6004, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7747/10000, Loss: 0.6004, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7748/10000, Loss: 0.6004, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7749/10000, Loss: 0.6004, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7750/10000, Loss: 0.6004, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7751/10000, Loss: 0.6004, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7752/10000, Loss: 0.6004, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7753/10000, Loss: 0.6004, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7754/10000, Loss: 0.6004, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7755/10000, Loss: 0.6004, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7756/10000, Loss: 0.6004, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7757/10000, Loss: 0.6004, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7758/10000, Loss: 0.6004, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7759/10000, Loss: 0.6004, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7760/10000, Loss: 0.6004, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7761/10000, Loss: 0.6004, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7762/10000, Loss: 0.6004, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7763/10000, Loss: 0.6004, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7764/10000, Loss: 0.6004, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7765/10000, Loss: 0.6004, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7766/10000, Loss: 0.6003, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7767/10000, Loss: 0.6003, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7768/10000, Loss: 0.6003, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7769/10000, Loss: 0.6003, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7770/10000, Loss: 0.6003, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7771/10000, Loss: 0.6003, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7772/10000, Loss: 0.6003, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7773/10000, Loss: 0.6003, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7774/10000, Loss: 0.6003, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7775/10000, Loss: 0.6003, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7776/10000, Loss: 0.6003, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7777/10000, Loss: 0.6003, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7778/10000, Loss: 0.6003, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7779/10000, Loss: 0.6003, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7780/10000, Loss: 0.6003, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7781/10000, Loss: 0.6003, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7782/10000, Loss: 0.6003, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7783/10000, Loss: 0.6003, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7784/10000, Loss: 0.6003, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7785/10000, Loss: 0.6003, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7786/10000, Loss: 0.6003, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7787/10000, Loss: 0.6003, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7788/10000, Loss: 0.6003, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7789/10000, Loss: 0.6003, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7790/10000, Loss: 0.6003, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7791/10000, Loss: 0.6003, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7792/10000, Loss: 0.6002, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7793/10000, Loss: 0.6002, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7794/10000, Loss: 0.6002, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7795/10000, Loss: 0.6002, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7796/10000, Loss: 0.6002, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7797/10000, Loss: 0.6002, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7798/10000, Loss: 0.6002, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7799/10000, Loss: 0.6002, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7800/10000, Loss: 0.6002, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7801/10000, Loss: 0.6002, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7802/10000, Loss: 0.6002, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7803/10000, Loss: 0.6002, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7804/10000, Loss: 0.6002, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7805/10000, Loss: 0.6002, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7806/10000, Loss: 0.6002, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7807/10000, Loss: 0.6002, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7808/10000, Loss: 0.6002, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7809/10000, Loss: 0.6002, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7810/10000, Loss: 0.6002, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7811/10000, Loss: 0.6002, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7812/10000, Loss: 0.6002, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7813/10000, Loss: 0.6002, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7814/10000, Loss: 0.6002, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7815/10000, Loss: 0.6002, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7816/10000, Loss: 0.6002, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7817/10000, Loss: 0.6002, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7818/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7819/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7820/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7821/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7822/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7823/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7824/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7825/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7826/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7827/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7828/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7829/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7830/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7831/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7832/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7833/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7834/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7835/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7836/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7837/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7838/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7839/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7840/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7841/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7842/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7843/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7844/10000, Loss: 0.6001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7845/10000, Loss: 0.6000, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7846/10000, Loss: 0.6000, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7847/10000, Loss: 0.6000, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7848/10000, Loss: 0.6000, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7849/10000, Loss: 0.6000, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7850/10000, Loss: 0.6000, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7851/10000, Loss: 0.6000, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7852/10000, Loss: 0.6000, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7853/10000, Loss: 0.6000, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7854/10000, Loss: 0.6000, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7855/10000, Loss: 0.6000, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7856/10000, Loss: 0.6000, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7857/10000, Loss: 0.6000, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7858/10000, Loss: 0.6000, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7859/10000, Loss: 0.6000, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7860/10000, Loss: 0.6000, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7861/10000, Loss: 0.6000, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7862/10000, Loss: 0.6000, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7863/10000, Loss: 0.6000, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7864/10000, Loss: 0.6000, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7865/10000, Loss: 0.6000, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7866/10000, Loss: 0.6000, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7867/10000, Loss: 0.6000, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7868/10000, Loss: 0.6000, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7869/10000, Loss: 0.6000, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7870/10000, Loss: 0.6000, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7871/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7872/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7873/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7874/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7875/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7876/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7877/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7878/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7879/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7880/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7881/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7882/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7883/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7884/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7885/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7886/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7887/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7888/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7889/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7890/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7891/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7892/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7893/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7894/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7895/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7896/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7897/10000, Loss: 0.5999, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7898/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7899/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7900/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7901/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7902/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7903/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7904/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7905/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7906/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7907/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7908/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7909/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7910/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7911/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7912/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7913/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7914/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7915/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7916/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7917/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7918/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7919/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7920/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7921/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7922/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7923/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7924/10000, Loss: 0.5998, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7925/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7926/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7927/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7928/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7929/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7930/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7931/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7932/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7933/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7934/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7935/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7936/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7937/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7938/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7939/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7940/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7941/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7942/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7943/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7944/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7945/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7946/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7947/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7948/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7949/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7950/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7951/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7952/10000, Loss: 0.5997, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7953/10000, Loss: 0.5996, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7954/10000, Loss: 0.5996, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7955/10000, Loss: 0.5996, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7956/10000, Loss: 0.5996, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7957/10000, Loss: 0.5996, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7958/10000, Loss: 0.5996, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7959/10000, Loss: 0.5996, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7960/10000, Loss: 0.5996, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7961/10000, Loss: 0.5996, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 7962/10000, Loss: 0.5996, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7963/10000, Loss: 0.5996, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7964/10000, Loss: 0.5996, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7965/10000, Loss: 0.5996, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7966/10000, Loss: 0.5996, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7967/10000, Loss: 0.5996, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7968/10000, Loss: 0.5996, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7969/10000, Loss: 0.5996, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7970/10000, Loss: 0.5996, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7971/10000, Loss: 0.5996, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7972/10000, Loss: 0.5996, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7973/10000, Loss: 0.5996, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7974/10000, Loss: 0.5996, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7975/10000, Loss: 0.5996, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7976/10000, Loss: 0.5996, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7977/10000, Loss: 0.5996, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7978/10000, Loss: 0.5996, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7979/10000, Loss: 0.5996, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7980/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7981/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7982/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7983/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7984/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7985/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7986/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7987/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7988/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7989/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7990/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7991/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7992/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7993/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7994/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7995/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7996/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7997/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7998/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 7999/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8000/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8001/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8002/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8003/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8004/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8005/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8006/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8007/10000, Loss: 0.5995, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8008/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8009/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8010/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8011/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8012/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8013/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8014/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8015/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8016/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8017/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8018/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8019/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8020/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8021/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8022/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8023/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8024/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8025/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8026/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8027/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8028/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8029/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8030/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8031/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8032/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8033/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8034/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8035/10000, Loss: 0.5994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8036/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8037/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8038/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8039/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8040/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8041/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8042/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8043/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8044/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8045/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8046/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8047/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8048/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8049/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8050/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8051/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8052/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8053/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8054/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8055/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8056/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8057/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8058/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8059/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8060/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8061/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8062/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8063/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8064/10000, Loss: 0.5993, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8065/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8066/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8067/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8068/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8069/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8070/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8071/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8072/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8073/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8074/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8075/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8076/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8077/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8078/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8079/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8080/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8081/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8082/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8083/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8084/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8085/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8086/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8087/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8088/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8089/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8090/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8091/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8092/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8093/10000, Loss: 0.5992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8094/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8095/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8096/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8097/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8098/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8099/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8100/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8101/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8102/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8103/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8104/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8105/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8106/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8107/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8108/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8109/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8110/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8111/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8112/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8113/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8114/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8115/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8116/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8117/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8118/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8119/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8120/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8121/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8122/10000, Loss: 0.5991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8123/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8124/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8125/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8126/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8127/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8128/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8129/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8130/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8131/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8132/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8133/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8134/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8135/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8136/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8137/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8138/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8139/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8140/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8141/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8142/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8143/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8144/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8145/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8146/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8147/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8148/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8149/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8150/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8151/10000, Loss: 0.5990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8152/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8153/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8154/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8155/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8156/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8157/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8158/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8159/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8160/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8161/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8162/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8163/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8164/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8165/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8166/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8167/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8168/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8169/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8170/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8171/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8172/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8173/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8174/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8175/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8176/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8177/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8178/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8179/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8180/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8181/10000, Loss: 0.5989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8182/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8183/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8184/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8185/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8186/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8187/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8188/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8189/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8190/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8191/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8192/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8193/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8194/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8195/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8196/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8197/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8198/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8199/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8200/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8201/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8202/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8203/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8204/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8205/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8206/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8207/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8208/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8209/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8210/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8211/10000, Loss: 0.5988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8212/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8213/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8214/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8215/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8216/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8217/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8218/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8219/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8220/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8221/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8222/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8223/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8224/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8225/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8226/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8227/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8228/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8229/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8230/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8231/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8232/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8233/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8234/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8235/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8236/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8237/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8238/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8239/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8240/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8241/10000, Loss: 0.5987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8242/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8243/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8244/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8245/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8246/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8247/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8248/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8249/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8250/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8251/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8252/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8253/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8254/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8255/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8256/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8257/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8258/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8259/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8260/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8261/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8262/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8263/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8264/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8265/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8266/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8267/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8268/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8269/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8270/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8271/10000, Loss: 0.5986, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8272/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8273/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8274/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8275/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8276/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8277/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8278/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8279/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8280/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8281/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8282/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8283/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8284/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8285/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8286/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8287/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8288/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8289/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8290/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8291/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8292/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8293/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8294/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8295/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8296/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8297/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8298/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8299/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8300/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8301/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8302/10000, Loss: 0.5985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8303/10000, Loss: 0.5984, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8304/10000, Loss: 0.5984, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8305/10000, Loss: 0.5984, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8306/10000, Loss: 0.5984, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8307/10000, Loss: 0.5984, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8308/10000, Loss: 0.5984, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8309/10000, Loss: 0.5984, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8310/10000, Loss: 0.5984, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8311/10000, Loss: 0.5984, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8312/10000, Loss: 0.5984, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8313/10000, Loss: 0.5984, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8314/10000, Loss: 0.5984, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8315/10000, Loss: 0.5984, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8316/10000, Loss: 0.5984, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8317/10000, Loss: 0.5984, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8318/10000, Loss: 0.5984, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8319/10000, Loss: 0.5984, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8320/10000, Loss: 0.5984, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8321/10000, Loss: 0.5984, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8322/10000, Loss: 0.5984, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8323/10000, Loss: 0.5984, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8324/10000, Loss: 0.5984, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8325/10000, Loss: 0.5984, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8326/10000, Loss: 0.5984, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8327/10000, Loss: 0.5984, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8328/10000, Loss: 0.5984, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8329/10000, Loss: 0.5984, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8330/10000, Loss: 0.5984, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8331/10000, Loss: 0.5984, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8332/10000, Loss: 0.5984, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8333/10000, Loss: 0.5984, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8334/10000, Loss: 0.5984, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8335/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8336/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8337/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8338/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8339/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8340/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8341/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8342/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8343/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8344/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8345/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8346/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8347/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8348/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8349/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8350/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8351/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8352/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8353/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8354/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8355/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8356/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8357/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8358/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8359/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8360/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8361/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8362/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8363/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8364/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8365/10000, Loss: 0.5983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8366/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8367/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8368/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8369/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8370/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8371/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8372/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8373/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8374/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8375/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8376/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8377/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8378/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8379/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8380/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8381/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8382/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8383/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8384/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8385/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8386/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8387/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8388/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8389/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8390/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8391/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8392/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8393/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8394/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8395/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8396/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8397/10000, Loss: 0.5982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8398/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8399/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8400/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8401/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8402/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8403/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8404/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8405/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8406/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8407/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8408/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8409/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8410/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8411/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8412/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8413/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8414/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8415/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8416/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8417/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8418/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8419/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8420/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8421/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8422/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8423/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8424/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8425/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8426/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8427/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8428/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8429/10000, Loss: 0.5981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8430/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8431/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8432/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8433/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8434/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8435/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8436/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8437/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8438/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8439/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8440/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8441/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8442/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8443/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8444/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8445/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8446/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8447/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8448/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8449/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8450/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8451/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8452/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8453/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8454/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8455/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8456/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8457/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8458/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8459/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8460/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8461/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8462/10000, Loss: 0.5980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8463/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8464/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8465/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8466/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8467/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8468/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8469/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8470/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8471/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8472/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8473/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8474/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8475/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8476/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8477/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8478/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8479/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8480/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8481/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8482/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8483/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8484/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8485/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8486/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8487/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8488/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8489/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8490/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8491/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8492/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8493/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8494/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8495/10000, Loss: 0.5979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8496/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8497/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8498/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8499/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8500/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8501/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8502/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8503/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8504/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8505/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8506/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8507/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8508/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8509/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8510/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8511/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8512/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8513/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8514/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8515/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8516/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8517/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8518/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8519/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8520/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8521/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8522/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8523/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8524/10000, Loss: 0.5978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 8525/10000, Loss: 0.5978, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8526/10000, Loss: 0.5978, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8527/10000, Loss: 0.5978, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8528/10000, Loss: 0.5978, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8529/10000, Loss: 0.5978, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8530/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8531/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8532/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8533/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8534/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8535/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8536/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8537/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8538/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8539/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8540/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8541/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8542/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8543/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8544/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8545/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8546/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8547/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8548/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8549/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8550/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8551/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8552/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8553/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8554/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8555/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8556/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8557/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8558/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8559/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8560/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8561/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8562/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8563/10000, Loss: 0.5977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8564/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8565/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8566/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8567/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8568/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8569/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8570/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8571/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8572/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8573/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8574/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8575/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8576/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8577/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8578/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8579/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8580/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8581/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8582/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8583/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8584/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8585/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8586/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8587/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8588/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8589/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8590/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8591/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8592/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8593/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8594/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8595/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8596/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8597/10000, Loss: 0.5976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8598/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8599/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8600/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8601/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8602/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8603/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8604/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8605/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8606/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8607/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8608/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8609/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8610/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8611/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8612/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8613/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8614/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8615/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8616/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8617/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8618/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8619/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8620/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8621/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8622/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8623/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8624/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8625/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8626/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8627/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8628/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8629/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8630/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8631/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8632/10000, Loss: 0.5975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8633/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8634/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8635/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8636/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8637/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8638/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8639/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8640/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8641/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8642/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8643/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8644/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8645/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8646/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8647/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8648/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8649/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8650/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8651/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8652/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8653/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8654/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8655/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8656/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8657/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8658/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8659/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8660/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8661/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8662/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8663/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8664/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8665/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8666/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8667/10000, Loss: 0.5974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8668/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8669/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8670/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8671/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8672/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8673/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8674/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8675/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8676/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8677/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8678/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8679/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8680/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8681/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8682/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8683/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8684/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8685/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8686/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8687/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8688/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8689/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8690/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8691/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8692/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8693/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8694/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8695/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8696/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8697/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8698/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8699/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8700/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8701/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8702/10000, Loss: 0.5973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8703/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8704/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8705/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8706/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8707/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8708/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8709/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8710/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8711/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8712/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8713/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8714/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8715/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8716/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8717/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8718/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8719/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8720/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8721/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8722/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8723/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8724/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8725/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8726/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8727/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8728/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8729/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8730/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8731/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8732/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8733/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8734/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8735/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8736/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8737/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8738/10000, Loss: 0.5972, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8739/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8740/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8741/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8742/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8743/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8744/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8745/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8746/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8747/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8748/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8749/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8750/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8751/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8752/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8753/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8754/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8755/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8756/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8757/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8758/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8759/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8760/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8761/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8762/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8763/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8764/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8765/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8766/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8767/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8768/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8769/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8770/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8771/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8772/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8773/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8774/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8775/10000, Loss: 0.5971, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8776/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8777/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8778/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8779/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8780/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8781/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8782/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8783/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8784/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8785/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8786/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8787/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8788/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8789/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8790/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8791/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8792/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8793/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8794/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8795/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8796/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8797/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8798/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8799/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8800/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8801/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8802/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8803/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8804/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8805/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8806/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8807/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8808/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8809/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8810/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8811/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8812/10000, Loss: 0.5970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8813/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8814/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8815/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8816/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8817/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8818/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8819/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8820/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8821/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8822/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8823/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8824/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8825/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8826/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8827/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8828/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8829/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8830/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8831/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8832/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8833/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8834/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8835/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8836/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8837/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8838/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8839/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8840/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8841/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8842/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8843/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8844/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8845/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8846/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8847/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8848/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8849/10000, Loss: 0.5969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8850/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8851/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8852/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8853/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8854/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8855/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8856/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8857/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8858/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8859/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8860/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8861/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8862/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8863/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8864/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8865/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8866/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8867/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8868/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8869/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8870/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8871/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8872/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8873/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8874/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8875/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8876/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8877/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8878/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8879/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8880/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8881/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8882/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8883/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8884/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8885/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8886/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8887/10000, Loss: 0.5968, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8888/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8889/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8890/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8891/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8892/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8893/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8894/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8895/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8896/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8897/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8898/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8899/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8900/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8901/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8902/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8903/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8904/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8905/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8906/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8907/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8908/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8909/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8910/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8911/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8912/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8913/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8914/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8915/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8916/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8917/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8918/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8919/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8920/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8921/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8922/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8923/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8924/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8925/10000, Loss: 0.5967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8926/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8927/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8928/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8929/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8930/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8931/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8932/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8933/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8934/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8935/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8936/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8937/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8938/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8939/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8940/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8941/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8942/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8943/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8944/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8945/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8946/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8947/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8948/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8949/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8950/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8951/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8952/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8953/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8954/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8955/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8956/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8957/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8958/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8959/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8960/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8961/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8962/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8963/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8964/10000, Loss: 0.5966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8965/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8966/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8967/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8968/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8969/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8970/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8971/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8972/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8973/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8974/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8975/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8976/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8977/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8978/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8979/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8980/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8981/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8982/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8983/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8984/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8985/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8986/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8987/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8988/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8989/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8990/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8991/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8992/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8993/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8994/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8995/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8996/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8997/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8998/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 8999/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9000/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9001/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9002/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9003/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9004/10000, Loss: 0.5965, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9005/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9006/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9007/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9008/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9009/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9010/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9011/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9012/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9013/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9014/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9015/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9016/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9017/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9018/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9019/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9020/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9021/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9022/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9023/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9024/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9025/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9026/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9027/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9028/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9029/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9030/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9031/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9032/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9033/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9034/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9035/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9036/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9037/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9038/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9039/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9040/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9041/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9042/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9043/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9044/10000, Loss: 0.5964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9045/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9046/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9047/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9048/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9049/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9050/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9051/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9052/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9053/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9054/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9055/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9056/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9057/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9058/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9059/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9060/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9061/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9062/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9063/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9064/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9065/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9066/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9067/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9068/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9069/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9070/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9071/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9072/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9073/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9074/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9075/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9076/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9077/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9078/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9079/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9080/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9081/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9082/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9083/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9084/10000, Loss: 0.5963, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9085/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9086/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9087/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9088/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9089/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9090/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9091/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9092/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9093/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9094/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9095/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9096/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9097/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9098/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9099/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9100/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9101/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9102/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9103/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9104/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9105/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9106/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9107/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9108/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9109/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9110/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9111/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9112/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9113/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9114/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9115/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9116/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9117/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9118/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9119/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9120/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9121/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9122/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9123/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9124/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9125/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9126/10000, Loss: 0.5962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9127/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9128/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9129/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9130/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9131/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9132/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9133/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9134/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9135/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9136/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9137/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9138/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9139/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9140/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9141/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9142/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9143/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9144/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9145/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9146/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9147/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9148/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9149/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9150/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9151/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9152/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9153/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9154/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9155/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9156/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9157/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9158/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9159/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9160/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9161/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9162/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9163/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9164/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9165/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9166/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9167/10000, Loss: 0.5961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9168/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9169/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9170/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9171/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9172/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9173/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9174/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9175/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9176/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9177/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9178/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9179/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9180/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9181/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9182/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9183/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9184/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9185/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9186/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9187/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9188/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9189/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9190/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9191/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9192/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9193/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9194/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9195/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9196/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9197/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9198/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9199/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9200/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9201/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9202/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9203/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9204/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9205/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9206/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9207/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9208/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9209/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9210/10000, Loss: 0.5960, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9211/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9212/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9213/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9214/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9215/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9216/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9217/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9218/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9219/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9220/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9221/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9222/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9223/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9224/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9225/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9226/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9227/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9228/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9229/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9230/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9231/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9232/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9233/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9234/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9235/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9236/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9237/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9238/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9239/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9240/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9241/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9242/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9243/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9244/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9245/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9246/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9247/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9248/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9249/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9250/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9251/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9252/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9253/10000, Loss: 0.5959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9254/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9255/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9256/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9257/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9258/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9259/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9260/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9261/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9262/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9263/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9264/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9265/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9266/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9267/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9268/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9269/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9270/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9271/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9272/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9273/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9274/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9275/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9276/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9277/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9278/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9279/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9280/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9281/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9282/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9283/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9284/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9285/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9286/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9287/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9288/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9289/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9290/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9291/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9292/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9293/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9294/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9295/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9296/10000, Loss: 0.5958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9297/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9298/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9299/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9300/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9301/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9302/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9303/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9304/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9305/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9306/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9307/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9308/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9309/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9310/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9311/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9312/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9313/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9314/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9315/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9316/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9317/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9318/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9319/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9320/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9321/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9322/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9323/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9324/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9325/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9326/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9327/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9328/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9329/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9330/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9331/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9332/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9333/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9334/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9335/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9336/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9337/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9338/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9339/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9340/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9341/10000, Loss: 0.5957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9342/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9343/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9344/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9345/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9346/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9347/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9348/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9349/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9350/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9351/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9352/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9353/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9354/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9355/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9356/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9357/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9358/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9359/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9360/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9361/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9362/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9363/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9364/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9365/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9366/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9367/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9368/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9369/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9370/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9371/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9372/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9373/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9374/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9375/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9376/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9377/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9378/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9379/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9380/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9381/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9382/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9383/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9384/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9385/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9386/10000, Loss: 0.5956, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9387/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9388/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9389/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9390/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9391/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9392/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9393/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9394/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9395/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9396/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9397/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9398/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9399/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9400/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9401/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9402/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9403/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9404/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9405/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9406/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9407/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9408/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9409/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9410/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9411/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9412/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9413/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9414/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9415/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9416/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9417/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9418/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9419/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9420/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9421/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9422/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9423/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9424/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9425/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9426/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9427/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9428/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9429/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9430/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9431/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9432/10000, Loss: 0.5955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9433/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9434/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9435/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9436/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9437/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9438/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9439/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9440/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9441/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9442/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9443/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9444/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9445/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9446/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9447/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9448/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9449/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9450/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9451/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9452/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9453/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9454/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9455/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9456/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9457/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9458/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9459/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9460/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9461/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9462/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9463/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9464/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9465/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9466/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9467/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9468/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9469/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9470/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9471/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9472/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9473/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9474/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9475/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9476/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9477/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9478/10000, Loss: 0.5954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9479/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9480/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9481/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9482/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9483/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9484/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9485/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9486/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9487/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9488/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9489/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9490/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9491/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9492/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9493/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9494/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9495/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9496/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9497/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9498/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9499/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9500/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9501/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9502/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9503/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9504/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9505/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9506/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9507/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9508/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9509/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9510/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9511/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9512/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9513/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9514/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9515/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9516/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9517/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9518/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9519/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9520/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9521/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9522/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9523/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9524/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9525/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9526/10000, Loss: 0.5953, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9527/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9528/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9529/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9530/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9531/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9532/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9533/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9534/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9535/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9536/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9537/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9538/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9539/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9540/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9541/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9542/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9543/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9544/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9545/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9546/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9547/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9548/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9549/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9550/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9551/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9552/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9553/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9554/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9555/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9556/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9557/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9558/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9559/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9560/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9561/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9562/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9563/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9564/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9565/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9566/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9567/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9568/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9569/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9570/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9571/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9572/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9573/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9574/10000, Loss: 0.5952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9575/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9576/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9577/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9578/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9579/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9580/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9581/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9582/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9583/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9584/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9585/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9586/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9587/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9588/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9589/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9590/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9591/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9592/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9593/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9594/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9595/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9596/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9597/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9598/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9599/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9600/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9601/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9602/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9603/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9604/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9605/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9606/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9607/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9608/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9609/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9610/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9611/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9612/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9613/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9614/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9615/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9616/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9617/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9618/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9619/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9620/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9621/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9622/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9623/10000, Loss: 0.5951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9624/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9625/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9626/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9627/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9628/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9629/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9630/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9631/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9632/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9633/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9634/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9635/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9636/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9637/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9638/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9639/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9640/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9641/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9642/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9643/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9644/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9645/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9646/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9647/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9648/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9649/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9650/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9651/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9652/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9653/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9654/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9655/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9656/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9657/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9658/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9659/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9660/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9661/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9662/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9663/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9664/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9665/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9666/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9667/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9668/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9669/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9670/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9671/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9672/10000, Loss: 0.5950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9673/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9674/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9675/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9676/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9677/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9678/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9679/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9680/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9681/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9682/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9683/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9684/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9685/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9686/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9687/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9688/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9689/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9690/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9691/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9692/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9693/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9694/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9695/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9696/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9697/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9698/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9699/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9700/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9701/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9702/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9703/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9704/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9705/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9706/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9707/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9708/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9709/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9710/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9711/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9712/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9713/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9714/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9715/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9716/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9717/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9718/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9719/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9720/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9721/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9722/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9723/10000, Loss: 0.5949, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9724/10000, Loss: 0.5948, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9725/10000, Loss: 0.5948, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9726/10000, Loss: 0.5948, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9727/10000, Loss: 0.5948, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9728/10000, Loss: 0.5948, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9729/10000, Loss: 0.5948, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9730/10000, Loss: 0.5948, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9731/10000, Loss: 0.5948, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9732/10000, Loss: 0.5948, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9733/10000, Loss: 0.5948, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9734/10000, Loss: 0.5948, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9735/10000, Loss: 0.5948, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9736/10000, Loss: 0.5948, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9737/10000, Loss: 0.5948, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 9738/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9739/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9740/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9741/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9742/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9743/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9744/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9745/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9746/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9747/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9748/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9749/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9750/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9751/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9752/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9753/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9754/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9755/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9756/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9757/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9758/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9759/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9760/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9761/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9762/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9763/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9764/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9765/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9766/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9767/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9768/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9769/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9770/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9771/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9772/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9773/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9774/10000, Loss: 0.5948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9775/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9776/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9777/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9778/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9779/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9780/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9781/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9782/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9783/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9784/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9785/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9786/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9787/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9788/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9789/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9790/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9791/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9792/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9793/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9794/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9795/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9796/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9797/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9798/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9799/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9800/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9801/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9802/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9803/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9804/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9805/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9806/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9807/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9808/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9809/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9810/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9811/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9812/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9813/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9814/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9815/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9816/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9817/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9818/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9819/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9820/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9821/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9822/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9823/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9824/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9825/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9826/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9827/10000, Loss: 0.5947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9828/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9829/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9830/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9831/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9832/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9833/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9834/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9835/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9836/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9837/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9838/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9839/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9840/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9841/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9842/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9843/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9844/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9845/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9846/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9847/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9848/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9849/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9850/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9851/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9852/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9853/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9854/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9855/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9856/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9857/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9858/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9859/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9860/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9861/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9862/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9863/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9864/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9865/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9866/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9867/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9868/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9869/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9870/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9871/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9872/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9873/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9874/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9875/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9876/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9877/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9878/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9879/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9880/10000, Loss: 0.5946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9881/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9882/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9883/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9884/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9885/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9886/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9887/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9888/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9889/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9890/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9891/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9892/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9893/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9894/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9895/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9896/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9897/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9898/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9899/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9900/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9901/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9902/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9903/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9904/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9905/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9906/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9907/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9908/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9909/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9910/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9911/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9912/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9913/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9914/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9915/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9916/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9917/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9918/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9919/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9920/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9921/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9922/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9923/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9924/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9925/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9926/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9927/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9928/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9929/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9930/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9931/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9932/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9933/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9934/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9935/10000, Loss: 0.5945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9936/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9937/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9938/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9939/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9940/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9941/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9942/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9943/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9944/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9945/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9946/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9947/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9948/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9949/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9950/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9951/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9952/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9953/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9954/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9955/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9956/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9957/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9958/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9959/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9960/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9961/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9962/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9963/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9964/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9965/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9966/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9967/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9968/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9969/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9970/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9971/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9972/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9973/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9974/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9975/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9976/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9977/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9978/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9979/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9980/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9981/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9982/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9983/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9984/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9985/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9986/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9987/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9988/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9989/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9990/10000, Loss: 0.5944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9991/10000, Loss: 0.5943, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9992/10000, Loss: 0.5943, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9993/10000, Loss: 0.5943, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9994/10000, Loss: 0.5943, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9995/10000, Loss: 0.5943, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9996/10000, Loss: 0.5943, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9997/10000, Loss: 0.5943, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9998/10000, Loss: 0.5943, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 9999/10000, Loss: 0.5943, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 10000/10000, Loss: 0.5943, Accuracy: 0.6538, Learning Rate: 0.000100\n"
     ]
    }
   ],
   "source": [
    "model.fit(val_x,val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "22e0611a-ede5-4c57-9feb-ae2591badef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ded6444f-c748-418e-9cd9-0160bb41812f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[103.  86.]\n",
      " [108. 240.]]\n",
      "Precision:  0.4881516587677725\n",
      "Recall:  0.544973544973545\n",
      "Accuracy:  0.638733705772812\n",
      "F1 Score:  0.515\n"
     ]
    }
   ],
   "source": [
    "train_pred = model.predict(train_x)\n",
    "performance_print(confusion_matrix(train_pred,train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585d8226-857c-4ce8-aeb9-6aa309a6e270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
