{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "85fb8f4e-df3d-4d92-91c9-b9603a6d3399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8aef4f13-1e05-40c2-83cd-c6ab750f4d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "906f29cf-6bed-4da7-b095-d48eef43ee73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definding our x and y values respectively\n",
    "\n",
    "x = data.drop(['Outcome'],axis =1)\n",
    "y = data['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "bb1cc93a-b1e8-44ff-8c54-f302f68e81aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x:  (768, 8)\n",
      "Shape of y:  (768,)\n"
     ]
    }
   ],
   "source": [
    "#Converting to numpy array to feed into model\n",
    "\n",
    "x = x.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "print(\"Shape of x: \",x.shape)\n",
    "print(\"Shape of y: \",y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c6c95767-6e2c-469a-ac0a-c9508e34f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperating data into training testing and validation set 70:20:10 (train:test:val)\n",
    "\n",
    "train = int(0.7*768)\n",
    "test = int(0.2*768)\n",
    "val = 768 - train - test \n",
    "\n",
    "train_x = x[0:train]\n",
    "train_y = y[0:train]\n",
    "\n",
    "test_x = x[train:test+train]\n",
    "test_y = y[train:test+train]\n",
    "\n",
    "val_x = x[train+test:]\n",
    "val_y = y[train+test:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f1af05ad-261d-4931-8b3f-18552e1667bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "\n",
    "    def __init__(self, learning_rate, epochs):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.b = 0.01\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return np.where(z >= 0, 1 / (1 + np.exp(-z)), np.exp(z) / (1 + np.exp(z)))\n",
    "\n",
    "    def forward_pass(self, x):\n",
    "        z = np.dot(x, self.w) + self.b\n",
    "        predictions = self.sigmoid(z)\n",
    "        return predictions\n",
    "\n",
    "    def binary_cross_entropy(self, pred):\n",
    "        loss = -(self.y * np.log(pred + 1e-9) + (1 - self.y) * np.log(1 - pred + 1e-9))\n",
    "        return np.mean(loss)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.n = x.shape[0]\n",
    "        self.w = np.ones(x.shape[1])\n",
    "        self.loss = []\n",
    "        self.accuracy = []  # Array to store accuracy values\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            predictions = self.forward_pass(x)\n",
    "            dw = (1 / self.n) * np.dot(self.x.T, (predictions - self.y))\n",
    "            db = (1 / self.n) * np.sum(predictions - self.y)\n",
    "\n",
    "            self.w -= self.learning_rate * dw\n",
    "            self.b -= self.learning_rate * db\n",
    "\n",
    "            l = self.binary_cross_entropy(predictions)\n",
    "            self.loss.append(l)\n",
    "\n",
    "            accuracy = self.compute_accuracy(predictions, y)\n",
    "            self.accuracy.append(accuracy)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{self.epochs}, Loss: {l:.4f}, Accuracy: {accuracy:.4f}, Learning Rate: {self.learning_rate:.6f}\")\n",
    "\n",
    "    def compute_accuracy(self, predictions, y):\n",
    "        predicted_labels = np.where(predictions >= 0.5, 1, 0)\n",
    "        correct_predictions = np.sum(predicted_labels == y)\n",
    "        accuracy = correct_predictions / len(y)\n",
    "        return accuracy\n",
    "\n",
    "    def plot(self):\n",
    "        plt.subplot(2,1,1)\n",
    "        plt.plot(lr.loss)\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Loss vs. Iteration')\n",
    "        \n",
    "        \n",
    "        plt.subplot(2,1,2)\n",
    "        plt.plot(lr.accuracy)\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.title('Accuracy vs. Iteration')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def predict(self, data):\n",
    "        z = np.dot(data, self.w) + self.b\n",
    "        predictions = self.sigmoid(z)\n",
    "        return np.where(predictions >= 0.5, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "cc356ecf-8124-4cbc-b7f4-a4eaca94a416",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_134762/1260086574.py:9: RuntimeWarning: overflow encountered in exp\n",
      "  return np.where(z >= 0, 1 / (1 + np.exp(-z)), np.exp(z) / (1 + np.exp(z)))\n",
      "/tmp/ipykernel_134762/1260086574.py:9: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.where(z >= 0, 1 / (1 + np.exp(-z)), np.exp(z) / (1 + np.exp(z)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 2/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 3/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 4/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 5/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 6/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 7/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 8/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 9/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 10/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 11/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 12/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 13/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 14/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 15/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 16/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 17/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 18/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 19/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 20/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 21/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 22/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 23/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 24/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 25/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 26/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 27/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 28/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 29/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 30/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 31/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 32/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 33/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 34/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 35/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 36/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 37/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 38/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 39/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 40/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 41/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 42/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 43/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 44/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 45/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 46/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 47/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 48/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 49/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 50/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 51/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 52/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 53/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 54/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 55/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 56/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 57/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 58/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 59/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 60/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 61/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 62/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 63/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 64/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 65/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 66/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 67/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 68/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 69/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 70/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 71/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 72/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 73/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 74/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 75/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 76/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 77/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 78/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 79/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 80/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 81/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 82/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 83/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 84/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 85/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 86/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 87/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 88/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 89/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 90/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 91/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 92/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 93/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 94/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 95/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 96/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 97/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 98/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 99/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 100/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 101/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 102/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 103/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 104/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 105/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 106/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 107/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 108/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 109/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 110/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 111/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 112/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 113/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 114/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 115/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 116/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 117/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 118/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 119/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 120/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 121/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 122/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 123/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 124/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 125/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 126/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 127/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 128/10000, Loss: 13.4296, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 129/10000, Loss: 13.4295, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 130/10000, Loss: 13.4295, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 131/10000, Loss: 13.4294, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 132/10000, Loss: 13.4292, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 133/10000, Loss: 13.4290, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 134/10000, Loss: 13.4285, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 135/10000, Loss: 13.4276, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 136/10000, Loss: 13.4263, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 137/10000, Loss: 13.4244, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 138/10000, Loss: 13.4219, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 139/10000, Loss: 13.4186, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 140/10000, Loss: 13.4148, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 141/10000, Loss: 13.4106, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 142/10000, Loss: 13.4061, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 143/10000, Loss: 13.4013, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 144/10000, Loss: 13.3963, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 145/10000, Loss: 13.3909, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 146/10000, Loss: 13.3848, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 147/10000, Loss: 13.3782, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 148/10000, Loss: 13.3710, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 149/10000, Loss: 13.3635, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 150/10000, Loss: 13.3558, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 151/10000, Loss: 13.3480, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 152/10000, Loss: 13.3402, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 153/10000, Loss: 13.3324, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 154/10000, Loss: 13.3245, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 155/10000, Loss: 13.3166, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 156/10000, Loss: 13.3085, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 157/10000, Loss: 13.3003, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 158/10000, Loss: 13.2917, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 159/10000, Loss: 13.2825, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 160/10000, Loss: 13.2726, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 161/10000, Loss: 13.2623, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 162/10000, Loss: 13.2516, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 163/10000, Loss: 13.2408, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 164/10000, Loss: 13.2300, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 165/10000, Loss: 13.2194, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 166/10000, Loss: 13.2089, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 167/10000, Loss: 13.1987, Accuracy: 0.3538, Learning Rate: 0.000100\n",
      "Epoch 168/10000, Loss: 13.1884, Accuracy: 0.3538, Learning Rate: 0.000100\n",
      "Epoch 169/10000, Loss: 13.1780, Accuracy: 0.3557, Learning Rate: 0.000100\n",
      "Epoch 170/10000, Loss: 13.1676, Accuracy: 0.3575, Learning Rate: 0.000100\n",
      "Epoch 171/10000, Loss: 13.1577, Accuracy: 0.3575, Learning Rate: 0.000100\n",
      "Epoch 172/10000, Loss: 13.1479, Accuracy: 0.3594, Learning Rate: 0.000100\n",
      "Epoch 173/10000, Loss: 13.1370, Accuracy: 0.3631, Learning Rate: 0.000100\n",
      "Epoch 174/10000, Loss: 13.1239, Accuracy: 0.3631, Learning Rate: 0.000100\n",
      "Epoch 175/10000, Loss: 13.1075, Accuracy: 0.3631, Learning Rate: 0.000100\n",
      "Epoch 176/10000, Loss: 13.0873, Accuracy: 0.3631, Learning Rate: 0.000100\n",
      "Epoch 177/10000, Loss: 13.0626, Accuracy: 0.3613, Learning Rate: 0.000100\n",
      "Epoch 178/10000, Loss: 13.0332, Accuracy: 0.3613, Learning Rate: 0.000100\n",
      "Epoch 179/10000, Loss: 12.9988, Accuracy: 0.3594, Learning Rate: 0.000100\n",
      "Epoch 180/10000, Loss: 12.9581, Accuracy: 0.3594, Learning Rate: 0.000100\n",
      "Epoch 181/10000, Loss: 12.9102, Accuracy: 0.3594, Learning Rate: 0.000100\n",
      "Epoch 182/10000, Loss: 12.8560, Accuracy: 0.3594, Learning Rate: 0.000100\n",
      "Epoch 183/10000, Loss: 12.7971, Accuracy: 0.3594, Learning Rate: 0.000100\n",
      "Epoch 184/10000, Loss: 12.7349, Accuracy: 0.3594, Learning Rate: 0.000100\n",
      "Epoch 185/10000, Loss: 12.6707, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 186/10000, Loss: 12.6042, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 187/10000, Loss: 12.5342, Accuracy: 0.3501, Learning Rate: 0.000100\n",
      "Epoch 188/10000, Loss: 12.4600, Accuracy: 0.3482, Learning Rate: 0.000100\n",
      "Epoch 189/10000, Loss: 12.3789, Accuracy: 0.3464, Learning Rate: 0.000100\n",
      "Epoch 190/10000, Loss: 12.2880, Accuracy: 0.3464, Learning Rate: 0.000100\n",
      "Epoch 191/10000, Loss: 12.1870, Accuracy: 0.3482, Learning Rate: 0.000100\n",
      "Epoch 192/10000, Loss: 12.0790, Accuracy: 0.3482, Learning Rate: 0.000100\n",
      "Epoch 193/10000, Loss: 11.9688, Accuracy: 0.3445, Learning Rate: 0.000100\n",
      "Epoch 194/10000, Loss: 11.8588, Accuracy: 0.3464, Learning Rate: 0.000100\n",
      "Epoch 195/10000, Loss: 11.7468, Accuracy: 0.3464, Learning Rate: 0.000100\n",
      "Epoch 196/10000, Loss: 11.6303, Accuracy: 0.3557, Learning Rate: 0.000100\n",
      "Epoch 197/10000, Loss: 11.5083, Accuracy: 0.3520, Learning Rate: 0.000100\n",
      "Epoch 198/10000, Loss: 11.3797, Accuracy: 0.3557, Learning Rate: 0.000100\n",
      "Epoch 199/10000, Loss: 11.2444, Accuracy: 0.3575, Learning Rate: 0.000100\n",
      "Epoch 200/10000, Loss: 11.1014, Accuracy: 0.3557, Learning Rate: 0.000100\n",
      "Epoch 201/10000, Loss: 10.9498, Accuracy: 0.3538, Learning Rate: 0.000100\n",
      "Epoch 202/10000, Loss: 10.7939, Accuracy: 0.3538, Learning Rate: 0.000100\n",
      "Epoch 203/10000, Loss: 10.6377, Accuracy: 0.3613, Learning Rate: 0.000100\n",
      "Epoch 204/10000, Loss: 10.4826, Accuracy: 0.3687, Learning Rate: 0.000100\n",
      "Epoch 205/10000, Loss: 10.3303, Accuracy: 0.3724, Learning Rate: 0.000100\n",
      "Epoch 206/10000, Loss: 10.1815, Accuracy: 0.3780, Learning Rate: 0.000100\n",
      "Epoch 207/10000, Loss: 10.0361, Accuracy: 0.3780, Learning Rate: 0.000100\n",
      "Epoch 208/10000, Loss: 9.8954, Accuracy: 0.3818, Learning Rate: 0.000100\n",
      "Epoch 209/10000, Loss: 9.7601, Accuracy: 0.3855, Learning Rate: 0.000100\n",
      "Epoch 210/10000, Loss: 9.6247, Accuracy: 0.3836, Learning Rate: 0.000100\n",
      "Epoch 211/10000, Loss: 9.4839, Accuracy: 0.3855, Learning Rate: 0.000100\n",
      "Epoch 212/10000, Loss: 9.3365, Accuracy: 0.3892, Learning Rate: 0.000100\n",
      "Epoch 213/10000, Loss: 9.1826, Accuracy: 0.3836, Learning Rate: 0.000100\n",
      "Epoch 214/10000, Loss: 9.0216, Accuracy: 0.3855, Learning Rate: 0.000100\n",
      "Epoch 215/10000, Loss: 8.8585, Accuracy: 0.3873, Learning Rate: 0.000100\n",
      "Epoch 216/10000, Loss: 8.6984, Accuracy: 0.3985, Learning Rate: 0.000100\n",
      "Epoch 217/10000, Loss: 8.5445, Accuracy: 0.4022, Learning Rate: 0.000100\n",
      "Epoch 218/10000, Loss: 8.3995, Accuracy: 0.4078, Learning Rate: 0.000100\n",
      "Epoch 219/10000, Loss: 8.2638, Accuracy: 0.4097, Learning Rate: 0.000100\n",
      "Epoch 220/10000, Loss: 8.1376, Accuracy: 0.4153, Learning Rate: 0.000100\n",
      "Epoch 221/10000, Loss: 8.0184, Accuracy: 0.4190, Learning Rate: 0.000100\n",
      "Epoch 222/10000, Loss: 7.9076, Accuracy: 0.4190, Learning Rate: 0.000100\n",
      "Epoch 223/10000, Loss: 7.8045, Accuracy: 0.4246, Learning Rate: 0.000100\n",
      "Epoch 224/10000, Loss: 7.7086, Accuracy: 0.4246, Learning Rate: 0.000100\n",
      "Epoch 225/10000, Loss: 7.6208, Accuracy: 0.4227, Learning Rate: 0.000100\n",
      "Epoch 226/10000, Loss: 7.5413, Accuracy: 0.4246, Learning Rate: 0.000100\n",
      "Epoch 227/10000, Loss: 7.4702, Accuracy: 0.4358, Learning Rate: 0.000100\n",
      "Epoch 228/10000, Loss: 7.4074, Accuracy: 0.4376, Learning Rate: 0.000100\n",
      "Epoch 229/10000, Loss: 7.3529, Accuracy: 0.4413, Learning Rate: 0.000100\n",
      "Epoch 230/10000, Loss: 7.3062, Accuracy: 0.4451, Learning Rate: 0.000100\n",
      "Epoch 231/10000, Loss: 7.2649, Accuracy: 0.4469, Learning Rate: 0.000100\n",
      "Epoch 232/10000, Loss: 7.2273, Accuracy: 0.4544, Learning Rate: 0.000100\n",
      "Epoch 233/10000, Loss: 7.1926, Accuracy: 0.4581, Learning Rate: 0.000100\n",
      "Epoch 234/10000, Loss: 7.1603, Accuracy: 0.4618, Learning Rate: 0.000100\n",
      "Epoch 235/10000, Loss: 7.1304, Accuracy: 0.4655, Learning Rate: 0.000100\n",
      "Epoch 236/10000, Loss: 7.1029, Accuracy: 0.4674, Learning Rate: 0.000100\n",
      "Epoch 237/10000, Loss: 7.0779, Accuracy: 0.4674, Learning Rate: 0.000100\n",
      "Epoch 238/10000, Loss: 7.0552, Accuracy: 0.4693, Learning Rate: 0.000100\n",
      "Epoch 239/10000, Loss: 7.0345, Accuracy: 0.4711, Learning Rate: 0.000100\n",
      "Epoch 240/10000, Loss: 7.0156, Accuracy: 0.4749, Learning Rate: 0.000100\n",
      "Epoch 241/10000, Loss: 6.9982, Accuracy: 0.4823, Learning Rate: 0.000100\n",
      "Epoch 242/10000, Loss: 6.9823, Accuracy: 0.4804, Learning Rate: 0.000100\n",
      "Epoch 243/10000, Loss: 6.9677, Accuracy: 0.4823, Learning Rate: 0.000100\n",
      "Epoch 244/10000, Loss: 6.9542, Accuracy: 0.4823, Learning Rate: 0.000100\n",
      "Epoch 245/10000, Loss: 6.9417, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 246/10000, Loss: 6.9300, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 247/10000, Loss: 6.9191, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 248/10000, Loss: 6.9088, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 249/10000, Loss: 6.8991, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 250/10000, Loss: 6.8899, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 251/10000, Loss: 6.8811, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 252/10000, Loss: 6.8728, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 253/10000, Loss: 6.8648, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 254/10000, Loss: 6.8571, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 255/10000, Loss: 6.8497, Accuracy: 0.4767, Learning Rate: 0.000100\n",
      "Epoch 256/10000, Loss: 6.8426, Accuracy: 0.4767, Learning Rate: 0.000100\n",
      "Epoch 257/10000, Loss: 6.8358, Accuracy: 0.4767, Learning Rate: 0.000100\n",
      "Epoch 258/10000, Loss: 6.8291, Accuracy: 0.4749, Learning Rate: 0.000100\n",
      "Epoch 259/10000, Loss: 6.8226, Accuracy: 0.4767, Learning Rate: 0.000100\n",
      "Epoch 260/10000, Loss: 6.8163, Accuracy: 0.4767, Learning Rate: 0.000100\n",
      "Epoch 261/10000, Loss: 6.8101, Accuracy: 0.4767, Learning Rate: 0.000100\n",
      "Epoch 262/10000, Loss: 6.8041, Accuracy: 0.4767, Learning Rate: 0.000100\n",
      "Epoch 263/10000, Loss: 6.7982, Accuracy: 0.4767, Learning Rate: 0.000100\n",
      "Epoch 264/10000, Loss: 6.7925, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 265/10000, Loss: 6.7868, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 266/10000, Loss: 6.7812, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 267/10000, Loss: 6.7758, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 268/10000, Loss: 6.7704, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 269/10000, Loss: 6.7650, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 270/10000, Loss: 6.7598, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 271/10000, Loss: 6.7546, Accuracy: 0.4804, Learning Rate: 0.000100\n",
      "Epoch 272/10000, Loss: 6.7495, Accuracy: 0.4804, Learning Rate: 0.000100\n",
      "Epoch 273/10000, Loss: 6.7444, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 274/10000, Loss: 6.7393, Accuracy: 0.4786, Learning Rate: 0.000100\n",
      "Epoch 275/10000, Loss: 6.7344, Accuracy: 0.4823, Learning Rate: 0.000100\n",
      "Epoch 276/10000, Loss: 6.7294, Accuracy: 0.4823, Learning Rate: 0.000100\n",
      "Epoch 277/10000, Loss: 6.7245, Accuracy: 0.4823, Learning Rate: 0.000100\n",
      "Epoch 278/10000, Loss: 6.7196, Accuracy: 0.4823, Learning Rate: 0.000100\n",
      "Epoch 279/10000, Loss: 6.7148, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 280/10000, Loss: 6.7100, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 281/10000, Loss: 6.7052, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 282/10000, Loss: 6.7005, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 283/10000, Loss: 6.6957, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 284/10000, Loss: 6.6910, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 285/10000, Loss: 6.6863, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 286/10000, Loss: 6.6817, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 287/10000, Loss: 6.6770, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 288/10000, Loss: 6.6724, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 289/10000, Loss: 6.6678, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 290/10000, Loss: 6.6632, Accuracy: 0.4823, Learning Rate: 0.000100\n",
      "Epoch 291/10000, Loss: 6.6586, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 292/10000, Loss: 6.6540, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 293/10000, Loss: 6.6495, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 294/10000, Loss: 6.6449, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 295/10000, Loss: 6.6404, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 296/10000, Loss: 6.6359, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 297/10000, Loss: 6.6314, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 298/10000, Loss: 6.6269, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 299/10000, Loss: 6.6224, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 300/10000, Loss: 6.6179, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 301/10000, Loss: 6.6134, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 302/10000, Loss: 6.6089, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 303/10000, Loss: 6.6045, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 304/10000, Loss: 6.6000, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 305/10000, Loss: 6.5956, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 306/10000, Loss: 6.5911, Accuracy: 0.4842, Learning Rate: 0.000100\n",
      "Epoch 307/10000, Loss: 6.5867, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 308/10000, Loss: 6.5822, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 309/10000, Loss: 6.5778, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 310/10000, Loss: 6.5734, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 311/10000, Loss: 6.5690, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 312/10000, Loss: 6.5646, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 313/10000, Loss: 6.5602, Accuracy: 0.4860, Learning Rate: 0.000100\n",
      "Epoch 314/10000, Loss: 6.5558, Accuracy: 0.4879, Learning Rate: 0.000100\n",
      "Epoch 315/10000, Loss: 6.5514, Accuracy: 0.4879, Learning Rate: 0.000100\n",
      "Epoch 316/10000, Loss: 6.5470, Accuracy: 0.4879, Learning Rate: 0.000100\n",
      "Epoch 317/10000, Loss: 6.5426, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 318/10000, Loss: 6.5382, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 319/10000, Loss: 6.5338, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 320/10000, Loss: 6.5294, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 321/10000, Loss: 6.5250, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 322/10000, Loss: 6.5207, Accuracy: 0.4898, Learning Rate: 0.000100\n",
      "Epoch 323/10000, Loss: 6.5163, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 324/10000, Loss: 6.5119, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 325/10000, Loss: 6.5076, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 326/10000, Loss: 6.5032, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 327/10000, Loss: 6.4988, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 328/10000, Loss: 6.4945, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 329/10000, Loss: 6.4901, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 330/10000, Loss: 6.4858, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 331/10000, Loss: 6.4814, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 332/10000, Loss: 6.4771, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 333/10000, Loss: 6.4728, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 334/10000, Loss: 6.4684, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 335/10000, Loss: 6.4641, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 336/10000, Loss: 6.4597, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 337/10000, Loss: 6.4554, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 338/10000, Loss: 6.4511, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 339/10000, Loss: 6.4467, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 340/10000, Loss: 6.4424, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 341/10000, Loss: 6.4381, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 342/10000, Loss: 6.4338, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 343/10000, Loss: 6.4294, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 344/10000, Loss: 6.4251, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 345/10000, Loss: 6.4208, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 346/10000, Loss: 6.4165, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 347/10000, Loss: 6.4122, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 348/10000, Loss: 6.4079, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 349/10000, Loss: 6.4035, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 350/10000, Loss: 6.3992, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 351/10000, Loss: 6.3949, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 352/10000, Loss: 6.3906, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 353/10000, Loss: 6.3863, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 354/10000, Loss: 6.3820, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 355/10000, Loss: 6.3777, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 356/10000, Loss: 6.3734, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 357/10000, Loss: 6.3691, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 358/10000, Loss: 6.3648, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 359/10000, Loss: 6.3605, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 360/10000, Loss: 6.3562, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 361/10000, Loss: 6.3519, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 362/10000, Loss: 6.3476, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 363/10000, Loss: 6.3433, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 364/10000, Loss: 6.3390, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 365/10000, Loss: 6.3347, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 366/10000, Loss: 6.3305, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 367/10000, Loss: 6.3262, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 368/10000, Loss: 6.3219, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 369/10000, Loss: 6.3176, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 370/10000, Loss: 6.3133, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 371/10000, Loss: 6.3090, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 372/10000, Loss: 6.3047, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 373/10000, Loss: 6.3004, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 374/10000, Loss: 6.2962, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 375/10000, Loss: 6.2919, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 376/10000, Loss: 6.2876, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 377/10000, Loss: 6.2833, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 378/10000, Loss: 6.2790, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 379/10000, Loss: 6.2747, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 380/10000, Loss: 6.2705, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 381/10000, Loss: 6.2662, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 382/10000, Loss: 6.2619, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 383/10000, Loss: 6.2576, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 384/10000, Loss: 6.2533, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 385/10000, Loss: 6.2490, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 386/10000, Loss: 6.2447, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 387/10000, Loss: 6.2405, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 388/10000, Loss: 6.2362, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 389/10000, Loss: 6.2319, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 390/10000, Loss: 6.2276, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 391/10000, Loss: 6.2233, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 392/10000, Loss: 6.2190, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 393/10000, Loss: 6.2147, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 394/10000, Loss: 6.2104, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 395/10000, Loss: 6.2061, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 396/10000, Loss: 6.2018, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 397/10000, Loss: 6.1975, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 398/10000, Loss: 6.1932, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 399/10000, Loss: 6.1889, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 400/10000, Loss: 6.1846, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 401/10000, Loss: 6.1803, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 402/10000, Loss: 6.1760, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 403/10000, Loss: 6.1717, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 404/10000, Loss: 6.1674, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 405/10000, Loss: 6.1631, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 406/10000, Loss: 6.1588, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 407/10000, Loss: 6.1545, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 408/10000, Loss: 6.1502, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 409/10000, Loss: 6.1458, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 410/10000, Loss: 6.1415, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 411/10000, Loss: 6.1372, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 412/10000, Loss: 6.1329, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 413/10000, Loss: 6.1285, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 414/10000, Loss: 6.1242, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 415/10000, Loss: 6.1199, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 416/10000, Loss: 6.1156, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 417/10000, Loss: 6.1112, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 418/10000, Loss: 6.1069, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 419/10000, Loss: 6.1025, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 420/10000, Loss: 6.0982, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 421/10000, Loss: 6.0938, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 422/10000, Loss: 6.0895, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 423/10000, Loss: 6.0852, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 424/10000, Loss: 6.0808, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 425/10000, Loss: 6.0764, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 426/10000, Loss: 6.0721, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 427/10000, Loss: 6.0677, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 428/10000, Loss: 6.0634, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 429/10000, Loss: 6.0590, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 430/10000, Loss: 6.0547, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 431/10000, Loss: 6.0503, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 432/10000, Loss: 6.0459, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 433/10000, Loss: 6.0415, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 434/10000, Loss: 6.0372, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 435/10000, Loss: 6.0328, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 436/10000, Loss: 6.0284, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 437/10000, Loss: 6.0241, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 438/10000, Loss: 6.0197, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 439/10000, Loss: 6.0153, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 440/10000, Loss: 6.0109, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 441/10000, Loss: 6.0065, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 442/10000, Loss: 6.0021, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 443/10000, Loss: 5.9978, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 444/10000, Loss: 5.9934, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 445/10000, Loss: 5.9890, Accuracy: 0.4916, Learning Rate: 0.000100\n",
      "Epoch 446/10000, Loss: 5.9846, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 447/10000, Loss: 5.9802, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 448/10000, Loss: 5.9758, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 449/10000, Loss: 5.9714, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 450/10000, Loss: 5.9670, Accuracy: 0.4935, Learning Rate: 0.000100\n",
      "Epoch 451/10000, Loss: 5.9626, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 452/10000, Loss: 5.9582, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 453/10000, Loss: 5.9538, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 454/10000, Loss: 5.9494, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 455/10000, Loss: 5.9450, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 456/10000, Loss: 5.9406, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 457/10000, Loss: 5.9362, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 458/10000, Loss: 5.9317, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 459/10000, Loss: 5.9273, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 460/10000, Loss: 5.9229, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 461/10000, Loss: 5.9185, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 462/10000, Loss: 5.9141, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 463/10000, Loss: 5.9096, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 464/10000, Loss: 5.9052, Accuracy: 0.4953, Learning Rate: 0.000100\n",
      "Epoch 465/10000, Loss: 5.9008, Accuracy: 0.4972, Learning Rate: 0.000100\n",
      "Epoch 466/10000, Loss: 5.8963, Accuracy: 0.4991, Learning Rate: 0.000100\n",
      "Epoch 467/10000, Loss: 5.8919, Accuracy: 0.4991, Learning Rate: 0.000100\n",
      "Epoch 468/10000, Loss: 5.8875, Accuracy: 0.4991, Learning Rate: 0.000100\n",
      "Epoch 469/10000, Loss: 5.8830, Accuracy: 0.4991, Learning Rate: 0.000100\n",
      "Epoch 470/10000, Loss: 5.8786, Accuracy: 0.4991, Learning Rate: 0.000100\n",
      "Epoch 471/10000, Loss: 5.8742, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 472/10000, Loss: 5.8697, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 473/10000, Loss: 5.8653, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 474/10000, Loss: 5.8608, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 475/10000, Loss: 5.8564, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 476/10000, Loss: 5.8519, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 477/10000, Loss: 5.8474, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 478/10000, Loss: 5.8430, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 479/10000, Loss: 5.8385, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 480/10000, Loss: 5.8341, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 481/10000, Loss: 5.8296, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 482/10000, Loss: 5.8251, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 483/10000, Loss: 5.8207, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 484/10000, Loss: 5.8162, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 485/10000, Loss: 5.8117, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 486/10000, Loss: 5.8072, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 487/10000, Loss: 5.8028, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 488/10000, Loss: 5.7983, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 489/10000, Loss: 5.7938, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 490/10000, Loss: 5.7893, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 491/10000, Loss: 5.7848, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 492/10000, Loss: 5.7803, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 493/10000, Loss: 5.7758, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 494/10000, Loss: 5.7713, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 495/10000, Loss: 5.7669, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 496/10000, Loss: 5.7624, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 497/10000, Loss: 5.7579, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 498/10000, Loss: 5.7534, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 499/10000, Loss: 5.7489, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 500/10000, Loss: 5.7443, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 501/10000, Loss: 5.7398, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 502/10000, Loss: 5.7353, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 503/10000, Loss: 5.7308, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 504/10000, Loss: 5.7263, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 505/10000, Loss: 5.7218, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 506/10000, Loss: 5.7173, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 507/10000, Loss: 5.7128, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 508/10000, Loss: 5.7082, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 509/10000, Loss: 5.7037, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 510/10000, Loss: 5.6992, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 511/10000, Loss: 5.6947, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 512/10000, Loss: 5.6901, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 513/10000, Loss: 5.6856, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 514/10000, Loss: 5.6811, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 515/10000, Loss: 5.6765, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 516/10000, Loss: 5.6720, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 517/10000, Loss: 5.6675, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 518/10000, Loss: 5.6629, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 519/10000, Loss: 5.6584, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 520/10000, Loss: 5.6538, Accuracy: 0.5009, Learning Rate: 0.000100\n",
      "Epoch 521/10000, Loss: 5.6493, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 522/10000, Loss: 5.6447, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 523/10000, Loss: 5.6402, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 524/10000, Loss: 5.6356, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 525/10000, Loss: 5.6310, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 526/10000, Loss: 5.6265, Accuracy: 0.5028, Learning Rate: 0.000100\n",
      "Epoch 527/10000, Loss: 5.6219, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 528/10000, Loss: 5.6174, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 529/10000, Loss: 5.6128, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 530/10000, Loss: 5.6082, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 531/10000, Loss: 5.6036, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 532/10000, Loss: 5.5991, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 533/10000, Loss: 5.5945, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 534/10000, Loss: 5.5899, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 535/10000, Loss: 5.5853, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 536/10000, Loss: 5.5808, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 537/10000, Loss: 5.5762, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 538/10000, Loss: 5.5716, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 539/10000, Loss: 5.5670, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 540/10000, Loss: 5.5624, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 541/10000, Loss: 5.5578, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 542/10000, Loss: 5.5532, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 543/10000, Loss: 5.5486, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 544/10000, Loss: 5.5440, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 545/10000, Loss: 5.5394, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 546/10000, Loss: 5.5348, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 547/10000, Loss: 5.5302, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 548/10000, Loss: 5.5256, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 549/10000, Loss: 5.5210, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 550/10000, Loss: 5.5164, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 551/10000, Loss: 5.5118, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 552/10000, Loss: 5.5072, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 553/10000, Loss: 5.5026, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 554/10000, Loss: 5.4980, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 555/10000, Loss: 5.4934, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 556/10000, Loss: 5.4888, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 557/10000, Loss: 5.4841, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 558/10000, Loss: 5.4795, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 559/10000, Loss: 5.4749, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 560/10000, Loss: 5.4703, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 561/10000, Loss: 5.4657, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 562/10000, Loss: 5.4611, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 563/10000, Loss: 5.4564, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 564/10000, Loss: 5.4518, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 565/10000, Loss: 5.4472, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 566/10000, Loss: 5.4426, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 567/10000, Loss: 5.4380, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 568/10000, Loss: 5.4333, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 569/10000, Loss: 5.4287, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 570/10000, Loss: 5.4241, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 571/10000, Loss: 5.4195, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 572/10000, Loss: 5.4148, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 573/10000, Loss: 5.4102, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 574/10000, Loss: 5.4056, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 575/10000, Loss: 5.4009, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 576/10000, Loss: 5.3963, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 577/10000, Loss: 5.3917, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 578/10000, Loss: 5.3871, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 579/10000, Loss: 5.3824, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 580/10000, Loss: 5.3778, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 581/10000, Loss: 5.3732, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 582/10000, Loss: 5.3685, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 583/10000, Loss: 5.3639, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 584/10000, Loss: 5.3593, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 585/10000, Loss: 5.3546, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 586/10000, Loss: 5.3500, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 587/10000, Loss: 5.3453, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 588/10000, Loss: 5.3407, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 589/10000, Loss: 5.3361, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 590/10000, Loss: 5.3314, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 591/10000, Loss: 5.3268, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 592/10000, Loss: 5.3221, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 593/10000, Loss: 5.3175, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 594/10000, Loss: 5.3128, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 595/10000, Loss: 5.3082, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 596/10000, Loss: 5.3035, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 597/10000, Loss: 5.2989, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 598/10000, Loss: 5.2942, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 599/10000, Loss: 5.2896, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 600/10000, Loss: 5.2849, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 601/10000, Loss: 5.2803, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 602/10000, Loss: 5.2756, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 603/10000, Loss: 5.2710, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 604/10000, Loss: 5.2663, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 605/10000, Loss: 5.2616, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 606/10000, Loss: 5.2570, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 607/10000, Loss: 5.2523, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 608/10000, Loss: 5.2476, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 609/10000, Loss: 5.2430, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 610/10000, Loss: 5.2383, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 611/10000, Loss: 5.2336, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 612/10000, Loss: 5.2289, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 613/10000, Loss: 5.2243, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 614/10000, Loss: 5.2196, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 615/10000, Loss: 5.2149, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 616/10000, Loss: 5.2102, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 617/10000, Loss: 5.2055, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 618/10000, Loss: 5.2008, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 619/10000, Loss: 5.1961, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 620/10000, Loss: 5.1914, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 621/10000, Loss: 5.1867, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 622/10000, Loss: 5.1820, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 623/10000, Loss: 5.1773, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 624/10000, Loss: 5.1726, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 625/10000, Loss: 5.1679, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 626/10000, Loss: 5.1632, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 627/10000, Loss: 5.1585, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 628/10000, Loss: 5.1538, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 629/10000, Loss: 5.1491, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 630/10000, Loss: 5.1443, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 631/10000, Loss: 5.1396, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 632/10000, Loss: 5.1349, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 633/10000, Loss: 5.1302, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 634/10000, Loss: 5.1254, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 635/10000, Loss: 5.1207, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 636/10000, Loss: 5.1160, Accuracy: 0.5047, Learning Rate: 0.000100\n",
      "Epoch 637/10000, Loss: 5.1112, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 638/10000, Loss: 5.1065, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 639/10000, Loss: 5.1017, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 640/10000, Loss: 5.0970, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 641/10000, Loss: 5.0922, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 642/10000, Loss: 5.0875, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 643/10000, Loss: 5.0827, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 644/10000, Loss: 5.0780, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 645/10000, Loss: 5.0732, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 646/10000, Loss: 5.0684, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 647/10000, Loss: 5.0637, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 648/10000, Loss: 5.0589, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 649/10000, Loss: 5.0541, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 650/10000, Loss: 5.0494, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 651/10000, Loss: 5.0446, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 652/10000, Loss: 5.0398, Accuracy: 0.5065, Learning Rate: 0.000100\n",
      "Epoch 653/10000, Loss: 5.0350, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 654/10000, Loss: 5.0303, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 655/10000, Loss: 5.0255, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 656/10000, Loss: 5.0207, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 657/10000, Loss: 5.0159, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 658/10000, Loss: 5.0111, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 659/10000, Loss: 5.0063, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 660/10000, Loss: 5.0015, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 661/10000, Loss: 4.9967, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 662/10000, Loss: 4.9919, Accuracy: 0.5084, Learning Rate: 0.000100\n",
      "Epoch 663/10000, Loss: 4.9871, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 664/10000, Loss: 4.9823, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 665/10000, Loss: 4.9775, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 666/10000, Loss: 4.9727, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 667/10000, Loss: 4.9679, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 668/10000, Loss: 4.9630, Accuracy: 0.5102, Learning Rate: 0.000100\n",
      "Epoch 669/10000, Loss: 4.9582, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 670/10000, Loss: 4.9534, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 671/10000, Loss: 4.9486, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 672/10000, Loss: 4.9437, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 673/10000, Loss: 4.9389, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 674/10000, Loss: 4.9341, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 675/10000, Loss: 4.9292, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 676/10000, Loss: 4.9244, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 677/10000, Loss: 4.9196, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 678/10000, Loss: 4.9147, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 679/10000, Loss: 4.9099, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 680/10000, Loss: 4.9050, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 681/10000, Loss: 4.9002, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 682/10000, Loss: 4.8953, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 683/10000, Loss: 4.8904, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 684/10000, Loss: 4.8856, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 685/10000, Loss: 4.8807, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 686/10000, Loss: 4.8758, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 687/10000, Loss: 4.8710, Accuracy: 0.5121, Learning Rate: 0.000100\n",
      "Epoch 688/10000, Loss: 4.8661, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 689/10000, Loss: 4.8612, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 690/10000, Loss: 4.8563, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 691/10000, Loss: 4.8514, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 692/10000, Loss: 4.8466, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 693/10000, Loss: 4.8417, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 694/10000, Loss: 4.8368, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 695/10000, Loss: 4.8319, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 696/10000, Loss: 4.8270, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 697/10000, Loss: 4.8221, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 698/10000, Loss: 4.8172, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 699/10000, Loss: 4.8123, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 700/10000, Loss: 4.8074, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 701/10000, Loss: 4.8024, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 702/10000, Loss: 4.7975, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 703/10000, Loss: 4.7926, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 704/10000, Loss: 4.7877, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 705/10000, Loss: 4.7828, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 706/10000, Loss: 4.7778, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 707/10000, Loss: 4.7729, Accuracy: 0.5140, Learning Rate: 0.000100\n",
      "Epoch 708/10000, Loss: 4.7680, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 709/10000, Loss: 4.7631, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 710/10000, Loss: 4.7581, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 711/10000, Loss: 4.7532, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 712/10000, Loss: 4.7482, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 713/10000, Loss: 4.7433, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 714/10000, Loss: 4.7384, Accuracy: 0.5158, Learning Rate: 0.000100\n",
      "Epoch 715/10000, Loss: 4.7334, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 716/10000, Loss: 4.7285, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 717/10000, Loss: 4.7235, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 718/10000, Loss: 4.7186, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 719/10000, Loss: 4.7136, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 720/10000, Loss: 4.7086, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 721/10000, Loss: 4.7037, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 722/10000, Loss: 4.6987, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 723/10000, Loss: 4.6938, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 724/10000, Loss: 4.6888, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 725/10000, Loss: 4.6838, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 726/10000, Loss: 4.6789, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 727/10000, Loss: 4.6739, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 728/10000, Loss: 4.6689, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 729/10000, Loss: 4.6640, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 730/10000, Loss: 4.6590, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 731/10000, Loss: 4.6540, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 732/10000, Loss: 4.6490, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 733/10000, Loss: 4.6441, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 734/10000, Loss: 4.6391, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 735/10000, Loss: 4.6341, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 736/10000, Loss: 4.6291, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 737/10000, Loss: 4.6241, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 738/10000, Loss: 4.6192, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 739/10000, Loss: 4.6142, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 740/10000, Loss: 4.6092, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 741/10000, Loss: 4.6042, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 742/10000, Loss: 4.5992, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 743/10000, Loss: 4.5943, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 744/10000, Loss: 4.5893, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 745/10000, Loss: 4.5843, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 746/10000, Loss: 4.5793, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 747/10000, Loss: 4.5743, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 748/10000, Loss: 4.5693, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 749/10000, Loss: 4.5644, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 750/10000, Loss: 4.5594, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 751/10000, Loss: 4.5544, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 752/10000, Loss: 4.5494, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 753/10000, Loss: 4.5444, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 754/10000, Loss: 4.5395, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 755/10000, Loss: 4.5345, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 756/10000, Loss: 4.5295, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 757/10000, Loss: 4.5245, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 758/10000, Loss: 4.5196, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 759/10000, Loss: 4.5146, Accuracy: 0.5177, Learning Rate: 0.000100\n",
      "Epoch 760/10000, Loss: 4.5096, Accuracy: 0.5196, Learning Rate: 0.000100\n",
      "Epoch 761/10000, Loss: 4.5047, Accuracy: 0.5196, Learning Rate: 0.000100\n",
      "Epoch 762/10000, Loss: 4.4997, Accuracy: 0.5196, Learning Rate: 0.000100\n",
      "Epoch 763/10000, Loss: 4.4947, Accuracy: 0.5196, Learning Rate: 0.000100\n",
      "Epoch 764/10000, Loss: 4.4898, Accuracy: 0.5196, Learning Rate: 0.000100\n",
      "Epoch 765/10000, Loss: 4.4848, Accuracy: 0.5196, Learning Rate: 0.000100\n",
      "Epoch 766/10000, Loss: 4.4799, Accuracy: 0.5196, Learning Rate: 0.000100\n",
      "Epoch 767/10000, Loss: 4.4749, Accuracy: 0.5196, Learning Rate: 0.000100\n",
      "Epoch 768/10000, Loss: 4.4699, Accuracy: 0.5196, Learning Rate: 0.000100\n",
      "Epoch 769/10000, Loss: 4.4650, Accuracy: 0.5214, Learning Rate: 0.000100\n",
      "Epoch 770/10000, Loss: 4.4600, Accuracy: 0.5233, Learning Rate: 0.000100\n",
      "Epoch 771/10000, Loss: 4.4551, Accuracy: 0.5233, Learning Rate: 0.000100\n",
      "Epoch 772/10000, Loss: 4.4502, Accuracy: 0.5233, Learning Rate: 0.000100\n",
      "Epoch 773/10000, Loss: 4.4452, Accuracy: 0.5233, Learning Rate: 0.000100\n",
      "Epoch 774/10000, Loss: 4.4403, Accuracy: 0.5233, Learning Rate: 0.000100\n",
      "Epoch 775/10000, Loss: 4.4354, Accuracy: 0.5233, Learning Rate: 0.000100\n",
      "Epoch 776/10000, Loss: 4.4304, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 777/10000, Loss: 4.4255, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 778/10000, Loss: 4.4206, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 779/10000, Loss: 4.4157, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 780/10000, Loss: 4.4107, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 781/10000, Loss: 4.4058, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 782/10000, Loss: 4.4009, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 783/10000, Loss: 4.3960, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 784/10000, Loss: 4.3911, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 785/10000, Loss: 4.3862, Accuracy: 0.5251, Learning Rate: 0.000100\n",
      "Epoch 786/10000, Loss: 4.3814, Accuracy: 0.5270, Learning Rate: 0.000100\n",
      "Epoch 787/10000, Loss: 4.3765, Accuracy: 0.5270, Learning Rate: 0.000100\n",
      "Epoch 788/10000, Loss: 4.3716, Accuracy: 0.5270, Learning Rate: 0.000100\n",
      "Epoch 789/10000, Loss: 4.3667, Accuracy: 0.5270, Learning Rate: 0.000100\n",
      "Epoch 790/10000, Loss: 4.3618, Accuracy: 0.5270, Learning Rate: 0.000100\n",
      "Epoch 791/10000, Loss: 4.3570, Accuracy: 0.5270, Learning Rate: 0.000100\n",
      "Epoch 792/10000, Loss: 4.3521, Accuracy: 0.5270, Learning Rate: 0.000100\n",
      "Epoch 793/10000, Loss: 4.3473, Accuracy: 0.5289, Learning Rate: 0.000100\n",
      "Epoch 794/10000, Loss: 4.3424, Accuracy: 0.5289, Learning Rate: 0.000100\n",
      "Epoch 795/10000, Loss: 4.3376, Accuracy: 0.5289, Learning Rate: 0.000100\n",
      "Epoch 796/10000, Loss: 4.3327, Accuracy: 0.5289, Learning Rate: 0.000100\n",
      "Epoch 797/10000, Loss: 4.3279, Accuracy: 0.5289, Learning Rate: 0.000100\n",
      "Epoch 798/10000, Loss: 4.3231, Accuracy: 0.5289, Learning Rate: 0.000100\n",
      "Epoch 799/10000, Loss: 4.3183, Accuracy: 0.5289, Learning Rate: 0.000100\n",
      "Epoch 800/10000, Loss: 4.3134, Accuracy: 0.5307, Learning Rate: 0.000100\n",
      "Epoch 801/10000, Loss: 4.3086, Accuracy: 0.5307, Learning Rate: 0.000100\n",
      "Epoch 802/10000, Loss: 4.3038, Accuracy: 0.5307, Learning Rate: 0.000100\n",
      "Epoch 803/10000, Loss: 4.2990, Accuracy: 0.5307, Learning Rate: 0.000100\n",
      "Epoch 804/10000, Loss: 4.2942, Accuracy: 0.5307, Learning Rate: 0.000100\n",
      "Epoch 805/10000, Loss: 4.2895, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 806/10000, Loss: 4.2847, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 807/10000, Loss: 4.2799, Accuracy: 0.5345, Learning Rate: 0.000100\n",
      "Epoch 808/10000, Loss: 4.2751, Accuracy: 0.5345, Learning Rate: 0.000100\n",
      "Epoch 809/10000, Loss: 4.2704, Accuracy: 0.5363, Learning Rate: 0.000100\n",
      "Epoch 810/10000, Loss: 4.2656, Accuracy: 0.5363, Learning Rate: 0.000100\n",
      "Epoch 811/10000, Loss: 4.2609, Accuracy: 0.5363, Learning Rate: 0.000100\n",
      "Epoch 812/10000, Loss: 4.2562, Accuracy: 0.5363, Learning Rate: 0.000100\n",
      "Epoch 813/10000, Loss: 4.2514, Accuracy: 0.5363, Learning Rate: 0.000100\n",
      "Epoch 814/10000, Loss: 4.2467, Accuracy: 0.5345, Learning Rate: 0.000100\n",
      "Epoch 815/10000, Loss: 4.2420, Accuracy: 0.5345, Learning Rate: 0.000100\n",
      "Epoch 816/10000, Loss: 4.2373, Accuracy: 0.5363, Learning Rate: 0.000100\n",
      "Epoch 817/10000, Loss: 4.2326, Accuracy: 0.5363, Learning Rate: 0.000100\n",
      "Epoch 818/10000, Loss: 4.2279, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 819/10000, Loss: 4.2232, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 820/10000, Loss: 4.2185, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 821/10000, Loss: 4.2138, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 822/10000, Loss: 4.2092, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 823/10000, Loss: 4.2045, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 824/10000, Loss: 4.1999, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 825/10000, Loss: 4.1952, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 826/10000, Loss: 4.1906, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 827/10000, Loss: 4.1860, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 828/10000, Loss: 4.1814, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 829/10000, Loss: 4.1768, Accuracy: 0.5326, Learning Rate: 0.000100\n",
      "Epoch 830/10000, Loss: 4.1722, Accuracy: 0.5345, Learning Rate: 0.000100\n",
      "Epoch 831/10000, Loss: 4.1676, Accuracy: 0.5363, Learning Rate: 0.000100\n",
      "Epoch 832/10000, Loss: 4.1630, Accuracy: 0.5363, Learning Rate: 0.000100\n",
      "Epoch 833/10000, Loss: 4.1584, Accuracy: 0.5382, Learning Rate: 0.000100\n",
      "Epoch 834/10000, Loss: 4.1538, Accuracy: 0.5382, Learning Rate: 0.000100\n",
      "Epoch 835/10000, Loss: 4.1493, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 836/10000, Loss: 4.1447, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 837/10000, Loss: 4.1402, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 838/10000, Loss: 4.1356, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 839/10000, Loss: 4.1311, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 840/10000, Loss: 4.1266, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 841/10000, Loss: 4.1221, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 842/10000, Loss: 4.1176, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 843/10000, Loss: 4.1131, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 844/10000, Loss: 4.1086, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 845/10000, Loss: 4.1042, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 846/10000, Loss: 4.0997, Accuracy: 0.5400, Learning Rate: 0.000100\n",
      "Epoch 847/10000, Loss: 4.0952, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 848/10000, Loss: 4.0908, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 849/10000, Loss: 4.0863, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 850/10000, Loss: 4.0819, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 851/10000, Loss: 4.0775, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 852/10000, Loss: 4.0731, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 853/10000, Loss: 4.0687, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 854/10000, Loss: 4.0643, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 855/10000, Loss: 4.0599, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 856/10000, Loss: 4.0555, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 857/10000, Loss: 4.0511, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 858/10000, Loss: 4.0468, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 859/10000, Loss: 4.0424, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 860/10000, Loss: 4.0381, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 861/10000, Loss: 4.0337, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 862/10000, Loss: 4.0294, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 863/10000, Loss: 4.0251, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 864/10000, Loss: 4.0208, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 865/10000, Loss: 4.0164, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 866/10000, Loss: 4.0121, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 867/10000, Loss: 4.0079, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 868/10000, Loss: 4.0036, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 869/10000, Loss: 3.9993, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 870/10000, Loss: 3.9950, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 871/10000, Loss: 3.9908, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 872/10000, Loss: 3.9865, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 873/10000, Loss: 3.9823, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 874/10000, Loss: 3.9780, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 875/10000, Loss: 3.9738, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 876/10000, Loss: 3.9696, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 877/10000, Loss: 3.9654, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 878/10000, Loss: 3.9612, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 879/10000, Loss: 3.9569, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 880/10000, Loss: 3.9528, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 881/10000, Loss: 3.9486, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 882/10000, Loss: 3.9444, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 883/10000, Loss: 3.9402, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 884/10000, Loss: 3.9360, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 885/10000, Loss: 3.9319, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 886/10000, Loss: 3.9277, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 887/10000, Loss: 3.9236, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 888/10000, Loss: 3.9194, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 889/10000, Loss: 3.9153, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 890/10000, Loss: 3.9112, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 891/10000, Loss: 3.9071, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 892/10000, Loss: 3.9029, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 893/10000, Loss: 3.8988, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 894/10000, Loss: 3.8947, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 895/10000, Loss: 3.8906, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 896/10000, Loss: 3.8866, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 897/10000, Loss: 3.8825, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 898/10000, Loss: 3.8784, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 899/10000, Loss: 3.8743, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 900/10000, Loss: 3.8703, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 901/10000, Loss: 3.8662, Accuracy: 0.5419, Learning Rate: 0.000100\n",
      "Epoch 902/10000, Loss: 3.8621, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 903/10000, Loss: 3.8581, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 904/10000, Loss: 3.8540, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 905/10000, Loss: 3.8500, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 906/10000, Loss: 3.8460, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 907/10000, Loss: 3.8420, Accuracy: 0.5438, Learning Rate: 0.000100\n",
      "Epoch 908/10000, Loss: 3.8379, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 909/10000, Loss: 3.8339, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 910/10000, Loss: 3.8299, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 911/10000, Loss: 3.8259, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 912/10000, Loss: 3.8219, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 913/10000, Loss: 3.8179, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 914/10000, Loss: 3.8139, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 915/10000, Loss: 3.8099, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 916/10000, Loss: 3.8060, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 917/10000, Loss: 3.8020, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 918/10000, Loss: 3.7980, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 919/10000, Loss: 3.7941, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 920/10000, Loss: 3.7901, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 921/10000, Loss: 3.7862, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 922/10000, Loss: 3.7822, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 923/10000, Loss: 3.7783, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 924/10000, Loss: 3.7743, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 925/10000, Loss: 3.7704, Accuracy: 0.5456, Learning Rate: 0.000100\n",
      "Epoch 926/10000, Loss: 3.7665, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 927/10000, Loss: 3.7626, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 928/10000, Loss: 3.7586, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 929/10000, Loss: 3.7547, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 930/10000, Loss: 3.7508, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 931/10000, Loss: 3.7469, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 932/10000, Loss: 3.7430, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 933/10000, Loss: 3.7391, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 934/10000, Loss: 3.7353, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 935/10000, Loss: 3.7314, Accuracy: 0.5475, Learning Rate: 0.000100\n",
      "Epoch 936/10000, Loss: 3.7275, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 937/10000, Loss: 3.7236, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 938/10000, Loss: 3.7198, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 939/10000, Loss: 3.7159, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 940/10000, Loss: 3.7121, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 941/10000, Loss: 3.7082, Accuracy: 0.5512, Learning Rate: 0.000100\n",
      "Epoch 942/10000, Loss: 3.7044, Accuracy: 0.5531, Learning Rate: 0.000100\n",
      "Epoch 943/10000, Loss: 3.7005, Accuracy: 0.5531, Learning Rate: 0.000100\n",
      "Epoch 944/10000, Loss: 3.6967, Accuracy: 0.5531, Learning Rate: 0.000100\n",
      "Epoch 945/10000, Loss: 3.6929, Accuracy: 0.5531, Learning Rate: 0.000100\n",
      "Epoch 946/10000, Loss: 3.6890, Accuracy: 0.5531, Learning Rate: 0.000100\n",
      "Epoch 947/10000, Loss: 3.6852, Accuracy: 0.5531, Learning Rate: 0.000100\n",
      "Epoch 948/10000, Loss: 3.6814, Accuracy: 0.5531, Learning Rate: 0.000100\n",
      "Epoch 949/10000, Loss: 3.6776, Accuracy: 0.5531, Learning Rate: 0.000100\n",
      "Epoch 950/10000, Loss: 3.6738, Accuracy: 0.5531, Learning Rate: 0.000100\n",
      "Epoch 951/10000, Loss: 3.6700, Accuracy: 0.5531, Learning Rate: 0.000100\n",
      "Epoch 952/10000, Loss: 3.6662, Accuracy: 0.5531, Learning Rate: 0.000100\n",
      "Epoch 953/10000, Loss: 3.6624, Accuracy: 0.5531, Learning Rate: 0.000100\n",
      "Epoch 954/10000, Loss: 3.6587, Accuracy: 0.5549, Learning Rate: 0.000100\n",
      "Epoch 955/10000, Loss: 3.6549, Accuracy: 0.5549, Learning Rate: 0.000100\n",
      "Epoch 956/10000, Loss: 3.6511, Accuracy: 0.5549, Learning Rate: 0.000100\n",
      "Epoch 957/10000, Loss: 3.6473, Accuracy: 0.5549, Learning Rate: 0.000100\n",
      "Epoch 958/10000, Loss: 3.6436, Accuracy: 0.5549, Learning Rate: 0.000100\n",
      "Epoch 959/10000, Loss: 3.6398, Accuracy: 0.5549, Learning Rate: 0.000100\n",
      "Epoch 960/10000, Loss: 3.6361, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 961/10000, Loss: 3.6323, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 962/10000, Loss: 3.6286, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 963/10000, Loss: 3.6249, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 964/10000, Loss: 3.6211, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 965/10000, Loss: 3.6174, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 966/10000, Loss: 3.6137, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 967/10000, Loss: 3.6100, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 968/10000, Loss: 3.6063, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 969/10000, Loss: 3.6026, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 970/10000, Loss: 3.5989, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 971/10000, Loss: 3.5952, Accuracy: 0.5568, Learning Rate: 0.000100\n",
      "Epoch 972/10000, Loss: 3.5915, Accuracy: 0.5587, Learning Rate: 0.000100\n",
      "Epoch 973/10000, Loss: 3.5878, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 974/10000, Loss: 3.5842, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 975/10000, Loss: 3.5805, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 976/10000, Loss: 3.5768, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 977/10000, Loss: 3.5732, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 978/10000, Loss: 3.5695, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 979/10000, Loss: 3.5659, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 980/10000, Loss: 3.5622, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 981/10000, Loss: 3.5586, Accuracy: 0.5605, Learning Rate: 0.000100\n",
      "Epoch 982/10000, Loss: 3.5550, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 983/10000, Loss: 3.5514, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 984/10000, Loss: 3.5477, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 985/10000, Loss: 3.5441, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 986/10000, Loss: 3.5405, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 987/10000, Loss: 3.5369, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 988/10000, Loss: 3.5333, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 989/10000, Loss: 3.5297, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 990/10000, Loss: 3.5262, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 991/10000, Loss: 3.5226, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 992/10000, Loss: 3.5190, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 993/10000, Loss: 3.5155, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 994/10000, Loss: 3.5119, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 995/10000, Loss: 3.5084, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 996/10000, Loss: 3.5048, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 997/10000, Loss: 3.5013, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 998/10000, Loss: 3.4977, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 999/10000, Loss: 3.4942, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 1000/10000, Loss: 3.4907, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 1001/10000, Loss: 3.4872, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 1002/10000, Loss: 3.4837, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 1003/10000, Loss: 3.4802, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 1004/10000, Loss: 3.4767, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 1005/10000, Loss: 3.4732, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 1006/10000, Loss: 3.4697, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 1007/10000, Loss: 3.4662, Accuracy: 0.5624, Learning Rate: 0.000100\n",
      "Epoch 1008/10000, Loss: 3.4628, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 1009/10000, Loss: 3.4593, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 1010/10000, Loss: 3.4558, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 1011/10000, Loss: 3.4524, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 1012/10000, Loss: 3.4489, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 1013/10000, Loss: 3.4455, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 1014/10000, Loss: 3.4421, Accuracy: 0.5642, Learning Rate: 0.000100\n",
      "Epoch 1015/10000, Loss: 3.4386, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1016/10000, Loss: 3.4352, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1017/10000, Loss: 3.4318, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1018/10000, Loss: 3.4284, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1019/10000, Loss: 3.4250, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1020/10000, Loss: 3.4216, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1021/10000, Loss: 3.4182, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1022/10000, Loss: 3.4148, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1023/10000, Loss: 3.4115, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1024/10000, Loss: 3.4081, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1025/10000, Loss: 3.4047, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1026/10000, Loss: 3.4014, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1027/10000, Loss: 3.3980, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1028/10000, Loss: 3.3947, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1029/10000, Loss: 3.3913, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1030/10000, Loss: 3.3880, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1031/10000, Loss: 3.3847, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1032/10000, Loss: 3.3814, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1033/10000, Loss: 3.3780, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1034/10000, Loss: 3.3747, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1035/10000, Loss: 3.3714, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1036/10000, Loss: 3.3681, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1037/10000, Loss: 3.3648, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1038/10000, Loss: 3.3616, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1039/10000, Loss: 3.3583, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1040/10000, Loss: 3.3550, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1041/10000, Loss: 3.3518, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1042/10000, Loss: 3.3485, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1043/10000, Loss: 3.3452, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1044/10000, Loss: 3.3420, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1045/10000, Loss: 3.3388, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1046/10000, Loss: 3.3355, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1047/10000, Loss: 3.3323, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1048/10000, Loss: 3.3291, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1049/10000, Loss: 3.3259, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1050/10000, Loss: 3.3227, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1051/10000, Loss: 3.3195, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1052/10000, Loss: 3.3163, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1053/10000, Loss: 3.3131, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1054/10000, Loss: 3.3099, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1055/10000, Loss: 3.3067, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1056/10000, Loss: 3.3035, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1057/10000, Loss: 3.3004, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1058/10000, Loss: 3.2972, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1059/10000, Loss: 3.2940, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1060/10000, Loss: 3.2909, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1061/10000, Loss: 3.2877, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1062/10000, Loss: 3.2846, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1063/10000, Loss: 3.2815, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1064/10000, Loss: 3.2784, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1065/10000, Loss: 3.2752, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1066/10000, Loss: 3.2721, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1067/10000, Loss: 3.2690, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1068/10000, Loss: 3.2659, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1069/10000, Loss: 3.2628, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1070/10000, Loss: 3.2597, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1071/10000, Loss: 3.2566, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1072/10000, Loss: 3.2535, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1073/10000, Loss: 3.2505, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1074/10000, Loss: 3.2474, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1075/10000, Loss: 3.2443, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1076/10000, Loss: 3.2413, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1077/10000, Loss: 3.2382, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1078/10000, Loss: 3.2352, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1079/10000, Loss: 3.2321, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1080/10000, Loss: 3.2291, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1081/10000, Loss: 3.2261, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1082/10000, Loss: 3.2230, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1083/10000, Loss: 3.2200, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1084/10000, Loss: 3.2170, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1085/10000, Loss: 3.2140, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1086/10000, Loss: 3.2110, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1087/10000, Loss: 3.2080, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1088/10000, Loss: 3.2050, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1089/10000, Loss: 3.2020, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1090/10000, Loss: 3.1990, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1091/10000, Loss: 3.1960, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1092/10000, Loss: 3.1931, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1093/10000, Loss: 3.1901, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1094/10000, Loss: 3.1871, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1095/10000, Loss: 3.1842, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1096/10000, Loss: 3.1812, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1097/10000, Loss: 3.1783, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1098/10000, Loss: 3.1753, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1099/10000, Loss: 3.1724, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1100/10000, Loss: 3.1695, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1101/10000, Loss: 3.1665, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1102/10000, Loss: 3.1636, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1103/10000, Loss: 3.1607, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1104/10000, Loss: 3.1578, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1105/10000, Loss: 3.1549, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1106/10000, Loss: 3.1520, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1107/10000, Loss: 3.1491, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1108/10000, Loss: 3.1462, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1109/10000, Loss: 3.1433, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1110/10000, Loss: 3.1404, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1111/10000, Loss: 3.1375, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1112/10000, Loss: 3.1347, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1113/10000, Loss: 3.1318, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1114/10000, Loss: 3.1289, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1115/10000, Loss: 3.1261, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1116/10000, Loss: 3.1232, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1117/10000, Loss: 3.1204, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1118/10000, Loss: 3.1175, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1119/10000, Loss: 3.1147, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1120/10000, Loss: 3.1119, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1121/10000, Loss: 3.1090, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1122/10000, Loss: 3.1062, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1123/10000, Loss: 3.1034, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1124/10000, Loss: 3.1006, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1125/10000, Loss: 3.0978, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1126/10000, Loss: 3.0949, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1127/10000, Loss: 3.0921, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1128/10000, Loss: 3.0893, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1129/10000, Loss: 3.0866, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1130/10000, Loss: 3.0838, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1131/10000, Loss: 3.0810, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1132/10000, Loss: 3.0782, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1133/10000, Loss: 3.0754, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1134/10000, Loss: 3.0727, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1135/10000, Loss: 3.0699, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1136/10000, Loss: 3.0671, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1137/10000, Loss: 3.0644, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1138/10000, Loss: 3.0616, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1139/10000, Loss: 3.0589, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1140/10000, Loss: 3.0561, Accuracy: 0.5661, Learning Rate: 0.000100\n",
      "Epoch 1141/10000, Loss: 3.0534, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1142/10000, Loss: 3.0507, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1143/10000, Loss: 3.0479, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1144/10000, Loss: 3.0452, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1145/10000, Loss: 3.0425, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1146/10000, Loss: 3.0398, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1147/10000, Loss: 3.0371, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1148/10000, Loss: 3.0343, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1149/10000, Loss: 3.0316, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1150/10000, Loss: 3.0289, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1151/10000, Loss: 3.0263, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1152/10000, Loss: 3.0236, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1153/10000, Loss: 3.0209, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1154/10000, Loss: 3.0182, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1155/10000, Loss: 3.0155, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1156/10000, Loss: 3.0128, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1157/10000, Loss: 3.0102, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1158/10000, Loss: 3.0075, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1159/10000, Loss: 3.0048, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1160/10000, Loss: 3.0022, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1161/10000, Loss: 2.9995, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1162/10000, Loss: 2.9969, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1163/10000, Loss: 2.9943, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1164/10000, Loss: 2.9916, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1165/10000, Loss: 2.9890, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1166/10000, Loss: 2.9863, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1167/10000, Loss: 2.9837, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1168/10000, Loss: 2.9811, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1169/10000, Loss: 2.9785, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1170/10000, Loss: 2.9759, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1171/10000, Loss: 2.9733, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1172/10000, Loss: 2.9706, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1173/10000, Loss: 2.9680, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1174/10000, Loss: 2.9655, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1175/10000, Loss: 2.9629, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1176/10000, Loss: 2.9603, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1177/10000, Loss: 2.9577, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1178/10000, Loss: 2.9551, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1179/10000, Loss: 2.9525, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1180/10000, Loss: 2.9500, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1181/10000, Loss: 2.9474, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1182/10000, Loss: 2.9448, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1183/10000, Loss: 2.9423, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1184/10000, Loss: 2.9397, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1185/10000, Loss: 2.9372, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1186/10000, Loss: 2.9346, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1187/10000, Loss: 2.9321, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1188/10000, Loss: 2.9295, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1189/10000, Loss: 2.9270, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1190/10000, Loss: 2.9244, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1191/10000, Loss: 2.9219, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1192/10000, Loss: 2.9194, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1193/10000, Loss: 2.9169, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1194/10000, Loss: 2.9144, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1195/10000, Loss: 2.9118, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1196/10000, Loss: 2.9093, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1197/10000, Loss: 2.9068, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1198/10000, Loss: 2.9043, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1199/10000, Loss: 2.9018, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1200/10000, Loss: 2.8993, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1201/10000, Loss: 2.8969, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1202/10000, Loss: 2.8944, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1203/10000, Loss: 2.8919, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1204/10000, Loss: 2.8894, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1205/10000, Loss: 2.8869, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1206/10000, Loss: 2.8845, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1207/10000, Loss: 2.8820, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1208/10000, Loss: 2.8796, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1209/10000, Loss: 2.8771, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1210/10000, Loss: 2.8746, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1211/10000, Loss: 2.8722, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1212/10000, Loss: 2.8697, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1213/10000, Loss: 2.8673, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1214/10000, Loss: 2.8649, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1215/10000, Loss: 2.8624, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1216/10000, Loss: 2.8600, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1217/10000, Loss: 2.8576, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1218/10000, Loss: 2.8552, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1219/10000, Loss: 2.8527, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1220/10000, Loss: 2.8503, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1221/10000, Loss: 2.8479, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1222/10000, Loss: 2.8455, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1223/10000, Loss: 2.8431, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1224/10000, Loss: 2.8407, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1225/10000, Loss: 2.8383, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1226/10000, Loss: 2.8359, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1227/10000, Loss: 2.8335, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1228/10000, Loss: 2.8311, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1229/10000, Loss: 2.8288, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1230/10000, Loss: 2.8264, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1231/10000, Loss: 2.8240, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1232/10000, Loss: 2.8217, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1233/10000, Loss: 2.8193, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1234/10000, Loss: 2.8169, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1235/10000, Loss: 2.8146, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1236/10000, Loss: 2.8122, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1237/10000, Loss: 2.8099, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1238/10000, Loss: 2.8075, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1239/10000, Loss: 2.8052, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1240/10000, Loss: 2.8028, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1241/10000, Loss: 2.8005, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1242/10000, Loss: 2.7982, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1243/10000, Loss: 2.7958, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1244/10000, Loss: 2.7935, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1245/10000, Loss: 2.7912, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1246/10000, Loss: 2.7889, Accuracy: 0.5680, Learning Rate: 0.000100\n",
      "Epoch 1247/10000, Loss: 2.7866, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1248/10000, Loss: 2.7843, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1249/10000, Loss: 2.7820, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1250/10000, Loss: 2.7796, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1251/10000, Loss: 2.7774, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1252/10000, Loss: 2.7751, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1253/10000, Loss: 2.7728, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1254/10000, Loss: 2.7705, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1255/10000, Loss: 2.7682, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1256/10000, Loss: 2.7659, Accuracy: 0.5698, Learning Rate: 0.000100\n",
      "Epoch 1257/10000, Loss: 2.7636, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1258/10000, Loss: 2.7614, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1259/10000, Loss: 2.7591, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1260/10000, Loss: 2.7568, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1261/10000, Loss: 2.7546, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1262/10000, Loss: 2.7523, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1263/10000, Loss: 2.7500, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1264/10000, Loss: 2.7478, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1265/10000, Loss: 2.7455, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1266/10000, Loss: 2.7433, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1267/10000, Loss: 2.7411, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1268/10000, Loss: 2.7388, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1269/10000, Loss: 2.7366, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1270/10000, Loss: 2.7344, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1271/10000, Loss: 2.7321, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1272/10000, Loss: 2.7299, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1273/10000, Loss: 2.7277, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1274/10000, Loss: 2.7255, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1275/10000, Loss: 2.7232, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1276/10000, Loss: 2.7210, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1277/10000, Loss: 2.7188, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1278/10000, Loss: 2.7166, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1279/10000, Loss: 2.7144, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1280/10000, Loss: 2.7122, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1281/10000, Loss: 2.7100, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1282/10000, Loss: 2.7078, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1283/10000, Loss: 2.7057, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1284/10000, Loss: 2.7035, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1285/10000, Loss: 2.7013, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1286/10000, Loss: 2.6991, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1287/10000, Loss: 2.6969, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1288/10000, Loss: 2.6948, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1289/10000, Loss: 2.6926, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1290/10000, Loss: 2.6904, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1291/10000, Loss: 2.6883, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1292/10000, Loss: 2.6861, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1293/10000, Loss: 2.6840, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1294/10000, Loss: 2.6818, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1295/10000, Loss: 2.6797, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1296/10000, Loss: 2.6775, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1297/10000, Loss: 2.6754, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1298/10000, Loss: 2.6732, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1299/10000, Loss: 2.6711, Accuracy: 0.5717, Learning Rate: 0.000100\n",
      "Epoch 1300/10000, Loss: 2.6690, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1301/10000, Loss: 2.6668, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1302/10000, Loss: 2.6647, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1303/10000, Loss: 2.6626, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1304/10000, Loss: 2.6605, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1305/10000, Loss: 2.6584, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1306/10000, Loss: 2.6562, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1307/10000, Loss: 2.6541, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1308/10000, Loss: 2.6520, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1309/10000, Loss: 2.6499, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1310/10000, Loss: 2.6478, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1311/10000, Loss: 2.6457, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1312/10000, Loss: 2.6436, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1313/10000, Loss: 2.6415, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1314/10000, Loss: 2.6395, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1315/10000, Loss: 2.6374, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1316/10000, Loss: 2.6353, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1317/10000, Loss: 2.6332, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1318/10000, Loss: 2.6311, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1319/10000, Loss: 2.6291, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1320/10000, Loss: 2.6270, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1321/10000, Loss: 2.6249, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1322/10000, Loss: 2.6229, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1323/10000, Loss: 2.6208, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1324/10000, Loss: 2.6187, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1325/10000, Loss: 2.6167, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1326/10000, Loss: 2.6146, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1327/10000, Loss: 2.6126, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1328/10000, Loss: 2.6105, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1329/10000, Loss: 2.6085, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1330/10000, Loss: 2.6065, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1331/10000, Loss: 2.6044, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1332/10000, Loss: 2.6024, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1333/10000, Loss: 2.6004, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1334/10000, Loss: 2.5983, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1335/10000, Loss: 2.5963, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1336/10000, Loss: 2.5943, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1337/10000, Loss: 2.5923, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1338/10000, Loss: 2.5902, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1339/10000, Loss: 2.5882, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1340/10000, Loss: 2.5862, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1341/10000, Loss: 2.5842, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1342/10000, Loss: 2.5822, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1343/10000, Loss: 2.5802, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1344/10000, Loss: 2.5782, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1345/10000, Loss: 2.5762, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1346/10000, Loss: 2.5742, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1347/10000, Loss: 2.5722, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1348/10000, Loss: 2.5702, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1349/10000, Loss: 2.5682, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1350/10000, Loss: 2.5663, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1351/10000, Loss: 2.5643, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1352/10000, Loss: 2.5623, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1353/10000, Loss: 2.5603, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1354/10000, Loss: 2.5584, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1355/10000, Loss: 2.5564, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1356/10000, Loss: 2.5544, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1357/10000, Loss: 2.5525, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1358/10000, Loss: 2.5505, Accuracy: 0.5736, Learning Rate: 0.000100\n",
      "Epoch 1359/10000, Loss: 2.5485, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1360/10000, Loss: 2.5466, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1361/10000, Loss: 2.5446, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1362/10000, Loss: 2.5427, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1363/10000, Loss: 2.5407, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1364/10000, Loss: 2.5388, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1365/10000, Loss: 2.5368, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1366/10000, Loss: 2.5349, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1367/10000, Loss: 2.5330, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1368/10000, Loss: 2.5310, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1369/10000, Loss: 2.5291, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1370/10000, Loss: 2.5272, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1371/10000, Loss: 2.5253, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1372/10000, Loss: 2.5233, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1373/10000, Loss: 2.5214, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1374/10000, Loss: 2.5195, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1375/10000, Loss: 2.5176, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1376/10000, Loss: 2.5157, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1377/10000, Loss: 2.5138, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1378/10000, Loss: 2.5119, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1379/10000, Loss: 2.5099, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1380/10000, Loss: 2.5080, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1381/10000, Loss: 2.5061, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1382/10000, Loss: 2.5042, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1383/10000, Loss: 2.5024, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1384/10000, Loss: 2.5005, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1385/10000, Loss: 2.4986, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1386/10000, Loss: 2.4967, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1387/10000, Loss: 2.4948, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1388/10000, Loss: 2.4929, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1389/10000, Loss: 2.4910, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1390/10000, Loss: 2.4892, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1391/10000, Loss: 2.4873, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1392/10000, Loss: 2.4854, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1393/10000, Loss: 2.4836, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1394/10000, Loss: 2.4817, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1395/10000, Loss: 2.4798, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1396/10000, Loss: 2.4780, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1397/10000, Loss: 2.4761, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1398/10000, Loss: 2.4743, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1399/10000, Loss: 2.4724, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1400/10000, Loss: 2.4706, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1401/10000, Loss: 2.4687, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1402/10000, Loss: 2.4669, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1403/10000, Loss: 2.4650, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1404/10000, Loss: 2.4632, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1405/10000, Loss: 2.4614, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1406/10000, Loss: 2.4595, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1407/10000, Loss: 2.4577, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1408/10000, Loss: 2.4559, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1409/10000, Loss: 2.4540, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1410/10000, Loss: 2.4522, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1411/10000, Loss: 2.4504, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1412/10000, Loss: 2.4486, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1413/10000, Loss: 2.4467, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1414/10000, Loss: 2.4449, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1415/10000, Loss: 2.4431, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1416/10000, Loss: 2.4413, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1417/10000, Loss: 2.4395, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1418/10000, Loss: 2.4377, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1419/10000, Loss: 2.4359, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1420/10000, Loss: 2.4341, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1421/10000, Loss: 2.4323, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1422/10000, Loss: 2.4305, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1423/10000, Loss: 2.4287, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1424/10000, Loss: 2.4269, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1425/10000, Loss: 2.4251, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1426/10000, Loss: 2.4234, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1427/10000, Loss: 2.4216, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1428/10000, Loss: 2.4198, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1429/10000, Loss: 2.4180, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1430/10000, Loss: 2.4162, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1431/10000, Loss: 2.4145, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1432/10000, Loss: 2.4127, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1433/10000, Loss: 2.4109, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1434/10000, Loss: 2.4092, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1435/10000, Loss: 2.4074, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1436/10000, Loss: 2.4057, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1437/10000, Loss: 2.4039, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1438/10000, Loss: 2.4021, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1439/10000, Loss: 2.4004, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1440/10000, Loss: 2.3986, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1441/10000, Loss: 2.3969, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1442/10000, Loss: 2.3951, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1443/10000, Loss: 2.3934, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1444/10000, Loss: 2.3917, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1445/10000, Loss: 2.3899, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1446/10000, Loss: 2.3882, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1447/10000, Loss: 2.3865, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1448/10000, Loss: 2.3847, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1449/10000, Loss: 2.3830, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1450/10000, Loss: 2.3813, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1451/10000, Loss: 2.3796, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1452/10000, Loss: 2.3778, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1453/10000, Loss: 2.3761, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1454/10000, Loss: 2.3744, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1455/10000, Loss: 2.3727, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1456/10000, Loss: 2.3710, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1457/10000, Loss: 2.3693, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1458/10000, Loss: 2.3676, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1459/10000, Loss: 2.3659, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1460/10000, Loss: 2.3642, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1461/10000, Loss: 2.3625, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1462/10000, Loss: 2.3608, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1463/10000, Loss: 2.3591, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1464/10000, Loss: 2.3574, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1465/10000, Loss: 2.3557, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1466/10000, Loss: 2.3540, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1467/10000, Loss: 2.3523, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1468/10000, Loss: 2.3506, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1469/10000, Loss: 2.3490, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1470/10000, Loss: 2.3473, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1471/10000, Loss: 2.3456, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1472/10000, Loss: 2.3439, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1473/10000, Loss: 2.3423, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1474/10000, Loss: 2.3406, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1475/10000, Loss: 2.3389, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1476/10000, Loss: 2.3373, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1477/10000, Loss: 2.3356, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1478/10000, Loss: 2.3339, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1479/10000, Loss: 2.3323, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1480/10000, Loss: 2.3306, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1481/10000, Loss: 2.3290, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1482/10000, Loss: 2.3273, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1483/10000, Loss: 2.3257, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1484/10000, Loss: 2.3240, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1485/10000, Loss: 2.3224, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1486/10000, Loss: 2.3208, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1487/10000, Loss: 2.3191, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1488/10000, Loss: 2.3175, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1489/10000, Loss: 2.3159, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1490/10000, Loss: 2.3142, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1491/10000, Loss: 2.3126, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1492/10000, Loss: 2.3110, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1493/10000, Loss: 2.3094, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1494/10000, Loss: 2.3077, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1495/10000, Loss: 2.3061, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1496/10000, Loss: 2.3045, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1497/10000, Loss: 2.3029, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1498/10000, Loss: 2.3013, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1499/10000, Loss: 2.2997, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1500/10000, Loss: 2.2981, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1501/10000, Loss: 2.2965, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1502/10000, Loss: 2.2949, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1503/10000, Loss: 2.2933, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1504/10000, Loss: 2.2917, Accuracy: 0.5754, Learning Rate: 0.000100\n",
      "Epoch 1505/10000, Loss: 2.2901, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1506/10000, Loss: 2.2885, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1507/10000, Loss: 2.2869, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1508/10000, Loss: 2.2853, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1509/10000, Loss: 2.2837, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1510/10000, Loss: 2.2821, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1511/10000, Loss: 2.2805, Accuracy: 0.5773, Learning Rate: 0.000100\n",
      "Epoch 1512/10000, Loss: 2.2790, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1513/10000, Loss: 2.2774, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1514/10000, Loss: 2.2758, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1515/10000, Loss: 2.2742, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1516/10000, Loss: 2.2727, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1517/10000, Loss: 2.2711, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1518/10000, Loss: 2.2695, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1519/10000, Loss: 2.2680, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1520/10000, Loss: 2.2664, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1521/10000, Loss: 2.2649, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1522/10000, Loss: 2.2633, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1523/10000, Loss: 2.2618, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1524/10000, Loss: 2.2602, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1525/10000, Loss: 2.2587, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1526/10000, Loss: 2.2571, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1527/10000, Loss: 2.2556, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1528/10000, Loss: 2.2540, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1529/10000, Loss: 2.2525, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1530/10000, Loss: 2.2509, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1531/10000, Loss: 2.2494, Accuracy: 0.5791, Learning Rate: 0.000100\n",
      "Epoch 1532/10000, Loss: 2.2479, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1533/10000, Loss: 2.2463, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1534/10000, Loss: 2.2448, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1535/10000, Loss: 2.2433, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1536/10000, Loss: 2.2418, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1537/10000, Loss: 2.2402, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1538/10000, Loss: 2.2387, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1539/10000, Loss: 2.2372, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1540/10000, Loss: 2.2357, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1541/10000, Loss: 2.2342, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1542/10000, Loss: 2.2327, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1543/10000, Loss: 2.2312, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1544/10000, Loss: 2.2297, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1545/10000, Loss: 2.2282, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1546/10000, Loss: 2.2267, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1547/10000, Loss: 2.2252, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1548/10000, Loss: 2.2237, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1549/10000, Loss: 2.2222, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1550/10000, Loss: 2.2207, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1551/10000, Loss: 2.2192, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1552/10000, Loss: 2.2177, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1553/10000, Loss: 2.2162, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1554/10000, Loss: 2.2147, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1555/10000, Loss: 2.2133, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1556/10000, Loss: 2.2118, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1557/10000, Loss: 2.2103, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1558/10000, Loss: 2.2088, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1559/10000, Loss: 2.2074, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1560/10000, Loss: 2.2059, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1561/10000, Loss: 2.2044, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1562/10000, Loss: 2.2030, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1563/10000, Loss: 2.2015, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1564/10000, Loss: 2.2000, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1565/10000, Loss: 2.1986, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1566/10000, Loss: 2.1971, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1567/10000, Loss: 2.1957, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1568/10000, Loss: 2.1942, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1569/10000, Loss: 2.1928, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1570/10000, Loss: 2.1913, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1571/10000, Loss: 2.1899, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1572/10000, Loss: 2.1884, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1573/10000, Loss: 2.1870, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1574/10000, Loss: 2.1856, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1575/10000, Loss: 2.1841, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1576/10000, Loss: 2.1827, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1577/10000, Loss: 2.1813, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1578/10000, Loss: 2.1798, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1579/10000, Loss: 2.1784, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1580/10000, Loss: 2.1770, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1581/10000, Loss: 2.1756, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1582/10000, Loss: 2.1741, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1583/10000, Loss: 2.1727, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1584/10000, Loss: 2.1713, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1585/10000, Loss: 2.1699, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1586/10000, Loss: 2.1685, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1587/10000, Loss: 2.1671, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1588/10000, Loss: 2.1657, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1589/10000, Loss: 2.1643, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1590/10000, Loss: 2.1629, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1591/10000, Loss: 2.1615, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1592/10000, Loss: 2.1601, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1593/10000, Loss: 2.1587, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1594/10000, Loss: 2.1573, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1595/10000, Loss: 2.1559, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1596/10000, Loss: 2.1545, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1597/10000, Loss: 2.1531, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1598/10000, Loss: 2.1517, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1599/10000, Loss: 2.1503, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1600/10000, Loss: 2.1490, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1601/10000, Loss: 2.1476, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1602/10000, Loss: 2.1462, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1603/10000, Loss: 2.1448, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1604/10000, Loss: 2.1435, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1605/10000, Loss: 2.1421, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1606/10000, Loss: 2.1407, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1607/10000, Loss: 2.1393, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1608/10000, Loss: 2.1380, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1609/10000, Loss: 2.1366, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1610/10000, Loss: 2.1353, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1611/10000, Loss: 2.1339, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1612/10000, Loss: 2.1326, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1613/10000, Loss: 2.1312, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1614/10000, Loss: 2.1299, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1615/10000, Loss: 2.1285, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1616/10000, Loss: 2.1272, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1617/10000, Loss: 2.1258, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1618/10000, Loss: 2.1245, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1619/10000, Loss: 2.1231, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1620/10000, Loss: 2.1218, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1621/10000, Loss: 2.1205, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1622/10000, Loss: 2.1191, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1623/10000, Loss: 2.1178, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1624/10000, Loss: 2.1165, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1625/10000, Loss: 2.1151, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1626/10000, Loss: 2.1138, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1627/10000, Loss: 2.1125, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1628/10000, Loss: 2.1112, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1629/10000, Loss: 2.1099, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1630/10000, Loss: 2.1085, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1631/10000, Loss: 2.1072, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1632/10000, Loss: 2.1059, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1633/10000, Loss: 2.1046, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1634/10000, Loss: 2.1033, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1635/10000, Loss: 2.1020, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1636/10000, Loss: 2.1007, Accuracy: 0.5810, Learning Rate: 0.000100\n",
      "Epoch 1637/10000, Loss: 2.0994, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1638/10000, Loss: 2.0981, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1639/10000, Loss: 2.0968, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1640/10000, Loss: 2.0955, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1641/10000, Loss: 2.0942, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1642/10000, Loss: 2.0929, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1643/10000, Loss: 2.0916, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1644/10000, Loss: 2.0903, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1645/10000, Loss: 2.0890, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1646/10000, Loss: 2.0878, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1647/10000, Loss: 2.0865, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1648/10000, Loss: 2.0852, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1649/10000, Loss: 2.0839, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1650/10000, Loss: 2.0826, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1651/10000, Loss: 2.0814, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1652/10000, Loss: 2.0801, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1653/10000, Loss: 2.0788, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1654/10000, Loss: 2.0776, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1655/10000, Loss: 2.0763, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1656/10000, Loss: 2.0750, Accuracy: 0.5829, Learning Rate: 0.000100\n",
      "Epoch 1657/10000, Loss: 2.0738, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1658/10000, Loss: 2.0725, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1659/10000, Loss: 2.0713, Accuracy: 0.5847, Learning Rate: 0.000100\n",
      "Epoch 1660/10000, Loss: 2.0700, Accuracy: 0.5866, Learning Rate: 0.000100\n",
      "Epoch 1661/10000, Loss: 2.0687, Accuracy: 0.5866, Learning Rate: 0.000100\n",
      "Epoch 1662/10000, Loss: 2.0675, Accuracy: 0.5866, Learning Rate: 0.000100\n",
      "Epoch 1663/10000, Loss: 2.0662, Accuracy: 0.5866, Learning Rate: 0.000100\n",
      "Epoch 1664/10000, Loss: 2.0650, Accuracy: 0.5866, Learning Rate: 0.000100\n",
      "Epoch 1665/10000, Loss: 2.0637, Accuracy: 0.5866, Learning Rate: 0.000100\n",
      "Epoch 1666/10000, Loss: 2.0625, Accuracy: 0.5866, Learning Rate: 0.000100\n",
      "Epoch 1667/10000, Loss: 2.0613, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1668/10000, Loss: 2.0600, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1669/10000, Loss: 2.0588, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1670/10000, Loss: 2.0576, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1671/10000, Loss: 2.0563, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1672/10000, Loss: 2.0551, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1673/10000, Loss: 2.0539, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1674/10000, Loss: 2.0526, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1675/10000, Loss: 2.0514, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1676/10000, Loss: 2.0502, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1677/10000, Loss: 2.0490, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1678/10000, Loss: 2.0477, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1679/10000, Loss: 2.0465, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1680/10000, Loss: 2.0453, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1681/10000, Loss: 2.0441, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1682/10000, Loss: 2.0429, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1683/10000, Loss: 2.0417, Accuracy: 0.5885, Learning Rate: 0.000100\n",
      "Epoch 1684/10000, Loss: 2.0405, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1685/10000, Loss: 2.0392, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1686/10000, Loss: 2.0380, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1687/10000, Loss: 2.0368, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1688/10000, Loss: 2.0356, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1689/10000, Loss: 2.0344, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1690/10000, Loss: 2.0332, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1691/10000, Loss: 2.0320, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1692/10000, Loss: 2.0308, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1693/10000, Loss: 2.0297, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1694/10000, Loss: 2.0285, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1695/10000, Loss: 2.0273, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1696/10000, Loss: 2.0261, Accuracy: 0.5903, Learning Rate: 0.000100\n",
      "Epoch 1697/10000, Loss: 2.0249, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1698/10000, Loss: 2.0237, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1699/10000, Loss: 2.0225, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1700/10000, Loss: 2.0214, Accuracy: 0.5922, Learning Rate: 0.000100\n",
      "Epoch 1701/10000, Loss: 2.0202, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1702/10000, Loss: 2.0190, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1703/10000, Loss: 2.0178, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1704/10000, Loss: 2.0167, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1705/10000, Loss: 2.0155, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1706/10000, Loss: 2.0143, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1707/10000, Loss: 2.0132, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1708/10000, Loss: 2.0120, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1709/10000, Loss: 2.0108, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1710/10000, Loss: 2.0097, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1711/10000, Loss: 2.0085, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1712/10000, Loss: 2.0073, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1713/10000, Loss: 2.0062, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1714/10000, Loss: 2.0050, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1715/10000, Loss: 2.0039, Accuracy: 0.5940, Learning Rate: 0.000100\n",
      "Epoch 1716/10000, Loss: 2.0027, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1717/10000, Loss: 2.0016, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1718/10000, Loss: 2.0004, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1719/10000, Loss: 1.9993, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1720/10000, Loss: 1.9981, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1721/10000, Loss: 1.9970, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1722/10000, Loss: 1.9959, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1723/10000, Loss: 1.9947, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1724/10000, Loss: 1.9936, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1725/10000, Loss: 1.9924, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1726/10000, Loss: 1.9913, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1727/10000, Loss: 1.9902, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1728/10000, Loss: 1.9891, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1729/10000, Loss: 1.9879, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1730/10000, Loss: 1.9868, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1731/10000, Loss: 1.9857, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1732/10000, Loss: 1.9845, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1733/10000, Loss: 1.9834, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1734/10000, Loss: 1.9823, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1735/10000, Loss: 1.9812, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1736/10000, Loss: 1.9801, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1737/10000, Loss: 1.9789, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1738/10000, Loss: 1.9778, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1739/10000, Loss: 1.9767, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1740/10000, Loss: 1.9756, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1741/10000, Loss: 1.9745, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1742/10000, Loss: 1.9734, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1743/10000, Loss: 1.9723, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1744/10000, Loss: 1.9712, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1745/10000, Loss: 1.9701, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1746/10000, Loss: 1.9690, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1747/10000, Loss: 1.9679, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1748/10000, Loss: 1.9668, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1749/10000, Loss: 1.9657, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1750/10000, Loss: 1.9646, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1751/10000, Loss: 1.9635, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1752/10000, Loss: 1.9624, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1753/10000, Loss: 1.9613, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1754/10000, Loss: 1.9602, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1755/10000, Loss: 1.9591, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1756/10000, Loss: 1.9580, Accuracy: 0.5959, Learning Rate: 0.000100\n",
      "Epoch 1757/10000, Loss: 1.9570, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1758/10000, Loss: 1.9559, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1759/10000, Loss: 1.9548, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1760/10000, Loss: 1.9537, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1761/10000, Loss: 1.9526, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1762/10000, Loss: 1.9515, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1763/10000, Loss: 1.9505, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1764/10000, Loss: 1.9494, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1765/10000, Loss: 1.9483, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1766/10000, Loss: 1.9473, Accuracy: 0.5978, Learning Rate: 0.000100\n",
      "Epoch 1767/10000, Loss: 1.9462, Accuracy: 0.5996, Learning Rate: 0.000100\n",
      "Epoch 1768/10000, Loss: 1.9451, Accuracy: 0.5996, Learning Rate: 0.000100\n",
      "Epoch 1769/10000, Loss: 1.9440, Accuracy: 0.5996, Learning Rate: 0.000100\n",
      "Epoch 1770/10000, Loss: 1.9430, Accuracy: 0.5996, Learning Rate: 0.000100\n",
      "Epoch 1771/10000, Loss: 1.9419, Accuracy: 0.5996, Learning Rate: 0.000100\n",
      "Epoch 1772/10000, Loss: 1.9409, Accuracy: 0.6015, Learning Rate: 0.000100\n",
      "Epoch 1773/10000, Loss: 1.9398, Accuracy: 0.6015, Learning Rate: 0.000100\n",
      "Epoch 1774/10000, Loss: 1.9387, Accuracy: 0.6015, Learning Rate: 0.000100\n",
      "Epoch 1775/10000, Loss: 1.9377, Accuracy: 0.6015, Learning Rate: 0.000100\n",
      "Epoch 1776/10000, Loss: 1.9366, Accuracy: 0.6015, Learning Rate: 0.000100\n",
      "Epoch 1777/10000, Loss: 1.9356, Accuracy: 0.6015, Learning Rate: 0.000100\n",
      "Epoch 1778/10000, Loss: 1.9345, Accuracy: 0.6015, Learning Rate: 0.000100\n",
      "Epoch 1779/10000, Loss: 1.9335, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1780/10000, Loss: 1.9324, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1781/10000, Loss: 1.9314, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1782/10000, Loss: 1.9303, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1783/10000, Loss: 1.9293, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1784/10000, Loss: 1.9282, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1785/10000, Loss: 1.9272, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1786/10000, Loss: 1.9261, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1787/10000, Loss: 1.9251, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1788/10000, Loss: 1.9240, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1789/10000, Loss: 1.9230, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1790/10000, Loss: 1.9220, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1791/10000, Loss: 1.9209, Accuracy: 0.6034, Learning Rate: 0.000100\n",
      "Epoch 1792/10000, Loss: 1.9199, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1793/10000, Loss: 1.9189, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1794/10000, Loss: 1.9178, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1795/10000, Loss: 1.9168, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1796/10000, Loss: 1.9158, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1797/10000, Loss: 1.9147, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1798/10000, Loss: 1.9137, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1799/10000, Loss: 1.9127, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1800/10000, Loss: 1.9117, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1801/10000, Loss: 1.9106, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1802/10000, Loss: 1.9096, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1803/10000, Loss: 1.9086, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1804/10000, Loss: 1.9076, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1805/10000, Loss: 1.9066, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1806/10000, Loss: 1.9055, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1807/10000, Loss: 1.9045, Accuracy: 0.6052, Learning Rate: 0.000100\n",
      "Epoch 1808/10000, Loss: 1.9035, Accuracy: 0.6071, Learning Rate: 0.000100\n",
      "Epoch 1809/10000, Loss: 1.9025, Accuracy: 0.6071, Learning Rate: 0.000100\n",
      "Epoch 1810/10000, Loss: 1.9015, Accuracy: 0.6071, Learning Rate: 0.000100\n",
      "Epoch 1811/10000, Loss: 1.9005, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1812/10000, Loss: 1.8995, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1813/10000, Loss: 1.8985, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1814/10000, Loss: 1.8974, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1815/10000, Loss: 1.8964, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1816/10000, Loss: 1.8954, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1817/10000, Loss: 1.8944, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1818/10000, Loss: 1.8934, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1819/10000, Loss: 1.8924, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1820/10000, Loss: 1.8914, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1821/10000, Loss: 1.8904, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1822/10000, Loss: 1.8894, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1823/10000, Loss: 1.8884, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1824/10000, Loss: 1.8874, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1825/10000, Loss: 1.8865, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1826/10000, Loss: 1.8855, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1827/10000, Loss: 1.8845, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1828/10000, Loss: 1.8835, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1829/10000, Loss: 1.8825, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1830/10000, Loss: 1.8815, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1831/10000, Loss: 1.8805, Accuracy: 0.6089, Learning Rate: 0.000100\n",
      "Epoch 1832/10000, Loss: 1.8795, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1833/10000, Loss: 1.8785, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1834/10000, Loss: 1.8776, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1835/10000, Loss: 1.8766, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1836/10000, Loss: 1.8756, Accuracy: 0.6108, Learning Rate: 0.000100\n",
      "Epoch 1837/10000, Loss: 1.8746, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1838/10000, Loss: 1.8736, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1839/10000, Loss: 1.8727, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1840/10000, Loss: 1.8717, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1841/10000, Loss: 1.8707, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1842/10000, Loss: 1.8697, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1843/10000, Loss: 1.8688, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1844/10000, Loss: 1.8678, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1845/10000, Loss: 1.8668, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1846/10000, Loss: 1.8659, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1847/10000, Loss: 1.8649, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1848/10000, Loss: 1.8639, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1849/10000, Loss: 1.8630, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1850/10000, Loss: 1.8620, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1851/10000, Loss: 1.8610, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1852/10000, Loss: 1.8601, Accuracy: 0.6127, Learning Rate: 0.000100\n",
      "Epoch 1853/10000, Loss: 1.8591, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1854/10000, Loss: 1.8581, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1855/10000, Loss: 1.8572, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1856/10000, Loss: 1.8562, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1857/10000, Loss: 1.8553, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1858/10000, Loss: 1.8543, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1859/10000, Loss: 1.8534, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1860/10000, Loss: 1.8524, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1861/10000, Loss: 1.8515, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1862/10000, Loss: 1.8505, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1863/10000, Loss: 1.8495, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1864/10000, Loss: 1.8486, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1865/10000, Loss: 1.8477, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1866/10000, Loss: 1.8467, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1867/10000, Loss: 1.8458, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1868/10000, Loss: 1.8448, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1869/10000, Loss: 1.8439, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1870/10000, Loss: 1.8429, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1871/10000, Loss: 1.8420, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1872/10000, Loss: 1.8410, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1873/10000, Loss: 1.8401, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1874/10000, Loss: 1.8392, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1875/10000, Loss: 1.8382, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1876/10000, Loss: 1.8373, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1877/10000, Loss: 1.8363, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1878/10000, Loss: 1.8354, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1879/10000, Loss: 1.8345, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1880/10000, Loss: 1.8335, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1881/10000, Loss: 1.8326, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1882/10000, Loss: 1.8317, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1883/10000, Loss: 1.8307, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1884/10000, Loss: 1.8298, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1885/10000, Loss: 1.8289, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1886/10000, Loss: 1.8280, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1887/10000, Loss: 1.8270, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1888/10000, Loss: 1.8261, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1889/10000, Loss: 1.8252, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1890/10000, Loss: 1.8243, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1891/10000, Loss: 1.8233, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1892/10000, Loss: 1.8224, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1893/10000, Loss: 1.8215, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1894/10000, Loss: 1.8206, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1895/10000, Loss: 1.8197, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1896/10000, Loss: 1.8187, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1897/10000, Loss: 1.8178, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1898/10000, Loss: 1.8169, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1899/10000, Loss: 1.8160, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1900/10000, Loss: 1.8151, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1901/10000, Loss: 1.8142, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1902/10000, Loss: 1.8133, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1903/10000, Loss: 1.8123, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1904/10000, Loss: 1.8114, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1905/10000, Loss: 1.8105, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1906/10000, Loss: 1.8096, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1907/10000, Loss: 1.8087, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1908/10000, Loss: 1.8078, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1909/10000, Loss: 1.8069, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1910/10000, Loss: 1.8060, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1911/10000, Loss: 1.8051, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1912/10000, Loss: 1.8042, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1913/10000, Loss: 1.8033, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1914/10000, Loss: 1.8024, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1915/10000, Loss: 1.8015, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1916/10000, Loss: 1.8006, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1917/10000, Loss: 1.7997, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1918/10000, Loss: 1.7988, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1919/10000, Loss: 1.7979, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1920/10000, Loss: 1.7970, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1921/10000, Loss: 1.7961, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1922/10000, Loss: 1.7952, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1923/10000, Loss: 1.7943, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1924/10000, Loss: 1.7934, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1925/10000, Loss: 1.7925, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1926/10000, Loss: 1.7916, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1927/10000, Loss: 1.7907, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1928/10000, Loss: 1.7898, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1929/10000, Loss: 1.7890, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1930/10000, Loss: 1.7881, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1931/10000, Loss: 1.7872, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1932/10000, Loss: 1.7863, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1933/10000, Loss: 1.7854, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1934/10000, Loss: 1.7845, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1935/10000, Loss: 1.7836, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1936/10000, Loss: 1.7828, Accuracy: 0.6145, Learning Rate: 0.000100\n",
      "Epoch 1937/10000, Loss: 1.7819, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1938/10000, Loss: 1.7810, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1939/10000, Loss: 1.7801, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1940/10000, Loss: 1.7792, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1941/10000, Loss: 1.7784, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1942/10000, Loss: 1.7775, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1943/10000, Loss: 1.7766, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1944/10000, Loss: 1.7757, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1945/10000, Loss: 1.7749, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1946/10000, Loss: 1.7740, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1947/10000, Loss: 1.7731, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1948/10000, Loss: 1.7722, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1949/10000, Loss: 1.7714, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1950/10000, Loss: 1.7705, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1951/10000, Loss: 1.7696, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1952/10000, Loss: 1.7688, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1953/10000, Loss: 1.7679, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1954/10000, Loss: 1.7670, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1955/10000, Loss: 1.7661, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1956/10000, Loss: 1.7653, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1957/10000, Loss: 1.7644, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1958/10000, Loss: 1.7636, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1959/10000, Loss: 1.7627, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1960/10000, Loss: 1.7618, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1961/10000, Loss: 1.7610, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1962/10000, Loss: 1.7601, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1963/10000, Loss: 1.7592, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1964/10000, Loss: 1.7584, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1965/10000, Loss: 1.7575, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1966/10000, Loss: 1.7567, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1967/10000, Loss: 1.7558, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1968/10000, Loss: 1.7549, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1969/10000, Loss: 1.7541, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1970/10000, Loss: 1.7532, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1971/10000, Loss: 1.7524, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1972/10000, Loss: 1.7515, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1973/10000, Loss: 1.7507, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1974/10000, Loss: 1.7498, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1975/10000, Loss: 1.7490, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1976/10000, Loss: 1.7481, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 1977/10000, Loss: 1.7473, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1978/10000, Loss: 1.7464, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1979/10000, Loss: 1.7456, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1980/10000, Loss: 1.7447, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1981/10000, Loss: 1.7439, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1982/10000, Loss: 1.7430, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1983/10000, Loss: 1.7422, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 1984/10000, Loss: 1.7413, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1985/10000, Loss: 1.7405, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1986/10000, Loss: 1.7397, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1987/10000, Loss: 1.7388, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1988/10000, Loss: 1.7380, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1989/10000, Loss: 1.7371, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1990/10000, Loss: 1.7363, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1991/10000, Loss: 1.7354, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1992/10000, Loss: 1.7346, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1993/10000, Loss: 1.7338, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1994/10000, Loss: 1.7329, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1995/10000, Loss: 1.7321, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1996/10000, Loss: 1.7313, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1997/10000, Loss: 1.7304, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1998/10000, Loss: 1.7296, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 1999/10000, Loss: 1.7288, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2000/10000, Loss: 1.7279, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2001/10000, Loss: 1.7271, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2002/10000, Loss: 1.7263, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2003/10000, Loss: 1.7254, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2004/10000, Loss: 1.7246, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2005/10000, Loss: 1.7238, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2006/10000, Loss: 1.7229, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2007/10000, Loss: 1.7221, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2008/10000, Loss: 1.7213, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2009/10000, Loss: 1.7205, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2010/10000, Loss: 1.7196, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2011/10000, Loss: 1.7188, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2012/10000, Loss: 1.7180, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2013/10000, Loss: 1.7172, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2014/10000, Loss: 1.7163, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2015/10000, Loss: 1.7155, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2016/10000, Loss: 1.7147, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2017/10000, Loss: 1.7139, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2018/10000, Loss: 1.7130, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2019/10000, Loss: 1.7122, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2020/10000, Loss: 1.7114, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2021/10000, Loss: 1.7106, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2022/10000, Loss: 1.7098, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2023/10000, Loss: 1.7090, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2024/10000, Loss: 1.7081, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2025/10000, Loss: 1.7073, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2026/10000, Loss: 1.7065, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2027/10000, Loss: 1.7057, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2028/10000, Loss: 1.7049, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2029/10000, Loss: 1.7041, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2030/10000, Loss: 1.7032, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2031/10000, Loss: 1.7024, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2032/10000, Loss: 1.7016, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2033/10000, Loss: 1.7008, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2034/10000, Loss: 1.7000, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2035/10000, Loss: 1.6992, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2036/10000, Loss: 1.6984, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2037/10000, Loss: 1.6976, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2038/10000, Loss: 1.6968, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2039/10000, Loss: 1.6960, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2040/10000, Loss: 1.6952, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2041/10000, Loss: 1.6944, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2042/10000, Loss: 1.6935, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2043/10000, Loss: 1.6927, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2044/10000, Loss: 1.6919, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2045/10000, Loss: 1.6911, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2046/10000, Loss: 1.6903, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2047/10000, Loss: 1.6895, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2048/10000, Loss: 1.6887, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2049/10000, Loss: 1.6879, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2050/10000, Loss: 1.6871, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2051/10000, Loss: 1.6863, Accuracy: 0.6164, Learning Rate: 0.000100\n",
      "Epoch 2052/10000, Loss: 1.6855, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2053/10000, Loss: 1.6847, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2054/10000, Loss: 1.6839, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2055/10000, Loss: 1.6831, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2056/10000, Loss: 1.6824, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2057/10000, Loss: 1.6816, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2058/10000, Loss: 1.6808, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2059/10000, Loss: 1.6800, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2060/10000, Loss: 1.6792, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2061/10000, Loss: 1.6784, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2062/10000, Loss: 1.6776, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2063/10000, Loss: 1.6768, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2064/10000, Loss: 1.6760, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2065/10000, Loss: 1.6752, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2066/10000, Loss: 1.6744, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2067/10000, Loss: 1.6736, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2068/10000, Loss: 1.6729, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2069/10000, Loss: 1.6721, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2070/10000, Loss: 1.6713, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2071/10000, Loss: 1.6705, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2072/10000, Loss: 1.6697, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2073/10000, Loss: 1.6689, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2074/10000, Loss: 1.6681, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2075/10000, Loss: 1.6674, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2076/10000, Loss: 1.6666, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2077/10000, Loss: 1.6658, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2078/10000, Loss: 1.6650, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2079/10000, Loss: 1.6642, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2080/10000, Loss: 1.6634, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2081/10000, Loss: 1.6627, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2082/10000, Loss: 1.6619, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2083/10000, Loss: 1.6611, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2084/10000, Loss: 1.6603, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2085/10000, Loss: 1.6596, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2086/10000, Loss: 1.6588, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2087/10000, Loss: 1.6580, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2088/10000, Loss: 1.6572, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2089/10000, Loss: 1.6564, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2090/10000, Loss: 1.6557, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2091/10000, Loss: 1.6549, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2092/10000, Loss: 1.6541, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2093/10000, Loss: 1.6534, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2094/10000, Loss: 1.6526, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2095/10000, Loss: 1.6518, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2096/10000, Loss: 1.6510, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2097/10000, Loss: 1.6503, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2098/10000, Loss: 1.6495, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2099/10000, Loss: 1.6487, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2100/10000, Loss: 1.6480, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2101/10000, Loss: 1.6472, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2102/10000, Loss: 1.6464, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2103/10000, Loss: 1.6457, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2104/10000, Loss: 1.6449, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2105/10000, Loss: 1.6441, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2106/10000, Loss: 1.6434, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2107/10000, Loss: 1.6426, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2108/10000, Loss: 1.6418, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2109/10000, Loss: 1.6411, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2110/10000, Loss: 1.6403, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2111/10000, Loss: 1.6395, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2112/10000, Loss: 1.6388, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2113/10000, Loss: 1.6380, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2114/10000, Loss: 1.6373, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2115/10000, Loss: 1.6365, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2116/10000, Loss: 1.6357, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2117/10000, Loss: 1.6350, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2118/10000, Loss: 1.6342, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2119/10000, Loss: 1.6335, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2120/10000, Loss: 1.6327, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2121/10000, Loss: 1.6320, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2122/10000, Loss: 1.6312, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2123/10000, Loss: 1.6305, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2124/10000, Loss: 1.6297, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2125/10000, Loss: 1.6289, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2126/10000, Loss: 1.6282, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2127/10000, Loss: 1.6274, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2128/10000, Loss: 1.6267, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2129/10000, Loss: 1.6259, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2130/10000, Loss: 1.6252, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2131/10000, Loss: 1.6244, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2132/10000, Loss: 1.6237, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2133/10000, Loss: 1.6229, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2134/10000, Loss: 1.6222, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2135/10000, Loss: 1.6214, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2136/10000, Loss: 1.6207, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2137/10000, Loss: 1.6199, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2138/10000, Loss: 1.6192, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2139/10000, Loss: 1.6185, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2140/10000, Loss: 1.6177, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2141/10000, Loss: 1.6170, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2142/10000, Loss: 1.6162, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2143/10000, Loss: 1.6155, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2144/10000, Loss: 1.6147, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2145/10000, Loss: 1.6140, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2146/10000, Loss: 1.6132, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2147/10000, Loss: 1.6125, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2148/10000, Loss: 1.6118, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2149/10000, Loss: 1.6110, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2150/10000, Loss: 1.6103, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2151/10000, Loss: 1.6095, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2152/10000, Loss: 1.6088, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2153/10000, Loss: 1.6081, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2154/10000, Loss: 1.6073, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2155/10000, Loss: 1.6066, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2156/10000, Loss: 1.6059, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2157/10000, Loss: 1.6051, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2158/10000, Loss: 1.6044, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2159/10000, Loss: 1.6037, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2160/10000, Loss: 1.6029, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2161/10000, Loss: 1.6022, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2162/10000, Loss: 1.6015, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2163/10000, Loss: 1.6007, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2164/10000, Loss: 1.6000, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2165/10000, Loss: 1.5993, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2166/10000, Loss: 1.5985, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2167/10000, Loss: 1.5978, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2168/10000, Loss: 1.5971, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2169/10000, Loss: 1.5963, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2170/10000, Loss: 1.5956, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2171/10000, Loss: 1.5949, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2172/10000, Loss: 1.5942, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2173/10000, Loss: 1.5934, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2174/10000, Loss: 1.5927, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2175/10000, Loss: 1.5920, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2176/10000, Loss: 1.5913, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2177/10000, Loss: 1.5905, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2178/10000, Loss: 1.5898, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2179/10000, Loss: 1.5891, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2180/10000, Loss: 1.5884, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2181/10000, Loss: 1.5876, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2182/10000, Loss: 1.5869, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2183/10000, Loss: 1.5862, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2184/10000, Loss: 1.5855, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2185/10000, Loss: 1.5847, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2186/10000, Loss: 1.5840, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2187/10000, Loss: 1.5833, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2188/10000, Loss: 1.5826, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2189/10000, Loss: 1.5819, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2190/10000, Loss: 1.5812, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2191/10000, Loss: 1.5804, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2192/10000, Loss: 1.5797, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2193/10000, Loss: 1.5790, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2194/10000, Loss: 1.5783, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2195/10000, Loss: 1.5776, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2196/10000, Loss: 1.5769, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2197/10000, Loss: 1.5761, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2198/10000, Loss: 1.5754, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2199/10000, Loss: 1.5747, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2200/10000, Loss: 1.5740, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2201/10000, Loss: 1.5733, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2202/10000, Loss: 1.5726, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2203/10000, Loss: 1.5719, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2204/10000, Loss: 1.5712, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2205/10000, Loss: 1.5705, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2206/10000, Loss: 1.5697, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2207/10000, Loss: 1.5690, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2208/10000, Loss: 1.5683, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2209/10000, Loss: 1.5676, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2210/10000, Loss: 1.5669, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2211/10000, Loss: 1.5662, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2212/10000, Loss: 1.5655, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2213/10000, Loss: 1.5648, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2214/10000, Loss: 1.5641, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2215/10000, Loss: 1.5634, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2216/10000, Loss: 1.5627, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2217/10000, Loss: 1.5620, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2218/10000, Loss: 1.5613, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2219/10000, Loss: 1.5606, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2220/10000, Loss: 1.5599, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2221/10000, Loss: 1.5592, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2222/10000, Loss: 1.5585, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2223/10000, Loss: 1.5578, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2224/10000, Loss: 1.5571, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2225/10000, Loss: 1.5564, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2226/10000, Loss: 1.5557, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2227/10000, Loss: 1.5550, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2228/10000, Loss: 1.5543, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2229/10000, Loss: 1.5536, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2230/10000, Loss: 1.5529, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2231/10000, Loss: 1.5522, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2232/10000, Loss: 1.5515, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2233/10000, Loss: 1.5508, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2234/10000, Loss: 1.5501, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2235/10000, Loss: 1.5494, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2236/10000, Loss: 1.5487, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2237/10000, Loss: 1.5480, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2238/10000, Loss: 1.5473, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2239/10000, Loss: 1.5466, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2240/10000, Loss: 1.5459, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2241/10000, Loss: 1.5453, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2242/10000, Loss: 1.5446, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2243/10000, Loss: 1.5439, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2244/10000, Loss: 1.5432, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2245/10000, Loss: 1.5425, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2246/10000, Loss: 1.5418, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2247/10000, Loss: 1.5411, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2248/10000, Loss: 1.5404, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2249/10000, Loss: 1.5397, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2250/10000, Loss: 1.5391, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2251/10000, Loss: 1.5384, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2252/10000, Loss: 1.5377, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2253/10000, Loss: 1.5370, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2254/10000, Loss: 1.5363, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2255/10000, Loss: 1.5356, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2256/10000, Loss: 1.5350, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2257/10000, Loss: 1.5343, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2258/10000, Loss: 1.5336, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2259/10000, Loss: 1.5329, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2260/10000, Loss: 1.5322, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2261/10000, Loss: 1.5315, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2262/10000, Loss: 1.5309, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2263/10000, Loss: 1.5302, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2264/10000, Loss: 1.5295, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2265/10000, Loss: 1.5288, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2266/10000, Loss: 1.5281, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2267/10000, Loss: 1.5275, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2268/10000, Loss: 1.5268, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2269/10000, Loss: 1.5261, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2270/10000, Loss: 1.5254, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2271/10000, Loss: 1.5248, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2272/10000, Loss: 1.5241, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2273/10000, Loss: 1.5234, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2274/10000, Loss: 1.5227, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2275/10000, Loss: 1.5221, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2276/10000, Loss: 1.5214, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2277/10000, Loss: 1.5207, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2278/10000, Loss: 1.5200, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2279/10000, Loss: 1.5194, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2280/10000, Loss: 1.5187, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2281/10000, Loss: 1.5180, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2282/10000, Loss: 1.5174, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2283/10000, Loss: 1.5167, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2284/10000, Loss: 1.5160, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2285/10000, Loss: 1.5153, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2286/10000, Loss: 1.5147, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2287/10000, Loss: 1.5140, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2288/10000, Loss: 1.5133, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2289/10000, Loss: 1.5127, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2290/10000, Loss: 1.5120, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2291/10000, Loss: 1.5113, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2292/10000, Loss: 1.5107, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2293/10000, Loss: 1.5100, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2294/10000, Loss: 1.5093, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2295/10000, Loss: 1.5087, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2296/10000, Loss: 1.5080, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2297/10000, Loss: 1.5074, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2298/10000, Loss: 1.5067, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2299/10000, Loss: 1.5060, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2300/10000, Loss: 1.5054, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2301/10000, Loss: 1.5047, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2302/10000, Loss: 1.5040, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2303/10000, Loss: 1.5034, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2304/10000, Loss: 1.5027, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2305/10000, Loss: 1.5021, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2306/10000, Loss: 1.5014, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2307/10000, Loss: 1.5007, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2308/10000, Loss: 1.5001, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2309/10000, Loss: 1.4994, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2310/10000, Loss: 1.4988, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2311/10000, Loss: 1.4981, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2312/10000, Loss: 1.4975, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2313/10000, Loss: 1.4968, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2314/10000, Loss: 1.4962, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2315/10000, Loss: 1.4955, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2316/10000, Loss: 1.4948, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2317/10000, Loss: 1.4942, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2318/10000, Loss: 1.4935, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2319/10000, Loss: 1.4929, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2320/10000, Loss: 1.4922, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2321/10000, Loss: 1.4916, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2322/10000, Loss: 1.4909, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2323/10000, Loss: 1.4903, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2324/10000, Loss: 1.4896, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2325/10000, Loss: 1.4890, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2326/10000, Loss: 1.4883, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2327/10000, Loss: 1.4877, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2328/10000, Loss: 1.4870, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2329/10000, Loss: 1.4864, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2330/10000, Loss: 1.4857, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2331/10000, Loss: 1.4851, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2332/10000, Loss: 1.4844, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2333/10000, Loss: 1.4838, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2334/10000, Loss: 1.4832, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2335/10000, Loss: 1.4825, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2336/10000, Loss: 1.4819, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2337/10000, Loss: 1.4812, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2338/10000, Loss: 1.4806, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2339/10000, Loss: 1.4799, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2340/10000, Loss: 1.4793, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2341/10000, Loss: 1.4786, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2342/10000, Loss: 1.4780, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2343/10000, Loss: 1.4774, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2344/10000, Loss: 1.4767, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2345/10000, Loss: 1.4761, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2346/10000, Loss: 1.4754, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2347/10000, Loss: 1.4748, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2348/10000, Loss: 1.4742, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2349/10000, Loss: 1.4735, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2350/10000, Loss: 1.4729, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2351/10000, Loss: 1.4722, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2352/10000, Loss: 1.4716, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2353/10000, Loss: 1.4710, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2354/10000, Loss: 1.4703, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2355/10000, Loss: 1.4697, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2356/10000, Loss: 1.4691, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2357/10000, Loss: 1.4684, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2358/10000, Loss: 1.4678, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2359/10000, Loss: 1.4672, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2360/10000, Loss: 1.4665, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2361/10000, Loss: 1.4659, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2362/10000, Loss: 1.4653, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2363/10000, Loss: 1.4646, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2364/10000, Loss: 1.4640, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2365/10000, Loss: 1.4634, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2366/10000, Loss: 1.4627, Accuracy: 0.6182, Learning Rate: 0.000100\n",
      "Epoch 2367/10000, Loss: 1.4621, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2368/10000, Loss: 1.4615, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2369/10000, Loss: 1.4608, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2370/10000, Loss: 1.4602, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2371/10000, Loss: 1.4596, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2372/10000, Loss: 1.4590, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2373/10000, Loss: 1.4583, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2374/10000, Loss: 1.4577, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2375/10000, Loss: 1.4571, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2376/10000, Loss: 1.4565, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2377/10000, Loss: 1.4558, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2378/10000, Loss: 1.4552, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2379/10000, Loss: 1.4546, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2380/10000, Loss: 1.4540, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2381/10000, Loss: 1.4533, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2382/10000, Loss: 1.4527, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2383/10000, Loss: 1.4521, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2384/10000, Loss: 1.4515, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2385/10000, Loss: 1.4508, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2386/10000, Loss: 1.4502, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2387/10000, Loss: 1.4496, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2388/10000, Loss: 1.4490, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2389/10000, Loss: 1.4484, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2390/10000, Loss: 1.4477, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2391/10000, Loss: 1.4471, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2392/10000, Loss: 1.4465, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2393/10000, Loss: 1.4459, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2394/10000, Loss: 1.4453, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2395/10000, Loss: 1.4446, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2396/10000, Loss: 1.4440, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2397/10000, Loss: 1.4434, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2398/10000, Loss: 1.4428, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2399/10000, Loss: 1.4422, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2400/10000, Loss: 1.4416, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2401/10000, Loss: 1.4409, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2402/10000, Loss: 1.4403, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2403/10000, Loss: 1.4397, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2404/10000, Loss: 1.4391, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2405/10000, Loss: 1.4385, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2406/10000, Loss: 1.4379, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2407/10000, Loss: 1.4373, Accuracy: 0.6201, Learning Rate: 0.000100\n",
      "Epoch 2408/10000, Loss: 1.4367, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2409/10000, Loss: 1.4360, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2410/10000, Loss: 1.4354, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2411/10000, Loss: 1.4348, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2412/10000, Loss: 1.4342, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2413/10000, Loss: 1.4336, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2414/10000, Loss: 1.4330, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2415/10000, Loss: 1.4324, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2416/10000, Loss: 1.4318, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2417/10000, Loss: 1.4312, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2418/10000, Loss: 1.4306, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2419/10000, Loss: 1.4300, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2420/10000, Loss: 1.4294, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2421/10000, Loss: 1.4287, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2422/10000, Loss: 1.4281, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2423/10000, Loss: 1.4275, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2424/10000, Loss: 1.4269, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2425/10000, Loss: 1.4263, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2426/10000, Loss: 1.4257, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2427/10000, Loss: 1.4251, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2428/10000, Loss: 1.4245, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2429/10000, Loss: 1.4239, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2430/10000, Loss: 1.4233, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2431/10000, Loss: 1.4227, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2432/10000, Loss: 1.4221, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2433/10000, Loss: 1.4215, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2434/10000, Loss: 1.4209, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2435/10000, Loss: 1.4203, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2436/10000, Loss: 1.4197, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2437/10000, Loss: 1.4191, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2438/10000, Loss: 1.4185, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2439/10000, Loss: 1.4179, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2440/10000, Loss: 1.4173, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2441/10000, Loss: 1.4167, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2442/10000, Loss: 1.4161, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2443/10000, Loss: 1.4155, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2444/10000, Loss: 1.4149, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2445/10000, Loss: 1.4143, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2446/10000, Loss: 1.4137, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2447/10000, Loss: 1.4131, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2448/10000, Loss: 1.4126, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2449/10000, Loss: 1.4120, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2450/10000, Loss: 1.4114, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2451/10000, Loss: 1.4108, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2452/10000, Loss: 1.4102, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2453/10000, Loss: 1.4096, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2454/10000, Loss: 1.4090, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2455/10000, Loss: 1.4084, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2456/10000, Loss: 1.4078, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2457/10000, Loss: 1.4072, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2458/10000, Loss: 1.4066, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2459/10000, Loss: 1.4060, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2460/10000, Loss: 1.4055, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2461/10000, Loss: 1.4049, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2462/10000, Loss: 1.4043, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2463/10000, Loss: 1.4037, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2464/10000, Loss: 1.4031, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2465/10000, Loss: 1.4025, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2466/10000, Loss: 1.4019, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2467/10000, Loss: 1.4013, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2468/10000, Loss: 1.4008, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2469/10000, Loss: 1.4002, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2470/10000, Loss: 1.3996, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2471/10000, Loss: 1.3990, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2472/10000, Loss: 1.3984, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2473/10000, Loss: 1.3978, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2474/10000, Loss: 1.3973, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2475/10000, Loss: 1.3967, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2476/10000, Loss: 1.3961, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2477/10000, Loss: 1.3955, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2478/10000, Loss: 1.3949, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2479/10000, Loss: 1.3944, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2480/10000, Loss: 1.3938, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2481/10000, Loss: 1.3932, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2482/10000, Loss: 1.3926, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2483/10000, Loss: 1.3920, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2484/10000, Loss: 1.3915, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2485/10000, Loss: 1.3909, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2486/10000, Loss: 1.3903, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2487/10000, Loss: 1.3897, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2488/10000, Loss: 1.3891, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2489/10000, Loss: 1.3886, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2490/10000, Loss: 1.3880, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2491/10000, Loss: 1.3874, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2492/10000, Loss: 1.3868, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2493/10000, Loss: 1.3863, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2494/10000, Loss: 1.3857, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2495/10000, Loss: 1.3851, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2496/10000, Loss: 1.3845, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2497/10000, Loss: 1.3840, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2498/10000, Loss: 1.3834, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2499/10000, Loss: 1.3828, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2500/10000, Loss: 1.3823, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2501/10000, Loss: 1.3817, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2502/10000, Loss: 1.3811, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2503/10000, Loss: 1.3805, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2504/10000, Loss: 1.3800, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2505/10000, Loss: 1.3794, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2506/10000, Loss: 1.3788, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2507/10000, Loss: 1.3783, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2508/10000, Loss: 1.3777, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2509/10000, Loss: 1.3771, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2510/10000, Loss: 1.3766, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2511/10000, Loss: 1.3760, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2512/10000, Loss: 1.3754, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2513/10000, Loss: 1.3749, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2514/10000, Loss: 1.3743, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2515/10000, Loss: 1.3737, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2516/10000, Loss: 1.3732, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2517/10000, Loss: 1.3726, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2518/10000, Loss: 1.3720, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2519/10000, Loss: 1.3715, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2520/10000, Loss: 1.3709, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2521/10000, Loss: 1.3703, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2522/10000, Loss: 1.3698, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2523/10000, Loss: 1.3692, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2524/10000, Loss: 1.3687, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2525/10000, Loss: 1.3681, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2526/10000, Loss: 1.3675, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2527/10000, Loss: 1.3670, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2528/10000, Loss: 1.3664, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2529/10000, Loss: 1.3659, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2530/10000, Loss: 1.3653, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2531/10000, Loss: 1.3647, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2532/10000, Loss: 1.3642, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2533/10000, Loss: 1.3636, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2534/10000, Loss: 1.3631, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2535/10000, Loss: 1.3625, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2536/10000, Loss: 1.3620, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2537/10000, Loss: 1.3614, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2538/10000, Loss: 1.3608, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2539/10000, Loss: 1.3603, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2540/10000, Loss: 1.3597, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2541/10000, Loss: 1.3592, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2542/10000, Loss: 1.3586, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2543/10000, Loss: 1.3581, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2544/10000, Loss: 1.3575, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2545/10000, Loss: 1.3570, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2546/10000, Loss: 1.3564, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2547/10000, Loss: 1.3559, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2548/10000, Loss: 1.3553, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2549/10000, Loss: 1.3548, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2550/10000, Loss: 1.3542, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2551/10000, Loss: 1.3537, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2552/10000, Loss: 1.3531, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2553/10000, Loss: 1.3526, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2554/10000, Loss: 1.3520, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2555/10000, Loss: 1.3515, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2556/10000, Loss: 1.3509, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2557/10000, Loss: 1.3504, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2558/10000, Loss: 1.3498, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2559/10000, Loss: 1.3493, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2560/10000, Loss: 1.3487, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2561/10000, Loss: 1.3482, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2562/10000, Loss: 1.3476, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2563/10000, Loss: 1.3471, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2564/10000, Loss: 1.3465, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2565/10000, Loss: 1.3460, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2566/10000, Loss: 1.3455, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2567/10000, Loss: 1.3449, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2568/10000, Loss: 1.3444, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2569/10000, Loss: 1.3438, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2570/10000, Loss: 1.3433, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2571/10000, Loss: 1.3427, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2572/10000, Loss: 1.3422, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2573/10000, Loss: 1.3417, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2574/10000, Loss: 1.3411, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2575/10000, Loss: 1.3406, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2576/10000, Loss: 1.3400, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2577/10000, Loss: 1.3395, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2578/10000, Loss: 1.3390, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2579/10000, Loss: 1.3384, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2580/10000, Loss: 1.3379, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2581/10000, Loss: 1.3374, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2582/10000, Loss: 1.3368, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2583/10000, Loss: 1.3363, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2584/10000, Loss: 1.3357, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2585/10000, Loss: 1.3352, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2586/10000, Loss: 1.3347, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2587/10000, Loss: 1.3341, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2588/10000, Loss: 1.3336, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2589/10000, Loss: 1.3331, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2590/10000, Loss: 1.3325, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2591/10000, Loss: 1.3320, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2592/10000, Loss: 1.3315, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2593/10000, Loss: 1.3309, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2594/10000, Loss: 1.3304, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2595/10000, Loss: 1.3299, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2596/10000, Loss: 1.3293, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2597/10000, Loss: 1.3288, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2598/10000, Loss: 1.3283, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2599/10000, Loss: 1.3277, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2600/10000, Loss: 1.3272, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2601/10000, Loss: 1.3267, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2602/10000, Loss: 1.3262, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2603/10000, Loss: 1.3256, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2604/10000, Loss: 1.3251, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2605/10000, Loss: 1.3246, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2606/10000, Loss: 1.3240, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2607/10000, Loss: 1.3235, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2608/10000, Loss: 1.3230, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2609/10000, Loss: 1.3225, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2610/10000, Loss: 1.3219, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2611/10000, Loss: 1.3214, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2612/10000, Loss: 1.3209, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2613/10000, Loss: 1.3204, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2614/10000, Loss: 1.3198, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2615/10000, Loss: 1.3193, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2616/10000, Loss: 1.3188, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2617/10000, Loss: 1.3183, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2618/10000, Loss: 1.3177, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2619/10000, Loss: 1.3172, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2620/10000, Loss: 1.3167, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2621/10000, Loss: 1.3162, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2622/10000, Loss: 1.3157, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2623/10000, Loss: 1.3151, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2624/10000, Loss: 1.3146, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2625/10000, Loss: 1.3141, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2626/10000, Loss: 1.3136, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2627/10000, Loss: 1.3131, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2628/10000, Loss: 1.3125, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2629/10000, Loss: 1.3120, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2630/10000, Loss: 1.3115, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2631/10000, Loss: 1.3110, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2632/10000, Loss: 1.3105, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2633/10000, Loss: 1.3100, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2634/10000, Loss: 1.3094, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2635/10000, Loss: 1.3089, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2636/10000, Loss: 1.3084, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2637/10000, Loss: 1.3079, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2638/10000, Loss: 1.3074, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2639/10000, Loss: 1.3069, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2640/10000, Loss: 1.3064, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2641/10000, Loss: 1.3058, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2642/10000, Loss: 1.3053, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2643/10000, Loss: 1.3048, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2644/10000, Loss: 1.3043, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2645/10000, Loss: 1.3038, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2646/10000, Loss: 1.3033, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2647/10000, Loss: 1.3028, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2648/10000, Loss: 1.3023, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2649/10000, Loss: 1.3018, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2650/10000, Loss: 1.3012, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2651/10000, Loss: 1.3007, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2652/10000, Loss: 1.3002, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2653/10000, Loss: 1.2997, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2654/10000, Loss: 1.2992, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2655/10000, Loss: 1.2987, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2656/10000, Loss: 1.2982, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2657/10000, Loss: 1.2977, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2658/10000, Loss: 1.2972, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2659/10000, Loss: 1.2967, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2660/10000, Loss: 1.2962, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2661/10000, Loss: 1.2957, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2662/10000, Loss: 1.2952, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2663/10000, Loss: 1.2947, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2664/10000, Loss: 1.2942, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2665/10000, Loss: 1.2937, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2666/10000, Loss: 1.2932, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2667/10000, Loss: 1.2926, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2668/10000, Loss: 1.2921, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2669/10000, Loss: 1.2916, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2670/10000, Loss: 1.2911, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2671/10000, Loss: 1.2906, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2672/10000, Loss: 1.2901, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2673/10000, Loss: 1.2896, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2674/10000, Loss: 1.2891, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2675/10000, Loss: 1.2886, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2676/10000, Loss: 1.2881, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2677/10000, Loss: 1.2876, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2678/10000, Loss: 1.2871, Accuracy: 0.6220, Learning Rate: 0.000100\n",
      "Epoch 2679/10000, Loss: 1.2867, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2680/10000, Loss: 1.2862, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2681/10000, Loss: 1.2857, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2682/10000, Loss: 1.2852, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2683/10000, Loss: 1.2847, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2684/10000, Loss: 1.2842, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2685/10000, Loss: 1.2837, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2686/10000, Loss: 1.2832, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2687/10000, Loss: 1.2827, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2688/10000, Loss: 1.2822, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2689/10000, Loss: 1.2817, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2690/10000, Loss: 1.2812, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2691/10000, Loss: 1.2807, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2692/10000, Loss: 1.2802, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2693/10000, Loss: 1.2797, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2694/10000, Loss: 1.2792, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2695/10000, Loss: 1.2787, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2696/10000, Loss: 1.2783, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2697/10000, Loss: 1.2778, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2698/10000, Loss: 1.2773, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2699/10000, Loss: 1.2768, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2700/10000, Loss: 1.2763, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2701/10000, Loss: 1.2758, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2702/10000, Loss: 1.2753, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2703/10000, Loss: 1.2748, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2704/10000, Loss: 1.2743, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2705/10000, Loss: 1.2739, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2706/10000, Loss: 1.2734, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2707/10000, Loss: 1.2729, Accuracy: 0.6238, Learning Rate: 0.000100\n",
      "Epoch 2708/10000, Loss: 1.2724, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2709/10000, Loss: 1.2719, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2710/10000, Loss: 1.2714, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2711/10000, Loss: 1.2709, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2712/10000, Loss: 1.2705, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2713/10000, Loss: 1.2700, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2714/10000, Loss: 1.2695, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2715/10000, Loss: 1.2690, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2716/10000, Loss: 1.2685, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2717/10000, Loss: 1.2680, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2718/10000, Loss: 1.2676, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2719/10000, Loss: 1.2671, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2720/10000, Loss: 1.2666, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2721/10000, Loss: 1.2661, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2722/10000, Loss: 1.2656, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2723/10000, Loss: 1.2652, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2724/10000, Loss: 1.2647, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2725/10000, Loss: 1.2642, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2726/10000, Loss: 1.2637, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2727/10000, Loss: 1.2632, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2728/10000, Loss: 1.2628, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2729/10000, Loss: 1.2623, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2730/10000, Loss: 1.2618, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2731/10000, Loss: 1.2613, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2732/10000, Loss: 1.2609, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2733/10000, Loss: 1.2604, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2734/10000, Loss: 1.2599, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2735/10000, Loss: 1.2594, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2736/10000, Loss: 1.2590, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2737/10000, Loss: 1.2585, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2738/10000, Loss: 1.2580, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2739/10000, Loss: 1.2575, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2740/10000, Loss: 1.2571, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2741/10000, Loss: 1.2566, Accuracy: 0.6257, Learning Rate: 0.000100\n",
      "Epoch 2742/10000, Loss: 1.2561, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2743/10000, Loss: 1.2556, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2744/10000, Loss: 1.2552, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2745/10000, Loss: 1.2547, Accuracy: 0.6276, Learning Rate: 0.000100\n",
      "Epoch 2746/10000, Loss: 1.2542, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2747/10000, Loss: 1.2538, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2748/10000, Loss: 1.2533, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2749/10000, Loss: 1.2528, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2750/10000, Loss: 1.2524, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2751/10000, Loss: 1.2519, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2752/10000, Loss: 1.2514, Accuracy: 0.6294, Learning Rate: 0.000100\n",
      "Epoch 2753/10000, Loss: 1.2510, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2754/10000, Loss: 1.2505, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2755/10000, Loss: 1.2500, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2756/10000, Loss: 1.2496, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2757/10000, Loss: 1.2491, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2758/10000, Loss: 1.2486, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2759/10000, Loss: 1.2482, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2760/10000, Loss: 1.2477, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2761/10000, Loss: 1.2472, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2762/10000, Loss: 1.2468, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2763/10000, Loss: 1.2463, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2764/10000, Loss: 1.2458, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2765/10000, Loss: 1.2454, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2766/10000, Loss: 1.2449, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2767/10000, Loss: 1.2444, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2768/10000, Loss: 1.2440, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2769/10000, Loss: 1.2435, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2770/10000, Loss: 1.2431, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2771/10000, Loss: 1.2426, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2772/10000, Loss: 1.2421, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2773/10000, Loss: 1.2417, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2774/10000, Loss: 1.2412, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2775/10000, Loss: 1.2408, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2776/10000, Loss: 1.2403, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2777/10000, Loss: 1.2398, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2778/10000, Loss: 1.2394, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2779/10000, Loss: 1.2389, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2780/10000, Loss: 1.2385, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2781/10000, Loss: 1.2380, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2782/10000, Loss: 1.2376, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2783/10000, Loss: 1.2371, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2784/10000, Loss: 1.2366, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2785/10000, Loss: 1.2362, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2786/10000, Loss: 1.2357, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2787/10000, Loss: 1.2353, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2788/10000, Loss: 1.2348, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2789/10000, Loss: 1.2344, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2790/10000, Loss: 1.2339, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2791/10000, Loss: 1.2335, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2792/10000, Loss: 1.2330, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2793/10000, Loss: 1.2326, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2794/10000, Loss: 1.2321, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2795/10000, Loss: 1.2317, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2796/10000, Loss: 1.2312, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2797/10000, Loss: 1.2308, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2798/10000, Loss: 1.2303, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2799/10000, Loss: 1.2299, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2800/10000, Loss: 1.2294, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2801/10000, Loss: 1.2290, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2802/10000, Loss: 1.2285, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2803/10000, Loss: 1.2281, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2804/10000, Loss: 1.2276, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2805/10000, Loss: 1.2272, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2806/10000, Loss: 1.2267, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2807/10000, Loss: 1.2263, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2808/10000, Loss: 1.2258, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2809/10000, Loss: 1.2254, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2810/10000, Loss: 1.2249, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2811/10000, Loss: 1.2245, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2812/10000, Loss: 1.2241, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2813/10000, Loss: 1.2236, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2814/10000, Loss: 1.2232, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2815/10000, Loss: 1.2227, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2816/10000, Loss: 1.2223, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2817/10000, Loss: 1.2218, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2818/10000, Loss: 1.2214, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2819/10000, Loss: 1.2210, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2820/10000, Loss: 1.2205, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2821/10000, Loss: 1.2201, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2822/10000, Loss: 1.2196, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2823/10000, Loss: 1.2192, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2824/10000, Loss: 1.2188, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2825/10000, Loss: 1.2183, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2826/10000, Loss: 1.2179, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2827/10000, Loss: 1.2174, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2828/10000, Loss: 1.2170, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2829/10000, Loss: 1.2166, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2830/10000, Loss: 1.2161, Accuracy: 0.6313, Learning Rate: 0.000100\n",
      "Epoch 2831/10000, Loss: 1.2157, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2832/10000, Loss: 1.2153, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2833/10000, Loss: 1.2148, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2834/10000, Loss: 1.2144, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2835/10000, Loss: 1.2140, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2836/10000, Loss: 1.2135, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2837/10000, Loss: 1.2131, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2838/10000, Loss: 1.2126, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2839/10000, Loss: 1.2122, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2840/10000, Loss: 1.2118, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2841/10000, Loss: 1.2113, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2842/10000, Loss: 1.2109, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2843/10000, Loss: 1.2105, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2844/10000, Loss: 1.2101, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2845/10000, Loss: 1.2096, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2846/10000, Loss: 1.2092, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2847/10000, Loss: 1.2088, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2848/10000, Loss: 1.2083, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2849/10000, Loss: 1.2079, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2850/10000, Loss: 1.2075, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2851/10000, Loss: 1.2070, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2852/10000, Loss: 1.2066, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2853/10000, Loss: 1.2062, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2854/10000, Loss: 1.2058, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2855/10000, Loss: 1.2053, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2856/10000, Loss: 1.2049, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2857/10000, Loss: 1.2045, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2858/10000, Loss: 1.2041, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2859/10000, Loss: 1.2036, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2860/10000, Loss: 1.2032, Accuracy: 0.6331, Learning Rate: 0.000100\n",
      "Epoch 2861/10000, Loss: 1.2028, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2862/10000, Loss: 1.2024, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2863/10000, Loss: 1.2019, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2864/10000, Loss: 1.2015, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2865/10000, Loss: 1.2011, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2866/10000, Loss: 1.2007, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2867/10000, Loss: 1.2002, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2868/10000, Loss: 1.1998, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2869/10000, Loss: 1.1994, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2870/10000, Loss: 1.1990, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2871/10000, Loss: 1.1985, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2872/10000, Loss: 1.1981, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2873/10000, Loss: 1.1977, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2874/10000, Loss: 1.1973, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2875/10000, Loss: 1.1969, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2876/10000, Loss: 1.1964, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2877/10000, Loss: 1.1960, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2878/10000, Loss: 1.1956, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2879/10000, Loss: 1.1952, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2880/10000, Loss: 1.1948, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2881/10000, Loss: 1.1944, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2882/10000, Loss: 1.1939, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2883/10000, Loss: 1.1935, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2884/10000, Loss: 1.1931, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2885/10000, Loss: 1.1927, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2886/10000, Loss: 1.1923, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2887/10000, Loss: 1.1919, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2888/10000, Loss: 1.1914, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2889/10000, Loss: 1.1910, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2890/10000, Loss: 1.1906, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2891/10000, Loss: 1.1902, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2892/10000, Loss: 1.1898, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2893/10000, Loss: 1.1894, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2894/10000, Loss: 1.1890, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2895/10000, Loss: 1.1886, Accuracy: 0.6350, Learning Rate: 0.000100\n",
      "Epoch 2896/10000, Loss: 1.1881, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2897/10000, Loss: 1.1877, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2898/10000, Loss: 1.1873, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2899/10000, Loss: 1.1869, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2900/10000, Loss: 1.1865, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2901/10000, Loss: 1.1861, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2902/10000, Loss: 1.1857, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2903/10000, Loss: 1.1853, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2904/10000, Loss: 1.1849, Accuracy: 0.6369, Learning Rate: 0.000100\n",
      "Epoch 2905/10000, Loss: 1.1845, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2906/10000, Loss: 1.1841, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2907/10000, Loss: 1.1836, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2908/10000, Loss: 1.1832, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2909/10000, Loss: 1.1828, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2910/10000, Loss: 1.1824, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2911/10000, Loss: 1.1820, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2912/10000, Loss: 1.1816, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2913/10000, Loss: 1.1812, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2914/10000, Loss: 1.1808, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2915/10000, Loss: 1.1804, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2916/10000, Loss: 1.1800, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2917/10000, Loss: 1.1796, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2918/10000, Loss: 1.1792, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2919/10000, Loss: 1.1788, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2920/10000, Loss: 1.1784, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2921/10000, Loss: 1.1780, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2922/10000, Loss: 1.1776, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2923/10000, Loss: 1.1772, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2924/10000, Loss: 1.1768, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2925/10000, Loss: 1.1764, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2926/10000, Loss: 1.1760, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2927/10000, Loss: 1.1756, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2928/10000, Loss: 1.1752, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2929/10000, Loss: 1.1748, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2930/10000, Loss: 1.1744, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2931/10000, Loss: 1.1740, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2932/10000, Loss: 1.1736, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2933/10000, Loss: 1.1732, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2934/10000, Loss: 1.1728, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2935/10000, Loss: 1.1724, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2936/10000, Loss: 1.1720, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2937/10000, Loss: 1.1716, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2938/10000, Loss: 1.1712, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2939/10000, Loss: 1.1708, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2940/10000, Loss: 1.1704, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2941/10000, Loss: 1.1700, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2942/10000, Loss: 1.1696, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2943/10000, Loss: 1.1692, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2944/10000, Loss: 1.1689, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2945/10000, Loss: 1.1685, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2946/10000, Loss: 1.1681, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2947/10000, Loss: 1.1677, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2948/10000, Loss: 1.1673, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2949/10000, Loss: 1.1669, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2950/10000, Loss: 1.1665, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2951/10000, Loss: 1.1661, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2952/10000, Loss: 1.1657, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2953/10000, Loss: 1.1653, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2954/10000, Loss: 1.1649, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2955/10000, Loss: 1.1646, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2956/10000, Loss: 1.1642, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2957/10000, Loss: 1.1638, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2958/10000, Loss: 1.1634, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2959/10000, Loss: 1.1630, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2960/10000, Loss: 1.1626, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2961/10000, Loss: 1.1622, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2962/10000, Loss: 1.1618, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2963/10000, Loss: 1.1615, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2964/10000, Loss: 1.1611, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2965/10000, Loss: 1.1607, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2966/10000, Loss: 1.1603, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2967/10000, Loss: 1.1599, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2968/10000, Loss: 1.1595, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2969/10000, Loss: 1.1592, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2970/10000, Loss: 1.1588, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2971/10000, Loss: 1.1584, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2972/10000, Loss: 1.1580, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2973/10000, Loss: 1.1576, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2974/10000, Loss: 1.1572, Accuracy: 0.6387, Learning Rate: 0.000100\n",
      "Epoch 2975/10000, Loss: 1.1569, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2976/10000, Loss: 1.1565, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2977/10000, Loss: 1.1561, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2978/10000, Loss: 1.1557, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2979/10000, Loss: 1.1553, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2980/10000, Loss: 1.1550, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 2981/10000, Loss: 1.1546, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2982/10000, Loss: 1.1542, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2983/10000, Loss: 1.1538, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2984/10000, Loss: 1.1534, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2985/10000, Loss: 1.1531, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2986/10000, Loss: 1.1527, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2987/10000, Loss: 1.1523, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2988/10000, Loss: 1.1519, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2989/10000, Loss: 1.1516, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2990/10000, Loss: 1.1512, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2991/10000, Loss: 1.1508, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2992/10000, Loss: 1.1504, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2993/10000, Loss: 1.1501, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2994/10000, Loss: 1.1497, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2995/10000, Loss: 1.1493, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2996/10000, Loss: 1.1489, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2997/10000, Loss: 1.1486, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2998/10000, Loss: 1.1482, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 2999/10000, Loss: 1.1478, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3000/10000, Loss: 1.1474, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3001/10000, Loss: 1.1471, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3002/10000, Loss: 1.1467, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3003/10000, Loss: 1.1463, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3004/10000, Loss: 1.1460, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3005/10000, Loss: 1.1456, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3006/10000, Loss: 1.1452, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3007/10000, Loss: 1.1449, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3008/10000, Loss: 1.1445, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3009/10000, Loss: 1.1441, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3010/10000, Loss: 1.1437, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3011/10000, Loss: 1.1434, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3012/10000, Loss: 1.1430, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3013/10000, Loss: 1.1426, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3014/10000, Loss: 1.1423, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3015/10000, Loss: 1.1419, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3016/10000, Loss: 1.1415, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3017/10000, Loss: 1.1412, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3018/10000, Loss: 1.1408, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3019/10000, Loss: 1.1404, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3020/10000, Loss: 1.1401, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3021/10000, Loss: 1.1397, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3022/10000, Loss: 1.1394, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3023/10000, Loss: 1.1390, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3024/10000, Loss: 1.1386, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3025/10000, Loss: 1.1383, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3026/10000, Loss: 1.1379, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3027/10000, Loss: 1.1375, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3028/10000, Loss: 1.1372, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3029/10000, Loss: 1.1368, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3030/10000, Loss: 1.1365, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3031/10000, Loss: 1.1361, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3032/10000, Loss: 1.1357, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3033/10000, Loss: 1.1354, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3034/10000, Loss: 1.1350, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3035/10000, Loss: 1.1347, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3036/10000, Loss: 1.1343, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3037/10000, Loss: 1.1339, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3038/10000, Loss: 1.1336, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3039/10000, Loss: 1.1332, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3040/10000, Loss: 1.1329, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3041/10000, Loss: 1.1325, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3042/10000, Loss: 1.1322, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3043/10000, Loss: 1.1318, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3044/10000, Loss: 1.1314, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3045/10000, Loss: 1.1311, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3046/10000, Loss: 1.1307, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3047/10000, Loss: 1.1304, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3048/10000, Loss: 1.1300, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3049/10000, Loss: 1.1297, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3050/10000, Loss: 1.1293, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3051/10000, Loss: 1.1290, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3052/10000, Loss: 1.1286, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3053/10000, Loss: 1.1283, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3054/10000, Loss: 1.1279, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3055/10000, Loss: 1.1275, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3056/10000, Loss: 1.1272, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3057/10000, Loss: 1.1268, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3058/10000, Loss: 1.1265, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3059/10000, Loss: 1.1261, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3060/10000, Loss: 1.1258, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3061/10000, Loss: 1.1254, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3062/10000, Loss: 1.1251, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3063/10000, Loss: 1.1247, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3064/10000, Loss: 1.1244, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3065/10000, Loss: 1.1240, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 3066/10000, Loss: 1.1237, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 3067/10000, Loss: 1.1233, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 3068/10000, Loss: 1.1230, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 3069/10000, Loss: 1.1227, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 3070/10000, Loss: 1.1223, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 3071/10000, Loss: 1.1220, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 3072/10000, Loss: 1.1216, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 3073/10000, Loss: 1.1213, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 3074/10000, Loss: 1.1209, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 3075/10000, Loss: 1.1206, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 3076/10000, Loss: 1.1202, Accuracy: 0.6406, Learning Rate: 0.000100\n",
      "Epoch 3077/10000, Loss: 1.1199, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3078/10000, Loss: 1.1195, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3079/10000, Loss: 1.1192, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3080/10000, Loss: 1.1189, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3081/10000, Loss: 1.1185, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3082/10000, Loss: 1.1182, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3083/10000, Loss: 1.1178, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3084/10000, Loss: 1.1175, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3085/10000, Loss: 1.1171, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3086/10000, Loss: 1.1168, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3087/10000, Loss: 1.1165, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3088/10000, Loss: 1.1161, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3089/10000, Loss: 1.1158, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3090/10000, Loss: 1.1154, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3091/10000, Loss: 1.1151, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3092/10000, Loss: 1.1148, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3093/10000, Loss: 1.1144, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3094/10000, Loss: 1.1141, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3095/10000, Loss: 1.1138, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3096/10000, Loss: 1.1134, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3097/10000, Loss: 1.1131, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3098/10000, Loss: 1.1127, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3099/10000, Loss: 1.1124, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3100/10000, Loss: 1.1121, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3101/10000, Loss: 1.1117, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3102/10000, Loss: 1.1114, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3103/10000, Loss: 1.1111, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3104/10000, Loss: 1.1107, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3105/10000, Loss: 1.1104, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3106/10000, Loss: 1.1101, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3107/10000, Loss: 1.1097, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3108/10000, Loss: 1.1094, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3109/10000, Loss: 1.1091, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3110/10000, Loss: 1.1087, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3111/10000, Loss: 1.1084, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3112/10000, Loss: 1.1081, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3113/10000, Loss: 1.1077, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3114/10000, Loss: 1.1074, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3115/10000, Loss: 1.1071, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3116/10000, Loss: 1.1067, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3117/10000, Loss: 1.1064, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3118/10000, Loss: 1.1061, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3119/10000, Loss: 1.1057, Accuracy: 0.6425, Learning Rate: 0.000100\n",
      "Epoch 3120/10000, Loss: 1.1054, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3121/10000, Loss: 1.1051, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3122/10000, Loss: 1.1048, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3123/10000, Loss: 1.1044, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3124/10000, Loss: 1.1041, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3125/10000, Loss: 1.1038, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3126/10000, Loss: 1.1034, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3127/10000, Loss: 1.1031, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3128/10000, Loss: 1.1028, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3129/10000, Loss: 1.1025, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3130/10000, Loss: 1.1021, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3131/10000, Loss: 1.1018, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3132/10000, Loss: 1.1015, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3133/10000, Loss: 1.1012, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3134/10000, Loss: 1.1008, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3135/10000, Loss: 1.1005, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3136/10000, Loss: 1.1002, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3137/10000, Loss: 1.0999, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3138/10000, Loss: 1.0995, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3139/10000, Loss: 1.0992, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3140/10000, Loss: 1.0989, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3141/10000, Loss: 1.0986, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3142/10000, Loss: 1.0983, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3143/10000, Loss: 1.0979, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3144/10000, Loss: 1.0976, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3145/10000, Loss: 1.0973, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3146/10000, Loss: 1.0970, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3147/10000, Loss: 1.0966, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3148/10000, Loss: 1.0963, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3149/10000, Loss: 1.0960, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3150/10000, Loss: 1.0957, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3151/10000, Loss: 1.0954, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3152/10000, Loss: 1.0950, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3153/10000, Loss: 1.0947, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3154/10000, Loss: 1.0944, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3155/10000, Loss: 1.0941, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3156/10000, Loss: 1.0938, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3157/10000, Loss: 1.0935, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3158/10000, Loss: 1.0931, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3159/10000, Loss: 1.0928, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3160/10000, Loss: 1.0925, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3161/10000, Loss: 1.0922, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3162/10000, Loss: 1.0919, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 3163/10000, Loss: 1.0916, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 3164/10000, Loss: 1.0912, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3165/10000, Loss: 1.0909, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3166/10000, Loss: 1.0906, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3167/10000, Loss: 1.0903, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3168/10000, Loss: 1.0900, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3169/10000, Loss: 1.0897, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3170/10000, Loss: 1.0894, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3171/10000, Loss: 1.0891, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3172/10000, Loss: 1.0887, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3173/10000, Loss: 1.0884, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3174/10000, Loss: 1.0881, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3175/10000, Loss: 1.0878, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3176/10000, Loss: 1.0875, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3177/10000, Loss: 1.0872, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3178/10000, Loss: 1.0869, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3179/10000, Loss: 1.0866, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3180/10000, Loss: 1.0863, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3181/10000, Loss: 1.0859, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3182/10000, Loss: 1.0856, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3183/10000, Loss: 1.0853, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3184/10000, Loss: 1.0850, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3185/10000, Loss: 1.0847, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3186/10000, Loss: 1.0844, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3187/10000, Loss: 1.0841, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3188/10000, Loss: 1.0838, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3189/10000, Loss: 1.0835, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3190/10000, Loss: 1.0832, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3191/10000, Loss: 1.0829, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3192/10000, Loss: 1.0826, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3193/10000, Loss: 1.0823, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3194/10000, Loss: 1.0820, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3195/10000, Loss: 1.0817, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3196/10000, Loss: 1.0813, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3197/10000, Loss: 1.0810, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3198/10000, Loss: 1.0807, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3199/10000, Loss: 1.0804, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3200/10000, Loss: 1.0801, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3201/10000, Loss: 1.0798, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3202/10000, Loss: 1.0795, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3203/10000, Loss: 1.0792, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3204/10000, Loss: 1.0789, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3205/10000, Loss: 1.0786, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3206/10000, Loss: 1.0783, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3207/10000, Loss: 1.0780, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3208/10000, Loss: 1.0777, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3209/10000, Loss: 1.0774, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3210/10000, Loss: 1.0771, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3211/10000, Loss: 1.0768, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3212/10000, Loss: 1.0765, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3213/10000, Loss: 1.0762, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3214/10000, Loss: 1.0759, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3215/10000, Loss: 1.0756, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3216/10000, Loss: 1.0753, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3217/10000, Loss: 1.0750, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3218/10000, Loss: 1.0747, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3219/10000, Loss: 1.0744, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3220/10000, Loss: 1.0741, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3221/10000, Loss: 1.0738, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3222/10000, Loss: 1.0735, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3223/10000, Loss: 1.0732, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3224/10000, Loss: 1.0729, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3225/10000, Loss: 1.0727, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3226/10000, Loss: 1.0724, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3227/10000, Loss: 1.0721, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3228/10000, Loss: 1.0718, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3229/10000, Loss: 1.0715, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3230/10000, Loss: 1.0712, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3231/10000, Loss: 1.0709, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3232/10000, Loss: 1.0706, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3233/10000, Loss: 1.0703, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3234/10000, Loss: 1.0700, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3235/10000, Loss: 1.0697, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3236/10000, Loss: 1.0694, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3237/10000, Loss: 1.0691, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3238/10000, Loss: 1.0688, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3239/10000, Loss: 1.0685, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3240/10000, Loss: 1.0683, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3241/10000, Loss: 1.0680, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3242/10000, Loss: 1.0677, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3243/10000, Loss: 1.0674, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3244/10000, Loss: 1.0671, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3245/10000, Loss: 1.0668, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3246/10000, Loss: 1.0665, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3247/10000, Loss: 1.0662, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3248/10000, Loss: 1.0659, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3249/10000, Loss: 1.0656, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3250/10000, Loss: 1.0654, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3251/10000, Loss: 1.0651, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3252/10000, Loss: 1.0648, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3253/10000, Loss: 1.0645, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3254/10000, Loss: 1.0642, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3255/10000, Loss: 1.0639, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3256/10000, Loss: 1.0636, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3257/10000, Loss: 1.0634, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3258/10000, Loss: 1.0631, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3259/10000, Loss: 1.0628, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3260/10000, Loss: 1.0625, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3261/10000, Loss: 1.0622, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3262/10000, Loss: 1.0619, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3263/10000, Loss: 1.0616, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3264/10000, Loss: 1.0614, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3265/10000, Loss: 1.0611, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3266/10000, Loss: 1.0608, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3267/10000, Loss: 1.0605, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3268/10000, Loss: 1.0602, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3269/10000, Loss: 1.0599, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3270/10000, Loss: 1.0597, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3271/10000, Loss: 1.0594, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3272/10000, Loss: 1.0591, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3273/10000, Loss: 1.0588, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3274/10000, Loss: 1.0585, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3275/10000, Loss: 1.0583, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3276/10000, Loss: 1.0580, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3277/10000, Loss: 1.0577, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3278/10000, Loss: 1.0574, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3279/10000, Loss: 1.0571, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3280/10000, Loss: 1.0569, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3281/10000, Loss: 1.0566, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3282/10000, Loss: 1.0563, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3283/10000, Loss: 1.0560, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3284/10000, Loss: 1.0557, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3285/10000, Loss: 1.0555, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3286/10000, Loss: 1.0552, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3287/10000, Loss: 1.0549, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3288/10000, Loss: 1.0546, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3289/10000, Loss: 1.0544, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3290/10000, Loss: 1.0541, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3291/10000, Loss: 1.0538, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3292/10000, Loss: 1.0535, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3293/10000, Loss: 1.0533, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3294/10000, Loss: 1.0530, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3295/10000, Loss: 1.0527, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3296/10000, Loss: 1.0524, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3297/10000, Loss: 1.0522, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3298/10000, Loss: 1.0519, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3299/10000, Loss: 1.0516, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3300/10000, Loss: 1.0513, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3301/10000, Loss: 1.0511, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3302/10000, Loss: 1.0508, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3303/10000, Loss: 1.0505, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3304/10000, Loss: 1.0502, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3305/10000, Loss: 1.0500, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3306/10000, Loss: 1.0497, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3307/10000, Loss: 1.0494, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3308/10000, Loss: 1.0492, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3309/10000, Loss: 1.0489, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3310/10000, Loss: 1.0486, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3311/10000, Loss: 1.0483, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3312/10000, Loss: 1.0481, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3313/10000, Loss: 1.0478, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3314/10000, Loss: 1.0475, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3315/10000, Loss: 1.0473, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3316/10000, Loss: 1.0470, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3317/10000, Loss: 1.0467, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3318/10000, Loss: 1.0465, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3319/10000, Loss: 1.0462, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3320/10000, Loss: 1.0459, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3321/10000, Loss: 1.0457, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3322/10000, Loss: 1.0454, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3323/10000, Loss: 1.0451, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3324/10000, Loss: 1.0449, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3325/10000, Loss: 1.0446, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3326/10000, Loss: 1.0443, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3327/10000, Loss: 1.0441, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3328/10000, Loss: 1.0438, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3329/10000, Loss: 1.0435, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3330/10000, Loss: 1.0433, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3331/10000, Loss: 1.0430, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3332/10000, Loss: 1.0427, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3333/10000, Loss: 1.0425, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3334/10000, Loss: 1.0422, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3335/10000, Loss: 1.0419, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3336/10000, Loss: 1.0417, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3337/10000, Loss: 1.0414, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3338/10000, Loss: 1.0412, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3339/10000, Loss: 1.0409, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3340/10000, Loss: 1.0406, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3341/10000, Loss: 1.0404, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3342/10000, Loss: 1.0401, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 3343/10000, Loss: 1.0398, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 3344/10000, Loss: 1.0396, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3345/10000, Loss: 1.0393, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3346/10000, Loss: 1.0391, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3347/10000, Loss: 1.0388, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3348/10000, Loss: 1.0385, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3349/10000, Loss: 1.0383, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3350/10000, Loss: 1.0380, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3351/10000, Loss: 1.0378, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3352/10000, Loss: 1.0375, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3353/10000, Loss: 1.0372, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3354/10000, Loss: 1.0370, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3355/10000, Loss: 1.0367, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3356/10000, Loss: 1.0365, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3357/10000, Loss: 1.0362, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3358/10000, Loss: 1.0360, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3359/10000, Loss: 1.0357, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3360/10000, Loss: 1.0354, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3361/10000, Loss: 1.0352, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3362/10000, Loss: 1.0349, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3363/10000, Loss: 1.0347, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3364/10000, Loss: 1.0344, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3365/10000, Loss: 1.0342, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3366/10000, Loss: 1.0339, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3367/10000, Loss: 1.0336, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3368/10000, Loss: 1.0334, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3369/10000, Loss: 1.0331, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3370/10000, Loss: 1.0329, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3371/10000, Loss: 1.0326, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 3372/10000, Loss: 1.0324, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3373/10000, Loss: 1.0321, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3374/10000, Loss: 1.0319, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3375/10000, Loss: 1.0316, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3376/10000, Loss: 1.0314, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3377/10000, Loss: 1.0311, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 3378/10000, Loss: 1.0309, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3379/10000, Loss: 1.0306, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3380/10000, Loss: 1.0303, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3381/10000, Loss: 1.0301, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3382/10000, Loss: 1.0298, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3383/10000, Loss: 1.0296, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3384/10000, Loss: 1.0293, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3385/10000, Loss: 1.0291, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3386/10000, Loss: 1.0288, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3387/10000, Loss: 1.0286, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3388/10000, Loss: 1.0283, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3389/10000, Loss: 1.0281, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3390/10000, Loss: 1.0278, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3391/10000, Loss: 1.0276, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3392/10000, Loss: 1.0273, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3393/10000, Loss: 1.0271, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3394/10000, Loss: 1.0268, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3395/10000, Loss: 1.0266, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3396/10000, Loss: 1.0264, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3397/10000, Loss: 1.0261, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3398/10000, Loss: 1.0259, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3399/10000, Loss: 1.0256, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3400/10000, Loss: 1.0254, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3401/10000, Loss: 1.0251, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3402/10000, Loss: 1.0249, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3403/10000, Loss: 1.0246, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3404/10000, Loss: 1.0244, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3405/10000, Loss: 1.0241, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3406/10000, Loss: 1.0239, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3407/10000, Loss: 1.0236, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3408/10000, Loss: 1.0234, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3409/10000, Loss: 1.0232, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3410/10000, Loss: 1.0229, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3411/10000, Loss: 1.0227, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3412/10000, Loss: 1.0224, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3413/10000, Loss: 1.0222, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3414/10000, Loss: 1.0219, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3415/10000, Loss: 1.0217, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3416/10000, Loss: 1.0214, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3417/10000, Loss: 1.0212, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3418/10000, Loss: 1.0210, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3419/10000, Loss: 1.0207, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3420/10000, Loss: 1.0205, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3421/10000, Loss: 1.0202, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3422/10000, Loss: 1.0200, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3423/10000, Loss: 1.0198, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3424/10000, Loss: 1.0195, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3425/10000, Loss: 1.0193, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3426/10000, Loss: 1.0190, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3427/10000, Loss: 1.0188, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3428/10000, Loss: 1.0186, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3429/10000, Loss: 1.0183, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3430/10000, Loss: 1.0181, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3431/10000, Loss: 1.0178, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3432/10000, Loss: 1.0176, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3433/10000, Loss: 1.0174, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3434/10000, Loss: 1.0171, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3435/10000, Loss: 1.0169, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3436/10000, Loss: 1.0166, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3437/10000, Loss: 1.0164, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3438/10000, Loss: 1.0162, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3439/10000, Loss: 1.0159, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3440/10000, Loss: 1.0157, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 3441/10000, Loss: 1.0155, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3442/10000, Loss: 1.0152, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3443/10000, Loss: 1.0150, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3444/10000, Loss: 1.0147, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3445/10000, Loss: 1.0145, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3446/10000, Loss: 1.0143, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3447/10000, Loss: 1.0140, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3448/10000, Loss: 1.0138, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3449/10000, Loss: 1.0136, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3450/10000, Loss: 1.0133, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3451/10000, Loss: 1.0131, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3452/10000, Loss: 1.0129, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3453/10000, Loss: 1.0126, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3454/10000, Loss: 1.0124, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3455/10000, Loss: 1.0122, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3456/10000, Loss: 1.0119, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3457/10000, Loss: 1.0117, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3458/10000, Loss: 1.0115, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3459/10000, Loss: 1.0112, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3460/10000, Loss: 1.0110, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3461/10000, Loss: 1.0108, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3462/10000, Loss: 1.0105, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3463/10000, Loss: 1.0103, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3464/10000, Loss: 1.0101, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3465/10000, Loss: 1.0098, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3466/10000, Loss: 1.0096, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3467/10000, Loss: 1.0094, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3468/10000, Loss: 1.0091, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3469/10000, Loss: 1.0089, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3470/10000, Loss: 1.0087, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3471/10000, Loss: 1.0085, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3472/10000, Loss: 1.0082, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3473/10000, Loss: 1.0080, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3474/10000, Loss: 1.0078, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3475/10000, Loss: 1.0075, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3476/10000, Loss: 1.0073, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3477/10000, Loss: 1.0071, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3478/10000, Loss: 1.0069, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3479/10000, Loss: 1.0066, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3480/10000, Loss: 1.0064, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3481/10000, Loss: 1.0062, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3482/10000, Loss: 1.0059, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3483/10000, Loss: 1.0057, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3484/10000, Loss: 1.0055, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3485/10000, Loss: 1.0053, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3486/10000, Loss: 1.0050, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3487/10000, Loss: 1.0048, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3488/10000, Loss: 1.0046, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3489/10000, Loss: 1.0044, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3490/10000, Loss: 1.0041, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3491/10000, Loss: 1.0039, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3492/10000, Loss: 1.0037, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3493/10000, Loss: 1.0035, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3494/10000, Loss: 1.0032, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3495/10000, Loss: 1.0030, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3496/10000, Loss: 1.0028, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3497/10000, Loss: 1.0026, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3498/10000, Loss: 1.0023, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3499/10000, Loss: 1.0021, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3500/10000, Loss: 1.0019, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3501/10000, Loss: 1.0017, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3502/10000, Loss: 1.0014, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3503/10000, Loss: 1.0012, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3504/10000, Loss: 1.0010, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3505/10000, Loss: 1.0008, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3506/10000, Loss: 1.0005, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3507/10000, Loss: 1.0003, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3508/10000, Loss: 1.0001, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3509/10000, Loss: 0.9999, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3510/10000, Loss: 0.9997, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3511/10000, Loss: 0.9994, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3512/10000, Loss: 0.9992, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3513/10000, Loss: 0.9990, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3514/10000, Loss: 0.9988, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3515/10000, Loss: 0.9986, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3516/10000, Loss: 0.9983, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3517/10000, Loss: 0.9981, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3518/10000, Loss: 0.9979, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3519/10000, Loss: 0.9977, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3520/10000, Loss: 0.9975, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3521/10000, Loss: 0.9972, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3522/10000, Loss: 0.9970, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3523/10000, Loss: 0.9968, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3524/10000, Loss: 0.9966, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3525/10000, Loss: 0.9964, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3526/10000, Loss: 0.9962, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3527/10000, Loss: 0.9959, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3528/10000, Loss: 0.9957, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3529/10000, Loss: 0.9955, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3530/10000, Loss: 0.9953, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3531/10000, Loss: 0.9951, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3532/10000, Loss: 0.9949, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3533/10000, Loss: 0.9946, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3534/10000, Loss: 0.9944, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3535/10000, Loss: 0.9942, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3536/10000, Loss: 0.9940, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3537/10000, Loss: 0.9938, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3538/10000, Loss: 0.9936, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3539/10000, Loss: 0.9933, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3540/10000, Loss: 0.9931, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3541/10000, Loss: 0.9929, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3542/10000, Loss: 0.9927, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3543/10000, Loss: 0.9925, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3544/10000, Loss: 0.9923, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3545/10000, Loss: 0.9921, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3546/10000, Loss: 0.9918, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3547/10000, Loss: 0.9916, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3548/10000, Loss: 0.9914, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3549/10000, Loss: 0.9912, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3550/10000, Loss: 0.9910, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3551/10000, Loss: 0.9908, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3552/10000, Loss: 0.9906, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3553/10000, Loss: 0.9904, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3554/10000, Loss: 0.9901, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3555/10000, Loss: 0.9899, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3556/10000, Loss: 0.9897, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3557/10000, Loss: 0.9895, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3558/10000, Loss: 0.9893, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3559/10000, Loss: 0.9891, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3560/10000, Loss: 0.9889, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3561/10000, Loss: 0.9887, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3562/10000, Loss: 0.9885, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3563/10000, Loss: 0.9882, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3564/10000, Loss: 0.9880, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3565/10000, Loss: 0.9878, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3566/10000, Loss: 0.9876, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3567/10000, Loss: 0.9874, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3568/10000, Loss: 0.9872, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3569/10000, Loss: 0.9870, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3570/10000, Loss: 0.9868, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3571/10000, Loss: 0.9866, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3572/10000, Loss: 0.9864, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3573/10000, Loss: 0.9862, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3574/10000, Loss: 0.9859, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3575/10000, Loss: 0.9857, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3576/10000, Loss: 0.9855, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3577/10000, Loss: 0.9853, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3578/10000, Loss: 0.9851, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3579/10000, Loss: 0.9849, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3580/10000, Loss: 0.9847, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3581/10000, Loss: 0.9845, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3582/10000, Loss: 0.9843, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3583/10000, Loss: 0.9841, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3584/10000, Loss: 0.9839, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3585/10000, Loss: 0.9837, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3586/10000, Loss: 0.9835, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3587/10000, Loss: 0.9833, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3588/10000, Loss: 0.9831, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3589/10000, Loss: 0.9829, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3590/10000, Loss: 0.9826, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3591/10000, Loss: 0.9824, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3592/10000, Loss: 0.9822, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3593/10000, Loss: 0.9820, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3594/10000, Loss: 0.9818, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3595/10000, Loss: 0.9816, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3596/10000, Loss: 0.9814, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3597/10000, Loss: 0.9812, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3598/10000, Loss: 0.9810, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3599/10000, Loss: 0.9808, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3600/10000, Loss: 0.9806, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3601/10000, Loss: 0.9804, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3602/10000, Loss: 0.9802, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3603/10000, Loss: 0.9800, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3604/10000, Loss: 0.9798, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3605/10000, Loss: 0.9796, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3606/10000, Loss: 0.9794, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3607/10000, Loss: 0.9792, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3608/10000, Loss: 0.9790, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3609/10000, Loss: 0.9788, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3610/10000, Loss: 0.9786, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3611/10000, Loss: 0.9784, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3612/10000, Loss: 0.9782, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3613/10000, Loss: 0.9780, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3614/10000, Loss: 0.9778, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3615/10000, Loss: 0.9776, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3616/10000, Loss: 0.9774, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3617/10000, Loss: 0.9772, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3618/10000, Loss: 0.9770, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3619/10000, Loss: 0.9768, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3620/10000, Loss: 0.9766, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3621/10000, Loss: 0.9764, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3622/10000, Loss: 0.9762, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3623/10000, Loss: 0.9760, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3624/10000, Loss: 0.9758, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3625/10000, Loss: 0.9756, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3626/10000, Loss: 0.9754, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3627/10000, Loss: 0.9752, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3628/10000, Loss: 0.9750, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3629/10000, Loss: 0.9748, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3630/10000, Loss: 0.9746, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3631/10000, Loss: 0.9744, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3632/10000, Loss: 0.9742, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 3633/10000, Loss: 0.9740, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3634/10000, Loss: 0.9738, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3635/10000, Loss: 0.9736, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3636/10000, Loss: 0.9734, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3637/10000, Loss: 0.9732, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3638/10000, Loss: 0.9731, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3639/10000, Loss: 0.9729, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3640/10000, Loss: 0.9727, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3641/10000, Loss: 0.9725, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3642/10000, Loss: 0.9723, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3643/10000, Loss: 0.9721, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3644/10000, Loss: 0.9719, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3645/10000, Loss: 0.9717, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3646/10000, Loss: 0.9715, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3647/10000, Loss: 0.9713, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3648/10000, Loss: 0.9711, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3649/10000, Loss: 0.9709, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3650/10000, Loss: 0.9707, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3651/10000, Loss: 0.9705, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3652/10000, Loss: 0.9703, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3653/10000, Loss: 0.9701, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3654/10000, Loss: 0.9700, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3655/10000, Loss: 0.9698, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3656/10000, Loss: 0.9696, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3657/10000, Loss: 0.9694, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3658/10000, Loss: 0.9692, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3659/10000, Loss: 0.9690, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3660/10000, Loss: 0.9688, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3661/10000, Loss: 0.9686, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3662/10000, Loss: 0.9684, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3663/10000, Loss: 0.9682, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3664/10000, Loss: 0.9680, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3665/10000, Loss: 0.9678, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3666/10000, Loss: 0.9677, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3667/10000, Loss: 0.9675, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3668/10000, Loss: 0.9673, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3669/10000, Loss: 0.9671, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3670/10000, Loss: 0.9669, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3671/10000, Loss: 0.9667, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3672/10000, Loss: 0.9665, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3673/10000, Loss: 0.9663, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3674/10000, Loss: 0.9661, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3675/10000, Loss: 0.9660, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3676/10000, Loss: 0.9658, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3677/10000, Loss: 0.9656, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3678/10000, Loss: 0.9654, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3679/10000, Loss: 0.9652, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3680/10000, Loss: 0.9650, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3681/10000, Loss: 0.9648, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3682/10000, Loss: 0.9646, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3683/10000, Loss: 0.9645, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3684/10000, Loss: 0.9643, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3685/10000, Loss: 0.9641, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3686/10000, Loss: 0.9639, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3687/10000, Loss: 0.9637, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3688/10000, Loss: 0.9635, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3689/10000, Loss: 0.9633, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3690/10000, Loss: 0.9631, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3691/10000, Loss: 0.9630, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3692/10000, Loss: 0.9628, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3693/10000, Loss: 0.9626, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3694/10000, Loss: 0.9624, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3695/10000, Loss: 0.9622, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3696/10000, Loss: 0.9620, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3697/10000, Loss: 0.9618, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3698/10000, Loss: 0.9617, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3699/10000, Loss: 0.9615, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3700/10000, Loss: 0.9613, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3701/10000, Loss: 0.9611, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3702/10000, Loss: 0.9609, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3703/10000, Loss: 0.9607, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3704/10000, Loss: 0.9606, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3705/10000, Loss: 0.9604, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3706/10000, Loss: 0.9602, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3707/10000, Loss: 0.9600, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3708/10000, Loss: 0.9598, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3709/10000, Loss: 0.9596, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3710/10000, Loss: 0.9595, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3711/10000, Loss: 0.9593, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3712/10000, Loss: 0.9591, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3713/10000, Loss: 0.9589, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3714/10000, Loss: 0.9587, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3715/10000, Loss: 0.9586, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3716/10000, Loss: 0.9584, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3717/10000, Loss: 0.9582, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3718/10000, Loss: 0.9580, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3719/10000, Loss: 0.9578, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3720/10000, Loss: 0.9577, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3721/10000, Loss: 0.9575, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3722/10000, Loss: 0.9573, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3723/10000, Loss: 0.9571, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3724/10000, Loss: 0.9569, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3725/10000, Loss: 0.9568, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3726/10000, Loss: 0.9566, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3727/10000, Loss: 0.9564, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3728/10000, Loss: 0.9562, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3729/10000, Loss: 0.9560, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3730/10000, Loss: 0.9559, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3731/10000, Loss: 0.9557, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3732/10000, Loss: 0.9555, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3733/10000, Loss: 0.9553, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3734/10000, Loss: 0.9551, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3735/10000, Loss: 0.9550, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3736/10000, Loss: 0.9548, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3737/10000, Loss: 0.9546, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3738/10000, Loss: 0.9544, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3739/10000, Loss: 0.9543, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3740/10000, Loss: 0.9541, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3741/10000, Loss: 0.9539, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3742/10000, Loss: 0.9537, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3743/10000, Loss: 0.9535, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3744/10000, Loss: 0.9534, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3745/10000, Loss: 0.9532, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3746/10000, Loss: 0.9530, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3747/10000, Loss: 0.9528, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3748/10000, Loss: 0.9527, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3749/10000, Loss: 0.9525, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3750/10000, Loss: 0.9523, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3751/10000, Loss: 0.9521, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3752/10000, Loss: 0.9520, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3753/10000, Loss: 0.9518, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3754/10000, Loss: 0.9516, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3755/10000, Loss: 0.9514, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3756/10000, Loss: 0.9513, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3757/10000, Loss: 0.9511, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3758/10000, Loss: 0.9509, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3759/10000, Loss: 0.9507, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3760/10000, Loss: 0.9506, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3761/10000, Loss: 0.9504, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3762/10000, Loss: 0.9502, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3763/10000, Loss: 0.9500, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3764/10000, Loss: 0.9499, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3765/10000, Loss: 0.9497, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3766/10000, Loss: 0.9495, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3767/10000, Loss: 0.9494, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3768/10000, Loss: 0.9492, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3769/10000, Loss: 0.9490, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3770/10000, Loss: 0.9488, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3771/10000, Loss: 0.9487, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3772/10000, Loss: 0.9485, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3773/10000, Loss: 0.9483, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3774/10000, Loss: 0.9481, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3775/10000, Loss: 0.9480, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3776/10000, Loss: 0.9478, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3777/10000, Loss: 0.9476, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3778/10000, Loss: 0.9475, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3779/10000, Loss: 0.9473, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3780/10000, Loss: 0.9471, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3781/10000, Loss: 0.9470, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3782/10000, Loss: 0.9468, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3783/10000, Loss: 0.9466, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3784/10000, Loss: 0.9464, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3785/10000, Loss: 0.9463, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3786/10000, Loss: 0.9461, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3787/10000, Loss: 0.9459, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3788/10000, Loss: 0.9458, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3789/10000, Loss: 0.9456, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3790/10000, Loss: 0.9454, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3791/10000, Loss: 0.9453, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3792/10000, Loss: 0.9451, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3793/10000, Loss: 0.9449, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3794/10000, Loss: 0.9447, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3795/10000, Loss: 0.9446, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3796/10000, Loss: 0.9444, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3797/10000, Loss: 0.9442, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3798/10000, Loss: 0.9441, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3799/10000, Loss: 0.9439, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3800/10000, Loss: 0.9437, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3801/10000, Loss: 0.9436, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3802/10000, Loss: 0.9434, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3803/10000, Loss: 0.9432, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3804/10000, Loss: 0.9431, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3805/10000, Loss: 0.9429, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3806/10000, Loss: 0.9427, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3807/10000, Loss: 0.9426, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3808/10000, Loss: 0.9424, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3809/10000, Loss: 0.9422, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3810/10000, Loss: 0.9421, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3811/10000, Loss: 0.9419, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3812/10000, Loss: 0.9417, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3813/10000, Loss: 0.9416, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3814/10000, Loss: 0.9414, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3815/10000, Loss: 0.9413, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3816/10000, Loss: 0.9411, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3817/10000, Loss: 0.9409, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3818/10000, Loss: 0.9408, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3819/10000, Loss: 0.9406, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3820/10000, Loss: 0.9404, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3821/10000, Loss: 0.9403, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3822/10000, Loss: 0.9401, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3823/10000, Loss: 0.9399, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3824/10000, Loss: 0.9398, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3825/10000, Loss: 0.9396, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3826/10000, Loss: 0.9394, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3827/10000, Loss: 0.9393, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3828/10000, Loss: 0.9391, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3829/10000, Loss: 0.9390, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3830/10000, Loss: 0.9388, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3831/10000, Loss: 0.9386, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3832/10000, Loss: 0.9385, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3833/10000, Loss: 0.9383, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3834/10000, Loss: 0.9381, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3835/10000, Loss: 0.9380, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3836/10000, Loss: 0.9378, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3837/10000, Loss: 0.9377, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3838/10000, Loss: 0.9375, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3839/10000, Loss: 0.9373, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3840/10000, Loss: 0.9372, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3841/10000, Loss: 0.9370, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3842/10000, Loss: 0.9369, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3843/10000, Loss: 0.9367, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3844/10000, Loss: 0.9365, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3845/10000, Loss: 0.9364, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3846/10000, Loss: 0.9362, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3847/10000, Loss: 0.9361, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3848/10000, Loss: 0.9359, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3849/10000, Loss: 0.9357, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3850/10000, Loss: 0.9356, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3851/10000, Loss: 0.9354, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3852/10000, Loss: 0.9353, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3853/10000, Loss: 0.9351, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3854/10000, Loss: 0.9349, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3855/10000, Loss: 0.9348, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3856/10000, Loss: 0.9346, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3857/10000, Loss: 0.9345, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 3858/10000, Loss: 0.9343, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3859/10000, Loss: 0.9341, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3860/10000, Loss: 0.9340, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3861/10000, Loss: 0.9338, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3862/10000, Loss: 0.9337, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3863/10000, Loss: 0.9335, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3864/10000, Loss: 0.9334, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3865/10000, Loss: 0.9332, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3866/10000, Loss: 0.9330, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3867/10000, Loss: 0.9329, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3868/10000, Loss: 0.9327, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3869/10000, Loss: 0.9326, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3870/10000, Loss: 0.9324, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3871/10000, Loss: 0.9323, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3872/10000, Loss: 0.9321, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3873/10000, Loss: 0.9319, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3874/10000, Loss: 0.9318, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3875/10000, Loss: 0.9316, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3876/10000, Loss: 0.9315, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3877/10000, Loss: 0.9313, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3878/10000, Loss: 0.9312, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3879/10000, Loss: 0.9310, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3880/10000, Loss: 0.9309, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3881/10000, Loss: 0.9307, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3882/10000, Loss: 0.9305, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3883/10000, Loss: 0.9304, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3884/10000, Loss: 0.9302, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3885/10000, Loss: 0.9301, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3886/10000, Loss: 0.9299, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3887/10000, Loss: 0.9298, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3888/10000, Loss: 0.9296, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3889/10000, Loss: 0.9295, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3890/10000, Loss: 0.9293, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3891/10000, Loss: 0.9292, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3892/10000, Loss: 0.9290, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3893/10000, Loss: 0.9289, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3894/10000, Loss: 0.9287, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3895/10000, Loss: 0.9285, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3896/10000, Loss: 0.9284, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3897/10000, Loss: 0.9282, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3898/10000, Loss: 0.9281, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3899/10000, Loss: 0.9279, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3900/10000, Loss: 0.9278, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3901/10000, Loss: 0.9276, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3902/10000, Loss: 0.9275, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3903/10000, Loss: 0.9273, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3904/10000, Loss: 0.9272, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3905/10000, Loss: 0.9270, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3906/10000, Loss: 0.9269, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3907/10000, Loss: 0.9267, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3908/10000, Loss: 0.9266, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3909/10000, Loss: 0.9264, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3910/10000, Loss: 0.9263, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3911/10000, Loss: 0.9261, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3912/10000, Loss: 0.9260, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3913/10000, Loss: 0.9258, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3914/10000, Loss: 0.9257, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3915/10000, Loss: 0.9255, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3916/10000, Loss: 0.9254, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3917/10000, Loss: 0.9252, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3918/10000, Loss: 0.9251, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3919/10000, Loss: 0.9249, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3920/10000, Loss: 0.9248, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3921/10000, Loss: 0.9246, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3922/10000, Loss: 0.9245, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3923/10000, Loss: 0.9243, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3924/10000, Loss: 0.9242, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3925/10000, Loss: 0.9240, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3926/10000, Loss: 0.9239, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3927/10000, Loss: 0.9237, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3928/10000, Loss: 0.9236, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3929/10000, Loss: 0.9234, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3930/10000, Loss: 0.9233, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3931/10000, Loss: 0.9231, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3932/10000, Loss: 0.9230, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3933/10000, Loss: 0.9228, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3934/10000, Loss: 0.9227, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3935/10000, Loss: 0.9226, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3936/10000, Loss: 0.9224, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3937/10000, Loss: 0.9223, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3938/10000, Loss: 0.9221, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3939/10000, Loss: 0.9220, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3940/10000, Loss: 0.9218, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3941/10000, Loss: 0.9217, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3942/10000, Loss: 0.9215, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3943/10000, Loss: 0.9214, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3944/10000, Loss: 0.9212, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3945/10000, Loss: 0.9211, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 3946/10000, Loss: 0.9209, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3947/10000, Loss: 0.9208, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3948/10000, Loss: 0.9207, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3949/10000, Loss: 0.9205, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3950/10000, Loss: 0.9204, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3951/10000, Loss: 0.9202, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3952/10000, Loss: 0.9201, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3953/10000, Loss: 0.9199, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3954/10000, Loss: 0.9198, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3955/10000, Loss: 0.9196, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3956/10000, Loss: 0.9195, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3957/10000, Loss: 0.9193, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3958/10000, Loss: 0.9192, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3959/10000, Loss: 0.9191, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3960/10000, Loss: 0.9189, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3961/10000, Loss: 0.9188, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3962/10000, Loss: 0.9186, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3963/10000, Loss: 0.9185, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3964/10000, Loss: 0.9183, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3965/10000, Loss: 0.9182, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3966/10000, Loss: 0.9181, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3967/10000, Loss: 0.9179, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3968/10000, Loss: 0.9178, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3969/10000, Loss: 0.9176, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3970/10000, Loss: 0.9175, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3971/10000, Loss: 0.9173, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3972/10000, Loss: 0.9172, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3973/10000, Loss: 0.9171, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3974/10000, Loss: 0.9169, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3975/10000, Loss: 0.9168, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3976/10000, Loss: 0.9166, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3977/10000, Loss: 0.9165, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3978/10000, Loss: 0.9164, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3979/10000, Loss: 0.9162, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3980/10000, Loss: 0.9161, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3981/10000, Loss: 0.9159, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3982/10000, Loss: 0.9158, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3983/10000, Loss: 0.9157, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3984/10000, Loss: 0.9155, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3985/10000, Loss: 0.9154, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3986/10000, Loss: 0.9152, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3987/10000, Loss: 0.9151, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3988/10000, Loss: 0.9149, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3989/10000, Loss: 0.9148, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3990/10000, Loss: 0.9147, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3991/10000, Loss: 0.9145, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3992/10000, Loss: 0.9144, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3993/10000, Loss: 0.9143, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3994/10000, Loss: 0.9141, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3995/10000, Loss: 0.9140, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3996/10000, Loss: 0.9138, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3997/10000, Loss: 0.9137, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3998/10000, Loss: 0.9136, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 3999/10000, Loss: 0.9134, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4000/10000, Loss: 0.9133, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4001/10000, Loss: 0.9131, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4002/10000, Loss: 0.9130, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4003/10000, Loss: 0.9129, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4004/10000, Loss: 0.9127, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4005/10000, Loss: 0.9126, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4006/10000, Loss: 0.9125, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4007/10000, Loss: 0.9123, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4008/10000, Loss: 0.9122, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4009/10000, Loss: 0.9120, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4010/10000, Loss: 0.9119, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4011/10000, Loss: 0.9118, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4012/10000, Loss: 0.9116, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4013/10000, Loss: 0.9115, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4014/10000, Loss: 0.9114, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4015/10000, Loss: 0.9112, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4016/10000, Loss: 0.9111, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4017/10000, Loss: 0.9110, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4018/10000, Loss: 0.9108, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4019/10000, Loss: 0.9107, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4020/10000, Loss: 0.9105, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4021/10000, Loss: 0.9104, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4022/10000, Loss: 0.9103, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4023/10000, Loss: 0.9101, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4024/10000, Loss: 0.9100, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4025/10000, Loss: 0.9099, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4026/10000, Loss: 0.9097, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4027/10000, Loss: 0.9096, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4028/10000, Loss: 0.9095, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4029/10000, Loss: 0.9093, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4030/10000, Loss: 0.9092, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4031/10000, Loss: 0.9091, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4032/10000, Loss: 0.9089, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4033/10000, Loss: 0.9088, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4034/10000, Loss: 0.9087, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4035/10000, Loss: 0.9085, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4036/10000, Loss: 0.9084, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4037/10000, Loss: 0.9083, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4038/10000, Loss: 0.9081, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4039/10000, Loss: 0.9080, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4040/10000, Loss: 0.9079, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4041/10000, Loss: 0.9077, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4042/10000, Loss: 0.9076, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4043/10000, Loss: 0.9075, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4044/10000, Loss: 0.9073, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4045/10000, Loss: 0.9072, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4046/10000, Loss: 0.9071, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4047/10000, Loss: 0.9069, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4048/10000, Loss: 0.9068, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4049/10000, Loss: 0.9067, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4050/10000, Loss: 0.9065, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4051/10000, Loss: 0.9064, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4052/10000, Loss: 0.9063, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4053/10000, Loss: 0.9061, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4054/10000, Loss: 0.9060, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4055/10000, Loss: 0.9059, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4056/10000, Loss: 0.9057, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4057/10000, Loss: 0.9056, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4058/10000, Loss: 0.9055, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4059/10000, Loss: 0.9054, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4060/10000, Loss: 0.9052, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4061/10000, Loss: 0.9051, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4062/10000, Loss: 0.9050, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4063/10000, Loss: 0.9048, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4064/10000, Loss: 0.9047, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4065/10000, Loss: 0.9046, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4066/10000, Loss: 0.9044, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4067/10000, Loss: 0.9043, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4068/10000, Loss: 0.9042, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4069/10000, Loss: 0.9041, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4070/10000, Loss: 0.9039, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4071/10000, Loss: 0.9038, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4072/10000, Loss: 0.9037, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4073/10000, Loss: 0.9035, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4074/10000, Loss: 0.9034, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4075/10000, Loss: 0.9033, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4076/10000, Loss: 0.9031, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4077/10000, Loss: 0.9030, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4078/10000, Loss: 0.9029, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4079/10000, Loss: 0.9028, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4080/10000, Loss: 0.9026, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4081/10000, Loss: 0.9025, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4082/10000, Loss: 0.9024, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4083/10000, Loss: 0.9023, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4084/10000, Loss: 0.9021, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4085/10000, Loss: 0.9020, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4086/10000, Loss: 0.9019, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4087/10000, Loss: 0.9017, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4088/10000, Loss: 0.9016, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4089/10000, Loss: 0.9015, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4090/10000, Loss: 0.9014, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4091/10000, Loss: 0.9012, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4092/10000, Loss: 0.9011, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4093/10000, Loss: 0.9010, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4094/10000, Loss: 0.9009, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4095/10000, Loss: 0.9007, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4096/10000, Loss: 0.9006, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4097/10000, Loss: 0.9005, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4098/10000, Loss: 0.9003, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4099/10000, Loss: 0.9002, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4100/10000, Loss: 0.9001, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4101/10000, Loss: 0.9000, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4102/10000, Loss: 0.8998, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4103/10000, Loss: 0.8997, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4104/10000, Loss: 0.8996, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4105/10000, Loss: 0.8995, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4106/10000, Loss: 0.8993, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4107/10000, Loss: 0.8992, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4108/10000, Loss: 0.8991, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4109/10000, Loss: 0.8990, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4110/10000, Loss: 0.8988, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4111/10000, Loss: 0.8987, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4112/10000, Loss: 0.8986, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4113/10000, Loss: 0.8985, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4114/10000, Loss: 0.8983, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4115/10000, Loss: 0.8982, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4116/10000, Loss: 0.8981, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4117/10000, Loss: 0.8980, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4118/10000, Loss: 0.8979, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4119/10000, Loss: 0.8977, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4120/10000, Loss: 0.8976, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4121/10000, Loss: 0.8975, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4122/10000, Loss: 0.8974, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4123/10000, Loss: 0.8972, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4124/10000, Loss: 0.8971, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4125/10000, Loss: 0.8970, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4126/10000, Loss: 0.8969, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4127/10000, Loss: 0.8967, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4128/10000, Loss: 0.8966, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4129/10000, Loss: 0.8965, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4130/10000, Loss: 0.8964, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4131/10000, Loss: 0.8963, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4132/10000, Loss: 0.8961, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4133/10000, Loss: 0.8960, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4134/10000, Loss: 0.8959, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4135/10000, Loss: 0.8958, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4136/10000, Loss: 0.8956, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4137/10000, Loss: 0.8955, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4138/10000, Loss: 0.8954, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4139/10000, Loss: 0.8953, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4140/10000, Loss: 0.8952, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4141/10000, Loss: 0.8950, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4142/10000, Loss: 0.8949, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4143/10000, Loss: 0.8948, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4144/10000, Loss: 0.8947, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4145/10000, Loss: 0.8946, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4146/10000, Loss: 0.8944, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4147/10000, Loss: 0.8943, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4148/10000, Loss: 0.8942, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4149/10000, Loss: 0.8941, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4150/10000, Loss: 0.8940, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4151/10000, Loss: 0.8938, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4152/10000, Loss: 0.8937, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4153/10000, Loss: 0.8936, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4154/10000, Loss: 0.8935, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4155/10000, Loss: 0.8934, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4156/10000, Loss: 0.8932, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4157/10000, Loss: 0.8931, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4158/10000, Loss: 0.8930, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4159/10000, Loss: 0.8929, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4160/10000, Loss: 0.8928, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4161/10000, Loss: 0.8926, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4162/10000, Loss: 0.8925, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4163/10000, Loss: 0.8924, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4164/10000, Loss: 0.8923, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4165/10000, Loss: 0.8922, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4166/10000, Loss: 0.8920, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4167/10000, Loss: 0.8919, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4168/10000, Loss: 0.8918, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4169/10000, Loss: 0.8917, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4170/10000, Loss: 0.8916, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4171/10000, Loss: 0.8915, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4172/10000, Loss: 0.8913, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4173/10000, Loss: 0.8912, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4174/10000, Loss: 0.8911, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4175/10000, Loss: 0.8910, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4176/10000, Loss: 0.8909, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4177/10000, Loss: 0.8908, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4178/10000, Loss: 0.8906, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4179/10000, Loss: 0.8905, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4180/10000, Loss: 0.8904, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4181/10000, Loss: 0.8903, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4182/10000, Loss: 0.8902, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4183/10000, Loss: 0.8900, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4184/10000, Loss: 0.8899, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4185/10000, Loss: 0.8898, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4186/10000, Loss: 0.8897, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4187/10000, Loss: 0.8896, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4188/10000, Loss: 0.8895, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4189/10000, Loss: 0.8894, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4190/10000, Loss: 0.8892, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4191/10000, Loss: 0.8891, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4192/10000, Loss: 0.8890, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4193/10000, Loss: 0.8889, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4194/10000, Loss: 0.8888, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4195/10000, Loss: 0.8887, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4196/10000, Loss: 0.8885, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4197/10000, Loss: 0.8884, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4198/10000, Loss: 0.8883, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4199/10000, Loss: 0.8882, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4200/10000, Loss: 0.8881, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4201/10000, Loss: 0.8880, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4202/10000, Loss: 0.8879, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4203/10000, Loss: 0.8877, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4204/10000, Loss: 0.8876, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4205/10000, Loss: 0.8875, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4206/10000, Loss: 0.8874, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4207/10000, Loss: 0.8873, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4208/10000, Loss: 0.8872, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4209/10000, Loss: 0.8871, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4210/10000, Loss: 0.8869, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4211/10000, Loss: 0.8868, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4212/10000, Loss: 0.8867, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4213/10000, Loss: 0.8866, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4214/10000, Loss: 0.8865, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4215/10000, Loss: 0.8864, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4216/10000, Loss: 0.8863, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4217/10000, Loss: 0.8861, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4218/10000, Loss: 0.8860, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4219/10000, Loss: 0.8859, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4220/10000, Loss: 0.8858, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4221/10000, Loss: 0.8857, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4222/10000, Loss: 0.8856, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4223/10000, Loss: 0.8855, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4224/10000, Loss: 0.8854, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4225/10000, Loss: 0.8852, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4226/10000, Loss: 0.8851, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4227/10000, Loss: 0.8850, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4228/10000, Loss: 0.8849, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4229/10000, Loss: 0.8848, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4230/10000, Loss: 0.8847, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4231/10000, Loss: 0.8846, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4232/10000, Loss: 0.8845, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4233/10000, Loss: 0.8844, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4234/10000, Loss: 0.8842, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4235/10000, Loss: 0.8841, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4236/10000, Loss: 0.8840, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4237/10000, Loss: 0.8839, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4238/10000, Loss: 0.8838, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4239/10000, Loss: 0.8837, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4240/10000, Loss: 0.8836, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4241/10000, Loss: 0.8835, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4242/10000, Loss: 0.8834, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4243/10000, Loss: 0.8832, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4244/10000, Loss: 0.8831, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4245/10000, Loss: 0.8830, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4246/10000, Loss: 0.8829, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4247/10000, Loss: 0.8828, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4248/10000, Loss: 0.8827, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4249/10000, Loss: 0.8826, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4250/10000, Loss: 0.8825, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4251/10000, Loss: 0.8824, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4252/10000, Loss: 0.8823, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4253/10000, Loss: 0.8821, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4254/10000, Loss: 0.8820, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4255/10000, Loss: 0.8819, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4256/10000, Loss: 0.8818, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4257/10000, Loss: 0.8817, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4258/10000, Loss: 0.8816, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4259/10000, Loss: 0.8815, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4260/10000, Loss: 0.8814, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4261/10000, Loss: 0.8813, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4262/10000, Loss: 0.8812, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4263/10000, Loss: 0.8811, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4264/10000, Loss: 0.8809, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4265/10000, Loss: 0.8808, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4266/10000, Loss: 0.8807, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4267/10000, Loss: 0.8806, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4268/10000, Loss: 0.8805, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4269/10000, Loss: 0.8804, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4270/10000, Loss: 0.8803, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4271/10000, Loss: 0.8802, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4272/10000, Loss: 0.8801, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4273/10000, Loss: 0.8800, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4274/10000, Loss: 0.8799, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4275/10000, Loss: 0.8798, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4276/10000, Loss: 0.8797, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4277/10000, Loss: 0.8795, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4278/10000, Loss: 0.8794, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4279/10000, Loss: 0.8793, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4280/10000, Loss: 0.8792, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4281/10000, Loss: 0.8791, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4282/10000, Loss: 0.8790, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4283/10000, Loss: 0.8789, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4284/10000, Loss: 0.8788, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4285/10000, Loss: 0.8787, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4286/10000, Loss: 0.8786, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4287/10000, Loss: 0.8785, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4288/10000, Loss: 0.8784, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4289/10000, Loss: 0.8783, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4290/10000, Loss: 0.8782, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4291/10000, Loss: 0.8781, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4292/10000, Loss: 0.8780, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4293/10000, Loss: 0.8778, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4294/10000, Loss: 0.8777, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4295/10000, Loss: 0.8776, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4296/10000, Loss: 0.8775, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4297/10000, Loss: 0.8774, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4298/10000, Loss: 0.8773, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4299/10000, Loss: 0.8772, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4300/10000, Loss: 0.8771, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4301/10000, Loss: 0.8770, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4302/10000, Loss: 0.8769, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4303/10000, Loss: 0.8768, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4304/10000, Loss: 0.8767, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4305/10000, Loss: 0.8766, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4306/10000, Loss: 0.8765, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4307/10000, Loss: 0.8764, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4308/10000, Loss: 0.8763, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4309/10000, Loss: 0.8762, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4310/10000, Loss: 0.8761, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4311/10000, Loss: 0.8760, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4312/10000, Loss: 0.8759, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4313/10000, Loss: 0.8758, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4314/10000, Loss: 0.8756, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4315/10000, Loss: 0.8755, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4316/10000, Loss: 0.8754, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4317/10000, Loss: 0.8753, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4318/10000, Loss: 0.8752, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4319/10000, Loss: 0.8751, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4320/10000, Loss: 0.8750, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4321/10000, Loss: 0.8749, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4322/10000, Loss: 0.8748, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4323/10000, Loss: 0.8747, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4324/10000, Loss: 0.8746, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4325/10000, Loss: 0.8745, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4326/10000, Loss: 0.8744, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4327/10000, Loss: 0.8743, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4328/10000, Loss: 0.8742, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4329/10000, Loss: 0.8741, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4330/10000, Loss: 0.8740, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4331/10000, Loss: 0.8739, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4332/10000, Loss: 0.8738, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4333/10000, Loss: 0.8737, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4334/10000, Loss: 0.8736, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4335/10000, Loss: 0.8735, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4336/10000, Loss: 0.8734, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4337/10000, Loss: 0.8733, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4338/10000, Loss: 0.8732, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4339/10000, Loss: 0.8731, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4340/10000, Loss: 0.8730, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4341/10000, Loss: 0.8729, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4342/10000, Loss: 0.8728, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4343/10000, Loss: 0.8727, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4344/10000, Loss: 0.8726, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4345/10000, Loss: 0.8725, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4346/10000, Loss: 0.8724, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4347/10000, Loss: 0.8723, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4348/10000, Loss: 0.8722, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4349/10000, Loss: 0.8721, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4350/10000, Loss: 0.8720, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4351/10000, Loss: 0.8719, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4352/10000, Loss: 0.8718, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4353/10000, Loss: 0.8717, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4354/10000, Loss: 0.8716, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4355/10000, Loss: 0.8715, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4356/10000, Loss: 0.8714, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4357/10000, Loss: 0.8713, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4358/10000, Loss: 0.8712, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4359/10000, Loss: 0.8711, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4360/10000, Loss: 0.8710, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4361/10000, Loss: 0.8709, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4362/10000, Loss: 0.8708, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4363/10000, Loss: 0.8707, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4364/10000, Loss: 0.8706, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4365/10000, Loss: 0.8705, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4366/10000, Loss: 0.8704, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4367/10000, Loss: 0.8703, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4368/10000, Loss: 0.8702, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4369/10000, Loss: 0.8701, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4370/10000, Loss: 0.8700, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4371/10000, Loss: 0.8699, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4372/10000, Loss: 0.8698, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4373/10000, Loss: 0.8697, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4374/10000, Loss: 0.8696, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4375/10000, Loss: 0.8695, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4376/10000, Loss: 0.8694, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4377/10000, Loss: 0.8693, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4378/10000, Loss: 0.8692, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4379/10000, Loss: 0.8691, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4380/10000, Loss: 0.8690, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4381/10000, Loss: 0.8689, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4382/10000, Loss: 0.8688, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4383/10000, Loss: 0.8687, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4384/10000, Loss: 0.8686, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4385/10000, Loss: 0.8685, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4386/10000, Loss: 0.8684, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4387/10000, Loss: 0.8683, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4388/10000, Loss: 0.8682, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4389/10000, Loss: 0.8681, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4390/10000, Loss: 0.8680, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4391/10000, Loss: 0.8679, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4392/10000, Loss: 0.8678, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4393/10000, Loss: 0.8677, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4394/10000, Loss: 0.8676, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4395/10000, Loss: 0.8675, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4396/10000, Loss: 0.8674, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4397/10000, Loss: 0.8673, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4398/10000, Loss: 0.8672, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4399/10000, Loss: 0.8671, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4400/10000, Loss: 0.8670, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4401/10000, Loss: 0.8669, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4402/10000, Loss: 0.8669, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4403/10000, Loss: 0.8668, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4404/10000, Loss: 0.8667, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4405/10000, Loss: 0.8666, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4406/10000, Loss: 0.8665, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4407/10000, Loss: 0.8664, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4408/10000, Loss: 0.8663, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4409/10000, Loss: 0.8662, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4410/10000, Loss: 0.8661, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4411/10000, Loss: 0.8660, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4412/10000, Loss: 0.8659, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4413/10000, Loss: 0.8658, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4414/10000, Loss: 0.8657, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4415/10000, Loss: 0.8656, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4416/10000, Loss: 0.8655, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4417/10000, Loss: 0.8654, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4418/10000, Loss: 0.8653, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4419/10000, Loss: 0.8652, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4420/10000, Loss: 0.8651, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4421/10000, Loss: 0.8650, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4422/10000, Loss: 0.8649, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4423/10000, Loss: 0.8648, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4424/10000, Loss: 0.8648, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4425/10000, Loss: 0.8647, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4426/10000, Loss: 0.8646, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4427/10000, Loss: 0.8645, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4428/10000, Loss: 0.8644, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4429/10000, Loss: 0.8643, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4430/10000, Loss: 0.8642, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4431/10000, Loss: 0.8641, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4432/10000, Loss: 0.8640, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4433/10000, Loss: 0.8639, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4434/10000, Loss: 0.8638, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4435/10000, Loss: 0.8637, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4436/10000, Loss: 0.8636, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4437/10000, Loss: 0.8635, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4438/10000, Loss: 0.8634, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4439/10000, Loss: 0.8633, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4440/10000, Loss: 0.8632, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4441/10000, Loss: 0.8632, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4442/10000, Loss: 0.8631, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4443/10000, Loss: 0.8630, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4444/10000, Loss: 0.8629, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4445/10000, Loss: 0.8628, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4446/10000, Loss: 0.8627, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4447/10000, Loss: 0.8626, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4448/10000, Loss: 0.8625, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4449/10000, Loss: 0.8624, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4450/10000, Loss: 0.8623, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4451/10000, Loss: 0.8622, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4452/10000, Loss: 0.8621, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4453/10000, Loss: 0.8620, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4454/10000, Loss: 0.8619, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4455/10000, Loss: 0.8619, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4456/10000, Loss: 0.8618, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4457/10000, Loss: 0.8617, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4458/10000, Loss: 0.8616, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4459/10000, Loss: 0.8615, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4460/10000, Loss: 0.8614, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4461/10000, Loss: 0.8613, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4462/10000, Loss: 0.8612, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4463/10000, Loss: 0.8611, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4464/10000, Loss: 0.8610, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4465/10000, Loss: 0.8609, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4466/10000, Loss: 0.8608, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4467/10000, Loss: 0.8608, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4468/10000, Loss: 0.8607, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4469/10000, Loss: 0.8606, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4470/10000, Loss: 0.8605, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4471/10000, Loss: 0.8604, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4472/10000, Loss: 0.8603, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4473/10000, Loss: 0.8602, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4474/10000, Loss: 0.8601, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4475/10000, Loss: 0.8600, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4476/10000, Loss: 0.8599, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4477/10000, Loss: 0.8598, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4478/10000, Loss: 0.8598, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4479/10000, Loss: 0.8597, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4480/10000, Loss: 0.8596, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4481/10000, Loss: 0.8595, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4482/10000, Loss: 0.8594, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4483/10000, Loss: 0.8593, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4484/10000, Loss: 0.8592, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4485/10000, Loss: 0.8591, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4486/10000, Loss: 0.8590, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4487/10000, Loss: 0.8589, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4488/10000, Loss: 0.8589, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4489/10000, Loss: 0.8588, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4490/10000, Loss: 0.8587, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4491/10000, Loss: 0.8586, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4492/10000, Loss: 0.8585, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4493/10000, Loss: 0.8584, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4494/10000, Loss: 0.8583, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4495/10000, Loss: 0.8582, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4496/10000, Loss: 0.8581, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4497/10000, Loss: 0.8580, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4498/10000, Loss: 0.8580, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4499/10000, Loss: 0.8579, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4500/10000, Loss: 0.8578, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4501/10000, Loss: 0.8577, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4502/10000, Loss: 0.8576, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4503/10000, Loss: 0.8575, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4504/10000, Loss: 0.8574, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4505/10000, Loss: 0.8573, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4506/10000, Loss: 0.8572, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4507/10000, Loss: 0.8572, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4508/10000, Loss: 0.8571, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4509/10000, Loss: 0.8570, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4510/10000, Loss: 0.8569, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4511/10000, Loss: 0.8568, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4512/10000, Loss: 0.8567, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4513/10000, Loss: 0.8566, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4514/10000, Loss: 0.8565, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4515/10000, Loss: 0.8565, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4516/10000, Loss: 0.8564, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4517/10000, Loss: 0.8563, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4518/10000, Loss: 0.8562, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4519/10000, Loss: 0.8561, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4520/10000, Loss: 0.8560, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4521/10000, Loss: 0.8559, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4522/10000, Loss: 0.8558, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4523/10000, Loss: 0.8558, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4524/10000, Loss: 0.8557, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4525/10000, Loss: 0.8556, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4526/10000, Loss: 0.8555, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4527/10000, Loss: 0.8554, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4528/10000, Loss: 0.8553, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4529/10000, Loss: 0.8552, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4530/10000, Loss: 0.8551, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4531/10000, Loss: 0.8551, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4532/10000, Loss: 0.8550, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4533/10000, Loss: 0.8549, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4534/10000, Loss: 0.8548, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4535/10000, Loss: 0.8547, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4536/10000, Loss: 0.8546, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4537/10000, Loss: 0.8545, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4538/10000, Loss: 0.8545, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4539/10000, Loss: 0.8544, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4540/10000, Loss: 0.8543, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4541/10000, Loss: 0.8542, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4542/10000, Loss: 0.8541, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4543/10000, Loss: 0.8540, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4544/10000, Loss: 0.8539, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4545/10000, Loss: 0.8538, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4546/10000, Loss: 0.8538, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4547/10000, Loss: 0.8537, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4548/10000, Loss: 0.8536, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4549/10000, Loss: 0.8535, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4550/10000, Loss: 0.8534, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4551/10000, Loss: 0.8533, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4552/10000, Loss: 0.8532, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4553/10000, Loss: 0.8532, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4554/10000, Loss: 0.8531, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4555/10000, Loss: 0.8530, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4556/10000, Loss: 0.8529, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4557/10000, Loss: 0.8528, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4558/10000, Loss: 0.8527, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4559/10000, Loss: 0.8527, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4560/10000, Loss: 0.8526, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4561/10000, Loss: 0.8525, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4562/10000, Loss: 0.8524, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4563/10000, Loss: 0.8523, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4564/10000, Loss: 0.8522, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4565/10000, Loss: 0.8521, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4566/10000, Loss: 0.8521, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4567/10000, Loss: 0.8520, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4568/10000, Loss: 0.8519, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4569/10000, Loss: 0.8518, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4570/10000, Loss: 0.8517, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4571/10000, Loss: 0.8516, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4572/10000, Loss: 0.8516, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4573/10000, Loss: 0.8515, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4574/10000, Loss: 0.8514, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4575/10000, Loss: 0.8513, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4576/10000, Loss: 0.8512, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4577/10000, Loss: 0.8511, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4578/10000, Loss: 0.8511, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4579/10000, Loss: 0.8510, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4580/10000, Loss: 0.8509, Accuracy: 0.6443, Learning Rate: 0.000100\n",
      "Epoch 4581/10000, Loss: 0.8508, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4582/10000, Loss: 0.8507, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4583/10000, Loss: 0.8506, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4584/10000, Loss: 0.8506, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4585/10000, Loss: 0.8505, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4586/10000, Loss: 0.8504, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4587/10000, Loss: 0.8503, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4588/10000, Loss: 0.8502, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4589/10000, Loss: 0.8501, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4590/10000, Loss: 0.8501, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4591/10000, Loss: 0.8500, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4592/10000, Loss: 0.8499, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4593/10000, Loss: 0.8498, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4594/10000, Loss: 0.8497, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4595/10000, Loss: 0.8496, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4596/10000, Loss: 0.8496, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4597/10000, Loss: 0.8495, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4598/10000, Loss: 0.8494, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4599/10000, Loss: 0.8493, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4600/10000, Loss: 0.8492, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4601/10000, Loss: 0.8491, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4602/10000, Loss: 0.8491, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4603/10000, Loss: 0.8490, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4604/10000, Loss: 0.8489, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4605/10000, Loss: 0.8488, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4606/10000, Loss: 0.8487, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4607/10000, Loss: 0.8487, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4608/10000, Loss: 0.8486, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4609/10000, Loss: 0.8485, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4610/10000, Loss: 0.8484, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4611/10000, Loss: 0.8483, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4612/10000, Loss: 0.8482, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4613/10000, Loss: 0.8482, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4614/10000, Loss: 0.8481, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4615/10000, Loss: 0.8480, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4616/10000, Loss: 0.8479, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4617/10000, Loss: 0.8478, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4618/10000, Loss: 0.8478, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4619/10000, Loss: 0.8477, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4620/10000, Loss: 0.8476, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4621/10000, Loss: 0.8475, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4622/10000, Loss: 0.8474, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4623/10000, Loss: 0.8474, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4624/10000, Loss: 0.8473, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4625/10000, Loss: 0.8472, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4626/10000, Loss: 0.8471, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4627/10000, Loss: 0.8470, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4628/10000, Loss: 0.8469, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4629/10000, Loss: 0.8469, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4630/10000, Loss: 0.8468, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4631/10000, Loss: 0.8467, Accuracy: 0.6462, Learning Rate: 0.000100\n",
      "Epoch 4632/10000, Loss: 0.8466, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4633/10000, Loss: 0.8465, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4634/10000, Loss: 0.8465, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4635/10000, Loss: 0.8464, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4636/10000, Loss: 0.8463, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4637/10000, Loss: 0.8462, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4638/10000, Loss: 0.8461, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4639/10000, Loss: 0.8461, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4640/10000, Loss: 0.8460, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4641/10000, Loss: 0.8459, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4642/10000, Loss: 0.8458, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4643/10000, Loss: 0.8457, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4644/10000, Loss: 0.8457, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4645/10000, Loss: 0.8456, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4646/10000, Loss: 0.8455, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4647/10000, Loss: 0.8454, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4648/10000, Loss: 0.8454, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4649/10000, Loss: 0.8453, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4650/10000, Loss: 0.8452, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4651/10000, Loss: 0.8451, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4652/10000, Loss: 0.8450, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4653/10000, Loss: 0.8450, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4654/10000, Loss: 0.8449, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4655/10000, Loss: 0.8448, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4656/10000, Loss: 0.8447, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4657/10000, Loss: 0.8446, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4658/10000, Loss: 0.8446, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4659/10000, Loss: 0.8445, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4660/10000, Loss: 0.8444, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4661/10000, Loss: 0.8443, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4662/10000, Loss: 0.8442, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4663/10000, Loss: 0.8442, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4664/10000, Loss: 0.8441, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4665/10000, Loss: 0.8440, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4666/10000, Loss: 0.8439, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4667/10000, Loss: 0.8439, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4668/10000, Loss: 0.8438, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4669/10000, Loss: 0.8437, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4670/10000, Loss: 0.8436, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4671/10000, Loss: 0.8435, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4672/10000, Loss: 0.8435, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4673/10000, Loss: 0.8434, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4674/10000, Loss: 0.8433, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4675/10000, Loss: 0.8432, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4676/10000, Loss: 0.8432, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4677/10000, Loss: 0.8431, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4678/10000, Loss: 0.8430, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4679/10000, Loss: 0.8429, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4680/10000, Loss: 0.8428, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4681/10000, Loss: 0.8428, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4682/10000, Loss: 0.8427, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4683/10000, Loss: 0.8426, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4684/10000, Loss: 0.8425, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4685/10000, Loss: 0.8425, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4686/10000, Loss: 0.8424, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4687/10000, Loss: 0.8423, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4688/10000, Loss: 0.8422, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4689/10000, Loss: 0.8422, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4690/10000, Loss: 0.8421, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4691/10000, Loss: 0.8420, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4692/10000, Loss: 0.8419, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4693/10000, Loss: 0.8418, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4694/10000, Loss: 0.8418, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4695/10000, Loss: 0.8417, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4696/10000, Loss: 0.8416, Accuracy: 0.6480, Learning Rate: 0.000100\n",
      "Epoch 4697/10000, Loss: 0.8415, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4698/10000, Loss: 0.8415, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4699/10000, Loss: 0.8414, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4700/10000, Loss: 0.8413, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4701/10000, Loss: 0.8412, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4702/10000, Loss: 0.8412, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4703/10000, Loss: 0.8411, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4704/10000, Loss: 0.8410, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4705/10000, Loss: 0.8409, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4706/10000, Loss: 0.8409, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4707/10000, Loss: 0.8408, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4708/10000, Loss: 0.8407, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4709/10000, Loss: 0.8406, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4710/10000, Loss: 0.8406, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4711/10000, Loss: 0.8405, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4712/10000, Loss: 0.8404, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4713/10000, Loss: 0.8403, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4714/10000, Loss: 0.8402, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4715/10000, Loss: 0.8402, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4716/10000, Loss: 0.8401, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4717/10000, Loss: 0.8400, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4718/10000, Loss: 0.8399, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4719/10000, Loss: 0.8399, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4720/10000, Loss: 0.8398, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4721/10000, Loss: 0.8397, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4722/10000, Loss: 0.8396, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4723/10000, Loss: 0.8396, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4724/10000, Loss: 0.8395, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4725/10000, Loss: 0.8394, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4726/10000, Loss: 0.8393, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4727/10000, Loss: 0.8393, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4728/10000, Loss: 0.8392, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4729/10000, Loss: 0.8391, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4730/10000, Loss: 0.8391, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4731/10000, Loss: 0.8390, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4732/10000, Loss: 0.8389, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4733/10000, Loss: 0.8388, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4734/10000, Loss: 0.8388, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4735/10000, Loss: 0.8387, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4736/10000, Loss: 0.8386, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4737/10000, Loss: 0.8385, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4738/10000, Loss: 0.8385, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4739/10000, Loss: 0.8384, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4740/10000, Loss: 0.8383, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4741/10000, Loss: 0.8382, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4742/10000, Loss: 0.8382, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4743/10000, Loss: 0.8381, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4744/10000, Loss: 0.8380, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4745/10000, Loss: 0.8379, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4746/10000, Loss: 0.8379, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4747/10000, Loss: 0.8378, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4748/10000, Loss: 0.8377, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4749/10000, Loss: 0.8376, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4750/10000, Loss: 0.8376, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4751/10000, Loss: 0.8375, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4752/10000, Loss: 0.8374, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4753/10000, Loss: 0.8374, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4754/10000, Loss: 0.8373, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4755/10000, Loss: 0.8372, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4756/10000, Loss: 0.8371, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4757/10000, Loss: 0.8371, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4758/10000, Loss: 0.8370, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4759/10000, Loss: 0.8369, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4760/10000, Loss: 0.8368, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4761/10000, Loss: 0.8368, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4762/10000, Loss: 0.8367, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4763/10000, Loss: 0.8366, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4764/10000, Loss: 0.8365, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4765/10000, Loss: 0.8365, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4766/10000, Loss: 0.8364, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4767/10000, Loss: 0.8363, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4768/10000, Loss: 0.8363, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4769/10000, Loss: 0.8362, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4770/10000, Loss: 0.8361, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4771/10000, Loss: 0.8360, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4772/10000, Loss: 0.8360, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4773/10000, Loss: 0.8359, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4774/10000, Loss: 0.8358, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4775/10000, Loss: 0.8358, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4776/10000, Loss: 0.8357, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4777/10000, Loss: 0.8356, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4778/10000, Loss: 0.8355, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4779/10000, Loss: 0.8355, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4780/10000, Loss: 0.8354, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4781/10000, Loss: 0.8353, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4782/10000, Loss: 0.8353, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4783/10000, Loss: 0.8352, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4784/10000, Loss: 0.8351, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4785/10000, Loss: 0.8350, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4786/10000, Loss: 0.8350, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4787/10000, Loss: 0.8349, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4788/10000, Loss: 0.8348, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4789/10000, Loss: 0.8348, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4790/10000, Loss: 0.8347, Accuracy: 0.6499, Learning Rate: 0.000100\n",
      "Epoch 4791/10000, Loss: 0.8346, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4792/10000, Loss: 0.8345, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4793/10000, Loss: 0.8345, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4794/10000, Loss: 0.8344, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4795/10000, Loss: 0.8343, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4796/10000, Loss: 0.8343, Accuracy: 0.6518, Learning Rate: 0.000100\n",
      "Epoch 4797/10000, Loss: 0.8342, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4798/10000, Loss: 0.8341, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4799/10000, Loss: 0.8340, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4800/10000, Loss: 0.8340, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4801/10000, Loss: 0.8339, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4802/10000, Loss: 0.8338, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4803/10000, Loss: 0.8338, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4804/10000, Loss: 0.8337, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4805/10000, Loss: 0.8336, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4806/10000, Loss: 0.8335, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4807/10000, Loss: 0.8335, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4808/10000, Loss: 0.8334, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4809/10000, Loss: 0.8333, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4810/10000, Loss: 0.8333, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4811/10000, Loss: 0.8332, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4812/10000, Loss: 0.8331, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4813/10000, Loss: 0.8331, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4814/10000, Loss: 0.8330, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4815/10000, Loss: 0.8329, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4816/10000, Loss: 0.8328, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4817/10000, Loss: 0.8328, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4818/10000, Loss: 0.8327, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4819/10000, Loss: 0.8326, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4820/10000, Loss: 0.8326, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4821/10000, Loss: 0.8325, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4822/10000, Loss: 0.8324, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4823/10000, Loss: 0.8324, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4824/10000, Loss: 0.8323, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4825/10000, Loss: 0.8322, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4826/10000, Loss: 0.8321, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4827/10000, Loss: 0.8321, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4828/10000, Loss: 0.8320, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4829/10000, Loss: 0.8319, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4830/10000, Loss: 0.8319, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4831/10000, Loss: 0.8318, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4832/10000, Loss: 0.8317, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4833/10000, Loss: 0.8317, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4834/10000, Loss: 0.8316, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4835/10000, Loss: 0.8315, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4836/10000, Loss: 0.8315, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4837/10000, Loss: 0.8314, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4838/10000, Loss: 0.8313, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4839/10000, Loss: 0.8313, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4840/10000, Loss: 0.8312, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4841/10000, Loss: 0.8311, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4842/10000, Loss: 0.8310, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4843/10000, Loss: 0.8310, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4844/10000, Loss: 0.8309, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4845/10000, Loss: 0.8308, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4846/10000, Loss: 0.8308, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4847/10000, Loss: 0.8307, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4848/10000, Loss: 0.8306, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4849/10000, Loss: 0.8306, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4850/10000, Loss: 0.8305, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4851/10000, Loss: 0.8304, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4852/10000, Loss: 0.8304, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4853/10000, Loss: 0.8303, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4854/10000, Loss: 0.8302, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4855/10000, Loss: 0.8302, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4856/10000, Loss: 0.8301, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4857/10000, Loss: 0.8300, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4858/10000, Loss: 0.8300, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4859/10000, Loss: 0.8299, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4860/10000, Loss: 0.8298, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4861/10000, Loss: 0.8298, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4862/10000, Loss: 0.8297, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4863/10000, Loss: 0.8296, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4864/10000, Loss: 0.8295, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4865/10000, Loss: 0.8295, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4866/10000, Loss: 0.8294, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4867/10000, Loss: 0.8293, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4868/10000, Loss: 0.8293, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4869/10000, Loss: 0.8292, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4870/10000, Loss: 0.8291, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4871/10000, Loss: 0.8291, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4872/10000, Loss: 0.8290, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4873/10000, Loss: 0.8289, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4874/10000, Loss: 0.8289, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4875/10000, Loss: 0.8288, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4876/10000, Loss: 0.8287, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4877/10000, Loss: 0.8287, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4878/10000, Loss: 0.8286, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4879/10000, Loss: 0.8285, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4880/10000, Loss: 0.8285, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4881/10000, Loss: 0.8284, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4882/10000, Loss: 0.8283, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4883/10000, Loss: 0.8283, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4884/10000, Loss: 0.8282, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4885/10000, Loss: 0.8281, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4886/10000, Loss: 0.8281, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4887/10000, Loss: 0.8280, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4888/10000, Loss: 0.8279, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4889/10000, Loss: 0.8279, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4890/10000, Loss: 0.8278, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4891/10000, Loss: 0.8277, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4892/10000, Loss: 0.8277, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4893/10000, Loss: 0.8276, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4894/10000, Loss: 0.8275, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4895/10000, Loss: 0.8275, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4896/10000, Loss: 0.8274, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4897/10000, Loss: 0.8273, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4898/10000, Loss: 0.8273, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4899/10000, Loss: 0.8272, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4900/10000, Loss: 0.8272, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4901/10000, Loss: 0.8271, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4902/10000, Loss: 0.8270, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4903/10000, Loss: 0.8270, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4904/10000, Loss: 0.8269, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4905/10000, Loss: 0.8268, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4906/10000, Loss: 0.8268, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4907/10000, Loss: 0.8267, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4908/10000, Loss: 0.8266, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4909/10000, Loss: 0.8266, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4910/10000, Loss: 0.8265, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4911/10000, Loss: 0.8264, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4912/10000, Loss: 0.8264, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4913/10000, Loss: 0.8263, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4914/10000, Loss: 0.8262, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4915/10000, Loss: 0.8262, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4916/10000, Loss: 0.8261, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4917/10000, Loss: 0.8260, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4918/10000, Loss: 0.8260, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4919/10000, Loss: 0.8259, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4920/10000, Loss: 0.8258, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4921/10000, Loss: 0.8258, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4922/10000, Loss: 0.8257, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4923/10000, Loss: 0.8257, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4924/10000, Loss: 0.8256, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4925/10000, Loss: 0.8255, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4926/10000, Loss: 0.8255, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4927/10000, Loss: 0.8254, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4928/10000, Loss: 0.8253, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4929/10000, Loss: 0.8253, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4930/10000, Loss: 0.8252, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4931/10000, Loss: 0.8251, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4932/10000, Loss: 0.8251, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4933/10000, Loss: 0.8250, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4934/10000, Loss: 0.8249, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4935/10000, Loss: 0.8249, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4936/10000, Loss: 0.8248, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4937/10000, Loss: 0.8248, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4938/10000, Loss: 0.8247, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4939/10000, Loss: 0.8246, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4940/10000, Loss: 0.8246, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4941/10000, Loss: 0.8245, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4942/10000, Loss: 0.8244, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4943/10000, Loss: 0.8244, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4944/10000, Loss: 0.8243, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4945/10000, Loss: 0.8242, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4946/10000, Loss: 0.8242, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4947/10000, Loss: 0.8241, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4948/10000, Loss: 0.8241, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4949/10000, Loss: 0.8240, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4950/10000, Loss: 0.8239, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4951/10000, Loss: 0.8239, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4952/10000, Loss: 0.8238, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4953/10000, Loss: 0.8237, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4954/10000, Loss: 0.8237, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4955/10000, Loss: 0.8236, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4956/10000, Loss: 0.8235, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4957/10000, Loss: 0.8235, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4958/10000, Loss: 0.8234, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4959/10000, Loss: 0.8234, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4960/10000, Loss: 0.8233, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 4961/10000, Loss: 0.8232, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4962/10000, Loss: 0.8232, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4963/10000, Loss: 0.8231, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4964/10000, Loss: 0.8230, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4965/10000, Loss: 0.8230, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4966/10000, Loss: 0.8229, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4967/10000, Loss: 0.8229, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4968/10000, Loss: 0.8228, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4969/10000, Loss: 0.8227, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4970/10000, Loss: 0.8227, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4971/10000, Loss: 0.8226, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4972/10000, Loss: 0.8225, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4973/10000, Loss: 0.8225, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4974/10000, Loss: 0.8224, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4975/10000, Loss: 0.8224, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4976/10000, Loss: 0.8223, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4977/10000, Loss: 0.8222, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4978/10000, Loss: 0.8222, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4979/10000, Loss: 0.8221, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4980/10000, Loss: 0.8220, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4981/10000, Loss: 0.8220, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4982/10000, Loss: 0.8219, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4983/10000, Loss: 0.8219, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4984/10000, Loss: 0.8218, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4985/10000, Loss: 0.8217, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4986/10000, Loss: 0.8217, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4987/10000, Loss: 0.8216, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4988/10000, Loss: 0.8215, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4989/10000, Loss: 0.8215, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4990/10000, Loss: 0.8214, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4991/10000, Loss: 0.8214, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4992/10000, Loss: 0.8213, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4993/10000, Loss: 0.8212, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4994/10000, Loss: 0.8212, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4995/10000, Loss: 0.8211, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4996/10000, Loss: 0.8211, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4997/10000, Loss: 0.8210, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4998/10000, Loss: 0.8209, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 4999/10000, Loss: 0.8209, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5000/10000, Loss: 0.8208, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5001/10000, Loss: 0.8208, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5002/10000, Loss: 0.8207, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5003/10000, Loss: 0.8206, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5004/10000, Loss: 0.8206, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5005/10000, Loss: 0.8205, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5006/10000, Loss: 0.8204, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5007/10000, Loss: 0.8204, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5008/10000, Loss: 0.8203, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5009/10000, Loss: 0.8203, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5010/10000, Loss: 0.8202, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5011/10000, Loss: 0.8201, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5012/10000, Loss: 0.8201, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5013/10000, Loss: 0.8200, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5014/10000, Loss: 0.8200, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5015/10000, Loss: 0.8199, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5016/10000, Loss: 0.8198, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5017/10000, Loss: 0.8198, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5018/10000, Loss: 0.8197, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5019/10000, Loss: 0.8197, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5020/10000, Loss: 0.8196, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5021/10000, Loss: 0.8195, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5022/10000, Loss: 0.8195, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5023/10000, Loss: 0.8194, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5024/10000, Loss: 0.8194, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5025/10000, Loss: 0.8193, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5026/10000, Loss: 0.8192, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5027/10000, Loss: 0.8192, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5028/10000, Loss: 0.8191, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5029/10000, Loss: 0.8191, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5030/10000, Loss: 0.8190, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5031/10000, Loss: 0.8189, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5032/10000, Loss: 0.8189, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5033/10000, Loss: 0.8188, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5034/10000, Loss: 0.8188, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5035/10000, Loss: 0.8187, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5036/10000, Loss: 0.8186, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5037/10000, Loss: 0.8186, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5038/10000, Loss: 0.8185, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5039/10000, Loss: 0.8185, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5040/10000, Loss: 0.8184, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5041/10000, Loss: 0.8183, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5042/10000, Loss: 0.8183, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5043/10000, Loss: 0.8182, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5044/10000, Loss: 0.8182, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5045/10000, Loss: 0.8181, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5046/10000, Loss: 0.8180, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5047/10000, Loss: 0.8180, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5048/10000, Loss: 0.8179, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5049/10000, Loss: 0.8179, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5050/10000, Loss: 0.8178, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5051/10000, Loss: 0.8177, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5052/10000, Loss: 0.8177, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5053/10000, Loss: 0.8176, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5054/10000, Loss: 0.8176, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5055/10000, Loss: 0.8175, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5056/10000, Loss: 0.8175, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5057/10000, Loss: 0.8174, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5058/10000, Loss: 0.8173, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5059/10000, Loss: 0.8173, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5060/10000, Loss: 0.8172, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5061/10000, Loss: 0.8172, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5062/10000, Loss: 0.8171, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5063/10000, Loss: 0.8170, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5064/10000, Loss: 0.8170, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5065/10000, Loss: 0.8169, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5066/10000, Loss: 0.8169, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5067/10000, Loss: 0.8168, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5068/10000, Loss: 0.8168, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5069/10000, Loss: 0.8167, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5070/10000, Loss: 0.8166, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5071/10000, Loss: 0.8166, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5072/10000, Loss: 0.8165, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5073/10000, Loss: 0.8165, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5074/10000, Loss: 0.8164, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5075/10000, Loss: 0.8163, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5076/10000, Loss: 0.8163, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5077/10000, Loss: 0.8162, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5078/10000, Loss: 0.8162, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5079/10000, Loss: 0.8161, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5080/10000, Loss: 0.8161, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5081/10000, Loss: 0.8160, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5082/10000, Loss: 0.8159, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5083/10000, Loss: 0.8159, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5084/10000, Loss: 0.8158, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5085/10000, Loss: 0.8158, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5086/10000, Loss: 0.8157, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5087/10000, Loss: 0.8157, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5088/10000, Loss: 0.8156, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5089/10000, Loss: 0.8155, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5090/10000, Loss: 0.8155, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5091/10000, Loss: 0.8154, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5092/10000, Loss: 0.8154, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5093/10000, Loss: 0.8153, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5094/10000, Loss: 0.8152, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5095/10000, Loss: 0.8152, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5096/10000, Loss: 0.8151, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5097/10000, Loss: 0.8151, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5098/10000, Loss: 0.8150, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5099/10000, Loss: 0.8150, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5100/10000, Loss: 0.8149, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5101/10000, Loss: 0.8148, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5102/10000, Loss: 0.8148, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5103/10000, Loss: 0.8147, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5104/10000, Loss: 0.8147, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5105/10000, Loss: 0.8146, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5106/10000, Loss: 0.8146, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5107/10000, Loss: 0.8145, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5108/10000, Loss: 0.8145, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5109/10000, Loss: 0.8144, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5110/10000, Loss: 0.8143, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5111/10000, Loss: 0.8143, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5112/10000, Loss: 0.8142, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5113/10000, Loss: 0.8142, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5114/10000, Loss: 0.8141, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5115/10000, Loss: 0.8141, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5116/10000, Loss: 0.8140, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5117/10000, Loss: 0.8139, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5118/10000, Loss: 0.8139, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5119/10000, Loss: 0.8138, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5120/10000, Loss: 0.8138, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5121/10000, Loss: 0.8137, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5122/10000, Loss: 0.8137, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5123/10000, Loss: 0.8136, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5124/10000, Loss: 0.8136, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5125/10000, Loss: 0.8135, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5126/10000, Loss: 0.8134, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5127/10000, Loss: 0.8134, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5128/10000, Loss: 0.8133, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5129/10000, Loss: 0.8133, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5130/10000, Loss: 0.8132, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5131/10000, Loss: 0.8132, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5132/10000, Loss: 0.8131, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5133/10000, Loss: 0.8130, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5134/10000, Loss: 0.8130, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5135/10000, Loss: 0.8129, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5136/10000, Loss: 0.8129, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5137/10000, Loss: 0.8128, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5138/10000, Loss: 0.8128, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5139/10000, Loss: 0.8127, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5140/10000, Loss: 0.8127, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5141/10000, Loss: 0.8126, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5142/10000, Loss: 0.8125, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5143/10000, Loss: 0.8125, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5144/10000, Loss: 0.8124, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5145/10000, Loss: 0.8124, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5146/10000, Loss: 0.8123, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5147/10000, Loss: 0.8123, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5148/10000, Loss: 0.8122, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5149/10000, Loss: 0.8122, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5150/10000, Loss: 0.8121, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5151/10000, Loss: 0.8121, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5152/10000, Loss: 0.8120, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5153/10000, Loss: 0.8119, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5154/10000, Loss: 0.8119, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5155/10000, Loss: 0.8118, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5156/10000, Loss: 0.8118, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5157/10000, Loss: 0.8117, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5158/10000, Loss: 0.8117, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5159/10000, Loss: 0.8116, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5160/10000, Loss: 0.8116, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5161/10000, Loss: 0.8115, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5162/10000, Loss: 0.8114, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5163/10000, Loss: 0.8114, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5164/10000, Loss: 0.8113, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5165/10000, Loss: 0.8113, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5166/10000, Loss: 0.8112, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5167/10000, Loss: 0.8112, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5168/10000, Loss: 0.8111, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5169/10000, Loss: 0.8111, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5170/10000, Loss: 0.8110, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5171/10000, Loss: 0.8110, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5172/10000, Loss: 0.8109, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5173/10000, Loss: 0.8108, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5174/10000, Loss: 0.8108, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5175/10000, Loss: 0.8107, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5176/10000, Loss: 0.8107, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5177/10000, Loss: 0.8106, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5178/10000, Loss: 0.8106, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5179/10000, Loss: 0.8105, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5180/10000, Loss: 0.8105, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5181/10000, Loss: 0.8104, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5182/10000, Loss: 0.8104, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5183/10000, Loss: 0.8103, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5184/10000, Loss: 0.8103, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5185/10000, Loss: 0.8102, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5186/10000, Loss: 0.8101, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5187/10000, Loss: 0.8101, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5188/10000, Loss: 0.8100, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5189/10000, Loss: 0.8100, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5190/10000, Loss: 0.8099, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5191/10000, Loss: 0.8099, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5192/10000, Loss: 0.8098, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5193/10000, Loss: 0.8098, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5194/10000, Loss: 0.8097, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5195/10000, Loss: 0.8097, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5196/10000, Loss: 0.8096, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5197/10000, Loss: 0.8096, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5198/10000, Loss: 0.8095, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5199/10000, Loss: 0.8095, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5200/10000, Loss: 0.8094, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5201/10000, Loss: 0.8093, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5202/10000, Loss: 0.8093, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5203/10000, Loss: 0.8092, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5204/10000, Loss: 0.8092, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5205/10000, Loss: 0.8091, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5206/10000, Loss: 0.8091, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5207/10000, Loss: 0.8090, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5208/10000, Loss: 0.8090, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5209/10000, Loss: 0.8089, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5210/10000, Loss: 0.8089, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5211/10000, Loss: 0.8088, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5212/10000, Loss: 0.8088, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5213/10000, Loss: 0.8087, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5214/10000, Loss: 0.8087, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5215/10000, Loss: 0.8086, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5216/10000, Loss: 0.8086, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5217/10000, Loss: 0.8085, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5218/10000, Loss: 0.8084, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5219/10000, Loss: 0.8084, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5220/10000, Loss: 0.8083, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5221/10000, Loss: 0.8083, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5222/10000, Loss: 0.8082, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5223/10000, Loss: 0.8082, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5224/10000, Loss: 0.8081, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5225/10000, Loss: 0.8081, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5226/10000, Loss: 0.8080, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5227/10000, Loss: 0.8080, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5228/10000, Loss: 0.8079, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5229/10000, Loss: 0.8079, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5230/10000, Loss: 0.8078, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5231/10000, Loss: 0.8078, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5232/10000, Loss: 0.8077, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5233/10000, Loss: 0.8077, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5234/10000, Loss: 0.8076, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5235/10000, Loss: 0.8076, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5236/10000, Loss: 0.8075, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5237/10000, Loss: 0.8075, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5238/10000, Loss: 0.8074, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5239/10000, Loss: 0.8074, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5240/10000, Loss: 0.8073, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5241/10000, Loss: 0.8072, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5242/10000, Loss: 0.8072, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5243/10000, Loss: 0.8071, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5244/10000, Loss: 0.8071, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5245/10000, Loss: 0.8070, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5246/10000, Loss: 0.8070, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5247/10000, Loss: 0.8069, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5248/10000, Loss: 0.8069, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5249/10000, Loss: 0.8068, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5250/10000, Loss: 0.8068, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5251/10000, Loss: 0.8067, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5252/10000, Loss: 0.8067, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5253/10000, Loss: 0.8066, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5254/10000, Loss: 0.8066, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5255/10000, Loss: 0.8065, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5256/10000, Loss: 0.8065, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5257/10000, Loss: 0.8064, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5258/10000, Loss: 0.8064, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5259/10000, Loss: 0.8063, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5260/10000, Loss: 0.8063, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5261/10000, Loss: 0.8062, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5262/10000, Loss: 0.8062, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5263/10000, Loss: 0.8061, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5264/10000, Loss: 0.8061, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5265/10000, Loss: 0.8060, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5266/10000, Loss: 0.8060, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5267/10000, Loss: 0.8059, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5268/10000, Loss: 0.8059, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5269/10000, Loss: 0.8058, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5270/10000, Loss: 0.8058, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5271/10000, Loss: 0.8057, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5272/10000, Loss: 0.8057, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5273/10000, Loss: 0.8056, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5274/10000, Loss: 0.8056, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5275/10000, Loss: 0.8055, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5276/10000, Loss: 0.8055, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5277/10000, Loss: 0.8054, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5278/10000, Loss: 0.8054, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5279/10000, Loss: 0.8053, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5280/10000, Loss: 0.8053, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5281/10000, Loss: 0.8052, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5282/10000, Loss: 0.8052, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5283/10000, Loss: 0.8051, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5284/10000, Loss: 0.8051, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5285/10000, Loss: 0.8050, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5286/10000, Loss: 0.8050, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5287/10000, Loss: 0.8049, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5288/10000, Loss: 0.8049, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5289/10000, Loss: 0.8048, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5290/10000, Loss: 0.8048, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5291/10000, Loss: 0.8047, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5292/10000, Loss: 0.8047, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5293/10000, Loss: 0.8046, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5294/10000, Loss: 0.8046, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5295/10000, Loss: 0.8045, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5296/10000, Loss: 0.8045, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5297/10000, Loss: 0.8044, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5298/10000, Loss: 0.8044, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5299/10000, Loss: 0.8043, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5300/10000, Loss: 0.8043, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5301/10000, Loss: 0.8042, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5302/10000, Loss: 0.8042, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5303/10000, Loss: 0.8041, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5304/10000, Loss: 0.8041, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5305/10000, Loss: 0.8040, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5306/10000, Loss: 0.8040, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5307/10000, Loss: 0.8039, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5308/10000, Loss: 0.8039, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5309/10000, Loss: 0.8038, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5310/10000, Loss: 0.8038, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5311/10000, Loss: 0.8037, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5312/10000, Loss: 0.8037, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5313/10000, Loss: 0.8036, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5314/10000, Loss: 0.8036, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5315/10000, Loss: 0.8035, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5316/10000, Loss: 0.8035, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5317/10000, Loss: 0.8034, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5318/10000, Loss: 0.8034, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5319/10000, Loss: 0.8033, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5320/10000, Loss: 0.8033, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5321/10000, Loss: 0.8032, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5322/10000, Loss: 0.8032, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5323/10000, Loss: 0.8031, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5324/10000, Loss: 0.8031, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5325/10000, Loss: 0.8030, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5326/10000, Loss: 0.8030, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5327/10000, Loss: 0.8029, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5328/10000, Loss: 0.8029, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5329/10000, Loss: 0.8028, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5330/10000, Loss: 0.8028, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5331/10000, Loss: 0.8027, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5332/10000, Loss: 0.8027, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5333/10000, Loss: 0.8026, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5334/10000, Loss: 0.8026, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5335/10000, Loss: 0.8025, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5336/10000, Loss: 0.8025, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5337/10000, Loss: 0.8024, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5338/10000, Loss: 0.8024, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5339/10000, Loss: 0.8023, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5340/10000, Loss: 0.8023, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5341/10000, Loss: 0.8022, Accuracy: 0.6536, Learning Rate: 0.000100\n",
      "Epoch 5342/10000, Loss: 0.8022, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5343/10000, Loss: 0.8021, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5344/10000, Loss: 0.8021, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5345/10000, Loss: 0.8020, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5346/10000, Loss: 0.8020, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5347/10000, Loss: 0.8020, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5348/10000, Loss: 0.8019, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5349/10000, Loss: 0.8019, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5350/10000, Loss: 0.8018, Accuracy: 0.6555, Learning Rate: 0.000100\n",
      "Epoch 5351/10000, Loss: 0.8018, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5352/10000, Loss: 0.8017, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5353/10000, Loss: 0.8017, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5354/10000, Loss: 0.8016, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5355/10000, Loss: 0.8016, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5356/10000, Loss: 0.8015, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5357/10000, Loss: 0.8015, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5358/10000, Loss: 0.8014, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5359/10000, Loss: 0.8014, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5360/10000, Loss: 0.8013, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5361/10000, Loss: 0.8013, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5362/10000, Loss: 0.8012, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5363/10000, Loss: 0.8012, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5364/10000, Loss: 0.8011, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5365/10000, Loss: 0.8011, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5366/10000, Loss: 0.8010, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5367/10000, Loss: 0.8010, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5368/10000, Loss: 0.8009, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5369/10000, Loss: 0.8009, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5370/10000, Loss: 0.8008, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5371/10000, Loss: 0.8008, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5372/10000, Loss: 0.8008, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5373/10000, Loss: 0.8007, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5374/10000, Loss: 0.8007, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5375/10000, Loss: 0.8006, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5376/10000, Loss: 0.8006, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5377/10000, Loss: 0.8005, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5378/10000, Loss: 0.8005, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5379/10000, Loss: 0.8004, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5380/10000, Loss: 0.8004, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5381/10000, Loss: 0.8003, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5382/10000, Loss: 0.8003, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5383/10000, Loss: 0.8002, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5384/10000, Loss: 0.8002, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5385/10000, Loss: 0.8001, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5386/10000, Loss: 0.8001, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5387/10000, Loss: 0.8000, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5388/10000, Loss: 0.8000, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5389/10000, Loss: 0.8000, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5390/10000, Loss: 0.7999, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5391/10000, Loss: 0.7999, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5392/10000, Loss: 0.7998, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5393/10000, Loss: 0.7998, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5394/10000, Loss: 0.7997, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5395/10000, Loss: 0.7997, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5396/10000, Loss: 0.7996, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5397/10000, Loss: 0.7996, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5398/10000, Loss: 0.7995, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5399/10000, Loss: 0.7995, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5400/10000, Loss: 0.7994, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5401/10000, Loss: 0.7994, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5402/10000, Loss: 0.7993, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5403/10000, Loss: 0.7993, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5404/10000, Loss: 0.7993, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5405/10000, Loss: 0.7992, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5406/10000, Loss: 0.7992, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5407/10000, Loss: 0.7991, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5408/10000, Loss: 0.7991, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5409/10000, Loss: 0.7990, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5410/10000, Loss: 0.7990, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5411/10000, Loss: 0.7989, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5412/10000, Loss: 0.7989, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5413/10000, Loss: 0.7988, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5414/10000, Loss: 0.7988, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5415/10000, Loss: 0.7987, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5416/10000, Loss: 0.7987, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5417/10000, Loss: 0.7986, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5418/10000, Loss: 0.7986, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5419/10000, Loss: 0.7986, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5420/10000, Loss: 0.7985, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5421/10000, Loss: 0.7985, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5422/10000, Loss: 0.7984, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5423/10000, Loss: 0.7984, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5424/10000, Loss: 0.7983, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5425/10000, Loss: 0.7983, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5426/10000, Loss: 0.7982, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5427/10000, Loss: 0.7982, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5428/10000, Loss: 0.7981, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5429/10000, Loss: 0.7981, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5430/10000, Loss: 0.7981, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5431/10000, Loss: 0.7980, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5432/10000, Loss: 0.7980, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5433/10000, Loss: 0.7979, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5434/10000, Loss: 0.7979, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5435/10000, Loss: 0.7978, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5436/10000, Loss: 0.7978, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5437/10000, Loss: 0.7977, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5438/10000, Loss: 0.7977, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5439/10000, Loss: 0.7976, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5440/10000, Loss: 0.7976, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5441/10000, Loss: 0.7975, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5442/10000, Loss: 0.7975, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5443/10000, Loss: 0.7975, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5444/10000, Loss: 0.7974, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5445/10000, Loss: 0.7974, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5446/10000, Loss: 0.7973, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5447/10000, Loss: 0.7973, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5448/10000, Loss: 0.7972, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5449/10000, Loss: 0.7972, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5450/10000, Loss: 0.7971, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5451/10000, Loss: 0.7971, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5452/10000, Loss: 0.7971, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5453/10000, Loss: 0.7970, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5454/10000, Loss: 0.7970, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5455/10000, Loss: 0.7969, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5456/10000, Loss: 0.7969, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5457/10000, Loss: 0.7968, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5458/10000, Loss: 0.7968, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5459/10000, Loss: 0.7967, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5460/10000, Loss: 0.7967, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5461/10000, Loss: 0.7966, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5462/10000, Loss: 0.7966, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5463/10000, Loss: 0.7966, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5464/10000, Loss: 0.7965, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5465/10000, Loss: 0.7965, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5466/10000, Loss: 0.7964, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5467/10000, Loss: 0.7964, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5468/10000, Loss: 0.7963, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5469/10000, Loss: 0.7963, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5470/10000, Loss: 0.7962, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5471/10000, Loss: 0.7962, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5472/10000, Loss: 0.7962, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5473/10000, Loss: 0.7961, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5474/10000, Loss: 0.7961, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5475/10000, Loss: 0.7960, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5476/10000, Loss: 0.7960, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5477/10000, Loss: 0.7959, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5478/10000, Loss: 0.7959, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5479/10000, Loss: 0.7958, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5480/10000, Loss: 0.7958, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5481/10000, Loss: 0.7958, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5482/10000, Loss: 0.7957, Accuracy: 0.6574, Learning Rate: 0.000100\n",
      "Epoch 5483/10000, Loss: 0.7957, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5484/10000, Loss: 0.7956, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5485/10000, Loss: 0.7956, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5486/10000, Loss: 0.7955, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5487/10000, Loss: 0.7955, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5488/10000, Loss: 0.7954, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5489/10000, Loss: 0.7954, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5490/10000, Loss: 0.7954, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5491/10000, Loss: 0.7953, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5492/10000, Loss: 0.7953, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5493/10000, Loss: 0.7952, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5494/10000, Loss: 0.7952, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5495/10000, Loss: 0.7951, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5496/10000, Loss: 0.7951, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5497/10000, Loss: 0.7950, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5498/10000, Loss: 0.7950, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5499/10000, Loss: 0.7950, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5500/10000, Loss: 0.7949, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5501/10000, Loss: 0.7949, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5502/10000, Loss: 0.7948, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5503/10000, Loss: 0.7948, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5504/10000, Loss: 0.7947, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5505/10000, Loss: 0.7947, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5506/10000, Loss: 0.7947, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5507/10000, Loss: 0.7946, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5508/10000, Loss: 0.7946, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5509/10000, Loss: 0.7945, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5510/10000, Loss: 0.7945, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5511/10000, Loss: 0.7944, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5512/10000, Loss: 0.7944, Accuracy: 0.6592, Learning Rate: 0.000100\n",
      "Epoch 5513/10000, Loss: 0.7944, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5514/10000, Loss: 0.7943, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5515/10000, Loss: 0.7943, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5516/10000, Loss: 0.7942, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5517/10000, Loss: 0.7942, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5518/10000, Loss: 0.7941, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5519/10000, Loss: 0.7941, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5520/10000, Loss: 0.7940, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5521/10000, Loss: 0.7940, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5522/10000, Loss: 0.7940, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5523/10000, Loss: 0.7939, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5524/10000, Loss: 0.7939, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5525/10000, Loss: 0.7938, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5526/10000, Loss: 0.7938, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5527/10000, Loss: 0.7937, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5528/10000, Loss: 0.7937, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5529/10000, Loss: 0.7937, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5530/10000, Loss: 0.7936, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5531/10000, Loss: 0.7936, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5532/10000, Loss: 0.7935, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5533/10000, Loss: 0.7935, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5534/10000, Loss: 0.7934, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5535/10000, Loss: 0.7934, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5536/10000, Loss: 0.7934, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5537/10000, Loss: 0.7933, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5538/10000, Loss: 0.7933, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5539/10000, Loss: 0.7932, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5540/10000, Loss: 0.7932, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5541/10000, Loss: 0.7931, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5542/10000, Loss: 0.7931, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5543/10000, Loss: 0.7931, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5544/10000, Loss: 0.7930, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5545/10000, Loss: 0.7930, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5546/10000, Loss: 0.7929, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5547/10000, Loss: 0.7929, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5548/10000, Loss: 0.7928, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5549/10000, Loss: 0.7928, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5550/10000, Loss: 0.7928, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5551/10000, Loss: 0.7927, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5552/10000, Loss: 0.7927, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5553/10000, Loss: 0.7926, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5554/10000, Loss: 0.7926, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5555/10000, Loss: 0.7925, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5556/10000, Loss: 0.7925, Accuracy: 0.6611, Learning Rate: 0.000100\n",
      "Epoch 5557/10000, Loss: 0.7925, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5558/10000, Loss: 0.7924, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5559/10000, Loss: 0.7924, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5560/10000, Loss: 0.7923, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5561/10000, Loss: 0.7923, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5562/10000, Loss: 0.7923, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5563/10000, Loss: 0.7922, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5564/10000, Loss: 0.7922, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5565/10000, Loss: 0.7921, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5566/10000, Loss: 0.7921, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5567/10000, Loss: 0.7920, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5568/10000, Loss: 0.7920, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5569/10000, Loss: 0.7920, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5570/10000, Loss: 0.7919, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5571/10000, Loss: 0.7919, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5572/10000, Loss: 0.7918, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5573/10000, Loss: 0.7918, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5574/10000, Loss: 0.7917, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5575/10000, Loss: 0.7917, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5576/10000, Loss: 0.7917, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5577/10000, Loss: 0.7916, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5578/10000, Loss: 0.7916, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5579/10000, Loss: 0.7915, Accuracy: 0.6629, Learning Rate: 0.000100\n",
      "Epoch 5580/10000, Loss: 0.7915, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5581/10000, Loss: 0.7915, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5582/10000, Loss: 0.7914, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5583/10000, Loss: 0.7914, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5584/10000, Loss: 0.7913, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5585/10000, Loss: 0.7913, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5586/10000, Loss: 0.7912, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5587/10000, Loss: 0.7912, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5588/10000, Loss: 0.7912, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5589/10000, Loss: 0.7911, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5590/10000, Loss: 0.7911, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5591/10000, Loss: 0.7910, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5592/10000, Loss: 0.7910, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5593/10000, Loss: 0.7910, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5594/10000, Loss: 0.7909, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5595/10000, Loss: 0.7909, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5596/10000, Loss: 0.7908, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5597/10000, Loss: 0.7908, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5598/10000, Loss: 0.7907, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5599/10000, Loss: 0.7907, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5600/10000, Loss: 0.7907, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5601/10000, Loss: 0.7906, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5602/10000, Loss: 0.7906, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5603/10000, Loss: 0.7905, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5604/10000, Loss: 0.7905, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5605/10000, Loss: 0.7905, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5606/10000, Loss: 0.7904, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5607/10000, Loss: 0.7904, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5608/10000, Loss: 0.7903, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5609/10000, Loss: 0.7903, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5610/10000, Loss: 0.7903, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5611/10000, Loss: 0.7902, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5612/10000, Loss: 0.7902, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5613/10000, Loss: 0.7901, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5614/10000, Loss: 0.7901, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5615/10000, Loss: 0.7901, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5616/10000, Loss: 0.7900, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5617/10000, Loss: 0.7900, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5618/10000, Loss: 0.7899, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5619/10000, Loss: 0.7899, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5620/10000, Loss: 0.7898, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5621/10000, Loss: 0.7898, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5622/10000, Loss: 0.7898, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5623/10000, Loss: 0.7897, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5624/10000, Loss: 0.7897, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5625/10000, Loss: 0.7896, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5626/10000, Loss: 0.7896, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5627/10000, Loss: 0.7896, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5628/10000, Loss: 0.7895, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5629/10000, Loss: 0.7895, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5630/10000, Loss: 0.7894, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5631/10000, Loss: 0.7894, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5632/10000, Loss: 0.7894, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5633/10000, Loss: 0.7893, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5634/10000, Loss: 0.7893, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5635/10000, Loss: 0.7892, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5636/10000, Loss: 0.7892, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5637/10000, Loss: 0.7892, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5638/10000, Loss: 0.7891, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5639/10000, Loss: 0.7891, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5640/10000, Loss: 0.7890, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5641/10000, Loss: 0.7890, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5642/10000, Loss: 0.7890, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5643/10000, Loss: 0.7889, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5644/10000, Loss: 0.7889, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5645/10000, Loss: 0.7888, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5646/10000, Loss: 0.7888, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5647/10000, Loss: 0.7888, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5648/10000, Loss: 0.7887, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5649/10000, Loss: 0.7887, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5650/10000, Loss: 0.7886, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5651/10000, Loss: 0.7886, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5652/10000, Loss: 0.7886, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5653/10000, Loss: 0.7885, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5654/10000, Loss: 0.7885, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5655/10000, Loss: 0.7884, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5656/10000, Loss: 0.7884, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5657/10000, Loss: 0.7884, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5658/10000, Loss: 0.7883, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5659/10000, Loss: 0.7883, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5660/10000, Loss: 0.7882, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5661/10000, Loss: 0.7882, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5662/10000, Loss: 0.7882, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5663/10000, Loss: 0.7881, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5664/10000, Loss: 0.7881, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5665/10000, Loss: 0.7880, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5666/10000, Loss: 0.7880, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5667/10000, Loss: 0.7880, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5668/10000, Loss: 0.7879, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5669/10000, Loss: 0.7879, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5670/10000, Loss: 0.7878, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5671/10000, Loss: 0.7878, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5672/10000, Loss: 0.7878, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5673/10000, Loss: 0.7877, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5674/10000, Loss: 0.7877, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5675/10000, Loss: 0.7876, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5676/10000, Loss: 0.7876, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5677/10000, Loss: 0.7876, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5678/10000, Loss: 0.7875, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5679/10000, Loss: 0.7875, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5680/10000, Loss: 0.7874, Accuracy: 0.6648, Learning Rate: 0.000100\n",
      "Epoch 5681/10000, Loss: 0.7874, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5682/10000, Loss: 0.7874, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5683/10000, Loss: 0.7873, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5684/10000, Loss: 0.7873, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5685/10000, Loss: 0.7872, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5686/10000, Loss: 0.7872, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5687/10000, Loss: 0.7872, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5688/10000, Loss: 0.7871, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5689/10000, Loss: 0.7871, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5690/10000, Loss: 0.7870, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5691/10000, Loss: 0.7870, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5692/10000, Loss: 0.7870, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5693/10000, Loss: 0.7869, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5694/10000, Loss: 0.7869, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5695/10000, Loss: 0.7869, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5696/10000, Loss: 0.7868, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5697/10000, Loss: 0.7868, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5698/10000, Loss: 0.7867, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5699/10000, Loss: 0.7867, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5700/10000, Loss: 0.7867, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5701/10000, Loss: 0.7866, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5702/10000, Loss: 0.7866, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5703/10000, Loss: 0.7865, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5704/10000, Loss: 0.7865, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5705/10000, Loss: 0.7865, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5706/10000, Loss: 0.7864, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5707/10000, Loss: 0.7864, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5708/10000, Loss: 0.7863, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5709/10000, Loss: 0.7863, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5710/10000, Loss: 0.7863, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5711/10000, Loss: 0.7862, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5712/10000, Loss: 0.7862, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5713/10000, Loss: 0.7862, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5714/10000, Loss: 0.7861, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5715/10000, Loss: 0.7861, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5716/10000, Loss: 0.7860, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5717/10000, Loss: 0.7860, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5718/10000, Loss: 0.7860, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5719/10000, Loss: 0.7859, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5720/10000, Loss: 0.7859, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5721/10000, Loss: 0.7858, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5722/10000, Loss: 0.7858, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5723/10000, Loss: 0.7858, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5724/10000, Loss: 0.7857, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5725/10000, Loss: 0.7857, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5726/10000, Loss: 0.7857, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5727/10000, Loss: 0.7856, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5728/10000, Loss: 0.7856, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5729/10000, Loss: 0.7855, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5730/10000, Loss: 0.7855, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5731/10000, Loss: 0.7855, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5732/10000, Loss: 0.7854, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5733/10000, Loss: 0.7854, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5734/10000, Loss: 0.7853, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5735/10000, Loss: 0.7853, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5736/10000, Loss: 0.7853, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5737/10000, Loss: 0.7852, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5738/10000, Loss: 0.7852, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5739/10000, Loss: 0.7852, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5740/10000, Loss: 0.7851, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5741/10000, Loss: 0.7851, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5742/10000, Loss: 0.7850, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5743/10000, Loss: 0.7850, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5744/10000, Loss: 0.7850, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5745/10000, Loss: 0.7849, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5746/10000, Loss: 0.7849, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5747/10000, Loss: 0.7848, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5748/10000, Loss: 0.7848, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5749/10000, Loss: 0.7848, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5750/10000, Loss: 0.7847, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5751/10000, Loss: 0.7847, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5752/10000, Loss: 0.7847, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5753/10000, Loss: 0.7846, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5754/10000, Loss: 0.7846, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5755/10000, Loss: 0.7845, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5756/10000, Loss: 0.7845, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5757/10000, Loss: 0.7845, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5758/10000, Loss: 0.7844, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5759/10000, Loss: 0.7844, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5760/10000, Loss: 0.7844, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5761/10000, Loss: 0.7843, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5762/10000, Loss: 0.7843, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5763/10000, Loss: 0.7842, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5764/10000, Loss: 0.7842, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5765/10000, Loss: 0.7842, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5766/10000, Loss: 0.7841, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5767/10000, Loss: 0.7841, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5768/10000, Loss: 0.7841, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5769/10000, Loss: 0.7840, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5770/10000, Loss: 0.7840, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5771/10000, Loss: 0.7839, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5772/10000, Loss: 0.7839, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5773/10000, Loss: 0.7839, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5774/10000, Loss: 0.7838, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5775/10000, Loss: 0.7838, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5776/10000, Loss: 0.7838, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5777/10000, Loss: 0.7837, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5778/10000, Loss: 0.7837, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5779/10000, Loss: 0.7836, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5780/10000, Loss: 0.7836, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5781/10000, Loss: 0.7836, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5782/10000, Loss: 0.7835, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5783/10000, Loss: 0.7835, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5784/10000, Loss: 0.7835, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5785/10000, Loss: 0.7834, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5786/10000, Loss: 0.7834, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5787/10000, Loss: 0.7833, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5788/10000, Loss: 0.7833, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5789/10000, Loss: 0.7833, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5790/10000, Loss: 0.7832, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5791/10000, Loss: 0.7832, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5792/10000, Loss: 0.7832, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5793/10000, Loss: 0.7831, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5794/10000, Loss: 0.7831, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5795/10000, Loss: 0.7831, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5796/10000, Loss: 0.7830, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5797/10000, Loss: 0.7830, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5798/10000, Loss: 0.7829, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5799/10000, Loss: 0.7829, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5800/10000, Loss: 0.7829, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5801/10000, Loss: 0.7828, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5802/10000, Loss: 0.7828, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5803/10000, Loss: 0.7828, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5804/10000, Loss: 0.7827, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5805/10000, Loss: 0.7827, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5806/10000, Loss: 0.7826, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5807/10000, Loss: 0.7826, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5808/10000, Loss: 0.7826, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5809/10000, Loss: 0.7825, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5810/10000, Loss: 0.7825, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5811/10000, Loss: 0.7825, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5812/10000, Loss: 0.7824, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5813/10000, Loss: 0.7824, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5814/10000, Loss: 0.7824, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5815/10000, Loss: 0.7823, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 5816/10000, Loss: 0.7823, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5817/10000, Loss: 0.7822, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5818/10000, Loss: 0.7822, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5819/10000, Loss: 0.7822, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5820/10000, Loss: 0.7821, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5821/10000, Loss: 0.7821, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 5822/10000, Loss: 0.7821, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5823/10000, Loss: 0.7820, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5824/10000, Loss: 0.7820, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5825/10000, Loss: 0.7819, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5826/10000, Loss: 0.7819, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5827/10000, Loss: 0.7819, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5828/10000, Loss: 0.7818, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5829/10000, Loss: 0.7818, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5830/10000, Loss: 0.7818, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5831/10000, Loss: 0.7817, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5832/10000, Loss: 0.7817, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5833/10000, Loss: 0.7817, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5834/10000, Loss: 0.7816, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5835/10000, Loss: 0.7816, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5836/10000, Loss: 0.7816, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5837/10000, Loss: 0.7815, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5838/10000, Loss: 0.7815, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5839/10000, Loss: 0.7814, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5840/10000, Loss: 0.7814, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5841/10000, Loss: 0.7814, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5842/10000, Loss: 0.7813, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5843/10000, Loss: 0.7813, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5844/10000, Loss: 0.7813, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5845/10000, Loss: 0.7812, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5846/10000, Loss: 0.7812, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5847/10000, Loss: 0.7812, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5848/10000, Loss: 0.7811, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5849/10000, Loss: 0.7811, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5850/10000, Loss: 0.7810, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5851/10000, Loss: 0.7810, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5852/10000, Loss: 0.7810, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5853/10000, Loss: 0.7809, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5854/10000, Loss: 0.7809, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5855/10000, Loss: 0.7809, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5856/10000, Loss: 0.7808, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5857/10000, Loss: 0.7808, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5858/10000, Loss: 0.7808, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5859/10000, Loss: 0.7807, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5860/10000, Loss: 0.7807, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5861/10000, Loss: 0.7807, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5862/10000, Loss: 0.7806, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5863/10000, Loss: 0.7806, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5864/10000, Loss: 0.7805, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5865/10000, Loss: 0.7805, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5866/10000, Loss: 0.7805, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5867/10000, Loss: 0.7804, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5868/10000, Loss: 0.7804, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5869/10000, Loss: 0.7804, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5870/10000, Loss: 0.7803, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5871/10000, Loss: 0.7803, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5872/10000, Loss: 0.7803, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5873/10000, Loss: 0.7802, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5874/10000, Loss: 0.7802, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5875/10000, Loss: 0.7802, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5876/10000, Loss: 0.7801, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5877/10000, Loss: 0.7801, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5878/10000, Loss: 0.7800, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5879/10000, Loss: 0.7800, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5880/10000, Loss: 0.7800, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5881/10000, Loss: 0.7799, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5882/10000, Loss: 0.7799, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5883/10000, Loss: 0.7799, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5884/10000, Loss: 0.7798, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5885/10000, Loss: 0.7798, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5886/10000, Loss: 0.7798, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5887/10000, Loss: 0.7797, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5888/10000, Loss: 0.7797, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5889/10000, Loss: 0.7797, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5890/10000, Loss: 0.7796, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5891/10000, Loss: 0.7796, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5892/10000, Loss: 0.7796, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5893/10000, Loss: 0.7795, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5894/10000, Loss: 0.7795, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5895/10000, Loss: 0.7794, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5896/10000, Loss: 0.7794, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5897/10000, Loss: 0.7794, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5898/10000, Loss: 0.7793, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5899/10000, Loss: 0.7793, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5900/10000, Loss: 0.7793, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5901/10000, Loss: 0.7792, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5902/10000, Loss: 0.7792, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5903/10000, Loss: 0.7792, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5904/10000, Loss: 0.7791, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5905/10000, Loss: 0.7791, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5906/10000, Loss: 0.7791, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5907/10000, Loss: 0.7790, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5908/10000, Loss: 0.7790, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5909/10000, Loss: 0.7790, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5910/10000, Loss: 0.7789, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5911/10000, Loss: 0.7789, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5912/10000, Loss: 0.7789, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5913/10000, Loss: 0.7788, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5914/10000, Loss: 0.7788, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5915/10000, Loss: 0.7787, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5916/10000, Loss: 0.7787, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5917/10000, Loss: 0.7787, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5918/10000, Loss: 0.7786, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5919/10000, Loss: 0.7786, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5920/10000, Loss: 0.7786, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5921/10000, Loss: 0.7785, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5922/10000, Loss: 0.7785, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5923/10000, Loss: 0.7785, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5924/10000, Loss: 0.7784, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5925/10000, Loss: 0.7784, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5926/10000, Loss: 0.7784, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5927/10000, Loss: 0.7783, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5928/10000, Loss: 0.7783, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5929/10000, Loss: 0.7783, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5930/10000, Loss: 0.7782, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5931/10000, Loss: 0.7782, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5932/10000, Loss: 0.7782, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5933/10000, Loss: 0.7781, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5934/10000, Loss: 0.7781, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5935/10000, Loss: 0.7781, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5936/10000, Loss: 0.7780, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5937/10000, Loss: 0.7780, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5938/10000, Loss: 0.7780, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5939/10000, Loss: 0.7779, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5940/10000, Loss: 0.7779, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5941/10000, Loss: 0.7778, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5942/10000, Loss: 0.7778, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5943/10000, Loss: 0.7778, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5944/10000, Loss: 0.7777, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5945/10000, Loss: 0.7777, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5946/10000, Loss: 0.7777, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5947/10000, Loss: 0.7776, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5948/10000, Loss: 0.7776, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5949/10000, Loss: 0.7776, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5950/10000, Loss: 0.7775, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5951/10000, Loss: 0.7775, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5952/10000, Loss: 0.7775, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5953/10000, Loss: 0.7774, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5954/10000, Loss: 0.7774, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5955/10000, Loss: 0.7774, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5956/10000, Loss: 0.7773, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5957/10000, Loss: 0.7773, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5958/10000, Loss: 0.7773, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5959/10000, Loss: 0.7772, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5960/10000, Loss: 0.7772, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5961/10000, Loss: 0.7772, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5962/10000, Loss: 0.7771, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5963/10000, Loss: 0.7771, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5964/10000, Loss: 0.7771, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5965/10000, Loss: 0.7770, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5966/10000, Loss: 0.7770, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5967/10000, Loss: 0.7770, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5968/10000, Loss: 0.7769, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5969/10000, Loss: 0.7769, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5970/10000, Loss: 0.7769, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5971/10000, Loss: 0.7768, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5972/10000, Loss: 0.7768, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5973/10000, Loss: 0.7768, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5974/10000, Loss: 0.7767, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5975/10000, Loss: 0.7767, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5976/10000, Loss: 0.7767, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5977/10000, Loss: 0.7766, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5978/10000, Loss: 0.7766, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5979/10000, Loss: 0.7766, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5980/10000, Loss: 0.7765, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5981/10000, Loss: 0.7765, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5982/10000, Loss: 0.7765, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5983/10000, Loss: 0.7764, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5984/10000, Loss: 0.7764, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5985/10000, Loss: 0.7764, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5986/10000, Loss: 0.7763, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5987/10000, Loss: 0.7763, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5988/10000, Loss: 0.7763, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5989/10000, Loss: 0.7762, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5990/10000, Loss: 0.7762, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5991/10000, Loss: 0.7762, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5992/10000, Loss: 0.7761, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5993/10000, Loss: 0.7761, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5994/10000, Loss: 0.7761, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5995/10000, Loss: 0.7760, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5996/10000, Loss: 0.7760, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5997/10000, Loss: 0.7760, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5998/10000, Loss: 0.7759, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 5999/10000, Loss: 0.7759, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6000/10000, Loss: 0.7759, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6001/10000, Loss: 0.7758, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6002/10000, Loss: 0.7758, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6003/10000, Loss: 0.7758, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6004/10000, Loss: 0.7757, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6005/10000, Loss: 0.7757, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6006/10000, Loss: 0.7757, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6007/10000, Loss: 0.7756, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6008/10000, Loss: 0.7756, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6009/10000, Loss: 0.7756, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6010/10000, Loss: 0.7755, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6011/10000, Loss: 0.7755, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6012/10000, Loss: 0.7755, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6013/10000, Loss: 0.7754, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6014/10000, Loss: 0.7754, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6015/10000, Loss: 0.7754, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6016/10000, Loss: 0.7753, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6017/10000, Loss: 0.7753, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6018/10000, Loss: 0.7753, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6019/10000, Loss: 0.7752, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6020/10000, Loss: 0.7752, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6021/10000, Loss: 0.7752, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6022/10000, Loss: 0.7751, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6023/10000, Loss: 0.7751, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6024/10000, Loss: 0.7751, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6025/10000, Loss: 0.7750, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6026/10000, Loss: 0.7750, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6027/10000, Loss: 0.7750, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6028/10000, Loss: 0.7749, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6029/10000, Loss: 0.7749, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6030/10000, Loss: 0.7749, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6031/10000, Loss: 0.7748, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6032/10000, Loss: 0.7748, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6033/10000, Loss: 0.7748, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6034/10000, Loss: 0.7747, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6035/10000, Loss: 0.7747, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6036/10000, Loss: 0.7747, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6037/10000, Loss: 0.7746, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6038/10000, Loss: 0.7746, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6039/10000, Loss: 0.7746, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6040/10000, Loss: 0.7745, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6041/10000, Loss: 0.7745, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6042/10000, Loss: 0.7745, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6043/10000, Loss: 0.7744, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6044/10000, Loss: 0.7744, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6045/10000, Loss: 0.7744, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6046/10000, Loss: 0.7743, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6047/10000, Loss: 0.7743, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6048/10000, Loss: 0.7743, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6049/10000, Loss: 0.7742, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6050/10000, Loss: 0.7742, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6051/10000, Loss: 0.7742, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6052/10000, Loss: 0.7741, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6053/10000, Loss: 0.7741, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6054/10000, Loss: 0.7741, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6055/10000, Loss: 0.7740, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6056/10000, Loss: 0.7740, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6057/10000, Loss: 0.7740, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6058/10000, Loss: 0.7739, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6059/10000, Loss: 0.7739, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6060/10000, Loss: 0.7739, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6061/10000, Loss: 0.7738, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6062/10000, Loss: 0.7738, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6063/10000, Loss: 0.7738, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6064/10000, Loss: 0.7737, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6065/10000, Loss: 0.7737, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6066/10000, Loss: 0.7737, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6067/10000, Loss: 0.7737, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6068/10000, Loss: 0.7736, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6069/10000, Loss: 0.7736, Accuracy: 0.6685, Learning Rate: 0.000100\n",
      "Epoch 6070/10000, Loss: 0.7736, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6071/10000, Loss: 0.7735, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6072/10000, Loss: 0.7735, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6073/10000, Loss: 0.7735, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6074/10000, Loss: 0.7734, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6075/10000, Loss: 0.7734, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6076/10000, Loss: 0.7734, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6077/10000, Loss: 0.7733, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6078/10000, Loss: 0.7733, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6079/10000, Loss: 0.7733, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6080/10000, Loss: 0.7732, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6081/10000, Loss: 0.7732, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6082/10000, Loss: 0.7732, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6083/10000, Loss: 0.7731, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6084/10000, Loss: 0.7731, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6085/10000, Loss: 0.7731, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6086/10000, Loss: 0.7730, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6087/10000, Loss: 0.7730, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6088/10000, Loss: 0.7730, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6089/10000, Loss: 0.7729, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6090/10000, Loss: 0.7729, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6091/10000, Loss: 0.7729, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6092/10000, Loss: 0.7728, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6093/10000, Loss: 0.7728, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6094/10000, Loss: 0.7728, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6095/10000, Loss: 0.7727, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6096/10000, Loss: 0.7727, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6097/10000, Loss: 0.7727, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6098/10000, Loss: 0.7727, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6099/10000, Loss: 0.7726, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6100/10000, Loss: 0.7726, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6101/10000, Loss: 0.7726, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6102/10000, Loss: 0.7725, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6103/10000, Loss: 0.7725, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6104/10000, Loss: 0.7725, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6105/10000, Loss: 0.7724, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6106/10000, Loss: 0.7724, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6107/10000, Loss: 0.7724, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6108/10000, Loss: 0.7723, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6109/10000, Loss: 0.7723, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6110/10000, Loss: 0.7723, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6111/10000, Loss: 0.7722, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6112/10000, Loss: 0.7722, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6113/10000, Loss: 0.7722, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6114/10000, Loss: 0.7721, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6115/10000, Loss: 0.7721, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6116/10000, Loss: 0.7721, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6117/10000, Loss: 0.7721, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6118/10000, Loss: 0.7720, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6119/10000, Loss: 0.7720, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6120/10000, Loss: 0.7720, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6121/10000, Loss: 0.7719, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6122/10000, Loss: 0.7719, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6123/10000, Loss: 0.7719, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6124/10000, Loss: 0.7718, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6125/10000, Loss: 0.7718, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6126/10000, Loss: 0.7718, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6127/10000, Loss: 0.7717, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6128/10000, Loss: 0.7717, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6129/10000, Loss: 0.7717, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6130/10000, Loss: 0.7716, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6131/10000, Loss: 0.7716, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6132/10000, Loss: 0.7716, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6133/10000, Loss: 0.7715, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6134/10000, Loss: 0.7715, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6135/10000, Loss: 0.7715, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6136/10000, Loss: 0.7715, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6137/10000, Loss: 0.7714, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6138/10000, Loss: 0.7714, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6139/10000, Loss: 0.7714, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6140/10000, Loss: 0.7713, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6141/10000, Loss: 0.7713, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6142/10000, Loss: 0.7713, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6143/10000, Loss: 0.7712, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6144/10000, Loss: 0.7712, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6145/10000, Loss: 0.7712, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6146/10000, Loss: 0.7711, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6147/10000, Loss: 0.7711, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6148/10000, Loss: 0.7711, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6149/10000, Loss: 0.7710, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6150/10000, Loss: 0.7710, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6151/10000, Loss: 0.7710, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6152/10000, Loss: 0.7710, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6153/10000, Loss: 0.7709, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6154/10000, Loss: 0.7709, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6155/10000, Loss: 0.7709, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6156/10000, Loss: 0.7708, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6157/10000, Loss: 0.7708, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6158/10000, Loss: 0.7708, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6159/10000, Loss: 0.7707, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6160/10000, Loss: 0.7707, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6161/10000, Loss: 0.7707, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6162/10000, Loss: 0.7706, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6163/10000, Loss: 0.7706, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6164/10000, Loss: 0.7706, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6165/10000, Loss: 0.7705, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6166/10000, Loss: 0.7705, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6167/10000, Loss: 0.7705, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6168/10000, Loss: 0.7705, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6169/10000, Loss: 0.7704, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6170/10000, Loss: 0.7704, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6171/10000, Loss: 0.7704, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6172/10000, Loss: 0.7703, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6173/10000, Loss: 0.7703, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6174/10000, Loss: 0.7703, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6175/10000, Loss: 0.7702, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6176/10000, Loss: 0.7702, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6177/10000, Loss: 0.7702, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6178/10000, Loss: 0.7701, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6179/10000, Loss: 0.7701, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6180/10000, Loss: 0.7701, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6181/10000, Loss: 0.7701, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6182/10000, Loss: 0.7700, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6183/10000, Loss: 0.7700, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6184/10000, Loss: 0.7700, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6185/10000, Loss: 0.7699, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6186/10000, Loss: 0.7699, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6187/10000, Loss: 0.7699, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6188/10000, Loss: 0.7698, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6189/10000, Loss: 0.7698, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6190/10000, Loss: 0.7698, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6191/10000, Loss: 0.7697, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6192/10000, Loss: 0.7697, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6193/10000, Loss: 0.7697, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6194/10000, Loss: 0.7697, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6195/10000, Loss: 0.7696, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6196/10000, Loss: 0.7696, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6197/10000, Loss: 0.7696, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6198/10000, Loss: 0.7695, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6199/10000, Loss: 0.7695, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6200/10000, Loss: 0.7695, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6201/10000, Loss: 0.7694, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6202/10000, Loss: 0.7694, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6203/10000, Loss: 0.7694, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6204/10000, Loss: 0.7693, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6205/10000, Loss: 0.7693, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6206/10000, Loss: 0.7693, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6207/10000, Loss: 0.7693, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6208/10000, Loss: 0.7692, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6209/10000, Loss: 0.7692, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6210/10000, Loss: 0.7692, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6211/10000, Loss: 0.7691, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6212/10000, Loss: 0.7691, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6213/10000, Loss: 0.7691, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6214/10000, Loss: 0.7690, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6215/10000, Loss: 0.7690, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6216/10000, Loss: 0.7690, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6217/10000, Loss: 0.7690, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6218/10000, Loss: 0.7689, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6219/10000, Loss: 0.7689, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6220/10000, Loss: 0.7689, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6221/10000, Loss: 0.7688, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6222/10000, Loss: 0.7688, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6223/10000, Loss: 0.7688, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6224/10000, Loss: 0.7687, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6225/10000, Loss: 0.7687, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6226/10000, Loss: 0.7687, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6227/10000, Loss: 0.7686, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6228/10000, Loss: 0.7686, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6229/10000, Loss: 0.7686, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6230/10000, Loss: 0.7686, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6231/10000, Loss: 0.7685, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6232/10000, Loss: 0.7685, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6233/10000, Loss: 0.7685, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6234/10000, Loss: 0.7684, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6235/10000, Loss: 0.7684, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6236/10000, Loss: 0.7684, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6237/10000, Loss: 0.7683, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6238/10000, Loss: 0.7683, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6239/10000, Loss: 0.7683, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6240/10000, Loss: 0.7683, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6241/10000, Loss: 0.7682, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6242/10000, Loss: 0.7682, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6243/10000, Loss: 0.7682, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6244/10000, Loss: 0.7681, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6245/10000, Loss: 0.7681, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6246/10000, Loss: 0.7681, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6247/10000, Loss: 0.7680, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6248/10000, Loss: 0.7680, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6249/10000, Loss: 0.7680, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6250/10000, Loss: 0.7680, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6251/10000, Loss: 0.7679, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6252/10000, Loss: 0.7679, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6253/10000, Loss: 0.7679, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6254/10000, Loss: 0.7678, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6255/10000, Loss: 0.7678, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6256/10000, Loss: 0.7678, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6257/10000, Loss: 0.7677, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6258/10000, Loss: 0.7677, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6259/10000, Loss: 0.7677, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6260/10000, Loss: 0.7677, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6261/10000, Loss: 0.7676, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6262/10000, Loss: 0.7676, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6263/10000, Loss: 0.7676, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6264/10000, Loss: 0.7675, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6265/10000, Loss: 0.7675, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6266/10000, Loss: 0.7675, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6267/10000, Loss: 0.7675, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6268/10000, Loss: 0.7674, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6269/10000, Loss: 0.7674, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6270/10000, Loss: 0.7674, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6271/10000, Loss: 0.7673, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6272/10000, Loss: 0.7673, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6273/10000, Loss: 0.7673, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6274/10000, Loss: 0.7672, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6275/10000, Loss: 0.7672, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6276/10000, Loss: 0.7672, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6277/10000, Loss: 0.7672, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6278/10000, Loss: 0.7671, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6279/10000, Loss: 0.7671, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6280/10000, Loss: 0.7671, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6281/10000, Loss: 0.7670, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6282/10000, Loss: 0.7670, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6283/10000, Loss: 0.7670, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6284/10000, Loss: 0.7669, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6285/10000, Loss: 0.7669, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6286/10000, Loss: 0.7669, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6287/10000, Loss: 0.7669, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6288/10000, Loss: 0.7668, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6289/10000, Loss: 0.7668, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6290/10000, Loss: 0.7668, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6291/10000, Loss: 0.7667, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6292/10000, Loss: 0.7667, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6293/10000, Loss: 0.7667, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6294/10000, Loss: 0.7667, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6295/10000, Loss: 0.7666, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6296/10000, Loss: 0.7666, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6297/10000, Loss: 0.7666, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6298/10000, Loss: 0.7665, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6299/10000, Loss: 0.7665, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6300/10000, Loss: 0.7665, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6301/10000, Loss: 0.7664, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6302/10000, Loss: 0.7664, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6303/10000, Loss: 0.7664, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6304/10000, Loss: 0.7664, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6305/10000, Loss: 0.7663, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6306/10000, Loss: 0.7663, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6307/10000, Loss: 0.7663, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6308/10000, Loss: 0.7662, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6309/10000, Loss: 0.7662, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6310/10000, Loss: 0.7662, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6311/10000, Loss: 0.7662, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6312/10000, Loss: 0.7661, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6313/10000, Loss: 0.7661, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6314/10000, Loss: 0.7661, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6315/10000, Loss: 0.7660, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6316/10000, Loss: 0.7660, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6317/10000, Loss: 0.7660, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6318/10000, Loss: 0.7660, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6319/10000, Loss: 0.7659, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6320/10000, Loss: 0.7659, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6321/10000, Loss: 0.7659, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6322/10000, Loss: 0.7658, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6323/10000, Loss: 0.7658, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6324/10000, Loss: 0.7658, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6325/10000, Loss: 0.7657, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6326/10000, Loss: 0.7657, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6327/10000, Loss: 0.7657, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6328/10000, Loss: 0.7657, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6329/10000, Loss: 0.7656, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6330/10000, Loss: 0.7656, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6331/10000, Loss: 0.7656, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6332/10000, Loss: 0.7655, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6333/10000, Loss: 0.7655, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6334/10000, Loss: 0.7655, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6335/10000, Loss: 0.7655, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6336/10000, Loss: 0.7654, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6337/10000, Loss: 0.7654, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6338/10000, Loss: 0.7654, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6339/10000, Loss: 0.7653, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6340/10000, Loss: 0.7653, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6341/10000, Loss: 0.7653, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6342/10000, Loss: 0.7653, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6343/10000, Loss: 0.7652, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6344/10000, Loss: 0.7652, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6345/10000, Loss: 0.7652, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6346/10000, Loss: 0.7651, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6347/10000, Loss: 0.7651, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6348/10000, Loss: 0.7651, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6349/10000, Loss: 0.7651, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6350/10000, Loss: 0.7650, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6351/10000, Loss: 0.7650, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6352/10000, Loss: 0.7650, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6353/10000, Loss: 0.7649, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6354/10000, Loss: 0.7649, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6355/10000, Loss: 0.7649, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6356/10000, Loss: 0.7649, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6357/10000, Loss: 0.7648, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6358/10000, Loss: 0.7648, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6359/10000, Loss: 0.7648, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6360/10000, Loss: 0.7647, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6361/10000, Loss: 0.7647, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6362/10000, Loss: 0.7647, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6363/10000, Loss: 0.7647, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6364/10000, Loss: 0.7646, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6365/10000, Loss: 0.7646, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6366/10000, Loss: 0.7646, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6367/10000, Loss: 0.7645, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6368/10000, Loss: 0.7645, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6369/10000, Loss: 0.7645, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6370/10000, Loss: 0.7645, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6371/10000, Loss: 0.7644, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6372/10000, Loss: 0.7644, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6373/10000, Loss: 0.7644, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6374/10000, Loss: 0.7643, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6375/10000, Loss: 0.7643, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6376/10000, Loss: 0.7643, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6377/10000, Loss: 0.7643, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6378/10000, Loss: 0.7642, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6379/10000, Loss: 0.7642, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6380/10000, Loss: 0.7642, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6381/10000, Loss: 0.7641, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6382/10000, Loss: 0.7641, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6383/10000, Loss: 0.7641, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6384/10000, Loss: 0.7641, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6385/10000, Loss: 0.7640, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6386/10000, Loss: 0.7640, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6387/10000, Loss: 0.7640, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6388/10000, Loss: 0.7639, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6389/10000, Loss: 0.7639, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6390/10000, Loss: 0.7639, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6391/10000, Loss: 0.7639, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6392/10000, Loss: 0.7638, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6393/10000, Loss: 0.7638, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6394/10000, Loss: 0.7638, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6395/10000, Loss: 0.7637, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6396/10000, Loss: 0.7637, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6397/10000, Loss: 0.7637, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6398/10000, Loss: 0.7637, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6399/10000, Loss: 0.7636, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6400/10000, Loss: 0.7636, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6401/10000, Loss: 0.7636, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6402/10000, Loss: 0.7635, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6403/10000, Loss: 0.7635, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6404/10000, Loss: 0.7635, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6405/10000, Loss: 0.7635, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6406/10000, Loss: 0.7634, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6407/10000, Loss: 0.7634, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6408/10000, Loss: 0.7634, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6409/10000, Loss: 0.7633, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6410/10000, Loss: 0.7633, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6411/10000, Loss: 0.7633, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6412/10000, Loss: 0.7633, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6413/10000, Loss: 0.7632, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6414/10000, Loss: 0.7632, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6415/10000, Loss: 0.7632, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6416/10000, Loss: 0.7631, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6417/10000, Loss: 0.7631, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6418/10000, Loss: 0.7631, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6419/10000, Loss: 0.7631, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6420/10000, Loss: 0.7630, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6421/10000, Loss: 0.7630, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6422/10000, Loss: 0.7630, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6423/10000, Loss: 0.7630, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6424/10000, Loss: 0.7629, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6425/10000, Loss: 0.7629, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6426/10000, Loss: 0.7629, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6427/10000, Loss: 0.7628, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6428/10000, Loss: 0.7628, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6429/10000, Loss: 0.7628, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6430/10000, Loss: 0.7628, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6431/10000, Loss: 0.7627, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6432/10000, Loss: 0.7627, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6433/10000, Loss: 0.7627, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6434/10000, Loss: 0.7626, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6435/10000, Loss: 0.7626, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6436/10000, Loss: 0.7626, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6437/10000, Loss: 0.7626, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6438/10000, Loss: 0.7625, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6439/10000, Loss: 0.7625, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6440/10000, Loss: 0.7625, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6441/10000, Loss: 0.7624, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6442/10000, Loss: 0.7624, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6443/10000, Loss: 0.7624, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6444/10000, Loss: 0.7624, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6445/10000, Loss: 0.7623, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6446/10000, Loss: 0.7623, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6447/10000, Loss: 0.7623, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6448/10000, Loss: 0.7623, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6449/10000, Loss: 0.7622, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6450/10000, Loss: 0.7622, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6451/10000, Loss: 0.7622, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6452/10000, Loss: 0.7621, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6453/10000, Loss: 0.7621, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6454/10000, Loss: 0.7621, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6455/10000, Loss: 0.7621, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6456/10000, Loss: 0.7620, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6457/10000, Loss: 0.7620, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6458/10000, Loss: 0.7620, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6459/10000, Loss: 0.7619, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6460/10000, Loss: 0.7619, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6461/10000, Loss: 0.7619, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6462/10000, Loss: 0.7619, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6463/10000, Loss: 0.7618, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6464/10000, Loss: 0.7618, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6465/10000, Loss: 0.7618, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6466/10000, Loss: 0.7618, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6467/10000, Loss: 0.7617, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6468/10000, Loss: 0.7617, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6469/10000, Loss: 0.7617, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6470/10000, Loss: 0.7616, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6471/10000, Loss: 0.7616, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6472/10000, Loss: 0.7616, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6473/10000, Loss: 0.7616, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6474/10000, Loss: 0.7615, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6475/10000, Loss: 0.7615, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6476/10000, Loss: 0.7615, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6477/10000, Loss: 0.7615, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6478/10000, Loss: 0.7614, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6479/10000, Loss: 0.7614, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6480/10000, Loss: 0.7614, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6481/10000, Loss: 0.7613, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6482/10000, Loss: 0.7613, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6483/10000, Loss: 0.7613, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6484/10000, Loss: 0.7613, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6485/10000, Loss: 0.7612, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6486/10000, Loss: 0.7612, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6487/10000, Loss: 0.7612, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6488/10000, Loss: 0.7611, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6489/10000, Loss: 0.7611, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6490/10000, Loss: 0.7611, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6491/10000, Loss: 0.7611, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6492/10000, Loss: 0.7610, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6493/10000, Loss: 0.7610, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6494/10000, Loss: 0.7610, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6495/10000, Loss: 0.7610, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6496/10000, Loss: 0.7609, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6497/10000, Loss: 0.7609, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6498/10000, Loss: 0.7609, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6499/10000, Loss: 0.7608, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6500/10000, Loss: 0.7608, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6501/10000, Loss: 0.7608, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6502/10000, Loss: 0.7608, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6503/10000, Loss: 0.7607, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6504/10000, Loss: 0.7607, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6505/10000, Loss: 0.7607, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6506/10000, Loss: 0.7607, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6507/10000, Loss: 0.7606, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6508/10000, Loss: 0.7606, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6509/10000, Loss: 0.7606, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6510/10000, Loss: 0.7605, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6511/10000, Loss: 0.7605, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6512/10000, Loss: 0.7605, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6513/10000, Loss: 0.7605, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6514/10000, Loss: 0.7604, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6515/10000, Loss: 0.7604, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6516/10000, Loss: 0.7604, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6517/10000, Loss: 0.7604, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6518/10000, Loss: 0.7603, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6519/10000, Loss: 0.7603, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6520/10000, Loss: 0.7603, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6521/10000, Loss: 0.7602, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6522/10000, Loss: 0.7602, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6523/10000, Loss: 0.7602, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6524/10000, Loss: 0.7602, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6525/10000, Loss: 0.7601, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6526/10000, Loss: 0.7601, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6527/10000, Loss: 0.7601, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6528/10000, Loss: 0.7601, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6529/10000, Loss: 0.7600, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6530/10000, Loss: 0.7600, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6531/10000, Loss: 0.7600, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6532/10000, Loss: 0.7600, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6533/10000, Loss: 0.7599, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6534/10000, Loss: 0.7599, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6535/10000, Loss: 0.7599, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6536/10000, Loss: 0.7598, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6537/10000, Loss: 0.7598, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6538/10000, Loss: 0.7598, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6539/10000, Loss: 0.7598, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6540/10000, Loss: 0.7597, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6541/10000, Loss: 0.7597, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6542/10000, Loss: 0.7597, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6543/10000, Loss: 0.7597, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6544/10000, Loss: 0.7596, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6545/10000, Loss: 0.7596, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6546/10000, Loss: 0.7596, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6547/10000, Loss: 0.7595, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6548/10000, Loss: 0.7595, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6549/10000, Loss: 0.7595, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6550/10000, Loss: 0.7595, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6551/10000, Loss: 0.7594, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6552/10000, Loss: 0.7594, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6553/10000, Loss: 0.7594, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6554/10000, Loss: 0.7594, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6555/10000, Loss: 0.7593, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6556/10000, Loss: 0.7593, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6557/10000, Loss: 0.7593, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6558/10000, Loss: 0.7593, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6559/10000, Loss: 0.7592, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6560/10000, Loss: 0.7592, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6561/10000, Loss: 0.7592, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 6562/10000, Loss: 0.7591, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6563/10000, Loss: 0.7591, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6564/10000, Loss: 0.7591, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6565/10000, Loss: 0.7591, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6566/10000, Loss: 0.7590, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6567/10000, Loss: 0.7590, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6568/10000, Loss: 0.7590, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6569/10000, Loss: 0.7590, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6570/10000, Loss: 0.7589, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6571/10000, Loss: 0.7589, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6572/10000, Loss: 0.7589, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6573/10000, Loss: 0.7589, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6574/10000, Loss: 0.7588, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6575/10000, Loss: 0.7588, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6576/10000, Loss: 0.7588, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6577/10000, Loss: 0.7587, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6578/10000, Loss: 0.7587, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6579/10000, Loss: 0.7587, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6580/10000, Loss: 0.7587, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6581/10000, Loss: 0.7586, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6582/10000, Loss: 0.7586, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6583/10000, Loss: 0.7586, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6584/10000, Loss: 0.7586, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6585/10000, Loss: 0.7585, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6586/10000, Loss: 0.7585, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6587/10000, Loss: 0.7585, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6588/10000, Loss: 0.7585, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6589/10000, Loss: 0.7584, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6590/10000, Loss: 0.7584, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6591/10000, Loss: 0.7584, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6592/10000, Loss: 0.7583, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6593/10000, Loss: 0.7583, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6594/10000, Loss: 0.7583, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6595/10000, Loss: 0.7583, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6596/10000, Loss: 0.7582, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6597/10000, Loss: 0.7582, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6598/10000, Loss: 0.7582, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6599/10000, Loss: 0.7582, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6600/10000, Loss: 0.7581, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6601/10000, Loss: 0.7581, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6602/10000, Loss: 0.7581, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6603/10000, Loss: 0.7581, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6604/10000, Loss: 0.7580, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6605/10000, Loss: 0.7580, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6606/10000, Loss: 0.7580, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6607/10000, Loss: 0.7580, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6608/10000, Loss: 0.7579, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6609/10000, Loss: 0.7579, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6610/10000, Loss: 0.7579, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6611/10000, Loss: 0.7578, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6612/10000, Loss: 0.7578, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6613/10000, Loss: 0.7578, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6614/10000, Loss: 0.7578, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6615/10000, Loss: 0.7577, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6616/10000, Loss: 0.7577, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6617/10000, Loss: 0.7577, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6618/10000, Loss: 0.7577, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6619/10000, Loss: 0.7576, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6620/10000, Loss: 0.7576, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6621/10000, Loss: 0.7576, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6622/10000, Loss: 0.7576, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6623/10000, Loss: 0.7575, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6624/10000, Loss: 0.7575, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6625/10000, Loss: 0.7575, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6626/10000, Loss: 0.7575, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6627/10000, Loss: 0.7574, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6628/10000, Loss: 0.7574, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6629/10000, Loss: 0.7574, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6630/10000, Loss: 0.7573, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6631/10000, Loss: 0.7573, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6632/10000, Loss: 0.7573, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6633/10000, Loss: 0.7573, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6634/10000, Loss: 0.7572, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6635/10000, Loss: 0.7572, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6636/10000, Loss: 0.7572, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6637/10000, Loss: 0.7572, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6638/10000, Loss: 0.7571, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6639/10000, Loss: 0.7571, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6640/10000, Loss: 0.7571, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6641/10000, Loss: 0.7571, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6642/10000, Loss: 0.7570, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6643/10000, Loss: 0.7570, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6644/10000, Loss: 0.7570, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6645/10000, Loss: 0.7570, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6646/10000, Loss: 0.7569, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6647/10000, Loss: 0.7569, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6648/10000, Loss: 0.7569, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6649/10000, Loss: 0.7569, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6650/10000, Loss: 0.7568, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6651/10000, Loss: 0.7568, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6652/10000, Loss: 0.7568, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6653/10000, Loss: 0.7567, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6654/10000, Loss: 0.7567, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6655/10000, Loss: 0.7567, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6656/10000, Loss: 0.7567, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6657/10000, Loss: 0.7566, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6658/10000, Loss: 0.7566, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6659/10000, Loss: 0.7566, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6660/10000, Loss: 0.7566, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6661/10000, Loss: 0.7565, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6662/10000, Loss: 0.7565, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6663/10000, Loss: 0.7565, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6664/10000, Loss: 0.7565, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6665/10000, Loss: 0.7564, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6666/10000, Loss: 0.7564, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6667/10000, Loss: 0.7564, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6668/10000, Loss: 0.7564, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6669/10000, Loss: 0.7563, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6670/10000, Loss: 0.7563, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6671/10000, Loss: 0.7563, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6672/10000, Loss: 0.7563, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6673/10000, Loss: 0.7562, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6674/10000, Loss: 0.7562, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6675/10000, Loss: 0.7562, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6676/10000, Loss: 0.7562, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6677/10000, Loss: 0.7561, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6678/10000, Loss: 0.7561, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6679/10000, Loss: 0.7561, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6680/10000, Loss: 0.7560, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6681/10000, Loss: 0.7560, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6682/10000, Loss: 0.7560, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6683/10000, Loss: 0.7560, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6684/10000, Loss: 0.7559, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6685/10000, Loss: 0.7559, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6686/10000, Loss: 0.7559, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6687/10000, Loss: 0.7559, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6688/10000, Loss: 0.7558, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6689/10000, Loss: 0.7558, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6690/10000, Loss: 0.7558, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6691/10000, Loss: 0.7558, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6692/10000, Loss: 0.7557, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6693/10000, Loss: 0.7557, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6694/10000, Loss: 0.7557, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6695/10000, Loss: 0.7557, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6696/10000, Loss: 0.7556, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6697/10000, Loss: 0.7556, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6698/10000, Loss: 0.7556, Accuracy: 0.6704, Learning Rate: 0.000100\n",
      "Epoch 6699/10000, Loss: 0.7556, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6700/10000, Loss: 0.7555, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6701/10000, Loss: 0.7555, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6702/10000, Loss: 0.7555, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6703/10000, Loss: 0.7555, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6704/10000, Loss: 0.7554, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6705/10000, Loss: 0.7554, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6706/10000, Loss: 0.7554, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6707/10000, Loss: 0.7554, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6708/10000, Loss: 0.7553, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6709/10000, Loss: 0.7553, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6710/10000, Loss: 0.7553, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6711/10000, Loss: 0.7553, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6712/10000, Loss: 0.7552, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6713/10000, Loss: 0.7552, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6714/10000, Loss: 0.7552, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6715/10000, Loss: 0.7552, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6716/10000, Loss: 0.7551, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6717/10000, Loss: 0.7551, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6718/10000, Loss: 0.7551, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6719/10000, Loss: 0.7550, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6720/10000, Loss: 0.7550, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6721/10000, Loss: 0.7550, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6722/10000, Loss: 0.7550, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6723/10000, Loss: 0.7549, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6724/10000, Loss: 0.7549, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6725/10000, Loss: 0.7549, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6726/10000, Loss: 0.7549, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6727/10000, Loss: 0.7548, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6728/10000, Loss: 0.7548, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6729/10000, Loss: 0.7548, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6730/10000, Loss: 0.7548, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6731/10000, Loss: 0.7547, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6732/10000, Loss: 0.7547, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6733/10000, Loss: 0.7547, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6734/10000, Loss: 0.7547, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6735/10000, Loss: 0.7546, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6736/10000, Loss: 0.7546, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6737/10000, Loss: 0.7546, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6738/10000, Loss: 0.7546, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6739/10000, Loss: 0.7545, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6740/10000, Loss: 0.7545, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6741/10000, Loss: 0.7545, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6742/10000, Loss: 0.7545, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6743/10000, Loss: 0.7544, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6744/10000, Loss: 0.7544, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6745/10000, Loss: 0.7544, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6746/10000, Loss: 0.7544, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6747/10000, Loss: 0.7543, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6748/10000, Loss: 0.7543, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6749/10000, Loss: 0.7543, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6750/10000, Loss: 0.7543, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6751/10000, Loss: 0.7542, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6752/10000, Loss: 0.7542, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6753/10000, Loss: 0.7542, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6754/10000, Loss: 0.7542, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6755/10000, Loss: 0.7541, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6756/10000, Loss: 0.7541, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6757/10000, Loss: 0.7541, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6758/10000, Loss: 0.7541, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6759/10000, Loss: 0.7540, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6760/10000, Loss: 0.7540, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6761/10000, Loss: 0.7540, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6762/10000, Loss: 0.7540, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6763/10000, Loss: 0.7539, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6764/10000, Loss: 0.7539, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6765/10000, Loss: 0.7539, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6766/10000, Loss: 0.7539, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6767/10000, Loss: 0.7538, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6768/10000, Loss: 0.7538, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6769/10000, Loss: 0.7538, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6770/10000, Loss: 0.7538, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6771/10000, Loss: 0.7537, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6772/10000, Loss: 0.7537, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6773/10000, Loss: 0.7537, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6774/10000, Loss: 0.7537, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6775/10000, Loss: 0.7536, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6776/10000, Loss: 0.7536, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6777/10000, Loss: 0.7536, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6778/10000, Loss: 0.7536, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6779/10000, Loss: 0.7535, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6780/10000, Loss: 0.7535, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6781/10000, Loss: 0.7535, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6782/10000, Loss: 0.7535, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6783/10000, Loss: 0.7534, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6784/10000, Loss: 0.7534, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6785/10000, Loss: 0.7534, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6786/10000, Loss: 0.7534, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6787/10000, Loss: 0.7533, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6788/10000, Loss: 0.7533, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6789/10000, Loss: 0.7533, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6790/10000, Loss: 0.7533, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6791/10000, Loss: 0.7532, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6792/10000, Loss: 0.7532, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6793/10000, Loss: 0.7532, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6794/10000, Loss: 0.7532, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6795/10000, Loss: 0.7531, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6796/10000, Loss: 0.7531, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6797/10000, Loss: 0.7531, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6798/10000, Loss: 0.7531, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6799/10000, Loss: 0.7530, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6800/10000, Loss: 0.7530, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6801/10000, Loss: 0.7530, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6802/10000, Loss: 0.7530, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6803/10000, Loss: 0.7529, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6804/10000, Loss: 0.7529, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6805/10000, Loss: 0.7529, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6806/10000, Loss: 0.7529, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6807/10000, Loss: 0.7528, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6808/10000, Loss: 0.7528, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6809/10000, Loss: 0.7528, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6810/10000, Loss: 0.7528, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6811/10000, Loss: 0.7527, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6812/10000, Loss: 0.7527, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6813/10000, Loss: 0.7527, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6814/10000, Loss: 0.7527, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6815/10000, Loss: 0.7526, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6816/10000, Loss: 0.7526, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6817/10000, Loss: 0.7526, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6818/10000, Loss: 0.7526, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6819/10000, Loss: 0.7525, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6820/10000, Loss: 0.7525, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6821/10000, Loss: 0.7525, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6822/10000, Loss: 0.7525, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6823/10000, Loss: 0.7524, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6824/10000, Loss: 0.7524, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6825/10000, Loss: 0.7524, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6826/10000, Loss: 0.7524, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6827/10000, Loss: 0.7523, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6828/10000, Loss: 0.7523, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6829/10000, Loss: 0.7523, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6830/10000, Loss: 0.7523, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6831/10000, Loss: 0.7522, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6832/10000, Loss: 0.7522, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6833/10000, Loss: 0.7522, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6834/10000, Loss: 0.7522, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6835/10000, Loss: 0.7521, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6836/10000, Loss: 0.7521, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6837/10000, Loss: 0.7521, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6838/10000, Loss: 0.7521, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6839/10000, Loss: 0.7520, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6840/10000, Loss: 0.7520, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6841/10000, Loss: 0.7520, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6842/10000, Loss: 0.7520, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6843/10000, Loss: 0.7519, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6844/10000, Loss: 0.7519, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6845/10000, Loss: 0.7519, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6846/10000, Loss: 0.7519, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6847/10000, Loss: 0.7518, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6848/10000, Loss: 0.7518, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6849/10000, Loss: 0.7518, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6850/10000, Loss: 0.7518, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6851/10000, Loss: 0.7517, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6852/10000, Loss: 0.7517, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6853/10000, Loss: 0.7517, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6854/10000, Loss: 0.7517, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6855/10000, Loss: 0.7516, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6856/10000, Loss: 0.7516, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6857/10000, Loss: 0.7516, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6858/10000, Loss: 0.7516, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6859/10000, Loss: 0.7516, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6860/10000, Loss: 0.7515, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6861/10000, Loss: 0.7515, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6862/10000, Loss: 0.7515, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6863/10000, Loss: 0.7515, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6864/10000, Loss: 0.7514, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6865/10000, Loss: 0.7514, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6866/10000, Loss: 0.7514, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6867/10000, Loss: 0.7514, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6868/10000, Loss: 0.7513, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6869/10000, Loss: 0.7513, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6870/10000, Loss: 0.7513, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6871/10000, Loss: 0.7513, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6872/10000, Loss: 0.7512, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6873/10000, Loss: 0.7512, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6874/10000, Loss: 0.7512, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6875/10000, Loss: 0.7512, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6876/10000, Loss: 0.7511, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6877/10000, Loss: 0.7511, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6878/10000, Loss: 0.7511, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6879/10000, Loss: 0.7511, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6880/10000, Loss: 0.7510, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6881/10000, Loss: 0.7510, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6882/10000, Loss: 0.7510, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6883/10000, Loss: 0.7510, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6884/10000, Loss: 0.7509, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6885/10000, Loss: 0.7509, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6886/10000, Loss: 0.7509, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6887/10000, Loss: 0.7509, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6888/10000, Loss: 0.7508, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6889/10000, Loss: 0.7508, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6890/10000, Loss: 0.7508, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6891/10000, Loss: 0.7508, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6892/10000, Loss: 0.7507, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6893/10000, Loss: 0.7507, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6894/10000, Loss: 0.7507, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6895/10000, Loss: 0.7507, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6896/10000, Loss: 0.7506, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6897/10000, Loss: 0.7506, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6898/10000, Loss: 0.7506, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6899/10000, Loss: 0.7506, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6900/10000, Loss: 0.7506, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6901/10000, Loss: 0.7505, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6902/10000, Loss: 0.7505, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6903/10000, Loss: 0.7505, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6904/10000, Loss: 0.7505, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6905/10000, Loss: 0.7504, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6906/10000, Loss: 0.7504, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6907/10000, Loss: 0.7504, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6908/10000, Loss: 0.7504, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6909/10000, Loss: 0.7503, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6910/10000, Loss: 0.7503, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6911/10000, Loss: 0.7503, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6912/10000, Loss: 0.7503, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6913/10000, Loss: 0.7502, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6914/10000, Loss: 0.7502, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6915/10000, Loss: 0.7502, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6916/10000, Loss: 0.7502, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6917/10000, Loss: 0.7501, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6918/10000, Loss: 0.7501, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6919/10000, Loss: 0.7501, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6920/10000, Loss: 0.7501, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6921/10000, Loss: 0.7500, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6922/10000, Loss: 0.7500, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6923/10000, Loss: 0.7500, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6924/10000, Loss: 0.7500, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6925/10000, Loss: 0.7499, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6926/10000, Loss: 0.7499, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6927/10000, Loss: 0.7499, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6928/10000, Loss: 0.7499, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6929/10000, Loss: 0.7499, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6930/10000, Loss: 0.7498, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6931/10000, Loss: 0.7498, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6932/10000, Loss: 0.7498, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6933/10000, Loss: 0.7498, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6934/10000, Loss: 0.7497, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6935/10000, Loss: 0.7497, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6936/10000, Loss: 0.7497, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6937/10000, Loss: 0.7497, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6938/10000, Loss: 0.7496, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6939/10000, Loss: 0.7496, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6940/10000, Loss: 0.7496, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6941/10000, Loss: 0.7496, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6942/10000, Loss: 0.7495, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6943/10000, Loss: 0.7495, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6944/10000, Loss: 0.7495, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6945/10000, Loss: 0.7495, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6946/10000, Loss: 0.7494, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6947/10000, Loss: 0.7494, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6948/10000, Loss: 0.7494, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 6949/10000, Loss: 0.7494, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6950/10000, Loss: 0.7493, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6951/10000, Loss: 0.7493, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6952/10000, Loss: 0.7493, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6953/10000, Loss: 0.7493, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6954/10000, Loss: 0.7493, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6955/10000, Loss: 0.7492, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6956/10000, Loss: 0.7492, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6957/10000, Loss: 0.7492, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6958/10000, Loss: 0.7492, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6959/10000, Loss: 0.7491, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6960/10000, Loss: 0.7491, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6961/10000, Loss: 0.7491, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6962/10000, Loss: 0.7491, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6963/10000, Loss: 0.7490, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6964/10000, Loss: 0.7490, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6965/10000, Loss: 0.7490, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6966/10000, Loss: 0.7490, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6967/10000, Loss: 0.7489, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6968/10000, Loss: 0.7489, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6969/10000, Loss: 0.7489, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6970/10000, Loss: 0.7489, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6971/10000, Loss: 0.7488, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6972/10000, Loss: 0.7488, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6973/10000, Loss: 0.7488, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6974/10000, Loss: 0.7488, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6975/10000, Loss: 0.7487, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6976/10000, Loss: 0.7487, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6977/10000, Loss: 0.7487, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6978/10000, Loss: 0.7487, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6979/10000, Loss: 0.7487, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6980/10000, Loss: 0.7486, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6981/10000, Loss: 0.7486, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6982/10000, Loss: 0.7486, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6983/10000, Loss: 0.7486, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6984/10000, Loss: 0.7485, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6985/10000, Loss: 0.7485, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6986/10000, Loss: 0.7485, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6987/10000, Loss: 0.7485, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6988/10000, Loss: 0.7484, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6989/10000, Loss: 0.7484, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6990/10000, Loss: 0.7484, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6991/10000, Loss: 0.7484, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6992/10000, Loss: 0.7483, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6993/10000, Loss: 0.7483, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6994/10000, Loss: 0.7483, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6995/10000, Loss: 0.7483, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6996/10000, Loss: 0.7483, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6997/10000, Loss: 0.7482, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6998/10000, Loss: 0.7482, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 6999/10000, Loss: 0.7482, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7000/10000, Loss: 0.7482, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7001/10000, Loss: 0.7481, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7002/10000, Loss: 0.7481, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7003/10000, Loss: 0.7481, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7004/10000, Loss: 0.7481, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7005/10000, Loss: 0.7480, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7006/10000, Loss: 0.7480, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7007/10000, Loss: 0.7480, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7008/10000, Loss: 0.7480, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7009/10000, Loss: 0.7479, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7010/10000, Loss: 0.7479, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7011/10000, Loss: 0.7479, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7012/10000, Loss: 0.7479, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7013/10000, Loss: 0.7478, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7014/10000, Loss: 0.7478, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7015/10000, Loss: 0.7478, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7016/10000, Loss: 0.7478, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7017/10000, Loss: 0.7478, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7018/10000, Loss: 0.7477, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7019/10000, Loss: 0.7477, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7020/10000, Loss: 0.7477, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7021/10000, Loss: 0.7477, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7022/10000, Loss: 0.7476, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7023/10000, Loss: 0.7476, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7024/10000, Loss: 0.7476, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7025/10000, Loss: 0.7476, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7026/10000, Loss: 0.7475, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7027/10000, Loss: 0.7475, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7028/10000, Loss: 0.7475, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7029/10000, Loss: 0.7475, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7030/10000, Loss: 0.7474, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7031/10000, Loss: 0.7474, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7032/10000, Loss: 0.7474, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7033/10000, Loss: 0.7474, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7034/10000, Loss: 0.7474, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7035/10000, Loss: 0.7473, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7036/10000, Loss: 0.7473, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7037/10000, Loss: 0.7473, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7038/10000, Loss: 0.7473, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7039/10000, Loss: 0.7472, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7040/10000, Loss: 0.7472, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7041/10000, Loss: 0.7472, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7042/10000, Loss: 0.7472, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7043/10000, Loss: 0.7471, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7044/10000, Loss: 0.7471, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7045/10000, Loss: 0.7471, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7046/10000, Loss: 0.7471, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7047/10000, Loss: 0.7471, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7048/10000, Loss: 0.7470, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7049/10000, Loss: 0.7470, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7050/10000, Loss: 0.7470, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7051/10000, Loss: 0.7470, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7052/10000, Loss: 0.7469, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7053/10000, Loss: 0.7469, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7054/10000, Loss: 0.7469, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7055/10000, Loss: 0.7469, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7056/10000, Loss: 0.7468, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7057/10000, Loss: 0.7468, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7058/10000, Loss: 0.7468, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7059/10000, Loss: 0.7468, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7060/10000, Loss: 0.7467, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7061/10000, Loss: 0.7467, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7062/10000, Loss: 0.7467, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7063/10000, Loss: 0.7467, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7064/10000, Loss: 0.7467, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7065/10000, Loss: 0.7466, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7066/10000, Loss: 0.7466, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7067/10000, Loss: 0.7466, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7068/10000, Loss: 0.7466, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7069/10000, Loss: 0.7465, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7070/10000, Loss: 0.7465, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7071/10000, Loss: 0.7465, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7072/10000, Loss: 0.7465, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7073/10000, Loss: 0.7464, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7074/10000, Loss: 0.7464, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7075/10000, Loss: 0.7464, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7076/10000, Loss: 0.7464, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7077/10000, Loss: 0.7464, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7078/10000, Loss: 0.7463, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7079/10000, Loss: 0.7463, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7080/10000, Loss: 0.7463, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7081/10000, Loss: 0.7463, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7082/10000, Loss: 0.7462, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7083/10000, Loss: 0.7462, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7084/10000, Loss: 0.7462, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7085/10000, Loss: 0.7462, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7086/10000, Loss: 0.7461, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7087/10000, Loss: 0.7461, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7088/10000, Loss: 0.7461, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7089/10000, Loss: 0.7461, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7090/10000, Loss: 0.7460, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7091/10000, Loss: 0.7460, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7092/10000, Loss: 0.7460, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7093/10000, Loss: 0.7460, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7094/10000, Loss: 0.7460, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7095/10000, Loss: 0.7459, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7096/10000, Loss: 0.7459, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7097/10000, Loss: 0.7459, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7098/10000, Loss: 0.7459, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7099/10000, Loss: 0.7458, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7100/10000, Loss: 0.7458, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7101/10000, Loss: 0.7458, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7102/10000, Loss: 0.7458, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7103/10000, Loss: 0.7457, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7104/10000, Loss: 0.7457, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7105/10000, Loss: 0.7457, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7106/10000, Loss: 0.7457, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7107/10000, Loss: 0.7457, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7108/10000, Loss: 0.7456, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7109/10000, Loss: 0.7456, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7110/10000, Loss: 0.7456, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7111/10000, Loss: 0.7456, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7112/10000, Loss: 0.7455, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7113/10000, Loss: 0.7455, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7114/10000, Loss: 0.7455, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7115/10000, Loss: 0.7455, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7116/10000, Loss: 0.7454, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7117/10000, Loss: 0.7454, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7118/10000, Loss: 0.7454, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7119/10000, Loss: 0.7454, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7120/10000, Loss: 0.7454, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7121/10000, Loss: 0.7453, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7122/10000, Loss: 0.7453, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7123/10000, Loss: 0.7453, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7124/10000, Loss: 0.7453, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7125/10000, Loss: 0.7452, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7126/10000, Loss: 0.7452, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7127/10000, Loss: 0.7452, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7128/10000, Loss: 0.7452, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7129/10000, Loss: 0.7451, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7130/10000, Loss: 0.7451, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7131/10000, Loss: 0.7451, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7132/10000, Loss: 0.7451, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7133/10000, Loss: 0.7451, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7134/10000, Loss: 0.7450, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7135/10000, Loss: 0.7450, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7136/10000, Loss: 0.7450, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7137/10000, Loss: 0.7450, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7138/10000, Loss: 0.7449, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7139/10000, Loss: 0.7449, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7140/10000, Loss: 0.7449, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7141/10000, Loss: 0.7449, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7142/10000, Loss: 0.7449, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7143/10000, Loss: 0.7448, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7144/10000, Loss: 0.7448, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7145/10000, Loss: 0.7448, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7146/10000, Loss: 0.7448, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7147/10000, Loss: 0.7447, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7148/10000, Loss: 0.7447, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7149/10000, Loss: 0.7447, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7150/10000, Loss: 0.7447, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7151/10000, Loss: 0.7446, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7152/10000, Loss: 0.7446, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7153/10000, Loss: 0.7446, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7154/10000, Loss: 0.7446, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7155/10000, Loss: 0.7446, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7156/10000, Loss: 0.7445, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7157/10000, Loss: 0.7445, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7158/10000, Loss: 0.7445, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7159/10000, Loss: 0.7445, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7160/10000, Loss: 0.7444, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7161/10000, Loss: 0.7444, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7162/10000, Loss: 0.7444, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7163/10000, Loss: 0.7444, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7164/10000, Loss: 0.7443, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7165/10000, Loss: 0.7443, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7166/10000, Loss: 0.7443, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7167/10000, Loss: 0.7443, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7168/10000, Loss: 0.7443, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7169/10000, Loss: 0.7442, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7170/10000, Loss: 0.7442, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7171/10000, Loss: 0.7442, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7172/10000, Loss: 0.7442, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7173/10000, Loss: 0.7441, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7174/10000, Loss: 0.7441, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7175/10000, Loss: 0.7441, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7176/10000, Loss: 0.7441, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7177/10000, Loss: 0.7441, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7178/10000, Loss: 0.7440, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7179/10000, Loss: 0.7440, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7180/10000, Loss: 0.7440, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7181/10000, Loss: 0.7440, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7182/10000, Loss: 0.7439, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7183/10000, Loss: 0.7439, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7184/10000, Loss: 0.7439, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7185/10000, Loss: 0.7439, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7186/10000, Loss: 0.7438, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7187/10000, Loss: 0.7438, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7188/10000, Loss: 0.7438, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7189/10000, Loss: 0.7438, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7190/10000, Loss: 0.7438, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7191/10000, Loss: 0.7437, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7192/10000, Loss: 0.7437, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7193/10000, Loss: 0.7437, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7194/10000, Loss: 0.7437, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7195/10000, Loss: 0.7436, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7196/10000, Loss: 0.7436, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7197/10000, Loss: 0.7436, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7198/10000, Loss: 0.7436, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7199/10000, Loss: 0.7436, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7200/10000, Loss: 0.7435, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7201/10000, Loss: 0.7435, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7202/10000, Loss: 0.7435, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7203/10000, Loss: 0.7435, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7204/10000, Loss: 0.7434, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7205/10000, Loss: 0.7434, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7206/10000, Loss: 0.7434, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7207/10000, Loss: 0.7434, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7208/10000, Loss: 0.7434, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7209/10000, Loss: 0.7433, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7210/10000, Loss: 0.7433, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7211/10000, Loss: 0.7433, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7212/10000, Loss: 0.7433, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7213/10000, Loss: 0.7432, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7214/10000, Loss: 0.7432, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7215/10000, Loss: 0.7432, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7216/10000, Loss: 0.7432, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7217/10000, Loss: 0.7431, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7218/10000, Loss: 0.7431, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7219/10000, Loss: 0.7431, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7220/10000, Loss: 0.7431, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7221/10000, Loss: 0.7431, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7222/10000, Loss: 0.7430, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7223/10000, Loss: 0.7430, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7224/10000, Loss: 0.7430, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7225/10000, Loss: 0.7430, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7226/10000, Loss: 0.7429, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7227/10000, Loss: 0.7429, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7228/10000, Loss: 0.7429, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7229/10000, Loss: 0.7429, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7230/10000, Loss: 0.7429, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7231/10000, Loss: 0.7428, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7232/10000, Loss: 0.7428, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7233/10000, Loss: 0.7428, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7234/10000, Loss: 0.7428, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7235/10000, Loss: 0.7427, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7236/10000, Loss: 0.7427, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7237/10000, Loss: 0.7427, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7238/10000, Loss: 0.7427, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7239/10000, Loss: 0.7427, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7240/10000, Loss: 0.7426, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7241/10000, Loss: 0.7426, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7242/10000, Loss: 0.7426, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7243/10000, Loss: 0.7426, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7244/10000, Loss: 0.7425, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7245/10000, Loss: 0.7425, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7246/10000, Loss: 0.7425, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7247/10000, Loss: 0.7425, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7248/10000, Loss: 0.7425, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7249/10000, Loss: 0.7424, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7250/10000, Loss: 0.7424, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7251/10000, Loss: 0.7424, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7252/10000, Loss: 0.7424, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7253/10000, Loss: 0.7423, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7254/10000, Loss: 0.7423, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7255/10000, Loss: 0.7423, Accuracy: 0.6723, Learning Rate: 0.000100\n",
      "Epoch 7256/10000, Loss: 0.7423, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7257/10000, Loss: 0.7422, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7258/10000, Loss: 0.7422, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7259/10000, Loss: 0.7422, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7260/10000, Loss: 0.7422, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7261/10000, Loss: 0.7422, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7262/10000, Loss: 0.7421, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7263/10000, Loss: 0.7421, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7264/10000, Loss: 0.7421, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7265/10000, Loss: 0.7421, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7266/10000, Loss: 0.7420, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7267/10000, Loss: 0.7420, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7268/10000, Loss: 0.7420, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7269/10000, Loss: 0.7420, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7270/10000, Loss: 0.7420, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7271/10000, Loss: 0.7419, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7272/10000, Loss: 0.7419, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7273/10000, Loss: 0.7419, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7274/10000, Loss: 0.7419, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7275/10000, Loss: 0.7418, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7276/10000, Loss: 0.7418, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7277/10000, Loss: 0.7418, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7278/10000, Loss: 0.7418, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7279/10000, Loss: 0.7418, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7280/10000, Loss: 0.7417, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7281/10000, Loss: 0.7417, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7282/10000, Loss: 0.7417, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7283/10000, Loss: 0.7417, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7284/10000, Loss: 0.7416, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7285/10000, Loss: 0.7416, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7286/10000, Loss: 0.7416, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7287/10000, Loss: 0.7416, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7288/10000, Loss: 0.7416, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7289/10000, Loss: 0.7415, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7290/10000, Loss: 0.7415, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7291/10000, Loss: 0.7415, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7292/10000, Loss: 0.7415, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7293/10000, Loss: 0.7414, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7294/10000, Loss: 0.7414, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7295/10000, Loss: 0.7414, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7296/10000, Loss: 0.7414, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7297/10000, Loss: 0.7414, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7298/10000, Loss: 0.7413, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7299/10000, Loss: 0.7413, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7300/10000, Loss: 0.7413, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7301/10000, Loss: 0.7413, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7302/10000, Loss: 0.7412, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7303/10000, Loss: 0.7412, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7304/10000, Loss: 0.7412, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7305/10000, Loss: 0.7412, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7306/10000, Loss: 0.7412, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7307/10000, Loss: 0.7411, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7308/10000, Loss: 0.7411, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7309/10000, Loss: 0.7411, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7310/10000, Loss: 0.7411, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7311/10000, Loss: 0.7410, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7312/10000, Loss: 0.7410, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7313/10000, Loss: 0.7410, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7314/10000, Loss: 0.7410, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7315/10000, Loss: 0.7410, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7316/10000, Loss: 0.7409, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7317/10000, Loss: 0.7409, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7318/10000, Loss: 0.7409, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7319/10000, Loss: 0.7409, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7320/10000, Loss: 0.7409, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7321/10000, Loss: 0.7408, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7322/10000, Loss: 0.7408, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7323/10000, Loss: 0.7408, Accuracy: 0.6741, Learning Rate: 0.000100\n",
      "Epoch 7324/10000, Loss: 0.7408, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7325/10000, Loss: 0.7407, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7326/10000, Loss: 0.7407, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7327/10000, Loss: 0.7407, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7328/10000, Loss: 0.7407, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7329/10000, Loss: 0.7407, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7330/10000, Loss: 0.7406, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7331/10000, Loss: 0.7406, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7332/10000, Loss: 0.7406, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7333/10000, Loss: 0.7406, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7334/10000, Loss: 0.7405, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7335/10000, Loss: 0.7405, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7336/10000, Loss: 0.7405, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7337/10000, Loss: 0.7405, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7338/10000, Loss: 0.7405, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7339/10000, Loss: 0.7404, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7340/10000, Loss: 0.7404, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7341/10000, Loss: 0.7404, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7342/10000, Loss: 0.7404, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7343/10000, Loss: 0.7403, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7344/10000, Loss: 0.7403, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7345/10000, Loss: 0.7403, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7346/10000, Loss: 0.7403, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7347/10000, Loss: 0.7403, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7348/10000, Loss: 0.7402, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7349/10000, Loss: 0.7402, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7350/10000, Loss: 0.7402, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7351/10000, Loss: 0.7402, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7352/10000, Loss: 0.7401, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7353/10000, Loss: 0.7401, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7354/10000, Loss: 0.7401, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7355/10000, Loss: 0.7401, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7356/10000, Loss: 0.7401, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7357/10000, Loss: 0.7400, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7358/10000, Loss: 0.7400, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7359/10000, Loss: 0.7400, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7360/10000, Loss: 0.7400, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7361/10000, Loss: 0.7399, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7362/10000, Loss: 0.7399, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7363/10000, Loss: 0.7399, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7364/10000, Loss: 0.7399, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7365/10000, Loss: 0.7399, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7366/10000, Loss: 0.7398, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7367/10000, Loss: 0.7398, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7368/10000, Loss: 0.7398, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7369/10000, Loss: 0.7398, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7370/10000, Loss: 0.7398, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7371/10000, Loss: 0.7397, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7372/10000, Loss: 0.7397, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7373/10000, Loss: 0.7397, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7374/10000, Loss: 0.7397, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7375/10000, Loss: 0.7396, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7376/10000, Loss: 0.7396, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7377/10000, Loss: 0.7396, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7378/10000, Loss: 0.7396, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7379/10000, Loss: 0.7396, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7380/10000, Loss: 0.7395, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7381/10000, Loss: 0.7395, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7382/10000, Loss: 0.7395, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7383/10000, Loss: 0.7395, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7384/10000, Loss: 0.7394, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7385/10000, Loss: 0.7394, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7386/10000, Loss: 0.7394, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7387/10000, Loss: 0.7394, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7388/10000, Loss: 0.7394, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7389/10000, Loss: 0.7393, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7390/10000, Loss: 0.7393, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7391/10000, Loss: 0.7393, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7392/10000, Loss: 0.7393, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7393/10000, Loss: 0.7393, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7394/10000, Loss: 0.7392, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7395/10000, Loss: 0.7392, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7396/10000, Loss: 0.7392, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7397/10000, Loss: 0.7392, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7398/10000, Loss: 0.7391, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7399/10000, Loss: 0.7391, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7400/10000, Loss: 0.7391, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7401/10000, Loss: 0.7391, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7402/10000, Loss: 0.7391, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7403/10000, Loss: 0.7390, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7404/10000, Loss: 0.7390, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7405/10000, Loss: 0.7390, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7406/10000, Loss: 0.7390, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7407/10000, Loss: 0.7389, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7408/10000, Loss: 0.7389, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7409/10000, Loss: 0.7389, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7410/10000, Loss: 0.7389, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7411/10000, Loss: 0.7389, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7412/10000, Loss: 0.7388, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7413/10000, Loss: 0.7388, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7414/10000, Loss: 0.7388, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7415/10000, Loss: 0.7388, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7416/10000, Loss: 0.7388, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7417/10000, Loss: 0.7387, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7418/10000, Loss: 0.7387, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7419/10000, Loss: 0.7387, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7420/10000, Loss: 0.7387, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7421/10000, Loss: 0.7386, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7422/10000, Loss: 0.7386, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7423/10000, Loss: 0.7386, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7424/10000, Loss: 0.7386, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7425/10000, Loss: 0.7386, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7426/10000, Loss: 0.7385, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7427/10000, Loss: 0.7385, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7428/10000, Loss: 0.7385, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7429/10000, Loss: 0.7385, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7430/10000, Loss: 0.7384, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7431/10000, Loss: 0.7384, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7432/10000, Loss: 0.7384, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7433/10000, Loss: 0.7384, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7434/10000, Loss: 0.7384, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7435/10000, Loss: 0.7383, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7436/10000, Loss: 0.7383, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7437/10000, Loss: 0.7383, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7438/10000, Loss: 0.7383, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7439/10000, Loss: 0.7383, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7440/10000, Loss: 0.7382, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7441/10000, Loss: 0.7382, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7442/10000, Loss: 0.7382, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7443/10000, Loss: 0.7382, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7444/10000, Loss: 0.7381, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7445/10000, Loss: 0.7381, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7446/10000, Loss: 0.7381, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7447/10000, Loss: 0.7381, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7448/10000, Loss: 0.7381, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7449/10000, Loss: 0.7380, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7450/10000, Loss: 0.7380, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7451/10000, Loss: 0.7380, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7452/10000, Loss: 0.7380, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7453/10000, Loss: 0.7380, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7454/10000, Loss: 0.7379, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7455/10000, Loss: 0.7379, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7456/10000, Loss: 0.7379, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7457/10000, Loss: 0.7379, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7458/10000, Loss: 0.7378, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7459/10000, Loss: 0.7378, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7460/10000, Loss: 0.7378, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7461/10000, Loss: 0.7378, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7462/10000, Loss: 0.7378, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7463/10000, Loss: 0.7377, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7464/10000, Loss: 0.7377, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7465/10000, Loss: 0.7377, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7466/10000, Loss: 0.7377, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7467/10000, Loss: 0.7377, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7468/10000, Loss: 0.7376, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7469/10000, Loss: 0.7376, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7470/10000, Loss: 0.7376, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7471/10000, Loss: 0.7376, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7472/10000, Loss: 0.7375, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7473/10000, Loss: 0.7375, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7474/10000, Loss: 0.7375, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7475/10000, Loss: 0.7375, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7476/10000, Loss: 0.7375, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7477/10000, Loss: 0.7374, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7478/10000, Loss: 0.7374, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7479/10000, Loss: 0.7374, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7480/10000, Loss: 0.7374, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7481/10000, Loss: 0.7374, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7482/10000, Loss: 0.7373, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7483/10000, Loss: 0.7373, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7484/10000, Loss: 0.7373, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7485/10000, Loss: 0.7373, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7486/10000, Loss: 0.7372, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7487/10000, Loss: 0.7372, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7488/10000, Loss: 0.7372, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7489/10000, Loss: 0.7372, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7490/10000, Loss: 0.7372, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7491/10000, Loss: 0.7371, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7492/10000, Loss: 0.7371, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7493/10000, Loss: 0.7371, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7494/10000, Loss: 0.7371, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7495/10000, Loss: 0.7371, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7496/10000, Loss: 0.7370, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7497/10000, Loss: 0.7370, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7498/10000, Loss: 0.7370, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7499/10000, Loss: 0.7370, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7500/10000, Loss: 0.7369, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7501/10000, Loss: 0.7369, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7502/10000, Loss: 0.7369, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7503/10000, Loss: 0.7369, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7504/10000, Loss: 0.7369, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7505/10000, Loss: 0.7368, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7506/10000, Loss: 0.7368, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7507/10000, Loss: 0.7368, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7508/10000, Loss: 0.7368, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7509/10000, Loss: 0.7368, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7510/10000, Loss: 0.7367, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7511/10000, Loss: 0.7367, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7512/10000, Loss: 0.7367, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7513/10000, Loss: 0.7367, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7514/10000, Loss: 0.7366, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7515/10000, Loss: 0.7366, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7516/10000, Loss: 0.7366, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7517/10000, Loss: 0.7366, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7518/10000, Loss: 0.7366, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7519/10000, Loss: 0.7365, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7520/10000, Loss: 0.7365, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7521/10000, Loss: 0.7365, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7522/10000, Loss: 0.7365, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7523/10000, Loss: 0.7365, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7524/10000, Loss: 0.7364, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7525/10000, Loss: 0.7364, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7526/10000, Loss: 0.7364, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7527/10000, Loss: 0.7364, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7528/10000, Loss: 0.7364, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7529/10000, Loss: 0.7363, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7530/10000, Loss: 0.7363, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7531/10000, Loss: 0.7363, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7532/10000, Loss: 0.7363, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7533/10000, Loss: 0.7362, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7534/10000, Loss: 0.7362, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7535/10000, Loss: 0.7362, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7536/10000, Loss: 0.7362, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7537/10000, Loss: 0.7362, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7538/10000, Loss: 0.7361, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7539/10000, Loss: 0.7361, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7540/10000, Loss: 0.7361, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7541/10000, Loss: 0.7361, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7542/10000, Loss: 0.7361, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7543/10000, Loss: 0.7360, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7544/10000, Loss: 0.7360, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7545/10000, Loss: 0.7360, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7546/10000, Loss: 0.7360, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7547/10000, Loss: 0.7359, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7548/10000, Loss: 0.7359, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7549/10000, Loss: 0.7359, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7550/10000, Loss: 0.7359, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7551/10000, Loss: 0.7359, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7552/10000, Loss: 0.7358, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7553/10000, Loss: 0.7358, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7554/10000, Loss: 0.7358, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7555/10000, Loss: 0.7358, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7556/10000, Loss: 0.7358, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7557/10000, Loss: 0.7357, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7558/10000, Loss: 0.7357, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7559/10000, Loss: 0.7357, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7560/10000, Loss: 0.7357, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7561/10000, Loss: 0.7357, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7562/10000, Loss: 0.7356, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7563/10000, Loss: 0.7356, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7564/10000, Loss: 0.7356, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7565/10000, Loss: 0.7356, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7566/10000, Loss: 0.7355, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7567/10000, Loss: 0.7355, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7568/10000, Loss: 0.7355, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7569/10000, Loss: 0.7355, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7570/10000, Loss: 0.7355, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7571/10000, Loss: 0.7354, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7572/10000, Loss: 0.7354, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7573/10000, Loss: 0.7354, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7574/10000, Loss: 0.7354, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7575/10000, Loss: 0.7354, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7576/10000, Loss: 0.7353, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7577/10000, Loss: 0.7353, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7578/10000, Loss: 0.7353, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7579/10000, Loss: 0.7353, Accuracy: 0.6760, Learning Rate: 0.000100\n",
      "Epoch 7580/10000, Loss: 0.7353, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7581/10000, Loss: 0.7352, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7582/10000, Loss: 0.7352, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7583/10000, Loss: 0.7352, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7584/10000, Loss: 0.7352, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7585/10000, Loss: 0.7351, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7586/10000, Loss: 0.7351, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7587/10000, Loss: 0.7351, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7588/10000, Loss: 0.7351, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7589/10000, Loss: 0.7351, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7590/10000, Loss: 0.7350, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7591/10000, Loss: 0.7350, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7592/10000, Loss: 0.7350, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7593/10000, Loss: 0.7350, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7594/10000, Loss: 0.7350, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7595/10000, Loss: 0.7349, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7596/10000, Loss: 0.7349, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7597/10000, Loss: 0.7349, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7598/10000, Loss: 0.7349, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7599/10000, Loss: 0.7349, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7600/10000, Loss: 0.7348, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7601/10000, Loss: 0.7348, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7602/10000, Loss: 0.7348, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7603/10000, Loss: 0.7348, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7604/10000, Loss: 0.7347, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7605/10000, Loss: 0.7347, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7606/10000, Loss: 0.7347, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7607/10000, Loss: 0.7347, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7608/10000, Loss: 0.7347, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7609/10000, Loss: 0.7346, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7610/10000, Loss: 0.7346, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7611/10000, Loss: 0.7346, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7612/10000, Loss: 0.7346, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7613/10000, Loss: 0.7346, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7614/10000, Loss: 0.7345, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7615/10000, Loss: 0.7345, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7616/10000, Loss: 0.7345, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7617/10000, Loss: 0.7345, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7618/10000, Loss: 0.7345, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7619/10000, Loss: 0.7344, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7620/10000, Loss: 0.7344, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7621/10000, Loss: 0.7344, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7622/10000, Loss: 0.7344, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7623/10000, Loss: 0.7344, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7624/10000, Loss: 0.7343, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7625/10000, Loss: 0.7343, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7626/10000, Loss: 0.7343, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7627/10000, Loss: 0.7343, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7628/10000, Loss: 0.7342, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7629/10000, Loss: 0.7342, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7630/10000, Loss: 0.7342, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7631/10000, Loss: 0.7342, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7632/10000, Loss: 0.7342, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7633/10000, Loss: 0.7341, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7634/10000, Loss: 0.7341, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7635/10000, Loss: 0.7341, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7636/10000, Loss: 0.7341, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7637/10000, Loss: 0.7341, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7638/10000, Loss: 0.7340, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7639/10000, Loss: 0.7340, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7640/10000, Loss: 0.7340, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7641/10000, Loss: 0.7340, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7642/10000, Loss: 0.7340, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7643/10000, Loss: 0.7339, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7644/10000, Loss: 0.7339, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7645/10000, Loss: 0.7339, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7646/10000, Loss: 0.7339, Accuracy: 0.6778, Learning Rate: 0.000100\n",
      "Epoch 7647/10000, Loss: 0.7339, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7648/10000, Loss: 0.7338, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7649/10000, Loss: 0.7338, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7650/10000, Loss: 0.7338, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7651/10000, Loss: 0.7338, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7652/10000, Loss: 0.7337, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7653/10000, Loss: 0.7337, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7654/10000, Loss: 0.7337, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7655/10000, Loss: 0.7337, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7656/10000, Loss: 0.7337, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7657/10000, Loss: 0.7336, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7658/10000, Loss: 0.7336, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7659/10000, Loss: 0.7336, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7660/10000, Loss: 0.7336, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7661/10000, Loss: 0.7336, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7662/10000, Loss: 0.7335, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7663/10000, Loss: 0.7335, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7664/10000, Loss: 0.7335, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7665/10000, Loss: 0.7335, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7666/10000, Loss: 0.7335, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7667/10000, Loss: 0.7334, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7668/10000, Loss: 0.7334, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7669/10000, Loss: 0.7334, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7670/10000, Loss: 0.7334, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7671/10000, Loss: 0.7334, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7672/10000, Loss: 0.7333, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7673/10000, Loss: 0.7333, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7674/10000, Loss: 0.7333, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7675/10000, Loss: 0.7333, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7676/10000, Loss: 0.7332, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7677/10000, Loss: 0.7332, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7678/10000, Loss: 0.7332, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7679/10000, Loss: 0.7332, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7680/10000, Loss: 0.7332, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7681/10000, Loss: 0.7331, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7682/10000, Loss: 0.7331, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7683/10000, Loss: 0.7331, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7684/10000, Loss: 0.7331, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7685/10000, Loss: 0.7331, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7686/10000, Loss: 0.7330, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7687/10000, Loss: 0.7330, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7688/10000, Loss: 0.7330, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7689/10000, Loss: 0.7330, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7690/10000, Loss: 0.7330, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7691/10000, Loss: 0.7329, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7692/10000, Loss: 0.7329, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7693/10000, Loss: 0.7329, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7694/10000, Loss: 0.7329, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7695/10000, Loss: 0.7329, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7696/10000, Loss: 0.7328, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7697/10000, Loss: 0.7328, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7698/10000, Loss: 0.7328, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7699/10000, Loss: 0.7328, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7700/10000, Loss: 0.7328, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7701/10000, Loss: 0.7327, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7702/10000, Loss: 0.7327, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7703/10000, Loss: 0.7327, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7704/10000, Loss: 0.7327, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7705/10000, Loss: 0.7327, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7706/10000, Loss: 0.7326, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7707/10000, Loss: 0.7326, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7708/10000, Loss: 0.7326, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7709/10000, Loss: 0.7326, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7710/10000, Loss: 0.7325, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7711/10000, Loss: 0.7325, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7712/10000, Loss: 0.7325, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7713/10000, Loss: 0.7325, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7714/10000, Loss: 0.7325, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7715/10000, Loss: 0.7324, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7716/10000, Loss: 0.7324, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7717/10000, Loss: 0.7324, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7718/10000, Loss: 0.7324, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7719/10000, Loss: 0.7324, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7720/10000, Loss: 0.7323, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7721/10000, Loss: 0.7323, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7722/10000, Loss: 0.7323, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7723/10000, Loss: 0.7323, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7724/10000, Loss: 0.7323, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7725/10000, Loss: 0.7322, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7726/10000, Loss: 0.7322, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7727/10000, Loss: 0.7322, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7728/10000, Loss: 0.7322, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7729/10000, Loss: 0.7322, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7730/10000, Loss: 0.7321, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7731/10000, Loss: 0.7321, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7732/10000, Loss: 0.7321, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7733/10000, Loss: 0.7321, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7734/10000, Loss: 0.7321, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7735/10000, Loss: 0.7320, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7736/10000, Loss: 0.7320, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7737/10000, Loss: 0.7320, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7738/10000, Loss: 0.7320, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7739/10000, Loss: 0.7320, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7740/10000, Loss: 0.7319, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7741/10000, Loss: 0.7319, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7742/10000, Loss: 0.7319, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7743/10000, Loss: 0.7319, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7744/10000, Loss: 0.7319, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7745/10000, Loss: 0.7318, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7746/10000, Loss: 0.7318, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7747/10000, Loss: 0.7318, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7748/10000, Loss: 0.7318, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7749/10000, Loss: 0.7317, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7750/10000, Loss: 0.7317, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7751/10000, Loss: 0.7317, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7752/10000, Loss: 0.7317, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7753/10000, Loss: 0.7317, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7754/10000, Loss: 0.7316, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7755/10000, Loss: 0.7316, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7756/10000, Loss: 0.7316, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7757/10000, Loss: 0.7316, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7758/10000, Loss: 0.7316, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7759/10000, Loss: 0.7315, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7760/10000, Loss: 0.7315, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7761/10000, Loss: 0.7315, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7762/10000, Loss: 0.7315, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7763/10000, Loss: 0.7315, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7764/10000, Loss: 0.7314, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7765/10000, Loss: 0.7314, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7766/10000, Loss: 0.7314, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7767/10000, Loss: 0.7314, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7768/10000, Loss: 0.7314, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7769/10000, Loss: 0.7313, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7770/10000, Loss: 0.7313, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7771/10000, Loss: 0.7313, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7772/10000, Loss: 0.7313, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7773/10000, Loss: 0.7313, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7774/10000, Loss: 0.7312, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7775/10000, Loss: 0.7312, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7776/10000, Loss: 0.7312, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7777/10000, Loss: 0.7312, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7778/10000, Loss: 0.7312, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7779/10000, Loss: 0.7311, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7780/10000, Loss: 0.7311, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7781/10000, Loss: 0.7311, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7782/10000, Loss: 0.7311, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7783/10000, Loss: 0.7311, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7784/10000, Loss: 0.7310, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7785/10000, Loss: 0.7310, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7786/10000, Loss: 0.7310, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7787/10000, Loss: 0.7310, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7788/10000, Loss: 0.7310, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7789/10000, Loss: 0.7309, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7790/10000, Loss: 0.7309, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7791/10000, Loss: 0.7309, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7792/10000, Loss: 0.7309, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7793/10000, Loss: 0.7309, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7794/10000, Loss: 0.7308, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7795/10000, Loss: 0.7308, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7796/10000, Loss: 0.7308, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7797/10000, Loss: 0.7308, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7798/10000, Loss: 0.7308, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7799/10000, Loss: 0.7307, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7800/10000, Loss: 0.7307, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7801/10000, Loss: 0.7307, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7802/10000, Loss: 0.7307, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7803/10000, Loss: 0.7306, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7804/10000, Loss: 0.7306, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7805/10000, Loss: 0.7306, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7806/10000, Loss: 0.7306, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7807/10000, Loss: 0.7306, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7808/10000, Loss: 0.7305, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7809/10000, Loss: 0.7305, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7810/10000, Loss: 0.7305, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7811/10000, Loss: 0.7305, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7812/10000, Loss: 0.7305, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7813/10000, Loss: 0.7304, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7814/10000, Loss: 0.7304, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7815/10000, Loss: 0.7304, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7816/10000, Loss: 0.7304, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7817/10000, Loss: 0.7304, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7818/10000, Loss: 0.7303, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7819/10000, Loss: 0.7303, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7820/10000, Loss: 0.7303, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7821/10000, Loss: 0.7303, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7822/10000, Loss: 0.7303, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7823/10000, Loss: 0.7302, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7824/10000, Loss: 0.7302, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7825/10000, Loss: 0.7302, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7826/10000, Loss: 0.7302, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7827/10000, Loss: 0.7302, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7828/10000, Loss: 0.7301, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7829/10000, Loss: 0.7301, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7830/10000, Loss: 0.7301, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7831/10000, Loss: 0.7301, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7832/10000, Loss: 0.7301, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7833/10000, Loss: 0.7300, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7834/10000, Loss: 0.7300, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7835/10000, Loss: 0.7300, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7836/10000, Loss: 0.7300, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7837/10000, Loss: 0.7300, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7838/10000, Loss: 0.7299, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7839/10000, Loss: 0.7299, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7840/10000, Loss: 0.7299, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7841/10000, Loss: 0.7299, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7842/10000, Loss: 0.7299, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7843/10000, Loss: 0.7298, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7844/10000, Loss: 0.7298, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7845/10000, Loss: 0.7298, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7846/10000, Loss: 0.7298, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7847/10000, Loss: 0.7298, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7848/10000, Loss: 0.7297, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7849/10000, Loss: 0.7297, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7850/10000, Loss: 0.7297, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7851/10000, Loss: 0.7297, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7852/10000, Loss: 0.7297, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7853/10000, Loss: 0.7296, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7854/10000, Loss: 0.7296, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7855/10000, Loss: 0.7296, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7856/10000, Loss: 0.7296, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7857/10000, Loss: 0.7296, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7858/10000, Loss: 0.7295, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7859/10000, Loss: 0.7295, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7860/10000, Loss: 0.7295, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7861/10000, Loss: 0.7295, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7862/10000, Loss: 0.7295, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7863/10000, Loss: 0.7294, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7864/10000, Loss: 0.7294, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7865/10000, Loss: 0.7294, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7866/10000, Loss: 0.7294, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7867/10000, Loss: 0.7294, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7868/10000, Loss: 0.7293, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7869/10000, Loss: 0.7293, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7870/10000, Loss: 0.7293, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7871/10000, Loss: 0.7293, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7872/10000, Loss: 0.7293, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7873/10000, Loss: 0.7292, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7874/10000, Loss: 0.7292, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7875/10000, Loss: 0.7292, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7876/10000, Loss: 0.7292, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7877/10000, Loss: 0.7292, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7878/10000, Loss: 0.7291, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7879/10000, Loss: 0.7291, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7880/10000, Loss: 0.7291, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7881/10000, Loss: 0.7291, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7882/10000, Loss: 0.7291, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7883/10000, Loss: 0.7290, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7884/10000, Loss: 0.7290, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7885/10000, Loss: 0.7290, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7886/10000, Loss: 0.7290, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7887/10000, Loss: 0.7290, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7888/10000, Loss: 0.7289, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7889/10000, Loss: 0.7289, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7890/10000, Loss: 0.7289, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7891/10000, Loss: 0.7289, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7892/10000, Loss: 0.7289, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7893/10000, Loss: 0.7288, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7894/10000, Loss: 0.7288, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7895/10000, Loss: 0.7288, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7896/10000, Loss: 0.7288, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7897/10000, Loss: 0.7288, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7898/10000, Loss: 0.7287, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7899/10000, Loss: 0.7287, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7900/10000, Loss: 0.7287, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7901/10000, Loss: 0.7287, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7902/10000, Loss: 0.7287, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7903/10000, Loss: 0.7286, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7904/10000, Loss: 0.7286, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7905/10000, Loss: 0.7286, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7906/10000, Loss: 0.7286, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7907/10000, Loss: 0.7286, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7908/10000, Loss: 0.7285, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7909/10000, Loss: 0.7285, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7910/10000, Loss: 0.7285, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7911/10000, Loss: 0.7285, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7912/10000, Loss: 0.7285, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7913/10000, Loss: 0.7284, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7914/10000, Loss: 0.7284, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7915/10000, Loss: 0.7284, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7916/10000, Loss: 0.7284, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7917/10000, Loss: 0.7284, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7918/10000, Loss: 0.7283, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7919/10000, Loss: 0.7283, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7920/10000, Loss: 0.7283, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7921/10000, Loss: 0.7283, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7922/10000, Loss: 0.7283, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7923/10000, Loss: 0.7282, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7924/10000, Loss: 0.7282, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7925/10000, Loss: 0.7282, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7926/10000, Loss: 0.7282, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7927/10000, Loss: 0.7282, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7928/10000, Loss: 0.7281, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7929/10000, Loss: 0.7281, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7930/10000, Loss: 0.7281, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7931/10000, Loss: 0.7281, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7932/10000, Loss: 0.7281, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7933/10000, Loss: 0.7280, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7934/10000, Loss: 0.7280, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7935/10000, Loss: 0.7280, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7936/10000, Loss: 0.7280, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7937/10000, Loss: 0.7280, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7938/10000, Loss: 0.7279, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7939/10000, Loss: 0.7279, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7940/10000, Loss: 0.7279, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7941/10000, Loss: 0.7279, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7942/10000, Loss: 0.7279, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7943/10000, Loss: 0.7278, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7944/10000, Loss: 0.7278, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7945/10000, Loss: 0.7278, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7946/10000, Loss: 0.7278, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7947/10000, Loss: 0.7278, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7948/10000, Loss: 0.7277, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7949/10000, Loss: 0.7277, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7950/10000, Loss: 0.7277, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7951/10000, Loss: 0.7277, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7952/10000, Loss: 0.7277, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 7953/10000, Loss: 0.7276, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7954/10000, Loss: 0.7276, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7955/10000, Loss: 0.7276, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7956/10000, Loss: 0.7276, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7957/10000, Loss: 0.7276, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7958/10000, Loss: 0.7275, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7959/10000, Loss: 0.7275, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7960/10000, Loss: 0.7275, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7961/10000, Loss: 0.7275, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7962/10000, Loss: 0.7275, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7963/10000, Loss: 0.7274, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7964/10000, Loss: 0.7274, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7965/10000, Loss: 0.7274, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7966/10000, Loss: 0.7274, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7967/10000, Loss: 0.7274, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7968/10000, Loss: 0.7273, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7969/10000, Loss: 0.7273, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7970/10000, Loss: 0.7273, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7971/10000, Loss: 0.7273, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7972/10000, Loss: 0.7273, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7973/10000, Loss: 0.7272, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7974/10000, Loss: 0.7272, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7975/10000, Loss: 0.7272, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7976/10000, Loss: 0.7272, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7977/10000, Loss: 0.7272, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7978/10000, Loss: 0.7272, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7979/10000, Loss: 0.7271, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7980/10000, Loss: 0.7271, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7981/10000, Loss: 0.7271, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7982/10000, Loss: 0.7271, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7983/10000, Loss: 0.7271, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7984/10000, Loss: 0.7270, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7985/10000, Loss: 0.7270, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7986/10000, Loss: 0.7270, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7987/10000, Loss: 0.7270, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7988/10000, Loss: 0.7270, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7989/10000, Loss: 0.7269, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7990/10000, Loss: 0.7269, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7991/10000, Loss: 0.7269, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7992/10000, Loss: 0.7269, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7993/10000, Loss: 0.7269, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7994/10000, Loss: 0.7268, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7995/10000, Loss: 0.7268, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7996/10000, Loss: 0.7268, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7997/10000, Loss: 0.7268, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7998/10000, Loss: 0.7268, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 7999/10000, Loss: 0.7267, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8000/10000, Loss: 0.7267, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8001/10000, Loss: 0.7267, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8002/10000, Loss: 0.7267, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8003/10000, Loss: 0.7267, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8004/10000, Loss: 0.7266, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8005/10000, Loss: 0.7266, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8006/10000, Loss: 0.7266, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8007/10000, Loss: 0.7266, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8008/10000, Loss: 0.7266, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8009/10000, Loss: 0.7265, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8010/10000, Loss: 0.7265, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8011/10000, Loss: 0.7265, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8012/10000, Loss: 0.7265, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8013/10000, Loss: 0.7265, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8014/10000, Loss: 0.7264, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8015/10000, Loss: 0.7264, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8016/10000, Loss: 0.7264, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8017/10000, Loss: 0.7264, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8018/10000, Loss: 0.7264, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8019/10000, Loss: 0.7263, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8020/10000, Loss: 0.7263, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8021/10000, Loss: 0.7263, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8022/10000, Loss: 0.7263, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8023/10000, Loss: 0.7263, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8024/10000, Loss: 0.7262, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8025/10000, Loss: 0.7262, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8026/10000, Loss: 0.7262, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8027/10000, Loss: 0.7262, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8028/10000, Loss: 0.7262, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8029/10000, Loss: 0.7261, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8030/10000, Loss: 0.7261, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8031/10000, Loss: 0.7261, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8032/10000, Loss: 0.7261, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8033/10000, Loss: 0.7261, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8034/10000, Loss: 0.7261, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8035/10000, Loss: 0.7260, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8036/10000, Loss: 0.7260, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8037/10000, Loss: 0.7260, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8038/10000, Loss: 0.7260, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8039/10000, Loss: 0.7260, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8040/10000, Loss: 0.7259, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8041/10000, Loss: 0.7259, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8042/10000, Loss: 0.7259, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8043/10000, Loss: 0.7259, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8044/10000, Loss: 0.7259, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8045/10000, Loss: 0.7258, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8046/10000, Loss: 0.7258, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8047/10000, Loss: 0.7258, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8048/10000, Loss: 0.7258, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8049/10000, Loss: 0.7258, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8050/10000, Loss: 0.7257, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8051/10000, Loss: 0.7257, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8052/10000, Loss: 0.7257, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8053/10000, Loss: 0.7257, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8054/10000, Loss: 0.7257, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8055/10000, Loss: 0.7256, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8056/10000, Loss: 0.7256, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8057/10000, Loss: 0.7256, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8058/10000, Loss: 0.7256, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8059/10000, Loss: 0.7256, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8060/10000, Loss: 0.7255, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8061/10000, Loss: 0.7255, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8062/10000, Loss: 0.7255, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8063/10000, Loss: 0.7255, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8064/10000, Loss: 0.7255, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8065/10000, Loss: 0.7254, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8066/10000, Loss: 0.7254, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8067/10000, Loss: 0.7254, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8068/10000, Loss: 0.7254, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8069/10000, Loss: 0.7254, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8070/10000, Loss: 0.7253, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8071/10000, Loss: 0.7253, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8072/10000, Loss: 0.7253, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8073/10000, Loss: 0.7253, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8074/10000, Loss: 0.7253, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8075/10000, Loss: 0.7253, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8076/10000, Loss: 0.7252, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8077/10000, Loss: 0.7252, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8078/10000, Loss: 0.7252, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8079/10000, Loss: 0.7252, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8080/10000, Loss: 0.7252, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8081/10000, Loss: 0.7251, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8082/10000, Loss: 0.7251, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8083/10000, Loss: 0.7251, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8084/10000, Loss: 0.7251, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8085/10000, Loss: 0.7251, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8086/10000, Loss: 0.7250, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8087/10000, Loss: 0.7250, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8088/10000, Loss: 0.7250, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8089/10000, Loss: 0.7250, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8090/10000, Loss: 0.7250, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8091/10000, Loss: 0.7249, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8092/10000, Loss: 0.7249, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8093/10000, Loss: 0.7249, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8094/10000, Loss: 0.7249, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8095/10000, Loss: 0.7249, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8096/10000, Loss: 0.7248, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8097/10000, Loss: 0.7248, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8098/10000, Loss: 0.7248, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8099/10000, Loss: 0.7248, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8100/10000, Loss: 0.7248, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8101/10000, Loss: 0.7247, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8102/10000, Loss: 0.7247, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8103/10000, Loss: 0.7247, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8104/10000, Loss: 0.7247, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8105/10000, Loss: 0.7247, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8106/10000, Loss: 0.7247, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8107/10000, Loss: 0.7246, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8108/10000, Loss: 0.7246, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8109/10000, Loss: 0.7246, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8110/10000, Loss: 0.7246, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8111/10000, Loss: 0.7246, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8112/10000, Loss: 0.7245, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8113/10000, Loss: 0.7245, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8114/10000, Loss: 0.7245, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8115/10000, Loss: 0.7245, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8116/10000, Loss: 0.7245, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8117/10000, Loss: 0.7244, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8118/10000, Loss: 0.7244, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8119/10000, Loss: 0.7244, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8120/10000, Loss: 0.7244, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8121/10000, Loss: 0.7244, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8122/10000, Loss: 0.7243, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8123/10000, Loss: 0.7243, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8124/10000, Loss: 0.7243, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8125/10000, Loss: 0.7243, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8126/10000, Loss: 0.7243, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8127/10000, Loss: 0.7242, Accuracy: 0.6797, Learning Rate: 0.000100\n",
      "Epoch 8128/10000, Loss: 0.7242, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8129/10000, Loss: 0.7242, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8130/10000, Loss: 0.7242, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8131/10000, Loss: 0.7242, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8132/10000, Loss: 0.7241, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8133/10000, Loss: 0.7241, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8134/10000, Loss: 0.7241, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8135/10000, Loss: 0.7241, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8136/10000, Loss: 0.7241, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8137/10000, Loss: 0.7241, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8138/10000, Loss: 0.7240, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8139/10000, Loss: 0.7240, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8140/10000, Loss: 0.7240, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8141/10000, Loss: 0.7240, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8142/10000, Loss: 0.7240, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8143/10000, Loss: 0.7239, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8144/10000, Loss: 0.7239, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8145/10000, Loss: 0.7239, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8146/10000, Loss: 0.7239, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8147/10000, Loss: 0.7239, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8148/10000, Loss: 0.7238, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8149/10000, Loss: 0.7238, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8150/10000, Loss: 0.7238, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8151/10000, Loss: 0.7238, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8152/10000, Loss: 0.7238, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8153/10000, Loss: 0.7237, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8154/10000, Loss: 0.7237, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8155/10000, Loss: 0.7237, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8156/10000, Loss: 0.7237, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8157/10000, Loss: 0.7237, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8158/10000, Loss: 0.7236, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8159/10000, Loss: 0.7236, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8160/10000, Loss: 0.7236, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8161/10000, Loss: 0.7236, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8162/10000, Loss: 0.7236, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8163/10000, Loss: 0.7236, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8164/10000, Loss: 0.7235, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8165/10000, Loss: 0.7235, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8166/10000, Loss: 0.7235, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8167/10000, Loss: 0.7235, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8168/10000, Loss: 0.7235, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8169/10000, Loss: 0.7234, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8170/10000, Loss: 0.7234, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8171/10000, Loss: 0.7234, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8172/10000, Loss: 0.7234, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8173/10000, Loss: 0.7234, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8174/10000, Loss: 0.7233, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8175/10000, Loss: 0.7233, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8176/10000, Loss: 0.7233, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8177/10000, Loss: 0.7233, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8178/10000, Loss: 0.7233, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8179/10000, Loss: 0.7232, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8180/10000, Loss: 0.7232, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8181/10000, Loss: 0.7232, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8182/10000, Loss: 0.7232, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8183/10000, Loss: 0.7232, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8184/10000, Loss: 0.7231, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8185/10000, Loss: 0.7231, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8186/10000, Loss: 0.7231, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8187/10000, Loss: 0.7231, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8188/10000, Loss: 0.7231, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8189/10000, Loss: 0.7231, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8190/10000, Loss: 0.7230, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8191/10000, Loss: 0.7230, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8192/10000, Loss: 0.7230, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8193/10000, Loss: 0.7230, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8194/10000, Loss: 0.7230, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8195/10000, Loss: 0.7229, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8196/10000, Loss: 0.7229, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8197/10000, Loss: 0.7229, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8198/10000, Loss: 0.7229, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8199/10000, Loss: 0.7229, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8200/10000, Loss: 0.7228, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8201/10000, Loss: 0.7228, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8202/10000, Loss: 0.7228, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8203/10000, Loss: 0.7228, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8204/10000, Loss: 0.7228, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8205/10000, Loss: 0.7227, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8206/10000, Loss: 0.7227, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8207/10000, Loss: 0.7227, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8208/10000, Loss: 0.7227, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8209/10000, Loss: 0.7227, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8210/10000, Loss: 0.7227, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8211/10000, Loss: 0.7226, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8212/10000, Loss: 0.7226, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8213/10000, Loss: 0.7226, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8214/10000, Loss: 0.7226, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8215/10000, Loss: 0.7226, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8216/10000, Loss: 0.7225, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8217/10000, Loss: 0.7225, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8218/10000, Loss: 0.7225, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8219/10000, Loss: 0.7225, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8220/10000, Loss: 0.7225, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8221/10000, Loss: 0.7224, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8222/10000, Loss: 0.7224, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8223/10000, Loss: 0.7224, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8224/10000, Loss: 0.7224, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8225/10000, Loss: 0.7224, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8226/10000, Loss: 0.7223, Accuracy: 0.6816, Learning Rate: 0.000100\n",
      "Epoch 8227/10000, Loss: 0.7223, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8228/10000, Loss: 0.7223, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8229/10000, Loss: 0.7223, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8230/10000, Loss: 0.7223, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8231/10000, Loss: 0.7223, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8232/10000, Loss: 0.7222, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8233/10000, Loss: 0.7222, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8234/10000, Loss: 0.7222, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8235/10000, Loss: 0.7222, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8236/10000, Loss: 0.7222, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8237/10000, Loss: 0.7221, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8238/10000, Loss: 0.7221, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8239/10000, Loss: 0.7221, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8240/10000, Loss: 0.7221, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8241/10000, Loss: 0.7221, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8242/10000, Loss: 0.7220, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8243/10000, Loss: 0.7220, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8244/10000, Loss: 0.7220, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8245/10000, Loss: 0.7220, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8246/10000, Loss: 0.7220, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8247/10000, Loss: 0.7219, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8248/10000, Loss: 0.7219, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8249/10000, Loss: 0.7219, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8250/10000, Loss: 0.7219, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8251/10000, Loss: 0.7219, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8252/10000, Loss: 0.7219, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8253/10000, Loss: 0.7218, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8254/10000, Loss: 0.7218, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8255/10000, Loss: 0.7218, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8256/10000, Loss: 0.7218, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8257/10000, Loss: 0.7218, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8258/10000, Loss: 0.7217, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8259/10000, Loss: 0.7217, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8260/10000, Loss: 0.7217, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8261/10000, Loss: 0.7217, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8262/10000, Loss: 0.7217, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8263/10000, Loss: 0.7216, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8264/10000, Loss: 0.7216, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8265/10000, Loss: 0.7216, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8266/10000, Loss: 0.7216, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8267/10000, Loss: 0.7216, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8268/10000, Loss: 0.7216, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8269/10000, Loss: 0.7215, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8270/10000, Loss: 0.7215, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8271/10000, Loss: 0.7215, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8272/10000, Loss: 0.7215, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8273/10000, Loss: 0.7215, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8274/10000, Loss: 0.7214, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8275/10000, Loss: 0.7214, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8276/10000, Loss: 0.7214, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8277/10000, Loss: 0.7214, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8278/10000, Loss: 0.7214, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8279/10000, Loss: 0.7213, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8280/10000, Loss: 0.7213, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8281/10000, Loss: 0.7213, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8282/10000, Loss: 0.7213, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8283/10000, Loss: 0.7213, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8284/10000, Loss: 0.7212, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8285/10000, Loss: 0.7212, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8286/10000, Loss: 0.7212, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8287/10000, Loss: 0.7212, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8288/10000, Loss: 0.7212, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8289/10000, Loss: 0.7212, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8290/10000, Loss: 0.7211, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8291/10000, Loss: 0.7211, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8292/10000, Loss: 0.7211, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8293/10000, Loss: 0.7211, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8294/10000, Loss: 0.7211, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8295/10000, Loss: 0.7210, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8296/10000, Loss: 0.7210, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8297/10000, Loss: 0.7210, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8298/10000, Loss: 0.7210, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8299/10000, Loss: 0.7210, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8300/10000, Loss: 0.7209, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8301/10000, Loss: 0.7209, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8302/10000, Loss: 0.7209, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8303/10000, Loss: 0.7209, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8304/10000, Loss: 0.7209, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8305/10000, Loss: 0.7209, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8306/10000, Loss: 0.7208, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8307/10000, Loss: 0.7208, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8308/10000, Loss: 0.7208, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8309/10000, Loss: 0.7208, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8310/10000, Loss: 0.7208, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8311/10000, Loss: 0.7207, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8312/10000, Loss: 0.7207, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8313/10000, Loss: 0.7207, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8314/10000, Loss: 0.7207, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8315/10000, Loss: 0.7207, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8316/10000, Loss: 0.7206, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8317/10000, Loss: 0.7206, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8318/10000, Loss: 0.7206, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8319/10000, Loss: 0.7206, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8320/10000, Loss: 0.7206, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8321/10000, Loss: 0.7206, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8322/10000, Loss: 0.7205, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8323/10000, Loss: 0.7205, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8324/10000, Loss: 0.7205, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8325/10000, Loss: 0.7205, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8326/10000, Loss: 0.7205, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8327/10000, Loss: 0.7204, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8328/10000, Loss: 0.7204, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8329/10000, Loss: 0.7204, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8330/10000, Loss: 0.7204, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8331/10000, Loss: 0.7204, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8332/10000, Loss: 0.7203, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8333/10000, Loss: 0.7203, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8334/10000, Loss: 0.7203, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8335/10000, Loss: 0.7203, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8336/10000, Loss: 0.7203, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8337/10000, Loss: 0.7203, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8338/10000, Loss: 0.7202, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8339/10000, Loss: 0.7202, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8340/10000, Loss: 0.7202, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8341/10000, Loss: 0.7202, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8342/10000, Loss: 0.7202, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8343/10000, Loss: 0.7201, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8344/10000, Loss: 0.7201, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8345/10000, Loss: 0.7201, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8346/10000, Loss: 0.7201, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8347/10000, Loss: 0.7201, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8348/10000, Loss: 0.7200, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8349/10000, Loss: 0.7200, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8350/10000, Loss: 0.7200, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8351/10000, Loss: 0.7200, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8352/10000, Loss: 0.7200, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8353/10000, Loss: 0.7200, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8354/10000, Loss: 0.7199, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8355/10000, Loss: 0.7199, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8356/10000, Loss: 0.7199, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8357/10000, Loss: 0.7199, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8358/10000, Loss: 0.7199, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8359/10000, Loss: 0.7198, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8360/10000, Loss: 0.7198, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8361/10000, Loss: 0.7198, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8362/10000, Loss: 0.7198, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8363/10000, Loss: 0.7198, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8364/10000, Loss: 0.7197, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8365/10000, Loss: 0.7197, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8366/10000, Loss: 0.7197, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8367/10000, Loss: 0.7197, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8368/10000, Loss: 0.7197, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8369/10000, Loss: 0.7197, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8370/10000, Loss: 0.7196, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8371/10000, Loss: 0.7196, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 8372/10000, Loss: 0.7196, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8373/10000, Loss: 0.7196, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8374/10000, Loss: 0.7196, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8375/10000, Loss: 0.7195, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8376/10000, Loss: 0.7195, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8377/10000, Loss: 0.7195, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8378/10000, Loss: 0.7195, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8379/10000, Loss: 0.7195, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8380/10000, Loss: 0.7194, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8381/10000, Loss: 0.7194, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8382/10000, Loss: 0.7194, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8383/10000, Loss: 0.7194, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8384/10000, Loss: 0.7194, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8385/10000, Loss: 0.7194, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8386/10000, Loss: 0.7193, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8387/10000, Loss: 0.7193, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8388/10000, Loss: 0.7193, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8389/10000, Loss: 0.7193, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8390/10000, Loss: 0.7193, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8391/10000, Loss: 0.7192, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8392/10000, Loss: 0.7192, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8393/10000, Loss: 0.7192, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8394/10000, Loss: 0.7192, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8395/10000, Loss: 0.7192, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8396/10000, Loss: 0.7192, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8397/10000, Loss: 0.7191, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8398/10000, Loss: 0.7191, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8399/10000, Loss: 0.7191, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8400/10000, Loss: 0.7191, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8401/10000, Loss: 0.7191, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8402/10000, Loss: 0.7190, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8403/10000, Loss: 0.7190, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8404/10000, Loss: 0.7190, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8405/10000, Loss: 0.7190, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 8406/10000, Loss: 0.7190, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8407/10000, Loss: 0.7189, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8408/10000, Loss: 0.7189, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8409/10000, Loss: 0.7189, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8410/10000, Loss: 0.7189, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8411/10000, Loss: 0.7189, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8412/10000, Loss: 0.7189, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8413/10000, Loss: 0.7188, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8414/10000, Loss: 0.7188, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8415/10000, Loss: 0.7188, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8416/10000, Loss: 0.7188, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8417/10000, Loss: 0.7188, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8418/10000, Loss: 0.7187, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8419/10000, Loss: 0.7187, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8420/10000, Loss: 0.7187, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8421/10000, Loss: 0.7187, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8422/10000, Loss: 0.7187, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8423/10000, Loss: 0.7186, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8424/10000, Loss: 0.7186, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8425/10000, Loss: 0.7186, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8426/10000, Loss: 0.7186, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8427/10000, Loss: 0.7186, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8428/10000, Loss: 0.7186, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8429/10000, Loss: 0.7185, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8430/10000, Loss: 0.7185, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8431/10000, Loss: 0.7185, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8432/10000, Loss: 0.7185, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8433/10000, Loss: 0.7185, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8434/10000, Loss: 0.7184, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8435/10000, Loss: 0.7184, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8436/10000, Loss: 0.7184, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8437/10000, Loss: 0.7184, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8438/10000, Loss: 0.7184, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8439/10000, Loss: 0.7184, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8440/10000, Loss: 0.7183, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8441/10000, Loss: 0.7183, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8442/10000, Loss: 0.7183, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8443/10000, Loss: 0.7183, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8444/10000, Loss: 0.7183, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8445/10000, Loss: 0.7182, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8446/10000, Loss: 0.7182, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8447/10000, Loss: 0.7182, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8448/10000, Loss: 0.7182, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8449/10000, Loss: 0.7182, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8450/10000, Loss: 0.7182, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8451/10000, Loss: 0.7181, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8452/10000, Loss: 0.7181, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8453/10000, Loss: 0.7181, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8454/10000, Loss: 0.7181, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8455/10000, Loss: 0.7181, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8456/10000, Loss: 0.7180, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8457/10000, Loss: 0.7180, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8458/10000, Loss: 0.7180, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8459/10000, Loss: 0.7180, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8460/10000, Loss: 0.7180, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8461/10000, Loss: 0.7179, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8462/10000, Loss: 0.7179, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8463/10000, Loss: 0.7179, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8464/10000, Loss: 0.7179, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8465/10000, Loss: 0.7179, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8466/10000, Loss: 0.7179, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8467/10000, Loss: 0.7178, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8468/10000, Loss: 0.7178, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8469/10000, Loss: 0.7178, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8470/10000, Loss: 0.7178, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8471/10000, Loss: 0.7178, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8472/10000, Loss: 0.7177, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8473/10000, Loss: 0.7177, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8474/10000, Loss: 0.7177, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8475/10000, Loss: 0.7177, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8476/10000, Loss: 0.7177, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8477/10000, Loss: 0.7177, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8478/10000, Loss: 0.7176, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8479/10000, Loss: 0.7176, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8480/10000, Loss: 0.7176, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8481/10000, Loss: 0.7176, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8482/10000, Loss: 0.7176, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8483/10000, Loss: 0.7175, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8484/10000, Loss: 0.7175, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8485/10000, Loss: 0.7175, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8486/10000, Loss: 0.7175, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8487/10000, Loss: 0.7175, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8488/10000, Loss: 0.7175, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8489/10000, Loss: 0.7174, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8490/10000, Loss: 0.7174, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8491/10000, Loss: 0.7174, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8492/10000, Loss: 0.7174, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8493/10000, Loss: 0.7174, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8494/10000, Loss: 0.7173, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8495/10000, Loss: 0.7173, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8496/10000, Loss: 0.7173, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8497/10000, Loss: 0.7173, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8498/10000, Loss: 0.7173, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8499/10000, Loss: 0.7173, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8500/10000, Loss: 0.7172, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8501/10000, Loss: 0.7172, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8502/10000, Loss: 0.7172, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8503/10000, Loss: 0.7172, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8504/10000, Loss: 0.7172, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8505/10000, Loss: 0.7171, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8506/10000, Loss: 0.7171, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8507/10000, Loss: 0.7171, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8508/10000, Loss: 0.7171, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8509/10000, Loss: 0.7171, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8510/10000, Loss: 0.7170, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8511/10000, Loss: 0.7170, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8512/10000, Loss: 0.7170, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8513/10000, Loss: 0.7170, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8514/10000, Loss: 0.7170, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8515/10000, Loss: 0.7170, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8516/10000, Loss: 0.7169, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8517/10000, Loss: 0.7169, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8518/10000, Loss: 0.7169, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8519/10000, Loss: 0.7169, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8520/10000, Loss: 0.7169, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8521/10000, Loss: 0.7168, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8522/10000, Loss: 0.7168, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8523/10000, Loss: 0.7168, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8524/10000, Loss: 0.7168, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8525/10000, Loss: 0.7168, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8526/10000, Loss: 0.7168, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8527/10000, Loss: 0.7167, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8528/10000, Loss: 0.7167, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8529/10000, Loss: 0.7167, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8530/10000, Loss: 0.7167, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8531/10000, Loss: 0.7167, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8532/10000, Loss: 0.7166, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8533/10000, Loss: 0.7166, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8534/10000, Loss: 0.7166, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8535/10000, Loss: 0.7166, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8536/10000, Loss: 0.7166, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8537/10000, Loss: 0.7166, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8538/10000, Loss: 0.7165, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8539/10000, Loss: 0.7165, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8540/10000, Loss: 0.7165, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8541/10000, Loss: 0.7165, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8542/10000, Loss: 0.7165, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8543/10000, Loss: 0.7164, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8544/10000, Loss: 0.7164, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8545/10000, Loss: 0.7164, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8546/10000, Loss: 0.7164, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8547/10000, Loss: 0.7164, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8548/10000, Loss: 0.7164, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8549/10000, Loss: 0.7163, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8550/10000, Loss: 0.7163, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8551/10000, Loss: 0.7163, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8552/10000, Loss: 0.7163, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8553/10000, Loss: 0.7163, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 8554/10000, Loss: 0.7162, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8555/10000, Loss: 0.7162, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8556/10000, Loss: 0.7162, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8557/10000, Loss: 0.7162, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8558/10000, Loss: 0.7162, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8559/10000, Loss: 0.7162, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8560/10000, Loss: 0.7161, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8561/10000, Loss: 0.7161, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8562/10000, Loss: 0.7161, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8563/10000, Loss: 0.7161, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8564/10000, Loss: 0.7161, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8565/10000, Loss: 0.7160, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8566/10000, Loss: 0.7160, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8567/10000, Loss: 0.7160, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8568/10000, Loss: 0.7160, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8569/10000, Loss: 0.7160, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8570/10000, Loss: 0.7160, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8571/10000, Loss: 0.7159, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8572/10000, Loss: 0.7159, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8573/10000, Loss: 0.7159, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8574/10000, Loss: 0.7159, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8575/10000, Loss: 0.7159, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8576/10000, Loss: 0.7158, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8577/10000, Loss: 0.7158, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8578/10000, Loss: 0.7158, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8579/10000, Loss: 0.7158, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8580/10000, Loss: 0.7158, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8581/10000, Loss: 0.7158, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8582/10000, Loss: 0.7157, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8583/10000, Loss: 0.7157, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8584/10000, Loss: 0.7157, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8585/10000, Loss: 0.7157, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8586/10000, Loss: 0.7157, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8587/10000, Loss: 0.7156, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8588/10000, Loss: 0.7156, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8589/10000, Loss: 0.7156, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8590/10000, Loss: 0.7156, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8591/10000, Loss: 0.7156, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8592/10000, Loss: 0.7156, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8593/10000, Loss: 0.7155, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8594/10000, Loss: 0.7155, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8595/10000, Loss: 0.7155, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8596/10000, Loss: 0.7155, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8597/10000, Loss: 0.7155, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8598/10000, Loss: 0.7154, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8599/10000, Loss: 0.7154, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8600/10000, Loss: 0.7154, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8601/10000, Loss: 0.7154, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8602/10000, Loss: 0.7154, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8603/10000, Loss: 0.7154, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8604/10000, Loss: 0.7153, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8605/10000, Loss: 0.7153, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8606/10000, Loss: 0.7153, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8607/10000, Loss: 0.7153, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8608/10000, Loss: 0.7153, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8609/10000, Loss: 0.7152, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8610/10000, Loss: 0.7152, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8611/10000, Loss: 0.7152, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8612/10000, Loss: 0.7152, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8613/10000, Loss: 0.7152, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8614/10000, Loss: 0.7152, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8615/10000, Loss: 0.7151, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8616/10000, Loss: 0.7151, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8617/10000, Loss: 0.7151, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8618/10000, Loss: 0.7151, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8619/10000, Loss: 0.7151, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8620/10000, Loss: 0.7151, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8621/10000, Loss: 0.7150, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8622/10000, Loss: 0.7150, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8623/10000, Loss: 0.7150, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8624/10000, Loss: 0.7150, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8625/10000, Loss: 0.7150, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8626/10000, Loss: 0.7149, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8627/10000, Loss: 0.7149, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8628/10000, Loss: 0.7149, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8629/10000, Loss: 0.7149, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8630/10000, Loss: 0.7149, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8631/10000, Loss: 0.7149, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8632/10000, Loss: 0.7148, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8633/10000, Loss: 0.7148, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8634/10000, Loss: 0.7148, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8635/10000, Loss: 0.7148, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8636/10000, Loss: 0.7148, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8637/10000, Loss: 0.7147, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8638/10000, Loss: 0.7147, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8639/10000, Loss: 0.7147, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8640/10000, Loss: 0.7147, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8641/10000, Loss: 0.7147, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8642/10000, Loss: 0.7147, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8643/10000, Loss: 0.7146, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8644/10000, Loss: 0.7146, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8645/10000, Loss: 0.7146, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8646/10000, Loss: 0.7146, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8647/10000, Loss: 0.7146, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8648/10000, Loss: 0.7145, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8649/10000, Loss: 0.7145, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8650/10000, Loss: 0.7145, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8651/10000, Loss: 0.7145, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8652/10000, Loss: 0.7145, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8653/10000, Loss: 0.7145, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8654/10000, Loss: 0.7144, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8655/10000, Loss: 0.7144, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8656/10000, Loss: 0.7144, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8657/10000, Loss: 0.7144, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8658/10000, Loss: 0.7144, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8659/10000, Loss: 0.7143, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8660/10000, Loss: 0.7143, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8661/10000, Loss: 0.7143, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8662/10000, Loss: 0.7143, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8663/10000, Loss: 0.7143, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8664/10000, Loss: 0.7143, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8665/10000, Loss: 0.7142, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8666/10000, Loss: 0.7142, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8667/10000, Loss: 0.7142, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8668/10000, Loss: 0.7142, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8669/10000, Loss: 0.7142, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8670/10000, Loss: 0.7142, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8671/10000, Loss: 0.7141, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8672/10000, Loss: 0.7141, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8673/10000, Loss: 0.7141, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8674/10000, Loss: 0.7141, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8675/10000, Loss: 0.7141, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8676/10000, Loss: 0.7140, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8677/10000, Loss: 0.7140, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8678/10000, Loss: 0.7140, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8679/10000, Loss: 0.7140, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8680/10000, Loss: 0.7140, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8681/10000, Loss: 0.7140, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8682/10000, Loss: 0.7139, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8683/10000, Loss: 0.7139, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8684/10000, Loss: 0.7139, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8685/10000, Loss: 0.7139, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8686/10000, Loss: 0.7139, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8687/10000, Loss: 0.7138, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8688/10000, Loss: 0.7138, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8689/10000, Loss: 0.7138, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8690/10000, Loss: 0.7138, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8691/10000, Loss: 0.7138, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8692/10000, Loss: 0.7138, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8693/10000, Loss: 0.7137, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8694/10000, Loss: 0.7137, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8695/10000, Loss: 0.7137, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8696/10000, Loss: 0.7137, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8697/10000, Loss: 0.7137, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8698/10000, Loss: 0.7137, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8699/10000, Loss: 0.7136, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8700/10000, Loss: 0.7136, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8701/10000, Loss: 0.7136, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8702/10000, Loss: 0.7136, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8703/10000, Loss: 0.7136, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8704/10000, Loss: 0.7135, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8705/10000, Loss: 0.7135, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8706/10000, Loss: 0.7135, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8707/10000, Loss: 0.7135, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8708/10000, Loss: 0.7135, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8709/10000, Loss: 0.7135, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8710/10000, Loss: 0.7134, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8711/10000, Loss: 0.7134, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8712/10000, Loss: 0.7134, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8713/10000, Loss: 0.7134, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8714/10000, Loss: 0.7134, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8715/10000, Loss: 0.7133, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8716/10000, Loss: 0.7133, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8717/10000, Loss: 0.7133, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8718/10000, Loss: 0.7133, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8719/10000, Loss: 0.7133, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8720/10000, Loss: 0.7133, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8721/10000, Loss: 0.7132, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8722/10000, Loss: 0.7132, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8723/10000, Loss: 0.7132, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8724/10000, Loss: 0.7132, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8725/10000, Loss: 0.7132, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8726/10000, Loss: 0.7132, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8727/10000, Loss: 0.7131, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8728/10000, Loss: 0.7131, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8729/10000, Loss: 0.7131, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8730/10000, Loss: 0.7131, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8731/10000, Loss: 0.7131, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8732/10000, Loss: 0.7130, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8733/10000, Loss: 0.7130, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8734/10000, Loss: 0.7130, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8735/10000, Loss: 0.7130, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8736/10000, Loss: 0.7130, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8737/10000, Loss: 0.7130, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8738/10000, Loss: 0.7129, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8739/10000, Loss: 0.7129, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8740/10000, Loss: 0.7129, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8741/10000, Loss: 0.7129, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8742/10000, Loss: 0.7129, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8743/10000, Loss: 0.7129, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8744/10000, Loss: 0.7128, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8745/10000, Loss: 0.7128, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8746/10000, Loss: 0.7128, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8747/10000, Loss: 0.7128, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8748/10000, Loss: 0.7128, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8749/10000, Loss: 0.7127, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8750/10000, Loss: 0.7127, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8751/10000, Loss: 0.7127, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8752/10000, Loss: 0.7127, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8753/10000, Loss: 0.7127, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8754/10000, Loss: 0.7127, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8755/10000, Loss: 0.7126, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8756/10000, Loss: 0.7126, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8757/10000, Loss: 0.7126, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8758/10000, Loss: 0.7126, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8759/10000, Loss: 0.7126, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8760/10000, Loss: 0.7125, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8761/10000, Loss: 0.7125, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8762/10000, Loss: 0.7125, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8763/10000, Loss: 0.7125, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8764/10000, Loss: 0.7125, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8765/10000, Loss: 0.7125, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8766/10000, Loss: 0.7124, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8767/10000, Loss: 0.7124, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8768/10000, Loss: 0.7124, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8769/10000, Loss: 0.7124, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8770/10000, Loss: 0.7124, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8771/10000, Loss: 0.7124, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8772/10000, Loss: 0.7123, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8773/10000, Loss: 0.7123, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8774/10000, Loss: 0.7123, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8775/10000, Loss: 0.7123, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8776/10000, Loss: 0.7123, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8777/10000, Loss: 0.7122, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8778/10000, Loss: 0.7122, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8779/10000, Loss: 0.7122, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8780/10000, Loss: 0.7122, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8781/10000, Loss: 0.7122, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8782/10000, Loss: 0.7122, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8783/10000, Loss: 0.7121, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8784/10000, Loss: 0.7121, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8785/10000, Loss: 0.7121, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8786/10000, Loss: 0.7121, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8787/10000, Loss: 0.7121, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8788/10000, Loss: 0.7121, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8789/10000, Loss: 0.7120, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8790/10000, Loss: 0.7120, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8791/10000, Loss: 0.7120, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8792/10000, Loss: 0.7120, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8793/10000, Loss: 0.7120, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8794/10000, Loss: 0.7119, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8795/10000, Loss: 0.7119, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8796/10000, Loss: 0.7119, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8797/10000, Loss: 0.7119, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8798/10000, Loss: 0.7119, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8799/10000, Loss: 0.7119, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8800/10000, Loss: 0.7118, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8801/10000, Loss: 0.7118, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8802/10000, Loss: 0.7118, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8803/10000, Loss: 0.7118, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8804/10000, Loss: 0.7118, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8805/10000, Loss: 0.7118, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8806/10000, Loss: 0.7117, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8807/10000, Loss: 0.7117, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8808/10000, Loss: 0.7117, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8809/10000, Loss: 0.7117, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8810/10000, Loss: 0.7117, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8811/10000, Loss: 0.7117, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8812/10000, Loss: 0.7116, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8813/10000, Loss: 0.7116, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8814/10000, Loss: 0.7116, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8815/10000, Loss: 0.7116, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8816/10000, Loss: 0.7116, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8817/10000, Loss: 0.7115, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8818/10000, Loss: 0.7115, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8819/10000, Loss: 0.7115, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8820/10000, Loss: 0.7115, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8821/10000, Loss: 0.7115, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8822/10000, Loss: 0.7115, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8823/10000, Loss: 0.7114, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8824/10000, Loss: 0.7114, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8825/10000, Loss: 0.7114, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8826/10000, Loss: 0.7114, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8827/10000, Loss: 0.7114, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8828/10000, Loss: 0.7114, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8829/10000, Loss: 0.7113, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8830/10000, Loss: 0.7113, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8831/10000, Loss: 0.7113, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8832/10000, Loss: 0.7113, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8833/10000, Loss: 0.7113, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8834/10000, Loss: 0.7112, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8835/10000, Loss: 0.7112, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8836/10000, Loss: 0.7112, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8837/10000, Loss: 0.7112, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8838/10000, Loss: 0.7112, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8839/10000, Loss: 0.7112, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8840/10000, Loss: 0.7111, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8841/10000, Loss: 0.7111, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8842/10000, Loss: 0.7111, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8843/10000, Loss: 0.7111, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8844/10000, Loss: 0.7111, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8845/10000, Loss: 0.7111, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8846/10000, Loss: 0.7110, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8847/10000, Loss: 0.7110, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8848/10000, Loss: 0.7110, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8849/10000, Loss: 0.7110, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8850/10000, Loss: 0.7110, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8851/10000, Loss: 0.7109, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8852/10000, Loss: 0.7109, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8853/10000, Loss: 0.7109, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8854/10000, Loss: 0.7109, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8855/10000, Loss: 0.7109, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8856/10000, Loss: 0.7109, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8857/10000, Loss: 0.7108, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8858/10000, Loss: 0.7108, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8859/10000, Loss: 0.7108, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8860/10000, Loss: 0.7108, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8861/10000, Loss: 0.7108, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8862/10000, Loss: 0.7108, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8863/10000, Loss: 0.7107, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8864/10000, Loss: 0.7107, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8865/10000, Loss: 0.7107, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8866/10000, Loss: 0.7107, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8867/10000, Loss: 0.7107, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8868/10000, Loss: 0.7107, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8869/10000, Loss: 0.7106, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8870/10000, Loss: 0.7106, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8871/10000, Loss: 0.7106, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8872/10000, Loss: 0.7106, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8873/10000, Loss: 0.7106, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8874/10000, Loss: 0.7105, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8875/10000, Loss: 0.7105, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8876/10000, Loss: 0.7105, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8877/10000, Loss: 0.7105, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8878/10000, Loss: 0.7105, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8879/10000, Loss: 0.7105, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8880/10000, Loss: 0.7104, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8881/10000, Loss: 0.7104, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8882/10000, Loss: 0.7104, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8883/10000, Loss: 0.7104, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8884/10000, Loss: 0.7104, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8885/10000, Loss: 0.7104, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8886/10000, Loss: 0.7103, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8887/10000, Loss: 0.7103, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8888/10000, Loss: 0.7103, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8889/10000, Loss: 0.7103, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8890/10000, Loss: 0.7103, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8891/10000, Loss: 0.7103, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8892/10000, Loss: 0.7102, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8893/10000, Loss: 0.7102, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8894/10000, Loss: 0.7102, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8895/10000, Loss: 0.7102, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8896/10000, Loss: 0.7102, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8897/10000, Loss: 0.7101, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8898/10000, Loss: 0.7101, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8899/10000, Loss: 0.7101, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8900/10000, Loss: 0.7101, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8901/10000, Loss: 0.7101, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8902/10000, Loss: 0.7101, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8903/10000, Loss: 0.7100, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8904/10000, Loss: 0.7100, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8905/10000, Loss: 0.7100, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8906/10000, Loss: 0.7100, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8907/10000, Loss: 0.7100, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8908/10000, Loss: 0.7100, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8909/10000, Loss: 0.7099, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8910/10000, Loss: 0.7099, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8911/10000, Loss: 0.7099, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8912/10000, Loss: 0.7099, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8913/10000, Loss: 0.7099, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8914/10000, Loss: 0.7099, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8915/10000, Loss: 0.7098, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8916/10000, Loss: 0.7098, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8917/10000, Loss: 0.7098, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8918/10000, Loss: 0.7098, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8919/10000, Loss: 0.7098, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8920/10000, Loss: 0.7097, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8921/10000, Loss: 0.7097, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8922/10000, Loss: 0.7097, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8923/10000, Loss: 0.7097, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8924/10000, Loss: 0.7097, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8925/10000, Loss: 0.7097, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8926/10000, Loss: 0.7096, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8927/10000, Loss: 0.7096, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8928/10000, Loss: 0.7096, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8929/10000, Loss: 0.7096, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8930/10000, Loss: 0.7096, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8931/10000, Loss: 0.7096, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8932/10000, Loss: 0.7095, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8933/10000, Loss: 0.7095, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8934/10000, Loss: 0.7095, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8935/10000, Loss: 0.7095, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8936/10000, Loss: 0.7095, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8937/10000, Loss: 0.7095, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8938/10000, Loss: 0.7094, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8939/10000, Loss: 0.7094, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8940/10000, Loss: 0.7094, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8941/10000, Loss: 0.7094, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8942/10000, Loss: 0.7094, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8943/10000, Loss: 0.7093, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8944/10000, Loss: 0.7093, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8945/10000, Loss: 0.7093, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8946/10000, Loss: 0.7093, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8947/10000, Loss: 0.7093, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8948/10000, Loss: 0.7093, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8949/10000, Loss: 0.7092, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8950/10000, Loss: 0.7092, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8951/10000, Loss: 0.7092, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8952/10000, Loss: 0.7092, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8953/10000, Loss: 0.7092, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8954/10000, Loss: 0.7092, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8955/10000, Loss: 0.7091, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8956/10000, Loss: 0.7091, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8957/10000, Loss: 0.7091, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8958/10000, Loss: 0.7091, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8959/10000, Loss: 0.7091, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8960/10000, Loss: 0.7091, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8961/10000, Loss: 0.7090, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8962/10000, Loss: 0.7090, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8963/10000, Loss: 0.7090, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8964/10000, Loss: 0.7090, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8965/10000, Loss: 0.7090, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8966/10000, Loss: 0.7090, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8967/10000, Loss: 0.7089, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8968/10000, Loss: 0.7089, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8969/10000, Loss: 0.7089, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8970/10000, Loss: 0.7089, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8971/10000, Loss: 0.7089, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8972/10000, Loss: 0.7088, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8973/10000, Loss: 0.7088, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8974/10000, Loss: 0.7088, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8975/10000, Loss: 0.7088, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8976/10000, Loss: 0.7088, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8977/10000, Loss: 0.7088, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8978/10000, Loss: 0.7087, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8979/10000, Loss: 0.7087, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8980/10000, Loss: 0.7087, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8981/10000, Loss: 0.7087, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8982/10000, Loss: 0.7087, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8983/10000, Loss: 0.7087, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8984/10000, Loss: 0.7086, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8985/10000, Loss: 0.7086, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8986/10000, Loss: 0.7086, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8987/10000, Loss: 0.7086, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8988/10000, Loss: 0.7086, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8989/10000, Loss: 0.7086, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8990/10000, Loss: 0.7085, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8991/10000, Loss: 0.7085, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8992/10000, Loss: 0.7085, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8993/10000, Loss: 0.7085, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8994/10000, Loss: 0.7085, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8995/10000, Loss: 0.7085, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8996/10000, Loss: 0.7084, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8997/10000, Loss: 0.7084, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8998/10000, Loss: 0.7084, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 8999/10000, Loss: 0.7084, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9000/10000, Loss: 0.7084, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9001/10000, Loss: 0.7084, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9002/10000, Loss: 0.7083, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9003/10000, Loss: 0.7083, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9004/10000, Loss: 0.7083, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9005/10000, Loss: 0.7083, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9006/10000, Loss: 0.7083, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9007/10000, Loss: 0.7082, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9008/10000, Loss: 0.7082, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9009/10000, Loss: 0.7082, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9010/10000, Loss: 0.7082, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9011/10000, Loss: 0.7082, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9012/10000, Loss: 0.7082, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9013/10000, Loss: 0.7081, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9014/10000, Loss: 0.7081, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9015/10000, Loss: 0.7081, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9016/10000, Loss: 0.7081, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9017/10000, Loss: 0.7081, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9018/10000, Loss: 0.7081, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9019/10000, Loss: 0.7080, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9020/10000, Loss: 0.7080, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9021/10000, Loss: 0.7080, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9022/10000, Loss: 0.7080, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9023/10000, Loss: 0.7080, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9024/10000, Loss: 0.7080, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9025/10000, Loss: 0.7079, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9026/10000, Loss: 0.7079, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9027/10000, Loss: 0.7079, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9028/10000, Loss: 0.7079, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9029/10000, Loss: 0.7079, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9030/10000, Loss: 0.7079, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9031/10000, Loss: 0.7078, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9032/10000, Loss: 0.7078, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9033/10000, Loss: 0.7078, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9034/10000, Loss: 0.7078, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9035/10000, Loss: 0.7078, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9036/10000, Loss: 0.7078, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9037/10000, Loss: 0.7077, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9038/10000, Loss: 0.7077, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9039/10000, Loss: 0.7077, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9040/10000, Loss: 0.7077, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9041/10000, Loss: 0.7077, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9042/10000, Loss: 0.7076, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9043/10000, Loss: 0.7076, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9044/10000, Loss: 0.7076, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9045/10000, Loss: 0.7076, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9046/10000, Loss: 0.7076, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9047/10000, Loss: 0.7076, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9048/10000, Loss: 0.7075, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9049/10000, Loss: 0.7075, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9050/10000, Loss: 0.7075, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9051/10000, Loss: 0.7075, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9052/10000, Loss: 0.7075, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9053/10000, Loss: 0.7075, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9054/10000, Loss: 0.7074, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9055/10000, Loss: 0.7074, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9056/10000, Loss: 0.7074, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9057/10000, Loss: 0.7074, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9058/10000, Loss: 0.7074, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9059/10000, Loss: 0.7074, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9060/10000, Loss: 0.7073, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9061/10000, Loss: 0.7073, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9062/10000, Loss: 0.7073, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9063/10000, Loss: 0.7073, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9064/10000, Loss: 0.7073, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9065/10000, Loss: 0.7073, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9066/10000, Loss: 0.7072, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9067/10000, Loss: 0.7072, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9068/10000, Loss: 0.7072, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9069/10000, Loss: 0.7072, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9070/10000, Loss: 0.7072, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9071/10000, Loss: 0.7072, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9072/10000, Loss: 0.7071, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9073/10000, Loss: 0.7071, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9074/10000, Loss: 0.7071, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9075/10000, Loss: 0.7071, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9076/10000, Loss: 0.7071, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9077/10000, Loss: 0.7071, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9078/10000, Loss: 0.7070, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9079/10000, Loss: 0.7070, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9080/10000, Loss: 0.7070, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9081/10000, Loss: 0.7070, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9082/10000, Loss: 0.7070, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9083/10000, Loss: 0.7070, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9084/10000, Loss: 0.7069, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9085/10000, Loss: 0.7069, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9086/10000, Loss: 0.7069, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9087/10000, Loss: 0.7069, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9088/10000, Loss: 0.7069, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9089/10000, Loss: 0.7069, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9090/10000, Loss: 0.7068, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9091/10000, Loss: 0.7068, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9092/10000, Loss: 0.7068, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9093/10000, Loss: 0.7068, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9094/10000, Loss: 0.7068, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9095/10000, Loss: 0.7067, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9096/10000, Loss: 0.7067, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9097/10000, Loss: 0.7067, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9098/10000, Loss: 0.7067, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9099/10000, Loss: 0.7067, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9100/10000, Loss: 0.7067, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9101/10000, Loss: 0.7066, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9102/10000, Loss: 0.7066, Accuracy: 0.6890, Learning Rate: 0.000100\n",
      "Epoch 9103/10000, Loss: 0.7066, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9104/10000, Loss: 0.7066, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9105/10000, Loss: 0.7066, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9106/10000, Loss: 0.7066, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9107/10000, Loss: 0.7065, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9108/10000, Loss: 0.7065, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9109/10000, Loss: 0.7065, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9110/10000, Loss: 0.7065, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9111/10000, Loss: 0.7065, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9112/10000, Loss: 0.7065, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9113/10000, Loss: 0.7064, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9114/10000, Loss: 0.7064, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9115/10000, Loss: 0.7064, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9116/10000, Loss: 0.7064, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9117/10000, Loss: 0.7064, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9118/10000, Loss: 0.7064, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9119/10000, Loss: 0.7063, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9120/10000, Loss: 0.7063, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9121/10000, Loss: 0.7063, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9122/10000, Loss: 0.7063, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9123/10000, Loss: 0.7063, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9124/10000, Loss: 0.7063, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9125/10000, Loss: 0.7062, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9126/10000, Loss: 0.7062, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9127/10000, Loss: 0.7062, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9128/10000, Loss: 0.7062, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9129/10000, Loss: 0.7062, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9130/10000, Loss: 0.7062, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9131/10000, Loss: 0.7061, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9132/10000, Loss: 0.7061, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9133/10000, Loss: 0.7061, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9134/10000, Loss: 0.7061, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9135/10000, Loss: 0.7061, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9136/10000, Loss: 0.7061, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9137/10000, Loss: 0.7060, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9138/10000, Loss: 0.7060, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9139/10000, Loss: 0.7060, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9140/10000, Loss: 0.7060, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9141/10000, Loss: 0.7060, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9142/10000, Loss: 0.7060, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9143/10000, Loss: 0.7059, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9144/10000, Loss: 0.7059, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9145/10000, Loss: 0.7059, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9146/10000, Loss: 0.7059, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9147/10000, Loss: 0.7059, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9148/10000, Loss: 0.7059, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9149/10000, Loss: 0.7058, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9150/10000, Loss: 0.7058, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9151/10000, Loss: 0.7058, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9152/10000, Loss: 0.7058, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9153/10000, Loss: 0.7058, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9154/10000, Loss: 0.7058, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9155/10000, Loss: 0.7057, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9156/10000, Loss: 0.7057, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9157/10000, Loss: 0.7057, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9158/10000, Loss: 0.7057, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9159/10000, Loss: 0.7057, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9160/10000, Loss: 0.7057, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9161/10000, Loss: 0.7056, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9162/10000, Loss: 0.7056, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9163/10000, Loss: 0.7056, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9164/10000, Loss: 0.7056, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9165/10000, Loss: 0.7056, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9166/10000, Loss: 0.7056, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9167/10000, Loss: 0.7055, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9168/10000, Loss: 0.7055, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9169/10000, Loss: 0.7055, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9170/10000, Loss: 0.7055, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9171/10000, Loss: 0.7055, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9172/10000, Loss: 0.7055, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9173/10000, Loss: 0.7054, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9174/10000, Loss: 0.7054, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9175/10000, Loss: 0.7054, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9176/10000, Loss: 0.7054, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9177/10000, Loss: 0.7054, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9178/10000, Loss: 0.7054, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9179/10000, Loss: 0.7053, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9180/10000, Loss: 0.7053, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9181/10000, Loss: 0.7053, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9182/10000, Loss: 0.7053, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9183/10000, Loss: 0.7053, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9184/10000, Loss: 0.7052, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9185/10000, Loss: 0.7052, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9186/10000, Loss: 0.7052, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9187/10000, Loss: 0.7052, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9188/10000, Loss: 0.7052, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9189/10000, Loss: 0.7052, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9190/10000, Loss: 0.7051, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9191/10000, Loss: 0.7051, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9192/10000, Loss: 0.7051, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9193/10000, Loss: 0.7051, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9194/10000, Loss: 0.7051, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9195/10000, Loss: 0.7051, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9196/10000, Loss: 0.7050, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9197/10000, Loss: 0.7050, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9198/10000, Loss: 0.7050, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9199/10000, Loss: 0.7050, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9200/10000, Loss: 0.7050, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9201/10000, Loss: 0.7050, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9202/10000, Loss: 0.7049, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9203/10000, Loss: 0.7049, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9204/10000, Loss: 0.7049, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9205/10000, Loss: 0.7049, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9206/10000, Loss: 0.7049, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9207/10000, Loss: 0.7049, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9208/10000, Loss: 0.7048, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9209/10000, Loss: 0.7048, Accuracy: 0.6872, Learning Rate: 0.000100\n",
      "Epoch 9210/10000, Loss: 0.7048, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9211/10000, Loss: 0.7048, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9212/10000, Loss: 0.7048, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9213/10000, Loss: 0.7048, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9214/10000, Loss: 0.7047, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9215/10000, Loss: 0.7047, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9216/10000, Loss: 0.7047, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9217/10000, Loss: 0.7047, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9218/10000, Loss: 0.7047, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9219/10000, Loss: 0.7047, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9220/10000, Loss: 0.7046, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9221/10000, Loss: 0.7046, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9222/10000, Loss: 0.7046, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9223/10000, Loss: 0.7046, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9224/10000, Loss: 0.7046, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9225/10000, Loss: 0.7046, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9226/10000, Loss: 0.7045, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9227/10000, Loss: 0.7045, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9228/10000, Loss: 0.7045, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9229/10000, Loss: 0.7045, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9230/10000, Loss: 0.7045, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9231/10000, Loss: 0.7045, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9232/10000, Loss: 0.7044, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9233/10000, Loss: 0.7044, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9234/10000, Loss: 0.7044, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9235/10000, Loss: 0.7044, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9236/10000, Loss: 0.7044, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9237/10000, Loss: 0.7044, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9238/10000, Loss: 0.7043, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9239/10000, Loss: 0.7043, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9240/10000, Loss: 0.7043, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9241/10000, Loss: 0.7043, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9242/10000, Loss: 0.7043, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9243/10000, Loss: 0.7043, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9244/10000, Loss: 0.7042, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9245/10000, Loss: 0.7042, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9246/10000, Loss: 0.7042, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9247/10000, Loss: 0.7042, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9248/10000, Loss: 0.7042, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9249/10000, Loss: 0.7042, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9250/10000, Loss: 0.7041, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9251/10000, Loss: 0.7041, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9252/10000, Loss: 0.7041, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9253/10000, Loss: 0.7041, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9254/10000, Loss: 0.7041, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9255/10000, Loss: 0.7041, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9256/10000, Loss: 0.7040, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9257/10000, Loss: 0.7040, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9258/10000, Loss: 0.7040, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9259/10000, Loss: 0.7040, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9260/10000, Loss: 0.7040, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9261/10000, Loss: 0.7040, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9262/10000, Loss: 0.7040, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9263/10000, Loss: 0.7039, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9264/10000, Loss: 0.7039, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9265/10000, Loss: 0.7039, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9266/10000, Loss: 0.7039, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9267/10000, Loss: 0.7039, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9268/10000, Loss: 0.7039, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9269/10000, Loss: 0.7038, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9270/10000, Loss: 0.7038, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9271/10000, Loss: 0.7038, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9272/10000, Loss: 0.7038, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9273/10000, Loss: 0.7038, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9274/10000, Loss: 0.7038, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9275/10000, Loss: 0.7037, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9276/10000, Loss: 0.7037, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9277/10000, Loss: 0.7037, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9278/10000, Loss: 0.7037, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9279/10000, Loss: 0.7037, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9280/10000, Loss: 0.7037, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9281/10000, Loss: 0.7036, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9282/10000, Loss: 0.7036, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9283/10000, Loss: 0.7036, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9284/10000, Loss: 0.7036, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9285/10000, Loss: 0.7036, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9286/10000, Loss: 0.7036, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9287/10000, Loss: 0.7035, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9288/10000, Loss: 0.7035, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9289/10000, Loss: 0.7035, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9290/10000, Loss: 0.7035, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9291/10000, Loss: 0.7035, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9292/10000, Loss: 0.7035, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9293/10000, Loss: 0.7034, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9294/10000, Loss: 0.7034, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9295/10000, Loss: 0.7034, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9296/10000, Loss: 0.7034, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9297/10000, Loss: 0.7034, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9298/10000, Loss: 0.7034, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9299/10000, Loss: 0.7033, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9300/10000, Loss: 0.7033, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9301/10000, Loss: 0.7033, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9302/10000, Loss: 0.7033, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9303/10000, Loss: 0.7033, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9304/10000, Loss: 0.7033, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9305/10000, Loss: 0.7032, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9306/10000, Loss: 0.7032, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9307/10000, Loss: 0.7032, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9308/10000, Loss: 0.7032, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9309/10000, Loss: 0.7032, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9310/10000, Loss: 0.7032, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9311/10000, Loss: 0.7031, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9312/10000, Loss: 0.7031, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9313/10000, Loss: 0.7031, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9314/10000, Loss: 0.7031, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9315/10000, Loss: 0.7031, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9316/10000, Loss: 0.7031, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9317/10000, Loss: 0.7030, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9318/10000, Loss: 0.7030, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9319/10000, Loss: 0.7030, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9320/10000, Loss: 0.7030, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9321/10000, Loss: 0.7030, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9322/10000, Loss: 0.7030, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9323/10000, Loss: 0.7029, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9324/10000, Loss: 0.7029, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9325/10000, Loss: 0.7029, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9326/10000, Loss: 0.7029, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9327/10000, Loss: 0.7029, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9328/10000, Loss: 0.7029, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9329/10000, Loss: 0.7028, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9330/10000, Loss: 0.7028, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9331/10000, Loss: 0.7028, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9332/10000, Loss: 0.7028, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9333/10000, Loss: 0.7028, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9334/10000, Loss: 0.7028, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9335/10000, Loss: 0.7027, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9336/10000, Loss: 0.7027, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9337/10000, Loss: 0.7027, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9338/10000, Loss: 0.7027, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9339/10000, Loss: 0.7027, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9340/10000, Loss: 0.7027, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9341/10000, Loss: 0.7026, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9342/10000, Loss: 0.7026, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9343/10000, Loss: 0.7026, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9344/10000, Loss: 0.7026, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9345/10000, Loss: 0.7026, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9346/10000, Loss: 0.7026, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9347/10000, Loss: 0.7025, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9348/10000, Loss: 0.7025, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9349/10000, Loss: 0.7025, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9350/10000, Loss: 0.7025, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9351/10000, Loss: 0.7025, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9352/10000, Loss: 0.7025, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9353/10000, Loss: 0.7025, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9354/10000, Loss: 0.7024, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9355/10000, Loss: 0.7024, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9356/10000, Loss: 0.7024, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9357/10000, Loss: 0.7024, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9358/10000, Loss: 0.7024, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9359/10000, Loss: 0.7024, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9360/10000, Loss: 0.7023, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9361/10000, Loss: 0.7023, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9362/10000, Loss: 0.7023, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9363/10000, Loss: 0.7023, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9364/10000, Loss: 0.7023, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9365/10000, Loss: 0.7023, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9366/10000, Loss: 0.7022, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9367/10000, Loss: 0.7022, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9368/10000, Loss: 0.7022, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9369/10000, Loss: 0.7022, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9370/10000, Loss: 0.7022, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9371/10000, Loss: 0.7022, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9372/10000, Loss: 0.7021, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9373/10000, Loss: 0.7021, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9374/10000, Loss: 0.7021, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9375/10000, Loss: 0.7021, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9376/10000, Loss: 0.7021, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9377/10000, Loss: 0.7021, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9378/10000, Loss: 0.7020, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9379/10000, Loss: 0.7020, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9380/10000, Loss: 0.7020, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9381/10000, Loss: 0.7020, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9382/10000, Loss: 0.7020, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9383/10000, Loss: 0.7020, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9384/10000, Loss: 0.7019, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9385/10000, Loss: 0.7019, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9386/10000, Loss: 0.7019, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9387/10000, Loss: 0.7019, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9388/10000, Loss: 0.7019, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9389/10000, Loss: 0.7019, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9390/10000, Loss: 0.7018, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9391/10000, Loss: 0.7018, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9392/10000, Loss: 0.7018, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9393/10000, Loss: 0.7018, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9394/10000, Loss: 0.7018, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9395/10000, Loss: 0.7018, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9396/10000, Loss: 0.7017, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9397/10000, Loss: 0.7017, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9398/10000, Loss: 0.7017, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9399/10000, Loss: 0.7017, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9400/10000, Loss: 0.7017, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9401/10000, Loss: 0.7017, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9402/10000, Loss: 0.7017, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9403/10000, Loss: 0.7016, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9404/10000, Loss: 0.7016, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9405/10000, Loss: 0.7016, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9406/10000, Loss: 0.7016, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9407/10000, Loss: 0.7016, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9408/10000, Loss: 0.7016, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9409/10000, Loss: 0.7015, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9410/10000, Loss: 0.7015, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9411/10000, Loss: 0.7015, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9412/10000, Loss: 0.7015, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9413/10000, Loss: 0.7015, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9414/10000, Loss: 0.7015, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9415/10000, Loss: 0.7014, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9416/10000, Loss: 0.7014, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9417/10000, Loss: 0.7014, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9418/10000, Loss: 0.7014, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9419/10000, Loss: 0.7014, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9420/10000, Loss: 0.7014, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9421/10000, Loss: 0.7013, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9422/10000, Loss: 0.7013, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9423/10000, Loss: 0.7013, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9424/10000, Loss: 0.7013, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9425/10000, Loss: 0.7013, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9426/10000, Loss: 0.7013, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9427/10000, Loss: 0.7012, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9428/10000, Loss: 0.7012, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9429/10000, Loss: 0.7012, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9430/10000, Loss: 0.7012, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9431/10000, Loss: 0.7012, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9432/10000, Loss: 0.7012, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9433/10000, Loss: 0.7011, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9434/10000, Loss: 0.7011, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9435/10000, Loss: 0.7011, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9436/10000, Loss: 0.7011, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9437/10000, Loss: 0.7011, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9438/10000, Loss: 0.7011, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9439/10000, Loss: 0.7011, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9440/10000, Loss: 0.7010, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9441/10000, Loss: 0.7010, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9442/10000, Loss: 0.7010, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9443/10000, Loss: 0.7010, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9444/10000, Loss: 0.7010, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9445/10000, Loss: 0.7010, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9446/10000, Loss: 0.7009, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9447/10000, Loss: 0.7009, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9448/10000, Loss: 0.7009, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9449/10000, Loss: 0.7009, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9450/10000, Loss: 0.7009, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9451/10000, Loss: 0.7009, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9452/10000, Loss: 0.7008, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9453/10000, Loss: 0.7008, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9454/10000, Loss: 0.7008, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9455/10000, Loss: 0.7008, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9456/10000, Loss: 0.7008, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9457/10000, Loss: 0.7008, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9458/10000, Loss: 0.7007, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9459/10000, Loss: 0.7007, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9460/10000, Loss: 0.7007, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9461/10000, Loss: 0.7007, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9462/10000, Loss: 0.7007, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9463/10000, Loss: 0.7007, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9464/10000, Loss: 0.7006, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9465/10000, Loss: 0.7006, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9466/10000, Loss: 0.7006, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9467/10000, Loss: 0.7006, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9468/10000, Loss: 0.7006, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9469/10000, Loss: 0.7006, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9470/10000, Loss: 0.7005, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9471/10000, Loss: 0.7005, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9472/10000, Loss: 0.7005, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9473/10000, Loss: 0.7005, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9474/10000, Loss: 0.7005, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9475/10000, Loss: 0.7005, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9476/10000, Loss: 0.7005, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9477/10000, Loss: 0.7004, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9478/10000, Loss: 0.7004, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9479/10000, Loss: 0.7004, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9480/10000, Loss: 0.7004, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9481/10000, Loss: 0.7004, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9482/10000, Loss: 0.7004, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9483/10000, Loss: 0.7003, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9484/10000, Loss: 0.7003, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9485/10000, Loss: 0.7003, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9486/10000, Loss: 0.7003, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9487/10000, Loss: 0.7003, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9488/10000, Loss: 0.7003, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9489/10000, Loss: 0.7002, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9490/10000, Loss: 0.7002, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9491/10000, Loss: 0.7002, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9492/10000, Loss: 0.7002, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9493/10000, Loss: 0.7002, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9494/10000, Loss: 0.7002, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9495/10000, Loss: 0.7001, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9496/10000, Loss: 0.7001, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9497/10000, Loss: 0.7001, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9498/10000, Loss: 0.7001, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9499/10000, Loss: 0.7001, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9500/10000, Loss: 0.7001, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9501/10000, Loss: 0.7001, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9502/10000, Loss: 0.7000, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9503/10000, Loss: 0.7000, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9504/10000, Loss: 0.7000, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9505/10000, Loss: 0.7000, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9506/10000, Loss: 0.7000, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9507/10000, Loss: 0.7000, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9508/10000, Loss: 0.6999, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9509/10000, Loss: 0.6999, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9510/10000, Loss: 0.6999, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9511/10000, Loss: 0.6999, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9512/10000, Loss: 0.6999, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9513/10000, Loss: 0.6999, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9514/10000, Loss: 0.6998, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9515/10000, Loss: 0.6998, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9516/10000, Loss: 0.6998, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9517/10000, Loss: 0.6998, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9518/10000, Loss: 0.6998, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9519/10000, Loss: 0.6998, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9520/10000, Loss: 0.6997, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9521/10000, Loss: 0.6997, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9522/10000, Loss: 0.6997, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9523/10000, Loss: 0.6997, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9524/10000, Loss: 0.6997, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9525/10000, Loss: 0.6997, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9526/10000, Loss: 0.6996, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9527/10000, Loss: 0.6996, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9528/10000, Loss: 0.6996, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9529/10000, Loss: 0.6996, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9530/10000, Loss: 0.6996, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9531/10000, Loss: 0.6996, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9532/10000, Loss: 0.6996, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9533/10000, Loss: 0.6995, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9534/10000, Loss: 0.6995, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9535/10000, Loss: 0.6995, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9536/10000, Loss: 0.6995, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9537/10000, Loss: 0.6995, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9538/10000, Loss: 0.6995, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9539/10000, Loss: 0.6994, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9540/10000, Loss: 0.6994, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9541/10000, Loss: 0.6994, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9542/10000, Loss: 0.6994, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9543/10000, Loss: 0.6994, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9544/10000, Loss: 0.6994, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9545/10000, Loss: 0.6993, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9546/10000, Loss: 0.6993, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9547/10000, Loss: 0.6993, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9548/10000, Loss: 0.6993, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9549/10000, Loss: 0.6993, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9550/10000, Loss: 0.6993, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9551/10000, Loss: 0.6992, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9552/10000, Loss: 0.6992, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9553/10000, Loss: 0.6992, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9554/10000, Loss: 0.6992, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9555/10000, Loss: 0.6992, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9556/10000, Loss: 0.6992, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9557/10000, Loss: 0.6992, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9558/10000, Loss: 0.6991, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9559/10000, Loss: 0.6991, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9560/10000, Loss: 0.6991, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9561/10000, Loss: 0.6991, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9562/10000, Loss: 0.6991, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9563/10000, Loss: 0.6991, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9564/10000, Loss: 0.6990, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9565/10000, Loss: 0.6990, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9566/10000, Loss: 0.6990, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9567/10000, Loss: 0.6990, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9568/10000, Loss: 0.6990, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9569/10000, Loss: 0.6990, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9570/10000, Loss: 0.6989, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9571/10000, Loss: 0.6989, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9572/10000, Loss: 0.6989, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9573/10000, Loss: 0.6989, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9574/10000, Loss: 0.6989, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9575/10000, Loss: 0.6989, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9576/10000, Loss: 0.6989, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9577/10000, Loss: 0.6988, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9578/10000, Loss: 0.6988, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9579/10000, Loss: 0.6988, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9580/10000, Loss: 0.6988, Accuracy: 0.6834, Learning Rate: 0.000100\n",
      "Epoch 9581/10000, Loss: 0.6988, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9582/10000, Loss: 0.6988, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9583/10000, Loss: 0.6987, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9584/10000, Loss: 0.6987, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9585/10000, Loss: 0.6987, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9586/10000, Loss: 0.6987, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9587/10000, Loss: 0.6987, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9588/10000, Loss: 0.6987, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9589/10000, Loss: 0.6986, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9590/10000, Loss: 0.6986, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9591/10000, Loss: 0.6986, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9592/10000, Loss: 0.6986, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9593/10000, Loss: 0.6986, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9594/10000, Loss: 0.6986, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9595/10000, Loss: 0.6985, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9596/10000, Loss: 0.6985, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9597/10000, Loss: 0.6985, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9598/10000, Loss: 0.6985, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9599/10000, Loss: 0.6985, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9600/10000, Loss: 0.6985, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9601/10000, Loss: 0.6985, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9602/10000, Loss: 0.6984, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9603/10000, Loss: 0.6984, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9604/10000, Loss: 0.6984, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9605/10000, Loss: 0.6984, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9606/10000, Loss: 0.6984, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9607/10000, Loss: 0.6984, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9608/10000, Loss: 0.6983, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9609/10000, Loss: 0.6983, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9610/10000, Loss: 0.6983, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9611/10000, Loss: 0.6983, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9612/10000, Loss: 0.6983, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9613/10000, Loss: 0.6983, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9614/10000, Loss: 0.6982, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9615/10000, Loss: 0.6982, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9616/10000, Loss: 0.6982, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9617/10000, Loss: 0.6982, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9618/10000, Loss: 0.6982, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9619/10000, Loss: 0.6982, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9620/10000, Loss: 0.6982, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9621/10000, Loss: 0.6981, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9622/10000, Loss: 0.6981, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9623/10000, Loss: 0.6981, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9624/10000, Loss: 0.6981, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9625/10000, Loss: 0.6981, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9626/10000, Loss: 0.6981, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9627/10000, Loss: 0.6980, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9628/10000, Loss: 0.6980, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9629/10000, Loss: 0.6980, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9630/10000, Loss: 0.6980, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9631/10000, Loss: 0.6980, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9632/10000, Loss: 0.6980, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9633/10000, Loss: 0.6979, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9634/10000, Loss: 0.6979, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9635/10000, Loss: 0.6979, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9636/10000, Loss: 0.6979, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9637/10000, Loss: 0.6979, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9638/10000, Loss: 0.6979, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9639/10000, Loss: 0.6979, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9640/10000, Loss: 0.6978, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9641/10000, Loss: 0.6978, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9642/10000, Loss: 0.6978, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9643/10000, Loss: 0.6978, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9644/10000, Loss: 0.6978, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9645/10000, Loss: 0.6978, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9646/10000, Loss: 0.6977, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9647/10000, Loss: 0.6977, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9648/10000, Loss: 0.6977, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9649/10000, Loss: 0.6977, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9650/10000, Loss: 0.6977, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9651/10000, Loss: 0.6977, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9652/10000, Loss: 0.6976, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9653/10000, Loss: 0.6976, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9654/10000, Loss: 0.6976, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9655/10000, Loss: 0.6976, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9656/10000, Loss: 0.6976, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9657/10000, Loss: 0.6976, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9658/10000, Loss: 0.6976, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9659/10000, Loss: 0.6975, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9660/10000, Loss: 0.6975, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9661/10000, Loss: 0.6975, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9662/10000, Loss: 0.6975, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9663/10000, Loss: 0.6975, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9664/10000, Loss: 0.6975, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9665/10000, Loss: 0.6974, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9666/10000, Loss: 0.6974, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9667/10000, Loss: 0.6974, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9668/10000, Loss: 0.6974, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9669/10000, Loss: 0.6974, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9670/10000, Loss: 0.6974, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9671/10000, Loss: 0.6973, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9672/10000, Loss: 0.6973, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9673/10000, Loss: 0.6973, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9674/10000, Loss: 0.6973, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9675/10000, Loss: 0.6973, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9676/10000, Loss: 0.6973, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9677/10000, Loss: 0.6973, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9678/10000, Loss: 0.6972, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9679/10000, Loss: 0.6972, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9680/10000, Loss: 0.6972, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9681/10000, Loss: 0.6972, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9682/10000, Loss: 0.6972, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9683/10000, Loss: 0.6972, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9684/10000, Loss: 0.6971, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9685/10000, Loss: 0.6971, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9686/10000, Loss: 0.6971, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9687/10000, Loss: 0.6971, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9688/10000, Loss: 0.6971, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9689/10000, Loss: 0.6971, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9690/10000, Loss: 0.6971, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9691/10000, Loss: 0.6970, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9692/10000, Loss: 0.6970, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9693/10000, Loss: 0.6970, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9694/10000, Loss: 0.6970, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9695/10000, Loss: 0.6970, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9696/10000, Loss: 0.6970, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9697/10000, Loss: 0.6969, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9698/10000, Loss: 0.6969, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9699/10000, Loss: 0.6969, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9700/10000, Loss: 0.6969, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9701/10000, Loss: 0.6969, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9702/10000, Loss: 0.6969, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9703/10000, Loss: 0.6968, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9704/10000, Loss: 0.6968, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9705/10000, Loss: 0.6968, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9706/10000, Loss: 0.6968, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9707/10000, Loss: 0.6968, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9708/10000, Loss: 0.6968, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9709/10000, Loss: 0.6968, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9710/10000, Loss: 0.6967, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9711/10000, Loss: 0.6967, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9712/10000, Loss: 0.6967, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9713/10000, Loss: 0.6967, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9714/10000, Loss: 0.6967, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9715/10000, Loss: 0.6967, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9716/10000, Loss: 0.6966, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9717/10000, Loss: 0.6966, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9718/10000, Loss: 0.6966, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9719/10000, Loss: 0.6966, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9720/10000, Loss: 0.6966, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9721/10000, Loss: 0.6966, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9722/10000, Loss: 0.6966, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9723/10000, Loss: 0.6965, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9724/10000, Loss: 0.6965, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9725/10000, Loss: 0.6965, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9726/10000, Loss: 0.6965, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9727/10000, Loss: 0.6965, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9728/10000, Loss: 0.6965, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9729/10000, Loss: 0.6964, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9730/10000, Loss: 0.6964, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9731/10000, Loss: 0.6964, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9732/10000, Loss: 0.6964, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9733/10000, Loss: 0.6964, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9734/10000, Loss: 0.6964, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9735/10000, Loss: 0.6963, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9736/10000, Loss: 0.6963, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9737/10000, Loss: 0.6963, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9738/10000, Loss: 0.6963, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9739/10000, Loss: 0.6963, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9740/10000, Loss: 0.6963, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9741/10000, Loss: 0.6963, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9742/10000, Loss: 0.6962, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9743/10000, Loss: 0.6962, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9744/10000, Loss: 0.6962, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9745/10000, Loss: 0.6962, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9746/10000, Loss: 0.6962, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9747/10000, Loss: 0.6962, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9748/10000, Loss: 0.6961, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9749/10000, Loss: 0.6961, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9750/10000, Loss: 0.6961, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9751/10000, Loss: 0.6961, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9752/10000, Loss: 0.6961, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9753/10000, Loss: 0.6961, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9754/10000, Loss: 0.6961, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9755/10000, Loss: 0.6960, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9756/10000, Loss: 0.6960, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9757/10000, Loss: 0.6960, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9758/10000, Loss: 0.6960, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9759/10000, Loss: 0.6960, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9760/10000, Loss: 0.6960, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9761/10000, Loss: 0.6959, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9762/10000, Loss: 0.6959, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9763/10000, Loss: 0.6959, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9764/10000, Loss: 0.6959, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9765/10000, Loss: 0.6959, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9766/10000, Loss: 0.6959, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9767/10000, Loss: 0.6959, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9768/10000, Loss: 0.6958, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9769/10000, Loss: 0.6958, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9770/10000, Loss: 0.6958, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9771/10000, Loss: 0.6958, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9772/10000, Loss: 0.6958, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9773/10000, Loss: 0.6958, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9774/10000, Loss: 0.6957, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9775/10000, Loss: 0.6957, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9776/10000, Loss: 0.6957, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9777/10000, Loss: 0.6957, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9778/10000, Loss: 0.6957, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9779/10000, Loss: 0.6957, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9780/10000, Loss: 0.6956, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9781/10000, Loss: 0.6956, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9782/10000, Loss: 0.6956, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9783/10000, Loss: 0.6956, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9784/10000, Loss: 0.6956, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9785/10000, Loss: 0.6956, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9786/10000, Loss: 0.6956, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9787/10000, Loss: 0.6955, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9788/10000, Loss: 0.6955, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9789/10000, Loss: 0.6955, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9790/10000, Loss: 0.6955, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9791/10000, Loss: 0.6955, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9792/10000, Loss: 0.6955, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9793/10000, Loss: 0.6954, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9794/10000, Loss: 0.6954, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9795/10000, Loss: 0.6954, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9796/10000, Loss: 0.6954, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9797/10000, Loss: 0.6954, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9798/10000, Loss: 0.6954, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9799/10000, Loss: 0.6954, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9800/10000, Loss: 0.6953, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9801/10000, Loss: 0.6953, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9802/10000, Loss: 0.6953, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9803/10000, Loss: 0.6953, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9804/10000, Loss: 0.6953, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9805/10000, Loss: 0.6953, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9806/10000, Loss: 0.6952, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9807/10000, Loss: 0.6952, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9808/10000, Loss: 0.6952, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9809/10000, Loss: 0.6952, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9810/10000, Loss: 0.6952, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9811/10000, Loss: 0.6952, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9812/10000, Loss: 0.6952, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9813/10000, Loss: 0.6951, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9814/10000, Loss: 0.6951, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9815/10000, Loss: 0.6951, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9816/10000, Loss: 0.6951, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9817/10000, Loss: 0.6951, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9818/10000, Loss: 0.6951, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9819/10000, Loss: 0.6950, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9820/10000, Loss: 0.6950, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9821/10000, Loss: 0.6950, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9822/10000, Loss: 0.6950, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9823/10000, Loss: 0.6950, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9824/10000, Loss: 0.6950, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9825/10000, Loss: 0.6950, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9826/10000, Loss: 0.6949, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9827/10000, Loss: 0.6949, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9828/10000, Loss: 0.6949, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9829/10000, Loss: 0.6949, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9830/10000, Loss: 0.6949, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9831/10000, Loss: 0.6949, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9832/10000, Loss: 0.6948, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9833/10000, Loss: 0.6948, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9834/10000, Loss: 0.6948, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9835/10000, Loss: 0.6948, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9836/10000, Loss: 0.6948, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9837/10000, Loss: 0.6948, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9838/10000, Loss: 0.6948, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9839/10000, Loss: 0.6947, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9840/10000, Loss: 0.6947, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9841/10000, Loss: 0.6947, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9842/10000, Loss: 0.6947, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9843/10000, Loss: 0.6947, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9844/10000, Loss: 0.6947, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9845/10000, Loss: 0.6946, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9846/10000, Loss: 0.6946, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9847/10000, Loss: 0.6946, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9848/10000, Loss: 0.6946, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9849/10000, Loss: 0.6946, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9850/10000, Loss: 0.6946, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9851/10000, Loss: 0.6946, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9852/10000, Loss: 0.6945, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9853/10000, Loss: 0.6945, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9854/10000, Loss: 0.6945, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9855/10000, Loss: 0.6945, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9856/10000, Loss: 0.6945, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9857/10000, Loss: 0.6945, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9858/10000, Loss: 0.6944, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9859/10000, Loss: 0.6944, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9860/10000, Loss: 0.6944, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9861/10000, Loss: 0.6944, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9862/10000, Loss: 0.6944, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9863/10000, Loss: 0.6944, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9864/10000, Loss: 0.6944, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9865/10000, Loss: 0.6943, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9866/10000, Loss: 0.6943, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9867/10000, Loss: 0.6943, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9868/10000, Loss: 0.6943, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9869/10000, Loss: 0.6943, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9870/10000, Loss: 0.6943, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9871/10000, Loss: 0.6942, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9872/10000, Loss: 0.6942, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9873/10000, Loss: 0.6942, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9874/10000, Loss: 0.6942, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9875/10000, Loss: 0.6942, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9876/10000, Loss: 0.6942, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9877/10000, Loss: 0.6942, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9878/10000, Loss: 0.6941, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9879/10000, Loss: 0.6941, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9880/10000, Loss: 0.6941, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9881/10000, Loss: 0.6941, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9882/10000, Loss: 0.6941, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9883/10000, Loss: 0.6941, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9884/10000, Loss: 0.6940, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9885/10000, Loss: 0.6940, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9886/10000, Loss: 0.6940, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9887/10000, Loss: 0.6940, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9888/10000, Loss: 0.6940, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9889/10000, Loss: 0.6940, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9890/10000, Loss: 0.6940, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9891/10000, Loss: 0.6939, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9892/10000, Loss: 0.6939, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9893/10000, Loss: 0.6939, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9894/10000, Loss: 0.6939, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9895/10000, Loss: 0.6939, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9896/10000, Loss: 0.6939, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9897/10000, Loss: 0.6939, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9898/10000, Loss: 0.6938, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9899/10000, Loss: 0.6938, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9900/10000, Loss: 0.6938, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9901/10000, Loss: 0.6938, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9902/10000, Loss: 0.6938, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9903/10000, Loss: 0.6938, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9904/10000, Loss: 0.6937, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9905/10000, Loss: 0.6937, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9906/10000, Loss: 0.6937, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9907/10000, Loss: 0.6937, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9908/10000, Loss: 0.6937, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9909/10000, Loss: 0.6937, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9910/10000, Loss: 0.6937, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9911/10000, Loss: 0.6936, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9912/10000, Loss: 0.6936, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9913/10000, Loss: 0.6936, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9914/10000, Loss: 0.6936, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9915/10000, Loss: 0.6936, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9916/10000, Loss: 0.6936, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9917/10000, Loss: 0.6935, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9918/10000, Loss: 0.6935, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9919/10000, Loss: 0.6935, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9920/10000, Loss: 0.6935, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9921/10000, Loss: 0.6935, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9922/10000, Loss: 0.6935, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9923/10000, Loss: 0.6935, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9924/10000, Loss: 0.6934, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9925/10000, Loss: 0.6934, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9926/10000, Loss: 0.6934, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9927/10000, Loss: 0.6934, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9928/10000, Loss: 0.6934, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9929/10000, Loss: 0.6934, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9930/10000, Loss: 0.6933, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9931/10000, Loss: 0.6933, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9932/10000, Loss: 0.6933, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9933/10000, Loss: 0.6933, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9934/10000, Loss: 0.6933, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9935/10000, Loss: 0.6933, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9936/10000, Loss: 0.6933, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9937/10000, Loss: 0.6932, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9938/10000, Loss: 0.6932, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9939/10000, Loss: 0.6932, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9940/10000, Loss: 0.6932, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9941/10000, Loss: 0.6932, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9942/10000, Loss: 0.6932, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9943/10000, Loss: 0.6932, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9944/10000, Loss: 0.6931, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9945/10000, Loss: 0.6931, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9946/10000, Loss: 0.6931, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9947/10000, Loss: 0.6931, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9948/10000, Loss: 0.6931, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9949/10000, Loss: 0.6931, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9950/10000, Loss: 0.6930, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9951/10000, Loss: 0.6930, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9952/10000, Loss: 0.6930, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9953/10000, Loss: 0.6930, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9954/10000, Loss: 0.6930, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9955/10000, Loss: 0.6930, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9956/10000, Loss: 0.6930, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9957/10000, Loss: 0.6929, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9958/10000, Loss: 0.6929, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9959/10000, Loss: 0.6929, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9960/10000, Loss: 0.6929, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9961/10000, Loss: 0.6929, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9962/10000, Loss: 0.6929, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9963/10000, Loss: 0.6928, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9964/10000, Loss: 0.6928, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9965/10000, Loss: 0.6928, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9966/10000, Loss: 0.6928, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9967/10000, Loss: 0.6928, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9968/10000, Loss: 0.6928, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9969/10000, Loss: 0.6928, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9970/10000, Loss: 0.6927, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9971/10000, Loss: 0.6927, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9972/10000, Loss: 0.6927, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9973/10000, Loss: 0.6927, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9974/10000, Loss: 0.6927, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9975/10000, Loss: 0.6927, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9976/10000, Loss: 0.6927, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9977/10000, Loss: 0.6926, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9978/10000, Loss: 0.6926, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9979/10000, Loss: 0.6926, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9980/10000, Loss: 0.6926, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9981/10000, Loss: 0.6926, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9982/10000, Loss: 0.6926, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9983/10000, Loss: 0.6925, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9984/10000, Loss: 0.6925, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9985/10000, Loss: 0.6925, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9986/10000, Loss: 0.6925, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9987/10000, Loss: 0.6925, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9988/10000, Loss: 0.6925, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9989/10000, Loss: 0.6925, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9990/10000, Loss: 0.6924, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9991/10000, Loss: 0.6924, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9992/10000, Loss: 0.6924, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9993/10000, Loss: 0.6924, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9994/10000, Loss: 0.6924, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9995/10000, Loss: 0.6924, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9996/10000, Loss: 0.6924, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9997/10000, Loss: 0.6923, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9998/10000, Loss: 0.6923, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 9999/10000, Loss: 0.6923, Accuracy: 0.6853, Learning Rate: 0.000100\n",
      "Epoch 10000/10000, Loss: 0.6923, Accuracy: 0.6853, Learning Rate: 0.000100\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(0.0001,10000)\n",
    "\n",
    "lr.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "0f1a89f6-04e4-44b4-adea-941c8c2e1f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#training loss vs training accuracy\n",
    "\n",
    "lr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a3ba315f-cca2-4d54-95ab-0df9c890a1d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_134762/1260086574.py:9: RuntimeWarning: overflow encountered in exp\n",
      "  return np.where(z >= 0, 1 / (1 + np.exp(-z)), np.exp(z) / (1 + np.exp(z)))\n",
      "/tmp/ipykernel_134762/1260086574.py:9: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.where(z >= 0, 1 / (1 + np.exp(-z)), np.exp(z) / (1 + np.exp(z)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 2/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 3/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 4/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 5/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 6/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 7/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 8/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 9/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 10/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 11/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 12/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 13/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 14/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 15/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 16/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 17/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 18/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 19/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 20/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 21/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 22/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 23/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 24/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 25/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 26/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 27/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 28/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 29/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 30/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 31/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 32/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 33/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 34/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 35/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 36/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 37/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 38/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 39/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 40/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 41/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 42/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 43/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 44/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 45/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 46/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 47/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 48/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 49/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 50/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 51/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 52/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 53/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 54/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 55/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 56/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 57/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 58/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 59/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 60/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 61/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 62/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 63/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 64/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 65/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 66/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 67/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 68/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 69/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 70/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 71/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 72/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 73/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 74/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 75/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 76/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 77/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 78/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 79/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 80/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 81/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 82/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 83/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 84/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 85/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 86/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 87/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 88/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 89/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 90/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 91/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 92/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 93/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 94/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 95/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 96/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 97/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 98/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 99/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 100/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 101/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 102/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 103/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 104/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 105/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 106/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 107/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 108/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 109/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 110/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 111/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 112/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 113/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 114/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 115/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 116/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 117/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 118/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 119/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 120/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 121/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 122/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 123/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 124/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 125/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 126/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 127/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 128/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 129/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 130/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 131/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 132/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 133/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 134/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 135/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 136/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 137/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 138/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 139/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 140/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 141/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 142/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 143/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 144/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 145/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 146/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 147/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 148/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 149/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 150/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 151/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 152/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 153/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 154/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 155/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 156/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 157/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 158/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 159/10000, Loss: 12.4871, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 160/10000, Loss: 12.4870, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 161/10000, Loss: 12.4870, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 162/10000, Loss: 12.4869, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 163/10000, Loss: 12.4866, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 164/10000, Loss: 12.4861, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 165/10000, Loss: 12.4851, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 166/10000, Loss: 12.4832, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 167/10000, Loss: 12.4799, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 168/10000, Loss: 12.4748, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 169/10000, Loss: 12.4681, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 170/10000, Loss: 12.4600, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 171/10000, Loss: 12.4512, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 172/10000, Loss: 12.4419, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 173/10000, Loss: 12.4325, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 174/10000, Loss: 12.4229, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 175/10000, Loss: 12.4133, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 176/10000, Loss: 12.4035, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 177/10000, Loss: 12.3935, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 178/10000, Loss: 12.3820, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 179/10000, Loss: 12.3658, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 180/10000, Loss: 12.3419, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 181/10000, Loss: 12.3132, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 182/10000, Loss: 12.2831, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 183/10000, Loss: 12.2527, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 184/10000, Loss: 12.2223, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 185/10000, Loss: 12.1918, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 186/10000, Loss: 12.1613, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 187/10000, Loss: 12.1301, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 188/10000, Loss: 12.0977, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 189/10000, Loss: 12.0636, Accuracy: 0.3846, Learning Rate: 0.000100\n",
      "Epoch 190/10000, Loss: 12.0274, Accuracy: 0.3846, Learning Rate: 0.000100\n",
      "Epoch 191/10000, Loss: 11.9894, Accuracy: 0.3846, Learning Rate: 0.000100\n",
      "Epoch 192/10000, Loss: 11.9525, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 193/10000, Loss: 11.9192, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 194/10000, Loss: 11.8880, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 195/10000, Loss: 11.8577, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 196/10000, Loss: 11.8281, Accuracy: 0.4103, Learning Rate: 0.000100\n",
      "Epoch 197/10000, Loss: 11.7978, Accuracy: 0.4103, Learning Rate: 0.000100\n",
      "Epoch 198/10000, Loss: 11.7646, Accuracy: 0.4103, Learning Rate: 0.000100\n",
      "Epoch 199/10000, Loss: 11.7248, Accuracy: 0.4103, Learning Rate: 0.000100\n",
      "Epoch 200/10000, Loss: 11.6748, Accuracy: 0.4103, Learning Rate: 0.000100\n",
      "Epoch 201/10000, Loss: 11.6108, Accuracy: 0.4103, Learning Rate: 0.000100\n",
      "Epoch 202/10000, Loss: 11.5330, Accuracy: 0.4103, Learning Rate: 0.000100\n",
      "Epoch 203/10000, Loss: 11.4456, Accuracy: 0.4103, Learning Rate: 0.000100\n",
      "Epoch 204/10000, Loss: 11.3527, Accuracy: 0.4103, Learning Rate: 0.000100\n",
      "Epoch 205/10000, Loss: 11.2537, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 206/10000, Loss: 11.1244, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 207/10000, Loss: 10.9461, Accuracy: 0.3846, Learning Rate: 0.000100\n",
      "Epoch 208/10000, Loss: 10.7427, Accuracy: 0.3846, Learning Rate: 0.000100\n",
      "Epoch 209/10000, Loss: 10.5187, Accuracy: 0.3846, Learning Rate: 0.000100\n",
      "Epoch 210/10000, Loss: 10.2726, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 211/10000, Loss: 10.0020, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 212/10000, Loss: 9.7251, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 213/10000, Loss: 9.4698, Accuracy: 0.3590, Learning Rate: 0.000100\n",
      "Epoch 214/10000, Loss: 9.2558, Accuracy: 0.3462, Learning Rate: 0.000100\n",
      "Epoch 215/10000, Loss: 9.0660, Accuracy: 0.3590, Learning Rate: 0.000100\n",
      "Epoch 216/10000, Loss: 8.8855, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 217/10000, Loss: 8.7041, Accuracy: 0.3846, Learning Rate: 0.000100\n",
      "Epoch 218/10000, Loss: 8.5287, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 219/10000, Loss: 8.3721, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 220/10000, Loss: 8.2314, Accuracy: 0.3846, Learning Rate: 0.000100\n",
      "Epoch 221/10000, Loss: 8.1121, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 222/10000, Loss: 8.0266, Accuracy: 0.3846, Learning Rate: 0.000100\n",
      "Epoch 223/10000, Loss: 7.9744, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 224/10000, Loss: 7.9406, Accuracy: 0.4103, Learning Rate: 0.000100\n",
      "Epoch 225/10000, Loss: 7.9162, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 226/10000, Loss: 7.8970, Accuracy: 0.4103, Learning Rate: 0.000100\n",
      "Epoch 227/10000, Loss: 7.8806, Accuracy: 0.4103, Learning Rate: 0.000100\n",
      "Epoch 228/10000, Loss: 7.8658, Accuracy: 0.4103, Learning Rate: 0.000100\n",
      "Epoch 229/10000, Loss: 7.8515, Accuracy: 0.4103, Learning Rate: 0.000100\n",
      "Epoch 230/10000, Loss: 7.8372, Accuracy: 0.3846, Learning Rate: 0.000100\n",
      "Epoch 231/10000, Loss: 7.8225, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 232/10000, Loss: 7.8075, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 233/10000, Loss: 7.7924, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 234/10000, Loss: 7.7777, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 235/10000, Loss: 7.7637, Accuracy: 0.3846, Learning Rate: 0.000100\n",
      "Epoch 236/10000, Loss: 7.7507, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 237/10000, Loss: 7.7387, Accuracy: 0.3590, Learning Rate: 0.000100\n",
      "Epoch 238/10000, Loss: 7.7276, Accuracy: 0.3590, Learning Rate: 0.000100\n",
      "Epoch 239/10000, Loss: 7.7172, Accuracy: 0.3590, Learning Rate: 0.000100\n",
      "Epoch 240/10000, Loss: 7.7075, Accuracy: 0.3590, Learning Rate: 0.000100\n",
      "Epoch 241/10000, Loss: 7.6984, Accuracy: 0.3590, Learning Rate: 0.000100\n",
      "Epoch 242/10000, Loss: 7.6898, Accuracy: 0.3462, Learning Rate: 0.000100\n",
      "Epoch 243/10000, Loss: 7.6816, Accuracy: 0.3462, Learning Rate: 0.000100\n",
      "Epoch 244/10000, Loss: 7.6737, Accuracy: 0.3590, Learning Rate: 0.000100\n",
      "Epoch 245/10000, Loss: 7.6662, Accuracy: 0.3590, Learning Rate: 0.000100\n",
      "Epoch 246/10000, Loss: 7.6589, Accuracy: 0.3590, Learning Rate: 0.000100\n",
      "Epoch 247/10000, Loss: 7.6519, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 248/10000, Loss: 7.6450, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 249/10000, Loss: 7.6384, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 250/10000, Loss: 7.6318, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 251/10000, Loss: 7.6255, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 252/10000, Loss: 7.6192, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 253/10000, Loss: 7.6130, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 254/10000, Loss: 7.6069, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 255/10000, Loss: 7.6008, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 256/10000, Loss: 7.5949, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 257/10000, Loss: 7.5889, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 258/10000, Loss: 7.5830, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 259/10000, Loss: 7.5772, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 260/10000, Loss: 7.5714, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 261/10000, Loss: 7.5656, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 262/10000, Loss: 7.5599, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 263/10000, Loss: 7.5541, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 264/10000, Loss: 7.5484, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 265/10000, Loss: 7.5428, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 266/10000, Loss: 7.5371, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 267/10000, Loss: 7.5315, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 268/10000, Loss: 7.5259, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 269/10000, Loss: 7.5203, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 270/10000, Loss: 7.5148, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 271/10000, Loss: 7.5093, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 272/10000, Loss: 7.5038, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 273/10000, Loss: 7.4983, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 274/10000, Loss: 7.4929, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 275/10000, Loss: 7.4874, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 276/10000, Loss: 7.4820, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 277/10000, Loss: 7.4767, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 278/10000, Loss: 7.4713, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 279/10000, Loss: 7.4660, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 280/10000, Loss: 7.4608, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 281/10000, Loss: 7.4555, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 282/10000, Loss: 7.4503, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 283/10000, Loss: 7.4451, Accuracy: 0.3718, Learning Rate: 0.000100\n",
      "Epoch 284/10000, Loss: 7.4399, Accuracy: 0.3846, Learning Rate: 0.000100\n",
      "Epoch 285/10000, Loss: 7.4348, Accuracy: 0.3846, Learning Rate: 0.000100\n",
      "Epoch 286/10000, Loss: 7.4297, Accuracy: 0.3846, Learning Rate: 0.000100\n",
      "Epoch 287/10000, Loss: 7.4246, Accuracy: 0.3846, Learning Rate: 0.000100\n",
      "Epoch 288/10000, Loss: 7.4196, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 289/10000, Loss: 7.4145, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 290/10000, Loss: 7.4095, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 291/10000, Loss: 7.4046, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 292/10000, Loss: 7.3996, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 293/10000, Loss: 7.3947, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 294/10000, Loss: 7.3898, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 295/10000, Loss: 7.3849, Accuracy: 0.3974, Learning Rate: 0.000100\n",
      "Epoch 296/10000, Loss: 7.3800, Accuracy: 0.4103, Learning Rate: 0.000100\n",
      "Epoch 297/10000, Loss: 7.3752, Accuracy: 0.4103, Learning Rate: 0.000100\n",
      "Epoch 298/10000, Loss: 7.3704, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 299/10000, Loss: 7.3656, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 300/10000, Loss: 7.3608, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 301/10000, Loss: 7.3560, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 302/10000, Loss: 7.3513, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 303/10000, Loss: 7.3466, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 304/10000, Loss: 7.3419, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 305/10000, Loss: 7.3372, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 306/10000, Loss: 7.3325, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 307/10000, Loss: 7.3279, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 308/10000, Loss: 7.3232, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 309/10000, Loss: 7.3186, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 310/10000, Loss: 7.3140, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 311/10000, Loss: 7.3094, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 312/10000, Loss: 7.3048, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 313/10000, Loss: 7.3002, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 314/10000, Loss: 7.2957, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 315/10000, Loss: 7.2911, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 316/10000, Loss: 7.2866, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 317/10000, Loss: 7.2820, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 318/10000, Loss: 7.2775, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 319/10000, Loss: 7.2730, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 320/10000, Loss: 7.2685, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 321/10000, Loss: 7.2640, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 322/10000, Loss: 7.2595, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 323/10000, Loss: 7.2550, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 324/10000, Loss: 7.2506, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 325/10000, Loss: 7.2461, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 326/10000, Loss: 7.2416, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 327/10000, Loss: 7.2372, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 328/10000, Loss: 7.2327, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 329/10000, Loss: 7.2282, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 330/10000, Loss: 7.2238, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 331/10000, Loss: 7.2194, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 332/10000, Loss: 7.2149, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 333/10000, Loss: 7.2105, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 334/10000, Loss: 7.2060, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 335/10000, Loss: 7.2016, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 336/10000, Loss: 7.1972, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 337/10000, Loss: 7.1927, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 338/10000, Loss: 7.1883, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 339/10000, Loss: 7.1839, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 340/10000, Loss: 7.1794, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 341/10000, Loss: 7.1750, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 342/10000, Loss: 7.1706, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 343/10000, Loss: 7.1661, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 344/10000, Loss: 7.1617, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 345/10000, Loss: 7.1573, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 346/10000, Loss: 7.1528, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 347/10000, Loss: 7.1484, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 348/10000, Loss: 7.1439, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 349/10000, Loss: 7.1395, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 350/10000, Loss: 7.1350, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 351/10000, Loss: 7.1306, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 352/10000, Loss: 7.1261, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 353/10000, Loss: 7.1217, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 354/10000, Loss: 7.1172, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 355/10000, Loss: 7.1127, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 356/10000, Loss: 7.1083, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 357/10000, Loss: 7.1038, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 358/10000, Loss: 7.0993, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 359/10000, Loss: 7.0948, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 360/10000, Loss: 7.0903, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 361/10000, Loss: 7.0858, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 362/10000, Loss: 7.0813, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 363/10000, Loss: 7.0768, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 364/10000, Loss: 7.0723, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 365/10000, Loss: 7.0677, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 366/10000, Loss: 7.0632, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 367/10000, Loss: 7.0587, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 368/10000, Loss: 7.0541, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 369/10000, Loss: 7.0496, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 370/10000, Loss: 7.0450, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 371/10000, Loss: 7.0404, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 372/10000, Loss: 7.0358, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 373/10000, Loss: 7.0312, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 374/10000, Loss: 7.0266, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 375/10000, Loss: 7.0220, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 376/10000, Loss: 7.0174, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 377/10000, Loss: 7.0128, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 378/10000, Loss: 7.0081, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 379/10000, Loss: 7.0035, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 380/10000, Loss: 6.9988, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 381/10000, Loss: 6.9941, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 382/10000, Loss: 6.9895, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 383/10000, Loss: 6.9848, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 384/10000, Loss: 6.9801, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 385/10000, Loss: 6.9753, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 386/10000, Loss: 6.9706, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 387/10000, Loss: 6.9658, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 388/10000, Loss: 6.9611, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 389/10000, Loss: 6.9563, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 390/10000, Loss: 6.9515, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 391/10000, Loss: 6.9467, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 392/10000, Loss: 6.9419, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 393/10000, Loss: 6.9371, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 394/10000, Loss: 6.9322, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 395/10000, Loss: 6.9274, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 396/10000, Loss: 6.9225, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 397/10000, Loss: 6.9176, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 398/10000, Loss: 6.9127, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 399/10000, Loss: 6.9078, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 400/10000, Loss: 6.9028, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 401/10000, Loss: 6.8979, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 402/10000, Loss: 6.8929, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 403/10000, Loss: 6.8879, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 404/10000, Loss: 6.8829, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 405/10000, Loss: 6.8779, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 406/10000, Loss: 6.8729, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 407/10000, Loss: 6.8679, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 408/10000, Loss: 6.8628, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 409/10000, Loss: 6.8577, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 410/10000, Loss: 6.8526, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 411/10000, Loss: 6.8475, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 412/10000, Loss: 6.8424, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 413/10000, Loss: 6.8372, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 414/10000, Loss: 6.8320, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 415/10000, Loss: 6.8269, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 416/10000, Loss: 6.8217, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 417/10000, Loss: 6.8164, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 418/10000, Loss: 6.8112, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 419/10000, Loss: 6.8060, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 420/10000, Loss: 6.8007, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 421/10000, Loss: 6.7954, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 422/10000, Loss: 6.7901, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 423/10000, Loss: 6.7848, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 424/10000, Loss: 6.7795, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 425/10000, Loss: 6.7741, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 426/10000, Loss: 6.7688, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 427/10000, Loss: 6.7634, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 428/10000, Loss: 6.7580, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 429/10000, Loss: 6.7526, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 430/10000, Loss: 6.7471, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 431/10000, Loss: 6.7417, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 432/10000, Loss: 6.7362, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 433/10000, Loss: 6.7308, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 434/10000, Loss: 6.7253, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 435/10000, Loss: 6.7198, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 436/10000, Loss: 6.7142, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 437/10000, Loss: 6.7087, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 438/10000, Loss: 6.7031, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 439/10000, Loss: 6.6976, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 440/10000, Loss: 6.6920, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 441/10000, Loss: 6.6864, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 442/10000, Loss: 6.6808, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 443/10000, Loss: 6.6752, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 444/10000, Loss: 6.6695, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 445/10000, Loss: 6.6639, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 446/10000, Loss: 6.6582, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 447/10000, Loss: 6.6525, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 448/10000, Loss: 6.6469, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 449/10000, Loss: 6.6411, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 450/10000, Loss: 6.6354, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 451/10000, Loss: 6.6297, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 452/10000, Loss: 6.6240, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 453/10000, Loss: 6.6182, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 454/10000, Loss: 6.6124, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 455/10000, Loss: 6.6066, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 456/10000, Loss: 6.6009, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 457/10000, Loss: 6.5950, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 458/10000, Loss: 6.5892, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 459/10000, Loss: 6.5834, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 460/10000, Loss: 6.5776, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 461/10000, Loss: 6.5717, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 462/10000, Loss: 6.5658, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 463/10000, Loss: 6.5600, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 464/10000, Loss: 6.5541, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 465/10000, Loss: 6.5482, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 466/10000, Loss: 6.5423, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 467/10000, Loss: 6.5363, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 468/10000, Loss: 6.5304, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 469/10000, Loss: 6.5245, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 470/10000, Loss: 6.5185, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 471/10000, Loss: 6.5125, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 472/10000, Loss: 6.5066, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 473/10000, Loss: 6.5006, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 474/10000, Loss: 6.4946, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 475/10000, Loss: 6.4886, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 476/10000, Loss: 6.4826, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 477/10000, Loss: 6.4765, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 478/10000, Loss: 6.4705, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 479/10000, Loss: 6.4644, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 480/10000, Loss: 6.4584, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 481/10000, Loss: 6.4523, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 482/10000, Loss: 6.4463, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 483/10000, Loss: 6.4402, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 484/10000, Loss: 6.4341, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 485/10000, Loss: 6.4280, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 486/10000, Loss: 6.4219, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 487/10000, Loss: 6.4158, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 488/10000, Loss: 6.4096, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 489/10000, Loss: 6.4035, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 490/10000, Loss: 6.3974, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 491/10000, Loss: 6.3912, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 492/10000, Loss: 6.3851, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 493/10000, Loss: 6.3789, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 494/10000, Loss: 6.3727, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 495/10000, Loss: 6.3665, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 496/10000, Loss: 6.3604, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 497/10000, Loss: 6.3542, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 498/10000, Loss: 6.3480, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 499/10000, Loss: 6.3418, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 500/10000, Loss: 6.3355, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 501/10000, Loss: 6.3293, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 502/10000, Loss: 6.3231, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 503/10000, Loss: 6.3169, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 504/10000, Loss: 6.3106, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 505/10000, Loss: 6.3044, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 506/10000, Loss: 6.2981, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 507/10000, Loss: 6.2919, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 508/10000, Loss: 6.2856, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 509/10000, Loss: 6.2793, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 510/10000, Loss: 6.2731, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 511/10000, Loss: 6.2668, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 512/10000, Loss: 6.2605, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 513/10000, Loss: 6.2542, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 514/10000, Loss: 6.2479, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 515/10000, Loss: 6.2416, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 516/10000, Loss: 6.2353, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 517/10000, Loss: 6.2290, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 518/10000, Loss: 6.2227, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 519/10000, Loss: 6.2164, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 520/10000, Loss: 6.2101, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 521/10000, Loss: 6.2038, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 522/10000, Loss: 6.1975, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 523/10000, Loss: 6.1912, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 524/10000, Loss: 6.1848, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 525/10000, Loss: 6.1785, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 526/10000, Loss: 6.1722, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 527/10000, Loss: 6.1659, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 528/10000, Loss: 6.1595, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 529/10000, Loss: 6.1532, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 530/10000, Loss: 6.1469, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 531/10000, Loss: 6.1406, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 532/10000, Loss: 6.1342, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 533/10000, Loss: 6.1279, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 534/10000, Loss: 6.1216, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 535/10000, Loss: 6.1152, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 536/10000, Loss: 6.1089, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 537/10000, Loss: 6.1026, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 538/10000, Loss: 6.0962, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 539/10000, Loss: 6.0899, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 540/10000, Loss: 6.0836, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 541/10000, Loss: 6.0773, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 542/10000, Loss: 6.0709, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 543/10000, Loss: 6.0646, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 544/10000, Loss: 6.0583, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 545/10000, Loss: 6.0520, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 546/10000, Loss: 6.0457, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 547/10000, Loss: 6.0394, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 548/10000, Loss: 6.0331, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 549/10000, Loss: 6.0268, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 550/10000, Loss: 6.0205, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 551/10000, Loss: 6.0142, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 552/10000, Loss: 6.0079, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 553/10000, Loss: 6.0017, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 554/10000, Loss: 5.9954, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 555/10000, Loss: 5.9891, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 556/10000, Loss: 5.9829, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 557/10000, Loss: 5.9766, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 558/10000, Loss: 5.9704, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 559/10000, Loss: 5.9641, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 560/10000, Loss: 5.9579, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 561/10000, Loss: 5.9517, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 562/10000, Loss: 5.9454, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 563/10000, Loss: 5.9392, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 564/10000, Loss: 5.9330, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 565/10000, Loss: 5.9268, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 566/10000, Loss: 5.9207, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 567/10000, Loss: 5.9145, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 568/10000, Loss: 5.9083, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 569/10000, Loss: 5.9021, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 570/10000, Loss: 5.8960, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 571/10000, Loss: 5.8898, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 572/10000, Loss: 5.8837, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 573/10000, Loss: 5.8776, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 574/10000, Loss: 5.8714, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 575/10000, Loss: 5.8653, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 576/10000, Loss: 5.8592, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 577/10000, Loss: 5.8531, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 578/10000, Loss: 5.8470, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 579/10000, Loss: 5.8410, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 580/10000, Loss: 5.8349, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 581/10000, Loss: 5.8288, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 582/10000, Loss: 5.8228, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 583/10000, Loss: 5.8167, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 584/10000, Loss: 5.8107, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 585/10000, Loss: 5.8047, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 586/10000, Loss: 5.7986, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 587/10000, Loss: 5.7926, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 588/10000, Loss: 5.7866, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 589/10000, Loss: 5.7806, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 590/10000, Loss: 5.7746, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 591/10000, Loss: 5.7686, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 592/10000, Loss: 5.7626, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 593/10000, Loss: 5.7567, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 594/10000, Loss: 5.7507, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 595/10000, Loss: 5.7447, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 596/10000, Loss: 5.7388, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 597/10000, Loss: 5.7328, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 598/10000, Loss: 5.7269, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 599/10000, Loss: 5.7210, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 600/10000, Loss: 5.7150, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 601/10000, Loss: 5.7091, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 602/10000, Loss: 5.7032, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 603/10000, Loss: 5.6972, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 604/10000, Loss: 5.6913, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 605/10000, Loss: 5.6854, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 606/10000, Loss: 5.6795, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 607/10000, Loss: 5.6736, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 608/10000, Loss: 5.6677, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 609/10000, Loss: 5.6618, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 610/10000, Loss: 5.6559, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 611/10000, Loss: 5.6500, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 612/10000, Loss: 5.6441, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 613/10000, Loss: 5.6382, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 614/10000, Loss: 5.6324, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 615/10000, Loss: 5.6265, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 616/10000, Loss: 5.6206, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 617/10000, Loss: 5.6147, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 618/10000, Loss: 5.6088, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 619/10000, Loss: 5.6030, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 620/10000, Loss: 5.5971, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 621/10000, Loss: 5.5912, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 622/10000, Loss: 5.5853, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 623/10000, Loss: 5.5795, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 624/10000, Loss: 5.5736, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 625/10000, Loss: 5.5677, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 626/10000, Loss: 5.5618, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 627/10000, Loss: 5.5560, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 628/10000, Loss: 5.5501, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 629/10000, Loss: 5.5442, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 630/10000, Loss: 5.5383, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 631/10000, Loss: 5.5325, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 632/10000, Loss: 5.5266, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 633/10000, Loss: 5.5207, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 634/10000, Loss: 5.5149, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 635/10000, Loss: 5.5090, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 636/10000, Loss: 5.5031, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 637/10000, Loss: 5.4972, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 638/10000, Loss: 5.4914, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 639/10000, Loss: 5.4855, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 640/10000, Loss: 5.4796, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 641/10000, Loss: 5.4737, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 642/10000, Loss: 5.4679, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 643/10000, Loss: 5.4620, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 644/10000, Loss: 5.4561, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 645/10000, Loss: 5.4502, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 646/10000, Loss: 5.4443, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 647/10000, Loss: 5.4385, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 648/10000, Loss: 5.4326, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 649/10000, Loss: 5.4267, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 650/10000, Loss: 5.4208, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 651/10000, Loss: 5.4149, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 652/10000, Loss: 5.4091, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 653/10000, Loss: 5.4032, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 654/10000, Loss: 5.3973, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 655/10000, Loss: 5.3914, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 656/10000, Loss: 5.3855, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 657/10000, Loss: 5.3796, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 658/10000, Loss: 5.3738, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 659/10000, Loss: 5.3679, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 660/10000, Loss: 5.3620, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 661/10000, Loss: 5.3561, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 662/10000, Loss: 5.3502, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 663/10000, Loss: 5.3443, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 664/10000, Loss: 5.3384, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 665/10000, Loss: 5.3326, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 666/10000, Loss: 5.3267, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 667/10000, Loss: 5.3208, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 668/10000, Loss: 5.3149, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 669/10000, Loss: 5.3090, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 670/10000, Loss: 5.3031, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 671/10000, Loss: 5.2973, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 672/10000, Loss: 5.2914, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 673/10000, Loss: 5.2855, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 674/10000, Loss: 5.2796, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 675/10000, Loss: 5.2737, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 676/10000, Loss: 5.2679, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 677/10000, Loss: 5.2620, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 678/10000, Loss: 5.2561, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 679/10000, Loss: 5.2502, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 680/10000, Loss: 5.2443, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 681/10000, Loss: 5.2385, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 682/10000, Loss: 5.2326, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 683/10000, Loss: 5.2267, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 684/10000, Loss: 5.2209, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 685/10000, Loss: 5.2150, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 686/10000, Loss: 5.2091, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 687/10000, Loss: 5.2033, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 688/10000, Loss: 5.1974, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 689/10000, Loss: 5.1915, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 690/10000, Loss: 5.1857, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 691/10000, Loss: 5.1798, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 692/10000, Loss: 5.1740, Accuracy: 0.4103, Learning Rate: 0.000100\n",
      "Epoch 693/10000, Loss: 5.1681, Accuracy: 0.4103, Learning Rate: 0.000100\n",
      "Epoch 694/10000, Loss: 5.1622, Accuracy: 0.4103, Learning Rate: 0.000100\n",
      "Epoch 695/10000, Loss: 5.1564, Accuracy: 0.4103, Learning Rate: 0.000100\n",
      "Epoch 696/10000, Loss: 5.1505, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 697/10000, Loss: 5.1447, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 698/10000, Loss: 5.1388, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 699/10000, Loss: 5.1330, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 700/10000, Loss: 5.1272, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 701/10000, Loss: 5.1213, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 702/10000, Loss: 5.1155, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 703/10000, Loss: 5.1097, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 704/10000, Loss: 5.1038, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 705/10000, Loss: 5.0980, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 706/10000, Loss: 5.0922, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 707/10000, Loss: 5.0863, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 708/10000, Loss: 5.0805, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 709/10000, Loss: 5.0747, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 710/10000, Loss: 5.0689, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 711/10000, Loss: 5.0631, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 712/10000, Loss: 5.0572, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 713/10000, Loss: 5.0514, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 714/10000, Loss: 5.0456, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 715/10000, Loss: 5.0398, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 716/10000, Loss: 5.0340, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 717/10000, Loss: 5.0282, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 718/10000, Loss: 5.0224, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 719/10000, Loss: 5.0166, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 720/10000, Loss: 5.0108, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 721/10000, Loss: 5.0050, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 722/10000, Loss: 4.9992, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 723/10000, Loss: 4.9935, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 724/10000, Loss: 4.9877, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 725/10000, Loss: 4.9819, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 726/10000, Loss: 4.9761, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 727/10000, Loss: 4.9703, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 728/10000, Loss: 4.9646, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 729/10000, Loss: 4.9588, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 730/10000, Loss: 4.9530, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 731/10000, Loss: 4.9473, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 732/10000, Loss: 4.9415, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 733/10000, Loss: 4.9358, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 734/10000, Loss: 4.9300, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 735/10000, Loss: 4.9242, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 736/10000, Loss: 4.9185, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 737/10000, Loss: 4.9127, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 738/10000, Loss: 4.9070, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 739/10000, Loss: 4.9013, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 740/10000, Loss: 4.8955, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 741/10000, Loss: 4.8898, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 742/10000, Loss: 4.8840, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 743/10000, Loss: 4.8783, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 744/10000, Loss: 4.8726, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 745/10000, Loss: 4.8668, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 746/10000, Loss: 4.8611, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 747/10000, Loss: 4.8554, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 748/10000, Loss: 4.8497, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 749/10000, Loss: 4.8440, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 750/10000, Loss: 4.8382, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 751/10000, Loss: 4.8325, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 752/10000, Loss: 4.8268, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 753/10000, Loss: 4.8211, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 754/10000, Loss: 4.8154, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 755/10000, Loss: 4.8097, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 756/10000, Loss: 4.8040, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 757/10000, Loss: 4.7983, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 758/10000, Loss: 4.7926, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 759/10000, Loss: 4.7870, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 760/10000, Loss: 4.7813, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 761/10000, Loss: 4.7756, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 762/10000, Loss: 4.7699, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 763/10000, Loss: 4.7642, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 764/10000, Loss: 4.7586, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 765/10000, Loss: 4.7529, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 766/10000, Loss: 4.7472, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 767/10000, Loss: 4.7416, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 768/10000, Loss: 4.7359, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 769/10000, Loss: 4.7303, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 770/10000, Loss: 4.7246, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 771/10000, Loss: 4.7190, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 772/10000, Loss: 4.7133, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 773/10000, Loss: 4.7077, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 774/10000, Loss: 4.7021, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 775/10000, Loss: 4.6964, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 776/10000, Loss: 4.6908, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 777/10000, Loss: 4.6852, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 778/10000, Loss: 4.6796, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 779/10000, Loss: 4.6740, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 780/10000, Loss: 4.6683, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 781/10000, Loss: 4.6627, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 782/10000, Loss: 4.6571, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 783/10000, Loss: 4.6516, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 784/10000, Loss: 4.6460, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 785/10000, Loss: 4.6404, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 786/10000, Loss: 4.6348, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 787/10000, Loss: 4.6292, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 788/10000, Loss: 4.6237, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 789/10000, Loss: 4.6181, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 790/10000, Loss: 4.6126, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 791/10000, Loss: 4.6070, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 792/10000, Loss: 4.6015, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 793/10000, Loss: 4.5960, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 794/10000, Loss: 4.5904, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 795/10000, Loss: 4.5849, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 796/10000, Loss: 4.5794, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 797/10000, Loss: 4.5739, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 798/10000, Loss: 4.5684, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 799/10000, Loss: 4.5629, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 800/10000, Loss: 4.5575, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 801/10000, Loss: 4.5520, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 802/10000, Loss: 4.5465, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 803/10000, Loss: 4.5411, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 804/10000, Loss: 4.5356, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 805/10000, Loss: 4.5302, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 806/10000, Loss: 4.5248, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 807/10000, Loss: 4.5193, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 808/10000, Loss: 4.5139, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 809/10000, Loss: 4.5085, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 810/10000, Loss: 4.5031, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 811/10000, Loss: 4.4978, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 812/10000, Loss: 4.4924, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 813/10000, Loss: 4.4870, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 814/10000, Loss: 4.4817, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 815/10000, Loss: 4.4763, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 816/10000, Loss: 4.4710, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 817/10000, Loss: 4.4657, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 818/10000, Loss: 4.4604, Accuracy: 0.4231, Learning Rate: 0.000100\n",
      "Epoch 819/10000, Loss: 4.4551, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 820/10000, Loss: 4.4498, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 821/10000, Loss: 4.4445, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 822/10000, Loss: 4.4393, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 823/10000, Loss: 4.4340, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 824/10000, Loss: 4.4288, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 825/10000, Loss: 4.4236, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 826/10000, Loss: 4.4183, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 827/10000, Loss: 4.4131, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 828/10000, Loss: 4.4080, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 829/10000, Loss: 4.4028, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 830/10000, Loss: 4.3976, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 831/10000, Loss: 4.3925, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 832/10000, Loss: 4.3873, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 833/10000, Loss: 4.3822, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 834/10000, Loss: 4.3771, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 835/10000, Loss: 4.3720, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 836/10000, Loss: 4.3669, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 837/10000, Loss: 4.3618, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 838/10000, Loss: 4.3567, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 839/10000, Loss: 4.3517, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 840/10000, Loss: 4.3466, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 841/10000, Loss: 4.3416, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 842/10000, Loss: 4.3366, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 843/10000, Loss: 4.3316, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 844/10000, Loss: 4.3266, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 845/10000, Loss: 4.3216, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 846/10000, Loss: 4.3167, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 847/10000, Loss: 4.3117, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 848/10000, Loss: 4.3068, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 849/10000, Loss: 4.3018, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 850/10000, Loss: 4.2969, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 851/10000, Loss: 4.2920, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 852/10000, Loss: 4.2871, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 853/10000, Loss: 4.2823, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 854/10000, Loss: 4.2774, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 855/10000, Loss: 4.2725, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 856/10000, Loss: 4.2677, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 857/10000, Loss: 4.2629, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 858/10000, Loss: 4.2580, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 859/10000, Loss: 4.2532, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 860/10000, Loss: 4.2484, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 861/10000, Loss: 4.2437, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 862/10000, Loss: 4.2389, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 863/10000, Loss: 4.2341, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 864/10000, Loss: 4.2294, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 865/10000, Loss: 4.2247, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 866/10000, Loss: 4.2199, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 867/10000, Loss: 4.2152, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 868/10000, Loss: 4.2105, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 869/10000, Loss: 4.2058, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 870/10000, Loss: 4.2011, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 871/10000, Loss: 4.1965, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 872/10000, Loss: 4.1918, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 873/10000, Loss: 4.1872, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 874/10000, Loss: 4.1825, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 875/10000, Loss: 4.1779, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 876/10000, Loss: 4.1733, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 877/10000, Loss: 4.1687, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 878/10000, Loss: 4.1641, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 879/10000, Loss: 4.1595, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 880/10000, Loss: 4.1549, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 881/10000, Loss: 4.1503, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 882/10000, Loss: 4.1458, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 883/10000, Loss: 4.1412, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 884/10000, Loss: 4.1367, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 885/10000, Loss: 4.1321, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 886/10000, Loss: 4.1276, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 887/10000, Loss: 4.1231, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 888/10000, Loss: 4.1186, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 889/10000, Loss: 4.1141, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 890/10000, Loss: 4.1096, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 891/10000, Loss: 4.1052, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 892/10000, Loss: 4.1007, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 893/10000, Loss: 4.0962, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 894/10000, Loss: 4.0918, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 895/10000, Loss: 4.0873, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 896/10000, Loss: 4.0829, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 897/10000, Loss: 4.0785, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 898/10000, Loss: 4.0741, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 899/10000, Loss: 4.0697, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 900/10000, Loss: 4.0653, Accuracy: 0.4359, Learning Rate: 0.000100\n",
      "Epoch 901/10000, Loss: 4.0609, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 902/10000, Loss: 4.0565, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 903/10000, Loss: 4.0521, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 904/10000, Loss: 4.0477, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 905/10000, Loss: 4.0434, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 906/10000, Loss: 4.0390, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 907/10000, Loss: 4.0347, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 908/10000, Loss: 4.0303, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 909/10000, Loss: 4.0260, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 910/10000, Loss: 4.0217, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 911/10000, Loss: 4.0174, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 912/10000, Loss: 4.0130, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 913/10000, Loss: 4.0087, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 914/10000, Loss: 4.0044, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 915/10000, Loss: 4.0002, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 916/10000, Loss: 3.9959, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 917/10000, Loss: 3.9916, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 918/10000, Loss: 3.9873, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 919/10000, Loss: 3.9831, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 920/10000, Loss: 3.9788, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 921/10000, Loss: 3.9746, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 922/10000, Loss: 3.9703, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 923/10000, Loss: 3.9661, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 924/10000, Loss: 3.9619, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 925/10000, Loss: 3.9577, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 926/10000, Loss: 3.9534, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 927/10000, Loss: 3.9492, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 928/10000, Loss: 3.9450, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 929/10000, Loss: 3.9408, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 930/10000, Loss: 3.9366, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 931/10000, Loss: 3.9325, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 932/10000, Loss: 3.9283, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 933/10000, Loss: 3.9241, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 934/10000, Loss: 3.9200, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 935/10000, Loss: 3.9158, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 936/10000, Loss: 3.9116, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 937/10000, Loss: 3.9075, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 938/10000, Loss: 3.9034, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 939/10000, Loss: 3.8992, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 940/10000, Loss: 3.8951, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 941/10000, Loss: 3.8910, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 942/10000, Loss: 3.8869, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 943/10000, Loss: 3.8827, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 944/10000, Loss: 3.8786, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 945/10000, Loss: 3.8745, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 946/10000, Loss: 3.8705, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 947/10000, Loss: 3.8664, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 948/10000, Loss: 3.8623, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 949/10000, Loss: 3.8582, Accuracy: 0.4487, Learning Rate: 0.000100\n",
      "Epoch 950/10000, Loss: 3.8541, Accuracy: 0.4615, Learning Rate: 0.000100\n",
      "Epoch 951/10000, Loss: 3.8501, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 952/10000, Loss: 3.8460, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 953/10000, Loss: 3.8420, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 954/10000, Loss: 3.8379, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 955/10000, Loss: 3.8339, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 956/10000, Loss: 3.8298, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 957/10000, Loss: 3.8258, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 958/10000, Loss: 3.8218, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 959/10000, Loss: 3.8178, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 960/10000, Loss: 3.8137, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 961/10000, Loss: 3.8097, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 962/10000, Loss: 3.8057, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 963/10000, Loss: 3.8017, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 964/10000, Loss: 3.7977, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 965/10000, Loss: 3.7937, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 966/10000, Loss: 3.7898, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 967/10000, Loss: 3.7858, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 968/10000, Loss: 3.7818, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 969/10000, Loss: 3.7778, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 970/10000, Loss: 3.7739, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 971/10000, Loss: 3.7699, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 972/10000, Loss: 3.7660, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 973/10000, Loss: 3.7620, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 974/10000, Loss: 3.7581, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 975/10000, Loss: 3.7541, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 976/10000, Loss: 3.7502, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 977/10000, Loss: 3.7463, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 978/10000, Loss: 3.7424, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 979/10000, Loss: 3.7385, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 980/10000, Loss: 3.7345, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 981/10000, Loss: 3.7306, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 982/10000, Loss: 3.7267, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 983/10000, Loss: 3.7229, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 984/10000, Loss: 3.7190, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 985/10000, Loss: 3.7151, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 986/10000, Loss: 3.7112, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 987/10000, Loss: 3.7073, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 988/10000, Loss: 3.7035, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 989/10000, Loss: 3.6996, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 990/10000, Loss: 3.6957, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 991/10000, Loss: 3.6919, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 992/10000, Loss: 3.6880, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 993/10000, Loss: 3.6842, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 994/10000, Loss: 3.6804, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 995/10000, Loss: 3.6765, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 996/10000, Loss: 3.6727, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 997/10000, Loss: 3.6689, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 998/10000, Loss: 3.6651, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 999/10000, Loss: 3.6613, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1000/10000, Loss: 3.6574, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1001/10000, Loss: 3.6536, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1002/10000, Loss: 3.6498, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1003/10000, Loss: 3.6461, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1004/10000, Loss: 3.6423, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1005/10000, Loss: 3.6385, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1006/10000, Loss: 3.6347, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1007/10000, Loss: 3.6309, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1008/10000, Loss: 3.6272, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1009/10000, Loss: 3.6234, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1010/10000, Loss: 3.6197, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1011/10000, Loss: 3.6159, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1012/10000, Loss: 3.6122, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1013/10000, Loss: 3.6084, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1014/10000, Loss: 3.6047, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1015/10000, Loss: 3.6010, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1016/10000, Loss: 3.5973, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1017/10000, Loss: 3.5935, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1018/10000, Loss: 3.5898, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1019/10000, Loss: 3.5861, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1020/10000, Loss: 3.5824, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1021/10000, Loss: 3.5787, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1022/10000, Loss: 3.5750, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1023/10000, Loss: 3.5714, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1024/10000, Loss: 3.5677, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1025/10000, Loss: 3.5640, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1026/10000, Loss: 3.5603, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1027/10000, Loss: 3.5567, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1028/10000, Loss: 3.5530, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1029/10000, Loss: 3.5494, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1030/10000, Loss: 3.5457, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1031/10000, Loss: 3.5421, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1032/10000, Loss: 3.5384, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1033/10000, Loss: 3.5348, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1034/10000, Loss: 3.5312, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1035/10000, Loss: 3.5275, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1036/10000, Loss: 3.5239, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1037/10000, Loss: 3.5203, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1038/10000, Loss: 3.5167, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1039/10000, Loss: 3.5131, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1040/10000, Loss: 3.5095, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1041/10000, Loss: 3.5059, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1042/10000, Loss: 3.5024, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1043/10000, Loss: 3.4988, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1044/10000, Loss: 3.4952, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1045/10000, Loss: 3.4916, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1046/10000, Loss: 3.4881, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1047/10000, Loss: 3.4845, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1048/10000, Loss: 3.4810, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1049/10000, Loss: 3.4774, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1050/10000, Loss: 3.4739, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1051/10000, Loss: 3.4704, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1052/10000, Loss: 3.4668, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1053/10000, Loss: 3.4633, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1054/10000, Loss: 3.4598, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1055/10000, Loss: 3.4563, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1056/10000, Loss: 3.4528, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1057/10000, Loss: 3.4493, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1058/10000, Loss: 3.4458, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1059/10000, Loss: 3.4423, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1060/10000, Loss: 3.4388, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1061/10000, Loss: 3.4354, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1062/10000, Loss: 3.4319, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1063/10000, Loss: 3.4284, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1064/10000, Loss: 3.4250, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1065/10000, Loss: 3.4215, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 1066/10000, Loss: 3.4181, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 1067/10000, Loss: 3.4146, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 1068/10000, Loss: 3.4112, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 1069/10000, Loss: 3.4078, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 1070/10000, Loss: 3.4044, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 1071/10000, Loss: 3.4009, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 1072/10000, Loss: 3.3975, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 1073/10000, Loss: 3.3941, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 1074/10000, Loss: 3.3907, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 1075/10000, Loss: 3.3873, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 1076/10000, Loss: 3.3839, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 1077/10000, Loss: 3.3806, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 1078/10000, Loss: 3.3772, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 1079/10000, Loss: 3.3738, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 1080/10000, Loss: 3.3705, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 1081/10000, Loss: 3.3671, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 1082/10000, Loss: 3.3638, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 1083/10000, Loss: 3.3604, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 1084/10000, Loss: 3.3571, Accuracy: 0.4744, Learning Rate: 0.000100\n",
      "Epoch 1085/10000, Loss: 3.3537, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1086/10000, Loss: 3.3504, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1087/10000, Loss: 3.3471, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1088/10000, Loss: 3.3438, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1089/10000, Loss: 3.3405, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1090/10000, Loss: 3.3372, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1091/10000, Loss: 3.3339, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1092/10000, Loss: 3.3306, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1093/10000, Loss: 3.3273, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1094/10000, Loss: 3.3240, Accuracy: 0.4872, Learning Rate: 0.000100\n",
      "Epoch 1095/10000, Loss: 3.3208, Accuracy: 0.5000, Learning Rate: 0.000100\n",
      "Epoch 1096/10000, Loss: 3.3175, Accuracy: 0.5128, Learning Rate: 0.000100\n",
      "Epoch 1097/10000, Loss: 3.3142, Accuracy: 0.5128, Learning Rate: 0.000100\n",
      "Epoch 1098/10000, Loss: 3.3110, Accuracy: 0.5128, Learning Rate: 0.000100\n",
      "Epoch 1099/10000, Loss: 3.3077, Accuracy: 0.5128, Learning Rate: 0.000100\n",
      "Epoch 1100/10000, Loss: 3.3045, Accuracy: 0.5128, Learning Rate: 0.000100\n",
      "Epoch 1101/10000, Loss: 3.3013, Accuracy: 0.5128, Learning Rate: 0.000100\n",
      "Epoch 1102/10000, Loss: 3.2980, Accuracy: 0.5128, Learning Rate: 0.000100\n",
      "Epoch 1103/10000, Loss: 3.2948, Accuracy: 0.5128, Learning Rate: 0.000100\n",
      "Epoch 1104/10000, Loss: 3.2916, Accuracy: 0.5128, Learning Rate: 0.000100\n",
      "Epoch 1105/10000, Loss: 3.2884, Accuracy: 0.5128, Learning Rate: 0.000100\n",
      "Epoch 1106/10000, Loss: 3.2852, Accuracy: 0.5128, Learning Rate: 0.000100\n",
      "Epoch 1107/10000, Loss: 3.2820, Accuracy: 0.5128, Learning Rate: 0.000100\n",
      "Epoch 1108/10000, Loss: 3.2788, Accuracy: 0.5128, Learning Rate: 0.000100\n",
      "Epoch 1109/10000, Loss: 3.2756, Accuracy: 0.5128, Learning Rate: 0.000100\n",
      "Epoch 1110/10000, Loss: 3.2724, Accuracy: 0.5128, Learning Rate: 0.000100\n",
      "Epoch 1111/10000, Loss: 3.2693, Accuracy: 0.5128, Learning Rate: 0.000100\n",
      "Epoch 1112/10000, Loss: 3.2661, Accuracy: 0.5128, Learning Rate: 0.000100\n",
      "Epoch 1113/10000, Loss: 3.2629, Accuracy: 0.5128, Learning Rate: 0.000100\n",
      "Epoch 1114/10000, Loss: 3.2598, Accuracy: 0.5128, Learning Rate: 0.000100\n",
      "Epoch 1115/10000, Loss: 3.2566, Accuracy: 0.5128, Learning Rate: 0.000100\n",
      "Epoch 1116/10000, Loss: 3.2535, Accuracy: 0.5128, Learning Rate: 0.000100\n",
      "Epoch 1117/10000, Loss: 3.2504, Accuracy: 0.5128, Learning Rate: 0.000100\n",
      "Epoch 1118/10000, Loss: 3.2472, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1119/10000, Loss: 3.2441, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1120/10000, Loss: 3.2410, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1121/10000, Loss: 3.2379, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1122/10000, Loss: 3.2348, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1123/10000, Loss: 3.2317, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1124/10000, Loss: 3.2286, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1125/10000, Loss: 3.2255, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1126/10000, Loss: 3.2224, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1127/10000, Loss: 3.2194, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1128/10000, Loss: 3.2163, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1129/10000, Loss: 3.2132, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1130/10000, Loss: 3.2102, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1131/10000, Loss: 3.2071, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1132/10000, Loss: 3.2041, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1133/10000, Loss: 3.2011, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1134/10000, Loss: 3.1980, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1135/10000, Loss: 3.1950, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1136/10000, Loss: 3.1920, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1137/10000, Loss: 3.1890, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1138/10000, Loss: 3.1860, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1139/10000, Loss: 3.1830, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1140/10000, Loss: 3.1800, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1141/10000, Loss: 3.1770, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1142/10000, Loss: 3.1740, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1143/10000, Loss: 3.1711, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1144/10000, Loss: 3.1681, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1145/10000, Loss: 3.1651, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1146/10000, Loss: 3.1622, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1147/10000, Loss: 3.1592, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1148/10000, Loss: 3.1563, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1149/10000, Loss: 3.1534, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1150/10000, Loss: 3.1504, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1151/10000, Loss: 3.1475, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1152/10000, Loss: 3.1446, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1153/10000, Loss: 3.1417, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1154/10000, Loss: 3.1388, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1155/10000, Loss: 3.1359, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1156/10000, Loss: 3.1330, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1157/10000, Loss: 3.1301, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1158/10000, Loss: 3.1272, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1159/10000, Loss: 3.1243, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1160/10000, Loss: 3.1215, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1161/10000, Loss: 3.1186, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1162/10000, Loss: 3.1157, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1163/10000, Loss: 3.1129, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1164/10000, Loss: 3.1101, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1165/10000, Loss: 3.1072, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1166/10000, Loss: 3.1044, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1167/10000, Loss: 3.1016, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1168/10000, Loss: 3.0987, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1169/10000, Loss: 3.0959, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1170/10000, Loss: 3.0931, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1171/10000, Loss: 3.0903, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1172/10000, Loss: 3.0875, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1173/10000, Loss: 3.0847, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1174/10000, Loss: 3.0819, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1175/10000, Loss: 3.0791, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1176/10000, Loss: 3.0764, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1177/10000, Loss: 3.0736, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1178/10000, Loss: 3.0708, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1179/10000, Loss: 3.0681, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1180/10000, Loss: 3.0653, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1181/10000, Loss: 3.0626, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1182/10000, Loss: 3.0598, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1183/10000, Loss: 3.0571, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1184/10000, Loss: 3.0544, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1185/10000, Loss: 3.0517, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1186/10000, Loss: 3.0489, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1187/10000, Loss: 3.0462, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1188/10000, Loss: 3.0435, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1189/10000, Loss: 3.0408, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1190/10000, Loss: 3.0381, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1191/10000, Loss: 3.0354, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1192/10000, Loss: 3.0328, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1193/10000, Loss: 3.0301, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1194/10000, Loss: 3.0274, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1195/10000, Loss: 3.0247, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1196/10000, Loss: 3.0221, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1197/10000, Loss: 3.0194, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1198/10000, Loss: 3.0168, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1199/10000, Loss: 3.0141, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1200/10000, Loss: 3.0115, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1201/10000, Loss: 3.0088, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1202/10000, Loss: 3.0062, Accuracy: 0.5256, Learning Rate: 0.000100\n",
      "Epoch 1203/10000, Loss: 3.0036, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1204/10000, Loss: 3.0010, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1205/10000, Loss: 2.9983, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1206/10000, Loss: 2.9957, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1207/10000, Loss: 2.9931, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1208/10000, Loss: 2.9905, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1209/10000, Loss: 2.9879, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1210/10000, Loss: 2.9853, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1211/10000, Loss: 2.9828, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1212/10000, Loss: 2.9802, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1213/10000, Loss: 2.9776, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1214/10000, Loss: 2.9750, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1215/10000, Loss: 2.9725, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1216/10000, Loss: 2.9699, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1217/10000, Loss: 2.9674, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1218/10000, Loss: 2.9648, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1219/10000, Loss: 2.9623, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1220/10000, Loss: 2.9597, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1221/10000, Loss: 2.9572, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1222/10000, Loss: 2.9547, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1223/10000, Loss: 2.9521, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1224/10000, Loss: 2.9496, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1225/10000, Loss: 2.9471, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1226/10000, Loss: 2.9446, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1227/10000, Loss: 2.9421, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1228/10000, Loss: 2.9396, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1229/10000, Loss: 2.9371, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1230/10000, Loss: 2.9346, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1231/10000, Loss: 2.9321, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1232/10000, Loss: 2.9296, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1233/10000, Loss: 2.9272, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1234/10000, Loss: 2.9247, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1235/10000, Loss: 2.9222, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1236/10000, Loss: 2.9198, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1237/10000, Loss: 2.9173, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1238/10000, Loss: 2.9148, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1239/10000, Loss: 2.9124, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1240/10000, Loss: 2.9100, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1241/10000, Loss: 2.9075, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1242/10000, Loss: 2.9051, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1243/10000, Loss: 2.9026, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1244/10000, Loss: 2.9002, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1245/10000, Loss: 2.8978, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1246/10000, Loss: 2.8954, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1247/10000, Loss: 2.8930, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1248/10000, Loss: 2.8905, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1249/10000, Loss: 2.8881, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1250/10000, Loss: 2.8857, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1251/10000, Loss: 2.8833, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1252/10000, Loss: 2.8810, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1253/10000, Loss: 2.8786, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1254/10000, Loss: 2.8762, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1255/10000, Loss: 2.8738, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1256/10000, Loss: 2.8714, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1257/10000, Loss: 2.8690, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1258/10000, Loss: 2.8667, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1259/10000, Loss: 2.8643, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1260/10000, Loss: 2.8620, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1261/10000, Loss: 2.8596, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1262/10000, Loss: 2.8572, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1263/10000, Loss: 2.8549, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1264/10000, Loss: 2.8526, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1265/10000, Loss: 2.8502, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1266/10000, Loss: 2.8479, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1267/10000, Loss: 2.8455, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1268/10000, Loss: 2.8432, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1269/10000, Loss: 2.8409, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1270/10000, Loss: 2.8386, Accuracy: 0.5385, Learning Rate: 0.000100\n",
      "Epoch 1271/10000, Loss: 2.8363, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1272/10000, Loss: 2.8339, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1273/10000, Loss: 2.8316, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1274/10000, Loss: 2.8293, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1275/10000, Loss: 2.8270, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1276/10000, Loss: 2.8247, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1277/10000, Loss: 2.8224, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1278/10000, Loss: 2.8201, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1279/10000, Loss: 2.8179, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1280/10000, Loss: 2.8156, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1281/10000, Loss: 2.8133, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1282/10000, Loss: 2.8110, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1283/10000, Loss: 2.8087, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1284/10000, Loss: 2.8065, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1285/10000, Loss: 2.8042, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1286/10000, Loss: 2.8019, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1287/10000, Loss: 2.7997, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1288/10000, Loss: 2.7974, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1289/10000, Loss: 2.7952, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1290/10000, Loss: 2.7929, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1291/10000, Loss: 2.7907, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1292/10000, Loss: 2.7884, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1293/10000, Loss: 2.7862, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1294/10000, Loss: 2.7840, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1295/10000, Loss: 2.7817, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1296/10000, Loss: 2.7795, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1297/10000, Loss: 2.7773, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1298/10000, Loss: 2.7751, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1299/10000, Loss: 2.7728, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1300/10000, Loss: 2.7706, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1301/10000, Loss: 2.7684, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1302/10000, Loss: 2.7662, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1303/10000, Loss: 2.7640, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1304/10000, Loss: 2.7618, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1305/10000, Loss: 2.7596, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1306/10000, Loss: 2.7574, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1307/10000, Loss: 2.7552, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1308/10000, Loss: 2.7530, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1309/10000, Loss: 2.7508, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1310/10000, Loss: 2.7487, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1311/10000, Loss: 2.7465, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1312/10000, Loss: 2.7443, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1313/10000, Loss: 2.7421, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1314/10000, Loss: 2.7399, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1315/10000, Loss: 2.7378, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1316/10000, Loss: 2.7356, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1317/10000, Loss: 2.7334, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1318/10000, Loss: 2.7313, Accuracy: 0.5641, Learning Rate: 0.000100\n",
      "Epoch 1319/10000, Loss: 2.7291, Accuracy: 0.5641, Learning Rate: 0.000100\n",
      "Epoch 1320/10000, Loss: 2.7270, Accuracy: 0.5641, Learning Rate: 0.000100\n",
      "Epoch 1321/10000, Loss: 2.7248, Accuracy: 0.5641, Learning Rate: 0.000100\n",
      "Epoch 1322/10000, Loss: 2.7227, Accuracy: 0.5641, Learning Rate: 0.000100\n",
      "Epoch 1323/10000, Loss: 2.7205, Accuracy: 0.5641, Learning Rate: 0.000100\n",
      "Epoch 1324/10000, Loss: 2.7184, Accuracy: 0.5641, Learning Rate: 0.000100\n",
      "Epoch 1325/10000, Loss: 2.7162, Accuracy: 0.5641, Learning Rate: 0.000100\n",
      "Epoch 1326/10000, Loss: 2.7141, Accuracy: 0.5641, Learning Rate: 0.000100\n",
      "Epoch 1327/10000, Loss: 2.7120, Accuracy: 0.5641, Learning Rate: 0.000100\n",
      "Epoch 1328/10000, Loss: 2.7098, Accuracy: 0.5641, Learning Rate: 0.000100\n",
      "Epoch 1329/10000, Loss: 2.7077, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1330/10000, Loss: 2.7056, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1331/10000, Loss: 2.7035, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1332/10000, Loss: 2.7013, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1333/10000, Loss: 2.6992, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1334/10000, Loss: 2.6971, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1335/10000, Loss: 2.6950, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1336/10000, Loss: 2.6929, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1337/10000, Loss: 2.6908, Accuracy: 0.5513, Learning Rate: 0.000100\n",
      "Epoch 1338/10000, Loss: 2.6887, Accuracy: 0.5641, Learning Rate: 0.000100\n",
      "Epoch 1339/10000, Loss: 2.6866, Accuracy: 0.5641, Learning Rate: 0.000100\n",
      "Epoch 1340/10000, Loss: 2.6845, Accuracy: 0.5641, Learning Rate: 0.000100\n",
      "Epoch 1341/10000, Loss: 2.6824, Accuracy: 0.5641, Learning Rate: 0.000100\n",
      "Epoch 1342/10000, Loss: 2.6803, Accuracy: 0.5641, Learning Rate: 0.000100\n",
      "Epoch 1343/10000, Loss: 2.6782, Accuracy: 0.5641, Learning Rate: 0.000100\n",
      "Epoch 1344/10000, Loss: 2.6761, Accuracy: 0.5641, Learning Rate: 0.000100\n",
      "Epoch 1345/10000, Loss: 2.6740, Accuracy: 0.5641, Learning Rate: 0.000100\n",
      "Epoch 1346/10000, Loss: 2.6719, Accuracy: 0.5641, Learning Rate: 0.000100\n",
      "Epoch 1347/10000, Loss: 2.6698, Accuracy: 0.5641, Learning Rate: 0.000100\n",
      "Epoch 1348/10000, Loss: 2.6677, Accuracy: 0.5641, Learning Rate: 0.000100\n",
      "Epoch 1349/10000, Loss: 2.6656, Accuracy: 0.5641, Learning Rate: 0.000100\n",
      "Epoch 1350/10000, Loss: 2.6636, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1351/10000, Loss: 2.6615, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1352/10000, Loss: 2.6594, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1353/10000, Loss: 2.6573, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1354/10000, Loss: 2.6553, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1355/10000, Loss: 2.6532, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1356/10000, Loss: 2.6511, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1357/10000, Loss: 2.6491, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1358/10000, Loss: 2.6470, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1359/10000, Loss: 2.6450, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1360/10000, Loss: 2.6429, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1361/10000, Loss: 2.6409, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1362/10000, Loss: 2.6388, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1363/10000, Loss: 2.6368, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1364/10000, Loss: 2.6347, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1365/10000, Loss: 2.6327, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1366/10000, Loss: 2.6306, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1367/10000, Loss: 2.6286, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1368/10000, Loss: 2.6265, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1369/10000, Loss: 2.6245, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1370/10000, Loss: 2.6225, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1371/10000, Loss: 2.6204, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1372/10000, Loss: 2.6184, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1373/10000, Loss: 2.6164, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1374/10000, Loss: 2.6143, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1375/10000, Loss: 2.6123, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1376/10000, Loss: 2.6103, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1377/10000, Loss: 2.6083, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1378/10000, Loss: 2.6063, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1379/10000, Loss: 2.6042, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1380/10000, Loss: 2.6022, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1381/10000, Loss: 2.6002, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1382/10000, Loss: 2.5982, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1383/10000, Loss: 2.5962, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1384/10000, Loss: 2.5942, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1385/10000, Loss: 2.5922, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1386/10000, Loss: 2.5902, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1387/10000, Loss: 2.5881, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1388/10000, Loss: 2.5861, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1389/10000, Loss: 2.5841, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1390/10000, Loss: 2.5821, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1391/10000, Loss: 2.5801, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1392/10000, Loss: 2.5782, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1393/10000, Loss: 2.5762, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1394/10000, Loss: 2.5742, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1395/10000, Loss: 2.5722, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1396/10000, Loss: 2.5702, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1397/10000, Loss: 2.5682, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1398/10000, Loss: 2.5662, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1399/10000, Loss: 2.5642, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1400/10000, Loss: 2.5622, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1401/10000, Loss: 2.5603, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1402/10000, Loss: 2.5583, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1403/10000, Loss: 2.5563, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1404/10000, Loss: 2.5543, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1405/10000, Loss: 2.5524, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1406/10000, Loss: 2.5504, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1407/10000, Loss: 2.5484, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1408/10000, Loss: 2.5464, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1409/10000, Loss: 2.5445, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1410/10000, Loss: 2.5425, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1411/10000, Loss: 2.5405, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1412/10000, Loss: 2.5386, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1413/10000, Loss: 2.5366, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1414/10000, Loss: 2.5346, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1415/10000, Loss: 2.5327, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1416/10000, Loss: 2.5307, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1417/10000, Loss: 2.5288, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1418/10000, Loss: 2.5268, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1419/10000, Loss: 2.5249, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1420/10000, Loss: 2.5229, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1421/10000, Loss: 2.5209, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1422/10000, Loss: 2.5190, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1423/10000, Loss: 2.5171, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1424/10000, Loss: 2.5151, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1425/10000, Loss: 2.5132, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1426/10000, Loss: 2.5112, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1427/10000, Loss: 2.5093, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1428/10000, Loss: 2.5073, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1429/10000, Loss: 2.5054, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1430/10000, Loss: 2.5035, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1431/10000, Loss: 2.5015, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1432/10000, Loss: 2.4996, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1433/10000, Loss: 2.4976, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1434/10000, Loss: 2.4957, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1435/10000, Loss: 2.4938, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1436/10000, Loss: 2.4918, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1437/10000, Loss: 2.4899, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1438/10000, Loss: 2.4880, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1439/10000, Loss: 2.4861, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1440/10000, Loss: 2.4841, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1441/10000, Loss: 2.4822, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1442/10000, Loss: 2.4803, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1443/10000, Loss: 2.4784, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1444/10000, Loss: 2.4765, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1445/10000, Loss: 2.4745, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1446/10000, Loss: 2.4726, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1447/10000, Loss: 2.4707, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1448/10000, Loss: 2.4688, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1449/10000, Loss: 2.4669, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1450/10000, Loss: 2.4650, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1451/10000, Loss: 2.4631, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1452/10000, Loss: 2.4612, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1453/10000, Loss: 2.4593, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1454/10000, Loss: 2.4574, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1455/10000, Loss: 2.4555, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1456/10000, Loss: 2.4535, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1457/10000, Loss: 2.4516, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1458/10000, Loss: 2.4498, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1459/10000, Loss: 2.4479, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1460/10000, Loss: 2.4460, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1461/10000, Loss: 2.4441, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1462/10000, Loss: 2.4422, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1463/10000, Loss: 2.4403, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1464/10000, Loss: 2.4384, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1465/10000, Loss: 2.4365, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1466/10000, Loss: 2.4346, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1467/10000, Loss: 2.4327, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1468/10000, Loss: 2.4309, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1469/10000, Loss: 2.4290, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1470/10000, Loss: 2.4271, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1471/10000, Loss: 2.4252, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1472/10000, Loss: 2.4233, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1473/10000, Loss: 2.4215, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1474/10000, Loss: 2.4196, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1475/10000, Loss: 2.4177, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1476/10000, Loss: 2.4158, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1477/10000, Loss: 2.4140, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1478/10000, Loss: 2.4121, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1479/10000, Loss: 2.4102, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1480/10000, Loss: 2.4084, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1481/10000, Loss: 2.4065, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1482/10000, Loss: 2.4047, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1483/10000, Loss: 2.4028, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1484/10000, Loss: 2.4009, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1485/10000, Loss: 2.3991, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1486/10000, Loss: 2.3972, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1487/10000, Loss: 2.3954, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1488/10000, Loss: 2.3935, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1489/10000, Loss: 2.3917, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1490/10000, Loss: 2.3898, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1491/10000, Loss: 2.3880, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1492/10000, Loss: 2.3861, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1493/10000, Loss: 2.3843, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1494/10000, Loss: 2.3825, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1495/10000, Loss: 2.3806, Accuracy: 0.5769, Learning Rate: 0.000100\n",
      "Epoch 1496/10000, Loss: 2.3788, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1497/10000, Loss: 2.3770, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1498/10000, Loss: 2.3751, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1499/10000, Loss: 2.3733, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1500/10000, Loss: 2.3715, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1501/10000, Loss: 2.3696, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1502/10000, Loss: 2.3678, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1503/10000, Loss: 2.3660, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1504/10000, Loss: 2.3642, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1505/10000, Loss: 2.3623, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1506/10000, Loss: 2.3605, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1507/10000, Loss: 2.3587, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1508/10000, Loss: 2.3569, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1509/10000, Loss: 2.3551, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1510/10000, Loss: 2.3533, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1511/10000, Loss: 2.3515, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1512/10000, Loss: 2.3497, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1513/10000, Loss: 2.3479, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1514/10000, Loss: 2.3461, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1515/10000, Loss: 2.3443, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1516/10000, Loss: 2.3425, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1517/10000, Loss: 2.3407, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1518/10000, Loss: 2.3389, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1519/10000, Loss: 2.3371, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1520/10000, Loss: 2.3353, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1521/10000, Loss: 2.3335, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1522/10000, Loss: 2.3317, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1523/10000, Loss: 2.3299, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1524/10000, Loss: 2.3281, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1525/10000, Loss: 2.3264, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1526/10000, Loss: 2.3246, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1527/10000, Loss: 2.3228, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1528/10000, Loss: 2.3210, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1529/10000, Loss: 2.3193, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1530/10000, Loss: 2.3175, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1531/10000, Loss: 2.3157, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1532/10000, Loss: 2.3140, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1533/10000, Loss: 2.3122, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1534/10000, Loss: 2.3104, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1535/10000, Loss: 2.3087, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1536/10000, Loss: 2.3069, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1537/10000, Loss: 2.3052, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1538/10000, Loss: 2.3034, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1539/10000, Loss: 2.3016, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1540/10000, Loss: 2.2999, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1541/10000, Loss: 2.2981, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1542/10000, Loss: 2.2964, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1543/10000, Loss: 2.2947, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1544/10000, Loss: 2.2929, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1545/10000, Loss: 2.2912, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1546/10000, Loss: 2.2894, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1547/10000, Loss: 2.2877, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1548/10000, Loss: 2.2860, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1549/10000, Loss: 2.2843, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1550/10000, Loss: 2.2825, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1551/10000, Loss: 2.2808, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1552/10000, Loss: 2.2791, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1553/10000, Loss: 2.2774, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1554/10000, Loss: 2.2756, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1555/10000, Loss: 2.2739, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1556/10000, Loss: 2.2722, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1557/10000, Loss: 2.2705, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1558/10000, Loss: 2.2688, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1559/10000, Loss: 2.2671, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1560/10000, Loss: 2.2654, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1561/10000, Loss: 2.2637, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1562/10000, Loss: 2.2620, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1563/10000, Loss: 2.2603, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1564/10000, Loss: 2.2586, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1565/10000, Loss: 2.2569, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1566/10000, Loss: 2.2552, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1567/10000, Loss: 2.2535, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1568/10000, Loss: 2.2518, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1569/10000, Loss: 2.2501, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1570/10000, Loss: 2.2484, Accuracy: 0.5897, Learning Rate: 0.000100\n",
      "Epoch 1571/10000, Loss: 2.2468, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1572/10000, Loss: 2.2451, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1573/10000, Loss: 2.2434, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1574/10000, Loss: 2.2417, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1575/10000, Loss: 2.2401, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1576/10000, Loss: 2.2384, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1577/10000, Loss: 2.2367, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1578/10000, Loss: 2.2351, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1579/10000, Loss: 2.2334, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1580/10000, Loss: 2.2318, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1581/10000, Loss: 2.2301, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1582/10000, Loss: 2.2284, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1583/10000, Loss: 2.2268, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1584/10000, Loss: 2.2251, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1585/10000, Loss: 2.2235, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1586/10000, Loss: 2.2219, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1587/10000, Loss: 2.2202, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1588/10000, Loss: 2.2186, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1589/10000, Loss: 2.2169, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1590/10000, Loss: 2.2153, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1591/10000, Loss: 2.2137, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1592/10000, Loss: 2.2120, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1593/10000, Loss: 2.2104, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1594/10000, Loss: 2.2088, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1595/10000, Loss: 2.2072, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1596/10000, Loss: 2.2055, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1597/10000, Loss: 2.2039, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1598/10000, Loss: 2.2023, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1599/10000, Loss: 2.2007, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1600/10000, Loss: 2.1991, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1601/10000, Loss: 2.1975, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1602/10000, Loss: 2.1959, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1603/10000, Loss: 2.1943, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1604/10000, Loss: 2.1927, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1605/10000, Loss: 2.1911, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1606/10000, Loss: 2.1895, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1607/10000, Loss: 2.1879, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1608/10000, Loss: 2.1863, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1609/10000, Loss: 2.1847, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1610/10000, Loss: 2.1831, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1611/10000, Loss: 2.1815, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1612/10000, Loss: 2.1800, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1613/10000, Loss: 2.1784, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1614/10000, Loss: 2.1768, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1615/10000, Loss: 2.1752, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1616/10000, Loss: 2.1737, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1617/10000, Loss: 2.1721, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1618/10000, Loss: 2.1705, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1619/10000, Loss: 2.1690, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1620/10000, Loss: 2.1674, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1621/10000, Loss: 2.1658, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1622/10000, Loss: 2.1643, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1623/10000, Loss: 2.1627, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1624/10000, Loss: 2.1612, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1625/10000, Loss: 2.1596, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1626/10000, Loss: 2.1581, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1627/10000, Loss: 2.1565, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1628/10000, Loss: 2.1550, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1629/10000, Loss: 2.1534, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1630/10000, Loss: 2.1519, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1631/10000, Loss: 2.1504, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1632/10000, Loss: 2.1488, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1633/10000, Loss: 2.1473, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1634/10000, Loss: 2.1458, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1635/10000, Loss: 2.1443, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1636/10000, Loss: 2.1427, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1637/10000, Loss: 2.1412, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1638/10000, Loss: 2.1397, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1639/10000, Loss: 2.1382, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1640/10000, Loss: 2.1367, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1641/10000, Loss: 2.1352, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1642/10000, Loss: 2.1337, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1643/10000, Loss: 2.1322, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1644/10000, Loss: 2.1307, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1645/10000, Loss: 2.1292, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1646/10000, Loss: 2.1277, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1647/10000, Loss: 2.1262, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1648/10000, Loss: 2.1247, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1649/10000, Loss: 2.1232, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1650/10000, Loss: 2.1217, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1651/10000, Loss: 2.1202, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1652/10000, Loss: 2.1187, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1653/10000, Loss: 2.1173, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1654/10000, Loss: 2.1158, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1655/10000, Loss: 2.1143, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1656/10000, Loss: 2.1128, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1657/10000, Loss: 2.1114, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1658/10000, Loss: 2.1099, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1659/10000, Loss: 2.1084, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1660/10000, Loss: 2.1070, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1661/10000, Loss: 2.1055, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1662/10000, Loss: 2.1041, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1663/10000, Loss: 2.1026, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1664/10000, Loss: 2.1011, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1665/10000, Loss: 2.0997, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1666/10000, Loss: 2.0983, Accuracy: 0.6026, Learning Rate: 0.000100\n",
      "Epoch 1667/10000, Loss: 2.0968, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1668/10000, Loss: 2.0954, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1669/10000, Loss: 2.0939, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1670/10000, Loss: 2.0925, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1671/10000, Loss: 2.0911, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1672/10000, Loss: 2.0896, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1673/10000, Loss: 2.0882, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1674/10000, Loss: 2.0868, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1675/10000, Loss: 2.0853, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1676/10000, Loss: 2.0839, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1677/10000, Loss: 2.0825, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1678/10000, Loss: 2.0811, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1679/10000, Loss: 2.0797, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1680/10000, Loss: 2.0783, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1681/10000, Loss: 2.0768, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1682/10000, Loss: 2.0754, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1683/10000, Loss: 2.0740, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1684/10000, Loss: 2.0726, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1685/10000, Loss: 2.0712, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1686/10000, Loss: 2.0698, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1687/10000, Loss: 2.0684, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1688/10000, Loss: 2.0670, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1689/10000, Loss: 2.0657, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1690/10000, Loss: 2.0643, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1691/10000, Loss: 2.0629, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1692/10000, Loss: 2.0615, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1693/10000, Loss: 2.0601, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1694/10000, Loss: 2.0587, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1695/10000, Loss: 2.0574, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1696/10000, Loss: 2.0560, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1697/10000, Loss: 2.0546, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1698/10000, Loss: 2.0532, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1699/10000, Loss: 2.0519, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1700/10000, Loss: 2.0505, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1701/10000, Loss: 2.0492, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1702/10000, Loss: 2.0478, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1703/10000, Loss: 2.0464, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1704/10000, Loss: 2.0451, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1705/10000, Loss: 2.0437, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1706/10000, Loss: 2.0424, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1707/10000, Loss: 2.0410, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1708/10000, Loss: 2.0397, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1709/10000, Loss: 2.0384, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1710/10000, Loss: 2.0370, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1711/10000, Loss: 2.0357, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1712/10000, Loss: 2.0343, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1713/10000, Loss: 2.0330, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1714/10000, Loss: 2.0317, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1715/10000, Loss: 2.0304, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1716/10000, Loss: 2.0290, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1717/10000, Loss: 2.0277, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1718/10000, Loss: 2.0264, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1719/10000, Loss: 2.0251, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1720/10000, Loss: 2.0238, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1721/10000, Loss: 2.0224, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1722/10000, Loss: 2.0211, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1723/10000, Loss: 2.0198, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1724/10000, Loss: 2.0185, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1725/10000, Loss: 2.0172, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1726/10000, Loss: 2.0159, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1727/10000, Loss: 2.0146, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1728/10000, Loss: 2.0133, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1729/10000, Loss: 2.0120, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1730/10000, Loss: 2.0107, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1731/10000, Loss: 2.0094, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1732/10000, Loss: 2.0081, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1733/10000, Loss: 2.0069, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1734/10000, Loss: 2.0056, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1735/10000, Loss: 2.0043, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1736/10000, Loss: 2.0030, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1737/10000, Loss: 2.0017, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1738/10000, Loss: 2.0005, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1739/10000, Loss: 1.9992, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1740/10000, Loss: 1.9979, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1741/10000, Loss: 1.9967, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1742/10000, Loss: 1.9954, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1743/10000, Loss: 1.9941, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1744/10000, Loss: 1.9929, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1745/10000, Loss: 1.9916, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1746/10000, Loss: 1.9904, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1747/10000, Loss: 1.9891, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1748/10000, Loss: 1.9879, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1749/10000, Loss: 1.9866, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1750/10000, Loss: 1.9854, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1751/10000, Loss: 1.9841, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1752/10000, Loss: 1.9829, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1753/10000, Loss: 1.9816, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1754/10000, Loss: 1.9804, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1755/10000, Loss: 1.9792, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1756/10000, Loss: 1.9779, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1757/10000, Loss: 1.9767, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1758/10000, Loss: 1.9755, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1759/10000, Loss: 1.9743, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1760/10000, Loss: 1.9730, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1761/10000, Loss: 1.9718, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1762/10000, Loss: 1.9706, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1763/10000, Loss: 1.9694, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1764/10000, Loss: 1.9682, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1765/10000, Loss: 1.9669, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1766/10000, Loss: 1.9657, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1767/10000, Loss: 1.9645, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1768/10000, Loss: 1.9633, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1769/10000, Loss: 1.9621, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1770/10000, Loss: 1.9609, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1771/10000, Loss: 1.9597, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1772/10000, Loss: 1.9585, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1773/10000, Loss: 1.9573, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1774/10000, Loss: 1.9561, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1775/10000, Loss: 1.9549, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1776/10000, Loss: 1.9538, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1777/10000, Loss: 1.9526, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1778/10000, Loss: 1.9514, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1779/10000, Loss: 1.9502, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1780/10000, Loss: 1.9490, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1781/10000, Loss: 1.9478, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1782/10000, Loss: 1.9467, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1783/10000, Loss: 1.9455, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1784/10000, Loss: 1.9443, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1785/10000, Loss: 1.9432, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1786/10000, Loss: 1.9420, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1787/10000, Loss: 1.9408, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1788/10000, Loss: 1.9397, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1789/10000, Loss: 1.9385, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1790/10000, Loss: 1.9373, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1791/10000, Loss: 1.9362, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1792/10000, Loss: 1.9350, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1793/10000, Loss: 1.9339, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1794/10000, Loss: 1.9327, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1795/10000, Loss: 1.9316, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1796/10000, Loss: 1.9304, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1797/10000, Loss: 1.9293, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1798/10000, Loss: 1.9281, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1799/10000, Loss: 1.9270, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1800/10000, Loss: 1.9259, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1801/10000, Loss: 1.9247, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1802/10000, Loss: 1.9236, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1803/10000, Loss: 1.9225, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1804/10000, Loss: 1.9213, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1805/10000, Loss: 1.9202, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1806/10000, Loss: 1.9191, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1807/10000, Loss: 1.9180, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1808/10000, Loss: 1.9168, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1809/10000, Loss: 1.9157, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1810/10000, Loss: 1.9146, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1811/10000, Loss: 1.9135, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1812/10000, Loss: 1.9124, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1813/10000, Loss: 1.9113, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1814/10000, Loss: 1.9102, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1815/10000, Loss: 1.9090, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1816/10000, Loss: 1.9079, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1817/10000, Loss: 1.9068, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1818/10000, Loss: 1.9057, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1819/10000, Loss: 1.9046, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1820/10000, Loss: 1.9035, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1821/10000, Loss: 1.9024, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1822/10000, Loss: 1.9014, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1823/10000, Loss: 1.9003, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1824/10000, Loss: 1.8992, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1825/10000, Loss: 1.8981, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1826/10000, Loss: 1.8970, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1827/10000, Loss: 1.8959, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1828/10000, Loss: 1.8948, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1829/10000, Loss: 1.8937, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1830/10000, Loss: 1.8927, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1831/10000, Loss: 1.8916, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1832/10000, Loss: 1.8905, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1833/10000, Loss: 1.8894, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1834/10000, Loss: 1.8884, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1835/10000, Loss: 1.8873, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1836/10000, Loss: 1.8862, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1837/10000, Loss: 1.8852, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1838/10000, Loss: 1.8841, Accuracy: 0.6154, Learning Rate: 0.000100\n",
      "Epoch 1839/10000, Loss: 1.8831, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1840/10000, Loss: 1.8820, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1841/10000, Loss: 1.8809, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1842/10000, Loss: 1.8799, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1843/10000, Loss: 1.8788, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1844/10000, Loss: 1.8778, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1845/10000, Loss: 1.8767, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1846/10000, Loss: 1.8757, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1847/10000, Loss: 1.8746, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1848/10000, Loss: 1.8736, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1849/10000, Loss: 1.8725, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1850/10000, Loss: 1.8715, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1851/10000, Loss: 1.8705, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1852/10000, Loss: 1.8694, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1853/10000, Loss: 1.8684, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1854/10000, Loss: 1.8674, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1855/10000, Loss: 1.8663, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1856/10000, Loss: 1.8653, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1857/10000, Loss: 1.8643, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1858/10000, Loss: 1.8632, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1859/10000, Loss: 1.8622, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1860/10000, Loss: 1.8612, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1861/10000, Loss: 1.8602, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1862/10000, Loss: 1.8592, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1863/10000, Loss: 1.8581, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1864/10000, Loss: 1.8571, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1865/10000, Loss: 1.8561, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1866/10000, Loss: 1.8551, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1867/10000, Loss: 1.8541, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1868/10000, Loss: 1.8531, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1869/10000, Loss: 1.8521, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1870/10000, Loss: 1.8511, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1871/10000, Loss: 1.8501, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1872/10000, Loss: 1.8491, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1873/10000, Loss: 1.8481, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1874/10000, Loss: 1.8471, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1875/10000, Loss: 1.8461, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1876/10000, Loss: 1.8451, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1877/10000, Loss: 1.8441, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1878/10000, Loss: 1.8431, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1879/10000, Loss: 1.8421, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1880/10000, Loss: 1.8411, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1881/10000, Loss: 1.8401, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1882/10000, Loss: 1.8391, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 1883/10000, Loss: 1.8381, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1884/10000, Loss: 1.8372, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1885/10000, Loss: 1.8362, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1886/10000, Loss: 1.8352, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1887/10000, Loss: 1.8342, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1888/10000, Loss: 1.8333, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1889/10000, Loss: 1.8323, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1890/10000, Loss: 1.8313, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1891/10000, Loss: 1.8303, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1892/10000, Loss: 1.8294, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1893/10000, Loss: 1.8284, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1894/10000, Loss: 1.8274, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1895/10000, Loss: 1.8265, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1896/10000, Loss: 1.8255, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1897/10000, Loss: 1.8246, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1898/10000, Loss: 1.8236, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1899/10000, Loss: 1.8226, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1900/10000, Loss: 1.8217, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1901/10000, Loss: 1.8207, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1902/10000, Loss: 1.8198, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1903/10000, Loss: 1.8188, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1904/10000, Loss: 1.8179, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1905/10000, Loss: 1.8169, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1906/10000, Loss: 1.8160, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1907/10000, Loss: 1.8150, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1908/10000, Loss: 1.8141, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1909/10000, Loss: 1.8131, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1910/10000, Loss: 1.8122, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1911/10000, Loss: 1.8113, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1912/10000, Loss: 1.8103, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1913/10000, Loss: 1.8094, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1914/10000, Loss: 1.8085, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1915/10000, Loss: 1.8075, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1916/10000, Loss: 1.8066, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1917/10000, Loss: 1.8057, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1918/10000, Loss: 1.8047, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1919/10000, Loss: 1.8038, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1920/10000, Loss: 1.8029, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1921/10000, Loss: 1.8020, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1922/10000, Loss: 1.8010, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1923/10000, Loss: 1.8001, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1924/10000, Loss: 1.7992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1925/10000, Loss: 1.7983, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1926/10000, Loss: 1.7974, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1927/10000, Loss: 1.7964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1928/10000, Loss: 1.7955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1929/10000, Loss: 1.7946, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1930/10000, Loss: 1.7937, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 1931/10000, Loss: 1.7928, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1932/10000, Loss: 1.7919, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1933/10000, Loss: 1.7910, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1934/10000, Loss: 1.7901, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1935/10000, Loss: 1.7892, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1936/10000, Loss: 1.7883, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1937/10000, Loss: 1.7874, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1938/10000, Loss: 1.7865, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1939/10000, Loss: 1.7856, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1940/10000, Loss: 1.7847, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1941/10000, Loss: 1.7838, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1942/10000, Loss: 1.7829, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1943/10000, Loss: 1.7820, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1944/10000, Loss: 1.7811, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1945/10000, Loss: 1.7802, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1946/10000, Loss: 1.7793, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1947/10000, Loss: 1.7784, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1948/10000, Loss: 1.7776, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1949/10000, Loss: 1.7767, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1950/10000, Loss: 1.7758, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1951/10000, Loss: 1.7749, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1952/10000, Loss: 1.7740, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1953/10000, Loss: 1.7732, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1954/10000, Loss: 1.7723, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1955/10000, Loss: 1.7714, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1956/10000, Loss: 1.7705, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1957/10000, Loss: 1.7696, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1958/10000, Loss: 1.7688, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1959/10000, Loss: 1.7679, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1960/10000, Loss: 1.7670, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1961/10000, Loss: 1.7662, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1962/10000, Loss: 1.7653, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1963/10000, Loss: 1.7644, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1964/10000, Loss: 1.7636, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1965/10000, Loss: 1.7627, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1966/10000, Loss: 1.7618, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1967/10000, Loss: 1.7610, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1968/10000, Loss: 1.7601, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1969/10000, Loss: 1.7593, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1970/10000, Loss: 1.7584, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1971/10000, Loss: 1.7576, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1972/10000, Loss: 1.7567, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1973/10000, Loss: 1.7558, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1974/10000, Loss: 1.7550, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1975/10000, Loss: 1.7541, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1976/10000, Loss: 1.7533, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1977/10000, Loss: 1.7524, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1978/10000, Loss: 1.7516, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1979/10000, Loss: 1.7508, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1980/10000, Loss: 1.7499, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1981/10000, Loss: 1.7491, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1982/10000, Loss: 1.7482, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1983/10000, Loss: 1.7474, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1984/10000, Loss: 1.7465, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1985/10000, Loss: 1.7457, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1986/10000, Loss: 1.7449, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1987/10000, Loss: 1.7440, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1988/10000, Loss: 1.7432, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1989/10000, Loss: 1.7424, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1990/10000, Loss: 1.7415, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1991/10000, Loss: 1.7407, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1992/10000, Loss: 1.7399, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1993/10000, Loss: 1.7390, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1994/10000, Loss: 1.7382, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1995/10000, Loss: 1.7374, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1996/10000, Loss: 1.7366, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1997/10000, Loss: 1.7357, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1998/10000, Loss: 1.7349, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 1999/10000, Loss: 1.7341, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2000/10000, Loss: 1.7333, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2001/10000, Loss: 1.7325, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2002/10000, Loss: 1.7316, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2003/10000, Loss: 1.7308, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2004/10000, Loss: 1.7300, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2005/10000, Loss: 1.7292, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2006/10000, Loss: 1.7284, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2007/10000, Loss: 1.7276, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2008/10000, Loss: 1.7268, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2009/10000, Loss: 1.7259, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2010/10000, Loss: 1.7251, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2011/10000, Loss: 1.7243, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2012/10000, Loss: 1.7235, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2013/10000, Loss: 1.7227, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2014/10000, Loss: 1.7219, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2015/10000, Loss: 1.7211, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2016/10000, Loss: 1.7203, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2017/10000, Loss: 1.7195, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2018/10000, Loss: 1.7187, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2019/10000, Loss: 1.7179, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2020/10000, Loss: 1.7171, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2021/10000, Loss: 1.7163, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2022/10000, Loss: 1.7155, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2023/10000, Loss: 1.7147, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2024/10000, Loss: 1.7139, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2025/10000, Loss: 1.7131, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2026/10000, Loss: 1.7123, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2027/10000, Loss: 1.7115, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2028/10000, Loss: 1.7108, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2029/10000, Loss: 1.7100, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2030/10000, Loss: 1.7092, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2031/10000, Loss: 1.7084, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2032/10000, Loss: 1.7076, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2033/10000, Loss: 1.7068, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2034/10000, Loss: 1.7060, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2035/10000, Loss: 1.7053, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2036/10000, Loss: 1.7045, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2037/10000, Loss: 1.7037, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2038/10000, Loss: 1.7029, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2039/10000, Loss: 1.7021, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2040/10000, Loss: 1.7014, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2041/10000, Loss: 1.7006, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2042/10000, Loss: 1.6998, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2043/10000, Loss: 1.6990, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2044/10000, Loss: 1.6983, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2045/10000, Loss: 1.6975, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2046/10000, Loss: 1.6967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2047/10000, Loss: 1.6959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2048/10000, Loss: 1.6952, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2049/10000, Loss: 1.6944, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2050/10000, Loss: 1.6936, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2051/10000, Loss: 1.6929, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2052/10000, Loss: 1.6921, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2053/10000, Loss: 1.6913, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2054/10000, Loss: 1.6906, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2055/10000, Loss: 1.6898, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2056/10000, Loss: 1.6891, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2057/10000, Loss: 1.6883, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2058/10000, Loss: 1.6875, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2059/10000, Loss: 1.6868, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2060/10000, Loss: 1.6860, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2061/10000, Loss: 1.6853, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2062/10000, Loss: 1.6845, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2063/10000, Loss: 1.6838, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2064/10000, Loss: 1.6830, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2065/10000, Loss: 1.6822, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2066/10000, Loss: 1.6815, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2067/10000, Loss: 1.6807, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2068/10000, Loss: 1.6800, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2069/10000, Loss: 1.6792, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2070/10000, Loss: 1.6785, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2071/10000, Loss: 1.6778, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2072/10000, Loss: 1.6770, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2073/10000, Loss: 1.6763, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2074/10000, Loss: 1.6755, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2075/10000, Loss: 1.6748, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2076/10000, Loss: 1.6740, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2077/10000, Loss: 1.6733, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2078/10000, Loss: 1.6725, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2079/10000, Loss: 1.6718, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2080/10000, Loss: 1.6711, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2081/10000, Loss: 1.6703, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2082/10000, Loss: 1.6696, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2083/10000, Loss: 1.6689, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2084/10000, Loss: 1.6681, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2085/10000, Loss: 1.6674, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2086/10000, Loss: 1.6667, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2087/10000, Loss: 1.6659, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2088/10000, Loss: 1.6652, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2089/10000, Loss: 1.6645, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2090/10000, Loss: 1.6637, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2091/10000, Loss: 1.6630, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2092/10000, Loss: 1.6623, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2093/10000, Loss: 1.6615, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2094/10000, Loss: 1.6608, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2095/10000, Loss: 1.6601, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2096/10000, Loss: 1.6594, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2097/10000, Loss: 1.6586, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2098/10000, Loss: 1.6579, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2099/10000, Loss: 1.6572, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2100/10000, Loss: 1.6565, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2101/10000, Loss: 1.6558, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2102/10000, Loss: 1.6550, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2103/10000, Loss: 1.6543, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2104/10000, Loss: 1.6536, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2105/10000, Loss: 1.6529, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2106/10000, Loss: 1.6522, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2107/10000, Loss: 1.6515, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2108/10000, Loss: 1.6507, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2109/10000, Loss: 1.6500, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2110/10000, Loss: 1.6493, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2111/10000, Loss: 1.6486, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2112/10000, Loss: 1.6479, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2113/10000, Loss: 1.6472, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2114/10000, Loss: 1.6465, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2115/10000, Loss: 1.6458, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2116/10000, Loss: 1.6451, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2117/10000, Loss: 1.6443, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2118/10000, Loss: 1.6436, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2119/10000, Loss: 1.6429, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2120/10000, Loss: 1.6422, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2121/10000, Loss: 1.6415, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2122/10000, Loss: 1.6408, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2123/10000, Loss: 1.6401, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2124/10000, Loss: 1.6394, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2125/10000, Loss: 1.6387, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2126/10000, Loss: 1.6380, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2127/10000, Loss: 1.6373, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2128/10000, Loss: 1.6366, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2129/10000, Loss: 1.6359, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2130/10000, Loss: 1.6352, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2131/10000, Loss: 1.6345, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2132/10000, Loss: 1.6338, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2133/10000, Loss: 1.6331, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2134/10000, Loss: 1.6324, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2135/10000, Loss: 1.6318, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2136/10000, Loss: 1.6311, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2137/10000, Loss: 1.6304, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2138/10000, Loss: 1.6297, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2139/10000, Loss: 1.6290, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2140/10000, Loss: 1.6283, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2141/10000, Loss: 1.6276, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2142/10000, Loss: 1.6269, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2143/10000, Loss: 1.6262, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2144/10000, Loss: 1.6256, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2145/10000, Loss: 1.6249, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2146/10000, Loss: 1.6242, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2147/10000, Loss: 1.6235, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2148/10000, Loss: 1.6228, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2149/10000, Loss: 1.6221, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2150/10000, Loss: 1.6215, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2151/10000, Loss: 1.6208, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2152/10000, Loss: 1.6201, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2153/10000, Loss: 1.6194, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2154/10000, Loss: 1.6187, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2155/10000, Loss: 1.6181, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2156/10000, Loss: 1.6174, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2157/10000, Loss: 1.6167, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2158/10000, Loss: 1.6160, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2159/10000, Loss: 1.6154, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2160/10000, Loss: 1.6147, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2161/10000, Loss: 1.6140, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2162/10000, Loss: 1.6133, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2163/10000, Loss: 1.6127, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2164/10000, Loss: 1.6120, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2165/10000, Loss: 1.6113, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2166/10000, Loss: 1.6107, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2167/10000, Loss: 1.6100, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2168/10000, Loss: 1.6093, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2169/10000, Loss: 1.6087, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2170/10000, Loss: 1.6080, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2171/10000, Loss: 1.6073, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2172/10000, Loss: 1.6067, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2173/10000, Loss: 1.6060, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2174/10000, Loss: 1.6053, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2175/10000, Loss: 1.6047, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2176/10000, Loss: 1.6040, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2177/10000, Loss: 1.6033, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2178/10000, Loss: 1.6027, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2179/10000, Loss: 1.6020, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2180/10000, Loss: 1.6014, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2181/10000, Loss: 1.6007, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2182/10000, Loss: 1.6000, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2183/10000, Loss: 1.5994, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2184/10000, Loss: 1.5987, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2185/10000, Loss: 1.5981, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2186/10000, Loss: 1.5974, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2187/10000, Loss: 1.5968, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2188/10000, Loss: 1.5961, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2189/10000, Loss: 1.5955, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2190/10000, Loss: 1.5948, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2191/10000, Loss: 1.5942, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2192/10000, Loss: 1.5935, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2193/10000, Loss: 1.5929, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2194/10000, Loss: 1.5922, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2195/10000, Loss: 1.5916, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2196/10000, Loss: 1.5909, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2197/10000, Loss: 1.5903, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2198/10000, Loss: 1.5896, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2199/10000, Loss: 1.5890, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2200/10000, Loss: 1.5883, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2201/10000, Loss: 1.5877, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2202/10000, Loss: 1.5870, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2203/10000, Loss: 1.5864, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2204/10000, Loss: 1.5857, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2205/10000, Loss: 1.5851, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2206/10000, Loss: 1.5845, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2207/10000, Loss: 1.5838, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2208/10000, Loss: 1.5832, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2209/10000, Loss: 1.5825, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2210/10000, Loss: 1.5819, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2211/10000, Loss: 1.5813, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2212/10000, Loss: 1.5806, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2213/10000, Loss: 1.5800, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2214/10000, Loss: 1.5794, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2215/10000, Loss: 1.5787, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2216/10000, Loss: 1.5781, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2217/10000, Loss: 1.5774, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2218/10000, Loss: 1.5768, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2219/10000, Loss: 1.5762, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2220/10000, Loss: 1.5755, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2221/10000, Loss: 1.5749, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2222/10000, Loss: 1.5743, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2223/10000, Loss: 1.5737, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2224/10000, Loss: 1.5730, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2225/10000, Loss: 1.5724, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2226/10000, Loss: 1.5718, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2227/10000, Loss: 1.5711, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2228/10000, Loss: 1.5705, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2229/10000, Loss: 1.5699, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2230/10000, Loss: 1.5693, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2231/10000, Loss: 1.5686, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2232/10000, Loss: 1.5680, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2233/10000, Loss: 1.5674, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 2234/10000, Loss: 1.5668, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2235/10000, Loss: 1.5661, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2236/10000, Loss: 1.5655, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2237/10000, Loss: 1.5649, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2238/10000, Loss: 1.5643, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2239/10000, Loss: 1.5637, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2240/10000, Loss: 1.5630, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2241/10000, Loss: 1.5624, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2242/10000, Loss: 1.5618, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2243/10000, Loss: 1.5612, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2244/10000, Loss: 1.5606, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2245/10000, Loss: 1.5599, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2246/10000, Loss: 1.5593, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2247/10000, Loss: 1.5587, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2248/10000, Loss: 1.5581, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2249/10000, Loss: 1.5575, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2250/10000, Loss: 1.5569, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2251/10000, Loss: 1.5563, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2252/10000, Loss: 1.5556, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2253/10000, Loss: 1.5550, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2254/10000, Loss: 1.5544, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2255/10000, Loss: 1.5538, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2256/10000, Loss: 1.5532, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2257/10000, Loss: 1.5526, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2258/10000, Loss: 1.5520, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2259/10000, Loss: 1.5514, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2260/10000, Loss: 1.5508, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2261/10000, Loss: 1.5502, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2262/10000, Loss: 1.5495, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2263/10000, Loss: 1.5489, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2264/10000, Loss: 1.5483, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2265/10000, Loss: 1.5477, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2266/10000, Loss: 1.5471, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2267/10000, Loss: 1.5465, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2268/10000, Loss: 1.5459, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2269/10000, Loss: 1.5453, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 2270/10000, Loss: 1.5447, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2271/10000, Loss: 1.5441, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2272/10000, Loss: 1.5435, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2273/10000, Loss: 1.5429, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2274/10000, Loss: 1.5423, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2275/10000, Loss: 1.5417, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2276/10000, Loss: 1.5411, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2277/10000, Loss: 1.5405, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2278/10000, Loss: 1.5399, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2279/10000, Loss: 1.5393, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2280/10000, Loss: 1.5387, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2281/10000, Loss: 1.5381, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2282/10000, Loss: 1.5375, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2283/10000, Loss: 1.5369, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2284/10000, Loss: 1.5364, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2285/10000, Loss: 1.5358, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2286/10000, Loss: 1.5352, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2287/10000, Loss: 1.5346, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2288/10000, Loss: 1.5340, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2289/10000, Loss: 1.5334, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2290/10000, Loss: 1.5328, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2291/10000, Loss: 1.5322, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2292/10000, Loss: 1.5316, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2293/10000, Loss: 1.5310, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2294/10000, Loss: 1.5305, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2295/10000, Loss: 1.5299, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2296/10000, Loss: 1.5293, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2297/10000, Loss: 1.5287, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2298/10000, Loss: 1.5281, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2299/10000, Loss: 1.5275, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2300/10000, Loss: 1.5269, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2301/10000, Loss: 1.5264, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2302/10000, Loss: 1.5258, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2303/10000, Loss: 1.5252, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2304/10000, Loss: 1.5246, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2305/10000, Loss: 1.5240, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2306/10000, Loss: 1.5234, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2307/10000, Loss: 1.5229, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2308/10000, Loss: 1.5223, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2309/10000, Loss: 1.5217, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2310/10000, Loss: 1.5211, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2311/10000, Loss: 1.5205, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2312/10000, Loss: 1.5200, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2313/10000, Loss: 1.5194, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2314/10000, Loss: 1.5188, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2315/10000, Loss: 1.5182, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2316/10000, Loss: 1.5177, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2317/10000, Loss: 1.5171, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2318/10000, Loss: 1.5165, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2319/10000, Loss: 1.5159, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2320/10000, Loss: 1.5154, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2321/10000, Loss: 1.5148, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2322/10000, Loss: 1.5142, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2323/10000, Loss: 1.5136, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2324/10000, Loss: 1.5131, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2325/10000, Loss: 1.5125, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2326/10000, Loss: 1.5119, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2327/10000, Loss: 1.5114, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2328/10000, Loss: 1.5108, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2329/10000, Loss: 1.5102, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2330/10000, Loss: 1.5097, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2331/10000, Loss: 1.5091, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2332/10000, Loss: 1.5085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2333/10000, Loss: 1.5080, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2334/10000, Loss: 1.5074, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2335/10000, Loss: 1.5068, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2336/10000, Loss: 1.5063, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2337/10000, Loss: 1.5057, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2338/10000, Loss: 1.5051, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2339/10000, Loss: 1.5046, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2340/10000, Loss: 1.5040, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2341/10000, Loss: 1.5034, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2342/10000, Loss: 1.5029, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2343/10000, Loss: 1.5023, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2344/10000, Loss: 1.5018, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2345/10000, Loss: 1.5012, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2346/10000, Loss: 1.5006, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2347/10000, Loss: 1.5001, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2348/10000, Loss: 1.4995, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2349/10000, Loss: 1.4990, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2350/10000, Loss: 1.4984, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2351/10000, Loss: 1.4978, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2352/10000, Loss: 1.4973, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2353/10000, Loss: 1.4967, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2354/10000, Loss: 1.4962, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2355/10000, Loss: 1.4956, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2356/10000, Loss: 1.4951, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2357/10000, Loss: 1.4945, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2358/10000, Loss: 1.4940, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2359/10000, Loss: 1.4934, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2360/10000, Loss: 1.4929, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2361/10000, Loss: 1.4923, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2362/10000, Loss: 1.4917, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2363/10000, Loss: 1.4912, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2364/10000, Loss: 1.4906, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2365/10000, Loss: 1.4901, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2366/10000, Loss: 1.4895, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2367/10000, Loss: 1.4890, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2368/10000, Loss: 1.4884, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2369/10000, Loss: 1.4879, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2370/10000, Loss: 1.4874, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2371/10000, Loss: 1.4868, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2372/10000, Loss: 1.4863, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2373/10000, Loss: 1.4857, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2374/10000, Loss: 1.4852, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2375/10000, Loss: 1.4846, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2376/10000, Loss: 1.4841, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2377/10000, Loss: 1.4835, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2378/10000, Loss: 1.4830, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2379/10000, Loss: 1.4824, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2380/10000, Loss: 1.4819, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2381/10000, Loss: 1.4814, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2382/10000, Loss: 1.4808, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2383/10000, Loss: 1.4803, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2384/10000, Loss: 1.4797, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2385/10000, Loss: 1.4792, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2386/10000, Loss: 1.4787, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2387/10000, Loss: 1.4781, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2388/10000, Loss: 1.4776, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2389/10000, Loss: 1.4770, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2390/10000, Loss: 1.4765, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2391/10000, Loss: 1.4760, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2392/10000, Loss: 1.4754, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2393/10000, Loss: 1.4749, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2394/10000, Loss: 1.4744, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2395/10000, Loss: 1.4738, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2396/10000, Loss: 1.4733, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2397/10000, Loss: 1.4728, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2398/10000, Loss: 1.4722, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2399/10000, Loss: 1.4717, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2400/10000, Loss: 1.4712, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2401/10000, Loss: 1.4706, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2402/10000, Loss: 1.4701, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2403/10000, Loss: 1.4696, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2404/10000, Loss: 1.4690, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2405/10000, Loss: 1.4685, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2406/10000, Loss: 1.4680, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2407/10000, Loss: 1.4674, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2408/10000, Loss: 1.4669, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2409/10000, Loss: 1.4664, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2410/10000, Loss: 1.4659, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2411/10000, Loss: 1.4653, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2412/10000, Loss: 1.4648, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2413/10000, Loss: 1.4643, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2414/10000, Loss: 1.4638, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2415/10000, Loss: 1.4632, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2416/10000, Loss: 1.4627, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2417/10000, Loss: 1.4622, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2418/10000, Loss: 1.4617, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2419/10000, Loss: 1.4611, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2420/10000, Loss: 1.4606, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2421/10000, Loss: 1.4601, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2422/10000, Loss: 1.4596, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2423/10000, Loss: 1.4590, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2424/10000, Loss: 1.4585, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2425/10000, Loss: 1.4580, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2426/10000, Loss: 1.4575, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2427/10000, Loss: 1.4570, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2428/10000, Loss: 1.4564, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2429/10000, Loss: 1.4559, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2430/10000, Loss: 1.4554, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2431/10000, Loss: 1.4549, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2432/10000, Loss: 1.4544, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2433/10000, Loss: 1.4538, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2434/10000, Loss: 1.4533, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2435/10000, Loss: 1.4528, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2436/10000, Loss: 1.4523, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2437/10000, Loss: 1.4518, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2438/10000, Loss: 1.4513, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2439/10000, Loss: 1.4508, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2440/10000, Loss: 1.4502, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2441/10000, Loss: 1.4497, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2442/10000, Loss: 1.4492, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2443/10000, Loss: 1.4487, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2444/10000, Loss: 1.4482, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2445/10000, Loss: 1.4477, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2446/10000, Loss: 1.4472, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2447/10000, Loss: 1.4467, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2448/10000, Loss: 1.4461, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2449/10000, Loss: 1.4456, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2450/10000, Loss: 1.4451, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2451/10000, Loss: 1.4446, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2452/10000, Loss: 1.4441, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2453/10000, Loss: 1.4436, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2454/10000, Loss: 1.4431, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2455/10000, Loss: 1.4426, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2456/10000, Loss: 1.4421, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2457/10000, Loss: 1.4416, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2458/10000, Loss: 1.4411, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2459/10000, Loss: 1.4406, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2460/10000, Loss: 1.4401, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2461/10000, Loss: 1.4396, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2462/10000, Loss: 1.4390, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2463/10000, Loss: 1.4385, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2464/10000, Loss: 1.4380, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2465/10000, Loss: 1.4375, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2466/10000, Loss: 1.4370, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2467/10000, Loss: 1.4365, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2468/10000, Loss: 1.4360, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2469/10000, Loss: 1.4355, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2470/10000, Loss: 1.4350, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2471/10000, Loss: 1.4345, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2472/10000, Loss: 1.4340, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2473/10000, Loss: 1.4335, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2474/10000, Loss: 1.4330, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2475/10000, Loss: 1.4325, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2476/10000, Loss: 1.4320, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2477/10000, Loss: 1.4315, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2478/10000, Loss: 1.4310, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2479/10000, Loss: 1.4305, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2480/10000, Loss: 1.4301, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2481/10000, Loss: 1.4296, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2482/10000, Loss: 1.4291, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2483/10000, Loss: 1.4286, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2484/10000, Loss: 1.4281, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2485/10000, Loss: 1.4276, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2486/10000, Loss: 1.4271, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2487/10000, Loss: 1.4266, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2488/10000, Loss: 1.4261, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2489/10000, Loss: 1.4256, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2490/10000, Loss: 1.4251, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2491/10000, Loss: 1.4246, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2492/10000, Loss: 1.4241, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2493/10000, Loss: 1.4236, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2494/10000, Loss: 1.4232, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2495/10000, Loss: 1.4227, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2496/10000, Loss: 1.4222, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2497/10000, Loss: 1.4217, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2498/10000, Loss: 1.4212, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2499/10000, Loss: 1.4207, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2500/10000, Loss: 1.4202, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2501/10000, Loss: 1.4197, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2502/10000, Loss: 1.4193, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2503/10000, Loss: 1.4188, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2504/10000, Loss: 1.4183, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2505/10000, Loss: 1.4178, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2506/10000, Loss: 1.4173, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2507/10000, Loss: 1.4168, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2508/10000, Loss: 1.4163, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2509/10000, Loss: 1.4159, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2510/10000, Loss: 1.4154, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2511/10000, Loss: 1.4149, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2512/10000, Loss: 1.4144, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2513/10000, Loss: 1.4139, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2514/10000, Loss: 1.4134, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2515/10000, Loss: 1.4130, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2516/10000, Loss: 1.4125, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2517/10000, Loss: 1.4120, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2518/10000, Loss: 1.4115, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2519/10000, Loss: 1.4110, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2520/10000, Loss: 1.4106, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2521/10000, Loss: 1.4101, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2522/10000, Loss: 1.4096, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2523/10000, Loss: 1.4091, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2524/10000, Loss: 1.4087, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2525/10000, Loss: 1.4082, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2526/10000, Loss: 1.4077, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2527/10000, Loss: 1.4072, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2528/10000, Loss: 1.4067, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2529/10000, Loss: 1.4063, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2530/10000, Loss: 1.4058, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2531/10000, Loss: 1.4053, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2532/10000, Loss: 1.4049, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2533/10000, Loss: 1.4044, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2534/10000, Loss: 1.4039, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2535/10000, Loss: 1.4034, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2536/10000, Loss: 1.4030, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2537/10000, Loss: 1.4025, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2538/10000, Loss: 1.4020, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2539/10000, Loss: 1.4015, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2540/10000, Loss: 1.4011, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2541/10000, Loss: 1.4006, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2542/10000, Loss: 1.4001, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2543/10000, Loss: 1.3997, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2544/10000, Loss: 1.3992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2545/10000, Loss: 1.3987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2546/10000, Loss: 1.3983, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2547/10000, Loss: 1.3978, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2548/10000, Loss: 1.3973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2549/10000, Loss: 1.3969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2550/10000, Loss: 1.3964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2551/10000, Loss: 1.3959, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2552/10000, Loss: 1.3955, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2553/10000, Loss: 1.3950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2554/10000, Loss: 1.3945, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2555/10000, Loss: 1.3941, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2556/10000, Loss: 1.3936, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2557/10000, Loss: 1.3931, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2558/10000, Loss: 1.3927, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2559/10000, Loss: 1.3922, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2560/10000, Loss: 1.3917, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2561/10000, Loss: 1.3913, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2562/10000, Loss: 1.3908, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2563/10000, Loss: 1.3904, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2564/10000, Loss: 1.3899, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2565/10000, Loss: 1.3894, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2566/10000, Loss: 1.3890, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2567/10000, Loss: 1.3885, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2568/10000, Loss: 1.3881, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2569/10000, Loss: 1.3876, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2570/10000, Loss: 1.3871, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2571/10000, Loss: 1.3867, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2572/10000, Loss: 1.3862, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2573/10000, Loss: 1.3858, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2574/10000, Loss: 1.3853, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2575/10000, Loss: 1.3849, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2576/10000, Loss: 1.3844, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2577/10000, Loss: 1.3839, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2578/10000, Loss: 1.3835, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2579/10000, Loss: 1.3830, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2580/10000, Loss: 1.3826, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2581/10000, Loss: 1.3821, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2582/10000, Loss: 1.3817, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2583/10000, Loss: 1.3812, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2584/10000, Loss: 1.3808, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2585/10000, Loss: 1.3803, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2586/10000, Loss: 1.3799, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2587/10000, Loss: 1.3794, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2588/10000, Loss: 1.3789, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2589/10000, Loss: 1.3785, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2590/10000, Loss: 1.3780, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2591/10000, Loss: 1.3776, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2592/10000, Loss: 1.3771, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2593/10000, Loss: 1.3767, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2594/10000, Loss: 1.3762, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2595/10000, Loss: 1.3758, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2596/10000, Loss: 1.3753, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2597/10000, Loss: 1.3749, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2598/10000, Loss: 1.3745, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2599/10000, Loss: 1.3740, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2600/10000, Loss: 1.3736, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2601/10000, Loss: 1.3731, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2602/10000, Loss: 1.3727, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2603/10000, Loss: 1.3722, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2604/10000, Loss: 1.3718, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2605/10000, Loss: 1.3713, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2606/10000, Loss: 1.3709, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2607/10000, Loss: 1.3704, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2608/10000, Loss: 1.3700, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2609/10000, Loss: 1.3695, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2610/10000, Loss: 1.3691, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2611/10000, Loss: 1.3687, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2612/10000, Loss: 1.3682, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2613/10000, Loss: 1.3678, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2614/10000, Loss: 1.3673, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2615/10000, Loss: 1.3669, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2616/10000, Loss: 1.3665, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2617/10000, Loss: 1.3660, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2618/10000, Loss: 1.3656, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2619/10000, Loss: 1.3651, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2620/10000, Loss: 1.3647, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2621/10000, Loss: 1.3643, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2622/10000, Loss: 1.3638, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2623/10000, Loss: 1.3634, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2624/10000, Loss: 1.3629, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2625/10000, Loss: 1.3625, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2626/10000, Loss: 1.3621, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2627/10000, Loss: 1.3616, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2628/10000, Loss: 1.3612, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2629/10000, Loss: 1.3608, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2630/10000, Loss: 1.3603, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2631/10000, Loss: 1.3599, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2632/10000, Loss: 1.3594, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2633/10000, Loss: 1.3590, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2634/10000, Loss: 1.3586, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2635/10000, Loss: 1.3581, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2636/10000, Loss: 1.3577, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2637/10000, Loss: 1.3573, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2638/10000, Loss: 1.3568, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2639/10000, Loss: 1.3564, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2640/10000, Loss: 1.3560, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2641/10000, Loss: 1.3555, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2642/10000, Loss: 1.3551, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2643/10000, Loss: 1.3547, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2644/10000, Loss: 1.3543, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2645/10000, Loss: 1.3538, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2646/10000, Loss: 1.3534, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2647/10000, Loss: 1.3530, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2648/10000, Loss: 1.3525, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 2649/10000, Loss: 1.3521, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 2650/10000, Loss: 1.3517, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 2651/10000, Loss: 1.3512, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 2652/10000, Loss: 1.3508, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2653/10000, Loss: 1.3504, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2654/10000, Loss: 1.3500, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2655/10000, Loss: 1.3495, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2656/10000, Loss: 1.3491, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2657/10000, Loss: 1.3487, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2658/10000, Loss: 1.3483, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2659/10000, Loss: 1.3478, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2660/10000, Loss: 1.3474, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2661/10000, Loss: 1.3470, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2662/10000, Loss: 1.3466, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2663/10000, Loss: 1.3461, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2664/10000, Loss: 1.3457, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2665/10000, Loss: 1.3453, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2666/10000, Loss: 1.3449, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2667/10000, Loss: 1.3444, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2668/10000, Loss: 1.3440, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2669/10000, Loss: 1.3436, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2670/10000, Loss: 1.3432, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2671/10000, Loss: 1.3428, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2672/10000, Loss: 1.3423, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2673/10000, Loss: 1.3419, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2674/10000, Loss: 1.3415, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2675/10000, Loss: 1.3411, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2676/10000, Loss: 1.3407, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2677/10000, Loss: 1.3402, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2678/10000, Loss: 1.3398, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2679/10000, Loss: 1.3394, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2680/10000, Loss: 1.3390, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2681/10000, Loss: 1.3386, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2682/10000, Loss: 1.3381, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2683/10000, Loss: 1.3377, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2684/10000, Loss: 1.3373, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2685/10000, Loss: 1.3369, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2686/10000, Loss: 1.3365, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2687/10000, Loss: 1.3361, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2688/10000, Loss: 1.3356, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2689/10000, Loss: 1.3352, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2690/10000, Loss: 1.3348, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2691/10000, Loss: 1.3344, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2692/10000, Loss: 1.3340, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2693/10000, Loss: 1.3336, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2694/10000, Loss: 1.3332, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2695/10000, Loss: 1.3327, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2696/10000, Loss: 1.3323, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2697/10000, Loss: 1.3319, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2698/10000, Loss: 1.3315, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2699/10000, Loss: 1.3311, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2700/10000, Loss: 1.3307, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2701/10000, Loss: 1.3303, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2702/10000, Loss: 1.3299, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2703/10000, Loss: 1.3295, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2704/10000, Loss: 1.3290, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2705/10000, Loss: 1.3286, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2706/10000, Loss: 1.3282, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2707/10000, Loss: 1.3278, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2708/10000, Loss: 1.3274, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2709/10000, Loss: 1.3270, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2710/10000, Loss: 1.3266, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2711/10000, Loss: 1.3262, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2712/10000, Loss: 1.3258, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2713/10000, Loss: 1.3254, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2714/10000, Loss: 1.3250, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2715/10000, Loss: 1.3246, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2716/10000, Loss: 1.3242, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2717/10000, Loss: 1.3237, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2718/10000, Loss: 1.3233, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2719/10000, Loss: 1.3229, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2720/10000, Loss: 1.3225, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2721/10000, Loss: 1.3221, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2722/10000, Loss: 1.3217, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2723/10000, Loss: 1.3213, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2724/10000, Loss: 1.3209, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2725/10000, Loss: 1.3205, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2726/10000, Loss: 1.3201, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2727/10000, Loss: 1.3197, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2728/10000, Loss: 1.3193, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2729/10000, Loss: 1.3189, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2730/10000, Loss: 1.3185, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2731/10000, Loss: 1.3181, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2732/10000, Loss: 1.3177, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2733/10000, Loss: 1.3173, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2734/10000, Loss: 1.3169, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2735/10000, Loss: 1.3165, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2736/10000, Loss: 1.3161, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2737/10000, Loss: 1.3157, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2738/10000, Loss: 1.3153, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2739/10000, Loss: 1.3149, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2740/10000, Loss: 1.3145, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2741/10000, Loss: 1.3141, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2742/10000, Loss: 1.3137, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2743/10000, Loss: 1.3133, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2744/10000, Loss: 1.3129, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2745/10000, Loss: 1.3125, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2746/10000, Loss: 1.3121, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2747/10000, Loss: 1.3117, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2748/10000, Loss: 1.3113, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2749/10000, Loss: 1.3109, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2750/10000, Loss: 1.3106, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2751/10000, Loss: 1.3102, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2752/10000, Loss: 1.3098, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2753/10000, Loss: 1.3094, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2754/10000, Loss: 1.3090, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2755/10000, Loss: 1.3086, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2756/10000, Loss: 1.3082, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2757/10000, Loss: 1.3078, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2758/10000, Loss: 1.3074, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2759/10000, Loss: 1.3070, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2760/10000, Loss: 1.3066, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2761/10000, Loss: 1.3062, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2762/10000, Loss: 1.3058, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2763/10000, Loss: 1.3055, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2764/10000, Loss: 1.3051, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2765/10000, Loss: 1.3047, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2766/10000, Loss: 1.3043, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2767/10000, Loss: 1.3039, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2768/10000, Loss: 1.3035, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2769/10000, Loss: 1.3031, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2770/10000, Loss: 1.3027, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2771/10000, Loss: 1.3023, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2772/10000, Loss: 1.3019, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2773/10000, Loss: 1.3016, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2774/10000, Loss: 1.3012, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2775/10000, Loss: 1.3008, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2776/10000, Loss: 1.3004, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2777/10000, Loss: 1.3000, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2778/10000, Loss: 1.2996, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2779/10000, Loss: 1.2992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2780/10000, Loss: 1.2989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2781/10000, Loss: 1.2985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2782/10000, Loss: 1.2981, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2783/10000, Loss: 1.2977, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2784/10000, Loss: 1.2973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2785/10000, Loss: 1.2969, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2786/10000, Loss: 1.2966, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2787/10000, Loss: 1.2962, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2788/10000, Loss: 1.2958, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2789/10000, Loss: 1.2954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2790/10000, Loss: 1.2950, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2791/10000, Loss: 1.2946, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2792/10000, Loss: 1.2943, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2793/10000, Loss: 1.2939, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2794/10000, Loss: 1.2935, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2795/10000, Loss: 1.2931, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2796/10000, Loss: 1.2927, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2797/10000, Loss: 1.2924, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2798/10000, Loss: 1.2920, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2799/10000, Loss: 1.2916, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2800/10000, Loss: 1.2912, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2801/10000, Loss: 1.2908, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2802/10000, Loss: 1.2905, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2803/10000, Loss: 1.2901, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2804/10000, Loss: 1.2897, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2805/10000, Loss: 1.2893, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2806/10000, Loss: 1.2890, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2807/10000, Loss: 1.2886, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2808/10000, Loss: 1.2882, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2809/10000, Loss: 1.2878, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2810/10000, Loss: 1.2874, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2811/10000, Loss: 1.2871, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2812/10000, Loss: 1.2867, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2813/10000, Loss: 1.2863, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2814/10000, Loss: 1.2859, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2815/10000, Loss: 1.2856, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2816/10000, Loss: 1.2852, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2817/10000, Loss: 1.2848, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2818/10000, Loss: 1.2844, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2819/10000, Loss: 1.2841, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2820/10000, Loss: 1.2837, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2821/10000, Loss: 1.2833, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2822/10000, Loss: 1.2830, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2823/10000, Loss: 1.2826, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2824/10000, Loss: 1.2822, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2825/10000, Loss: 1.2818, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2826/10000, Loss: 1.2815, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2827/10000, Loss: 1.2811, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2828/10000, Loss: 1.2807, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2829/10000, Loss: 1.2804, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2830/10000, Loss: 1.2800, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2831/10000, Loss: 1.2796, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2832/10000, Loss: 1.2792, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2833/10000, Loss: 1.2789, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2834/10000, Loss: 1.2785, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2835/10000, Loss: 1.2781, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2836/10000, Loss: 1.2778, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2837/10000, Loss: 1.2774, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2838/10000, Loss: 1.2770, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2839/10000, Loss: 1.2767, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2840/10000, Loss: 1.2763, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2841/10000, Loss: 1.2759, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2842/10000, Loss: 1.2756, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2843/10000, Loss: 1.2752, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2844/10000, Loss: 1.2748, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2845/10000, Loss: 1.2745, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2846/10000, Loss: 1.2741, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2847/10000, Loss: 1.2737, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2848/10000, Loss: 1.2734, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2849/10000, Loss: 1.2730, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2850/10000, Loss: 1.2727, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2851/10000, Loss: 1.2723, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2852/10000, Loss: 1.2719, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2853/10000, Loss: 1.2716, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2854/10000, Loss: 1.2712, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2855/10000, Loss: 1.2708, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2856/10000, Loss: 1.2705, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2857/10000, Loss: 1.2701, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2858/10000, Loss: 1.2697, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2859/10000, Loss: 1.2694, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2860/10000, Loss: 1.2690, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2861/10000, Loss: 1.2687, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2862/10000, Loss: 1.2683, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2863/10000, Loss: 1.2679, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2864/10000, Loss: 1.2676, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2865/10000, Loss: 1.2672, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2866/10000, Loss: 1.2669, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2867/10000, Loss: 1.2665, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2868/10000, Loss: 1.2661, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2869/10000, Loss: 1.2658, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2870/10000, Loss: 1.2654, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2871/10000, Loss: 1.2651, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2872/10000, Loss: 1.2647, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2873/10000, Loss: 1.2644, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2874/10000, Loss: 1.2640, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2875/10000, Loss: 1.2636, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2876/10000, Loss: 1.2633, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2877/10000, Loss: 1.2629, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2878/10000, Loss: 1.2626, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2879/10000, Loss: 1.2622, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2880/10000, Loss: 1.2619, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2881/10000, Loss: 1.2615, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2882/10000, Loss: 1.2611, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2883/10000, Loss: 1.2608, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2884/10000, Loss: 1.2604, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2885/10000, Loss: 1.2601, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2886/10000, Loss: 1.2597, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2887/10000, Loss: 1.2594, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2888/10000, Loss: 1.2590, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2889/10000, Loss: 1.2587, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2890/10000, Loss: 1.2583, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2891/10000, Loss: 1.2580, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2892/10000, Loss: 1.2576, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2893/10000, Loss: 1.2573, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2894/10000, Loss: 1.2569, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2895/10000, Loss: 1.2566, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2896/10000, Loss: 1.2562, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2897/10000, Loss: 1.2559, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2898/10000, Loss: 1.2555, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2899/10000, Loss: 1.2552, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2900/10000, Loss: 1.2548, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2901/10000, Loss: 1.2545, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2902/10000, Loss: 1.2541, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2903/10000, Loss: 1.2538, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2904/10000, Loss: 1.2534, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2905/10000, Loss: 1.2531, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2906/10000, Loss: 1.2527, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2907/10000, Loss: 1.2524, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2908/10000, Loss: 1.2520, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2909/10000, Loss: 1.2517, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2910/10000, Loss: 1.2513, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2911/10000, Loss: 1.2510, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2912/10000, Loss: 1.2506, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2913/10000, Loss: 1.2503, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2914/10000, Loss: 1.2499, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2915/10000, Loss: 1.2496, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2916/10000, Loss: 1.2492, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2917/10000, Loss: 1.2489, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2918/10000, Loss: 1.2486, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2919/10000, Loss: 1.2482, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2920/10000, Loss: 1.2479, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2921/10000, Loss: 1.2475, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2922/10000, Loss: 1.2472, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2923/10000, Loss: 1.2468, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2924/10000, Loss: 1.2465, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2925/10000, Loss: 1.2461, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2926/10000, Loss: 1.2458, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2927/10000, Loss: 1.2455, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2928/10000, Loss: 1.2451, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2929/10000, Loss: 1.2448, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2930/10000, Loss: 1.2444, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2931/10000, Loss: 1.2441, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2932/10000, Loss: 1.2437, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2933/10000, Loss: 1.2434, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2934/10000, Loss: 1.2431, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2935/10000, Loss: 1.2427, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 2936/10000, Loss: 1.2424, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2937/10000, Loss: 1.2420, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2938/10000, Loss: 1.2417, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2939/10000, Loss: 1.2414, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2940/10000, Loss: 1.2410, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2941/10000, Loss: 1.2407, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2942/10000, Loss: 1.2404, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2943/10000, Loss: 1.2400, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2944/10000, Loss: 1.2397, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2945/10000, Loss: 1.2393, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2946/10000, Loss: 1.2390, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2947/10000, Loss: 1.2387, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2948/10000, Loss: 1.2383, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2949/10000, Loss: 1.2380, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2950/10000, Loss: 1.2377, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2951/10000, Loss: 1.2373, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2952/10000, Loss: 1.2370, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2953/10000, Loss: 1.2366, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2954/10000, Loss: 1.2363, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2955/10000, Loss: 1.2360, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2956/10000, Loss: 1.2356, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2957/10000, Loss: 1.2353, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2958/10000, Loss: 1.2350, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2959/10000, Loss: 1.2346, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2960/10000, Loss: 1.2343, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2961/10000, Loss: 1.2340, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2962/10000, Loss: 1.2336, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2963/10000, Loss: 1.2333, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2964/10000, Loss: 1.2330, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2965/10000, Loss: 1.2326, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2966/10000, Loss: 1.2323, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2967/10000, Loss: 1.2320, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2968/10000, Loss: 1.2316, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2969/10000, Loss: 1.2313, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2970/10000, Loss: 1.2310, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2971/10000, Loss: 1.2306, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2972/10000, Loss: 1.2303, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2973/10000, Loss: 1.2300, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2974/10000, Loss: 1.2297, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2975/10000, Loss: 1.2293, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2976/10000, Loss: 1.2290, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2977/10000, Loss: 1.2287, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2978/10000, Loss: 1.2283, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2979/10000, Loss: 1.2280, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2980/10000, Loss: 1.2277, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2981/10000, Loss: 1.2273, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2982/10000, Loss: 1.2270, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2983/10000, Loss: 1.2267, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2984/10000, Loss: 1.2264, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2985/10000, Loss: 1.2260, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2986/10000, Loss: 1.2257, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2987/10000, Loss: 1.2254, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2988/10000, Loss: 1.2251, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2989/10000, Loss: 1.2247, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2990/10000, Loss: 1.2244, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2991/10000, Loss: 1.2241, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2992/10000, Loss: 1.2237, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2993/10000, Loss: 1.2234, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2994/10000, Loss: 1.2231, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2995/10000, Loss: 1.2228, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2996/10000, Loss: 1.2224, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2997/10000, Loss: 1.2221, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2998/10000, Loss: 1.2218, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 2999/10000, Loss: 1.2215, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3000/10000, Loss: 1.2212, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3001/10000, Loss: 1.2208, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3002/10000, Loss: 1.2205, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3003/10000, Loss: 1.2202, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3004/10000, Loss: 1.2199, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3005/10000, Loss: 1.2195, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3006/10000, Loss: 1.2192, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3007/10000, Loss: 1.2189, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3008/10000, Loss: 1.2186, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3009/10000, Loss: 1.2183, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3010/10000, Loss: 1.2179, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3011/10000, Loss: 1.2176, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3012/10000, Loss: 1.2173, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3013/10000, Loss: 1.2170, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3014/10000, Loss: 1.2166, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3015/10000, Loss: 1.2163, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3016/10000, Loss: 1.2160, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3017/10000, Loss: 1.2157, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3018/10000, Loss: 1.2154, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3019/10000, Loss: 1.2151, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3020/10000, Loss: 1.2147, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3021/10000, Loss: 1.2144, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3022/10000, Loss: 1.2141, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3023/10000, Loss: 1.2138, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3024/10000, Loss: 1.2135, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3025/10000, Loss: 1.2131, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3026/10000, Loss: 1.2128, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3027/10000, Loss: 1.2125, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3028/10000, Loss: 1.2122, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3029/10000, Loss: 1.2119, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3030/10000, Loss: 1.2116, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3031/10000, Loss: 1.2112, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3032/10000, Loss: 1.2109, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3033/10000, Loss: 1.2106, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3034/10000, Loss: 1.2103, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3035/10000, Loss: 1.2100, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3036/10000, Loss: 1.2097, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3037/10000, Loss: 1.2094, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3038/10000, Loss: 1.2090, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3039/10000, Loss: 1.2087, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3040/10000, Loss: 1.2084, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3041/10000, Loss: 1.2081, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3042/10000, Loss: 1.2078, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3043/10000, Loss: 1.2075, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3044/10000, Loss: 1.2072, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3045/10000, Loss: 1.2068, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3046/10000, Loss: 1.2065, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3047/10000, Loss: 1.2062, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3048/10000, Loss: 1.2059, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3049/10000, Loss: 1.2056, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3050/10000, Loss: 1.2053, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3051/10000, Loss: 1.2050, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3052/10000, Loss: 1.2047, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3053/10000, Loss: 1.2044, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3054/10000, Loss: 1.2040, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3055/10000, Loss: 1.2037, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3056/10000, Loss: 1.2034, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3057/10000, Loss: 1.2031, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3058/10000, Loss: 1.2028, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3059/10000, Loss: 1.2025, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3060/10000, Loss: 1.2022, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3061/10000, Loss: 1.2019, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3062/10000, Loss: 1.2016, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3063/10000, Loss: 1.2013, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3064/10000, Loss: 1.2010, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3065/10000, Loss: 1.2006, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3066/10000, Loss: 1.2003, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3067/10000, Loss: 1.2000, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3068/10000, Loss: 1.1997, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3069/10000, Loss: 1.1994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3070/10000, Loss: 1.1991, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3071/10000, Loss: 1.1988, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3072/10000, Loss: 1.1985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3073/10000, Loss: 1.1982, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3074/10000, Loss: 1.1979, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3075/10000, Loss: 1.1976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3076/10000, Loss: 1.1973, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3077/10000, Loss: 1.1970, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3078/10000, Loss: 1.1967, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3079/10000, Loss: 1.1964, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3080/10000, Loss: 1.1961, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3081/10000, Loss: 1.1957, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3082/10000, Loss: 1.1954, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3083/10000, Loss: 1.1951, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3084/10000, Loss: 1.1948, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3085/10000, Loss: 1.1945, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3086/10000, Loss: 1.1942, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3087/10000, Loss: 1.1939, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3088/10000, Loss: 1.1936, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3089/10000, Loss: 1.1933, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3090/10000, Loss: 1.1930, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3091/10000, Loss: 1.1927, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3092/10000, Loss: 1.1924, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3093/10000, Loss: 1.1921, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3094/10000, Loss: 1.1918, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3095/10000, Loss: 1.1915, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3096/10000, Loss: 1.1912, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3097/10000, Loss: 1.1909, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3098/10000, Loss: 1.1906, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3099/10000, Loss: 1.1903, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3100/10000, Loss: 1.1900, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3101/10000, Loss: 1.1897, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3102/10000, Loss: 1.1894, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3103/10000, Loss: 1.1891, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3104/10000, Loss: 1.1888, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3105/10000, Loss: 1.1885, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3106/10000, Loss: 1.1882, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3107/10000, Loss: 1.1879, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3108/10000, Loss: 1.1876, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3109/10000, Loss: 1.1873, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3110/10000, Loss: 1.1870, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3111/10000, Loss: 1.1867, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3112/10000, Loss: 1.1864, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3113/10000, Loss: 1.1861, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3114/10000, Loss: 1.1858, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3115/10000, Loss: 1.1856, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3116/10000, Loss: 1.1853, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3117/10000, Loss: 1.1850, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3118/10000, Loss: 1.1847, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3119/10000, Loss: 1.1844, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3120/10000, Loss: 1.1841, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3121/10000, Loss: 1.1838, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3122/10000, Loss: 1.1835, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3123/10000, Loss: 1.1832, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3124/10000, Loss: 1.1829, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3125/10000, Loss: 1.1826, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3126/10000, Loss: 1.1823, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3127/10000, Loss: 1.1820, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3128/10000, Loss: 1.1817, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3129/10000, Loss: 1.1814, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3130/10000, Loss: 1.1811, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3131/10000, Loss: 1.1808, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3132/10000, Loss: 1.1805, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3133/10000, Loss: 1.1803, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3134/10000, Loss: 1.1800, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3135/10000, Loss: 1.1797, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3136/10000, Loss: 1.1794, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3137/10000, Loss: 1.1791, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3138/10000, Loss: 1.1788, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3139/10000, Loss: 1.1785, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3140/10000, Loss: 1.1782, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3141/10000, Loss: 1.1779, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3142/10000, Loss: 1.1776, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3143/10000, Loss: 1.1773, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3144/10000, Loss: 1.1771, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3145/10000, Loss: 1.1768, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3146/10000, Loss: 1.1765, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3147/10000, Loss: 1.1762, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3148/10000, Loss: 1.1759, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3149/10000, Loss: 1.1756, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3150/10000, Loss: 1.1753, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3151/10000, Loss: 1.1750, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3152/10000, Loss: 1.1747, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3153/10000, Loss: 1.1745, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3154/10000, Loss: 1.1742, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3155/10000, Loss: 1.1739, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3156/10000, Loss: 1.1736, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3157/10000, Loss: 1.1733, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3158/10000, Loss: 1.1730, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3159/10000, Loss: 1.1727, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3160/10000, Loss: 1.1725, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3161/10000, Loss: 1.1722, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3162/10000, Loss: 1.1719, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3163/10000, Loss: 1.1716, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3164/10000, Loss: 1.1713, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3165/10000, Loss: 1.1710, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3166/10000, Loss: 1.1707, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3167/10000, Loss: 1.1705, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3168/10000, Loss: 1.1702, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3169/10000, Loss: 1.1699, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3170/10000, Loss: 1.1696, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3171/10000, Loss: 1.1693, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3172/10000, Loss: 1.1690, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3173/10000, Loss: 1.1688, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3174/10000, Loss: 1.1685, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3175/10000, Loss: 1.1682, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3176/10000, Loss: 1.1679, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3177/10000, Loss: 1.1676, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3178/10000, Loss: 1.1673, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3179/10000, Loss: 1.1671, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3180/10000, Loss: 1.1668, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3181/10000, Loss: 1.1665, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3182/10000, Loss: 1.1662, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3183/10000, Loss: 1.1659, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3184/10000, Loss: 1.1657, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3185/10000, Loss: 1.1654, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3186/10000, Loss: 1.1651, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3187/10000, Loss: 1.1648, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3188/10000, Loss: 1.1645, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3189/10000, Loss: 1.1643, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3190/10000, Loss: 1.1640, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3191/10000, Loss: 1.1637, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3192/10000, Loss: 1.1634, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3193/10000, Loss: 1.1631, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3194/10000, Loss: 1.1629, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3195/10000, Loss: 1.1626, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3196/10000, Loss: 1.1623, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3197/10000, Loss: 1.1620, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3198/10000, Loss: 1.1617, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3199/10000, Loss: 1.1615, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3200/10000, Loss: 1.1612, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3201/10000, Loss: 1.1609, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3202/10000, Loss: 1.1606, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3203/10000, Loss: 1.1604, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3204/10000, Loss: 1.1601, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3205/10000, Loss: 1.1598, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3206/10000, Loss: 1.1595, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3207/10000, Loss: 1.1592, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3208/10000, Loss: 1.1590, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3209/10000, Loss: 1.1587, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3210/10000, Loss: 1.1584, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3211/10000, Loss: 1.1581, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3212/10000, Loss: 1.1579, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3213/10000, Loss: 1.1576, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3214/10000, Loss: 1.1573, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3215/10000, Loss: 1.1570, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3216/10000, Loss: 1.1568, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3217/10000, Loss: 1.1565, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3218/10000, Loss: 1.1562, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3219/10000, Loss: 1.1560, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3220/10000, Loss: 1.1557, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3221/10000, Loss: 1.1554, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3222/10000, Loss: 1.1551, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3223/10000, Loss: 1.1549, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3224/10000, Loss: 1.1546, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3225/10000, Loss: 1.1543, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3226/10000, Loss: 1.1540, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3227/10000, Loss: 1.1538, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3228/10000, Loss: 1.1535, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3229/10000, Loss: 1.1532, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3230/10000, Loss: 1.1530, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3231/10000, Loss: 1.1527, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3232/10000, Loss: 1.1524, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3233/10000, Loss: 1.1521, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3234/10000, Loss: 1.1519, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3235/10000, Loss: 1.1516, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3236/10000, Loss: 1.1513, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3237/10000, Loss: 1.1511, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3238/10000, Loss: 1.1508, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3239/10000, Loss: 1.1505, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3240/10000, Loss: 1.1503, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3241/10000, Loss: 1.1500, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3242/10000, Loss: 1.1497, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3243/10000, Loss: 1.1494, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3244/10000, Loss: 1.1492, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3245/10000, Loss: 1.1489, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3246/10000, Loss: 1.1486, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3247/10000, Loss: 1.1484, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3248/10000, Loss: 1.1481, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3249/10000, Loss: 1.1478, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3250/10000, Loss: 1.1476, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3251/10000, Loss: 1.1473, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3252/10000, Loss: 1.1470, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3253/10000, Loss: 1.1468, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3254/10000, Loss: 1.1465, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3255/10000, Loss: 1.1462, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3256/10000, Loss: 1.1460, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3257/10000, Loss: 1.1457, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3258/10000, Loss: 1.1454, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3259/10000, Loss: 1.1452, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3260/10000, Loss: 1.1449, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3261/10000, Loss: 1.1446, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3262/10000, Loss: 1.1444, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3263/10000, Loss: 1.1441, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3264/10000, Loss: 1.1439, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3265/10000, Loss: 1.1436, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3266/10000, Loss: 1.1433, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3267/10000, Loss: 1.1431, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3268/10000, Loss: 1.1428, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3269/10000, Loss: 1.1425, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3270/10000, Loss: 1.1423, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3271/10000, Loss: 1.1420, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3272/10000, Loss: 1.1417, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3273/10000, Loss: 1.1415, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3274/10000, Loss: 1.1412, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3275/10000, Loss: 1.1410, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3276/10000, Loss: 1.1407, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3277/10000, Loss: 1.1404, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3278/10000, Loss: 1.1402, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3279/10000, Loss: 1.1399, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3280/10000, Loss: 1.1397, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3281/10000, Loss: 1.1394, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3282/10000, Loss: 1.1391, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3283/10000, Loss: 1.1389, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3284/10000, Loss: 1.1386, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3285/10000, Loss: 1.1384, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3286/10000, Loss: 1.1381, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3287/10000, Loss: 1.1378, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3288/10000, Loss: 1.1376, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3289/10000, Loss: 1.1373, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3290/10000, Loss: 1.1371, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3291/10000, Loss: 1.1368, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3292/10000, Loss: 1.1365, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3293/10000, Loss: 1.1363, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3294/10000, Loss: 1.1360, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3295/10000, Loss: 1.1358, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3296/10000, Loss: 1.1355, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3297/10000, Loss: 1.1352, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3298/10000, Loss: 1.1350, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3299/10000, Loss: 1.1347, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3300/10000, Loss: 1.1345, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3301/10000, Loss: 1.1342, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3302/10000, Loss: 1.1340, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3303/10000, Loss: 1.1337, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3304/10000, Loss: 1.1334, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3305/10000, Loss: 1.1332, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3306/10000, Loss: 1.1329, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3307/10000, Loss: 1.1327, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3308/10000, Loss: 1.1324, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3309/10000, Loss: 1.1322, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3310/10000, Loss: 1.1319, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3311/10000, Loss: 1.1317, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3312/10000, Loss: 1.1314, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3313/10000, Loss: 1.1311, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3314/10000, Loss: 1.1309, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3315/10000, Loss: 1.1306, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3316/10000, Loss: 1.1304, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3317/10000, Loss: 1.1301, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3318/10000, Loss: 1.1299, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3319/10000, Loss: 1.1296, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3320/10000, Loss: 1.1294, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3321/10000, Loss: 1.1291, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3322/10000, Loss: 1.1289, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3323/10000, Loss: 1.1286, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3324/10000, Loss: 1.1284, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3325/10000, Loss: 1.1281, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3326/10000, Loss: 1.1279, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3327/10000, Loss: 1.1276, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3328/10000, Loss: 1.1274, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3329/10000, Loss: 1.1271, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3330/10000, Loss: 1.1268, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3331/10000, Loss: 1.1266, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3332/10000, Loss: 1.1263, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3333/10000, Loss: 1.1261, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3334/10000, Loss: 1.1258, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3335/10000, Loss: 1.1256, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3336/10000, Loss: 1.1253, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3337/10000, Loss: 1.1251, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3338/10000, Loss: 1.1248, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3339/10000, Loss: 1.1246, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3340/10000, Loss: 1.1243, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3341/10000, Loss: 1.1241, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3342/10000, Loss: 1.1238, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3343/10000, Loss: 1.1236, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3344/10000, Loss: 1.1233, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3345/10000, Loss: 1.1231, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3346/10000, Loss: 1.1229, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3347/10000, Loss: 1.1226, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3348/10000, Loss: 1.1224, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3349/10000, Loss: 1.1221, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3350/10000, Loss: 1.1219, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3351/10000, Loss: 1.1216, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3352/10000, Loss: 1.1214, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3353/10000, Loss: 1.1211, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3354/10000, Loss: 1.1209, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3355/10000, Loss: 1.1206, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3356/10000, Loss: 1.1204, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3357/10000, Loss: 1.1201, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3358/10000, Loss: 1.1199, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3359/10000, Loss: 1.1196, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3360/10000, Loss: 1.1194, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3361/10000, Loss: 1.1191, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3362/10000, Loss: 1.1189, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3363/10000, Loss: 1.1187, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3364/10000, Loss: 1.1184, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3365/10000, Loss: 1.1182, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3366/10000, Loss: 1.1179, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3367/10000, Loss: 1.1177, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3368/10000, Loss: 1.1174, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3369/10000, Loss: 1.1172, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3370/10000, Loss: 1.1169, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3371/10000, Loss: 1.1167, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3372/10000, Loss: 1.1165, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3373/10000, Loss: 1.1162, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3374/10000, Loss: 1.1160, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3375/10000, Loss: 1.1157, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3376/10000, Loss: 1.1155, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3377/10000, Loss: 1.1152, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3378/10000, Loss: 1.1150, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3379/10000, Loss: 1.1148, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3380/10000, Loss: 1.1145, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3381/10000, Loss: 1.1143, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3382/10000, Loss: 1.1140, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3383/10000, Loss: 1.1138, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3384/10000, Loss: 1.1136, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3385/10000, Loss: 1.1133, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3386/10000, Loss: 1.1131, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3387/10000, Loss: 1.1128, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3388/10000, Loss: 1.1126, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3389/10000, Loss: 1.1123, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3390/10000, Loss: 1.1121, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3391/10000, Loss: 1.1119, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3392/10000, Loss: 1.1116, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3393/10000, Loss: 1.1114, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3394/10000, Loss: 1.1111, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3395/10000, Loss: 1.1109, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3396/10000, Loss: 1.1107, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3397/10000, Loss: 1.1104, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3398/10000, Loss: 1.1102, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3399/10000, Loss: 1.1100, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3400/10000, Loss: 1.1097, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3401/10000, Loss: 1.1095, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3402/10000, Loss: 1.1092, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3403/10000, Loss: 1.1090, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3404/10000, Loss: 1.1088, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3405/10000, Loss: 1.1085, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3406/10000, Loss: 1.1083, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3407/10000, Loss: 1.1081, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3408/10000, Loss: 1.1078, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3409/10000, Loss: 1.1076, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3410/10000, Loss: 1.1073, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3411/10000, Loss: 1.1071, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3412/10000, Loss: 1.1069, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3413/10000, Loss: 1.1066, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3414/10000, Loss: 1.1064, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3415/10000, Loss: 1.1062, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3416/10000, Loss: 1.1059, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3417/10000, Loss: 1.1057, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3418/10000, Loss: 1.1055, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3419/10000, Loss: 1.1052, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3420/10000, Loss: 1.1050, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3421/10000, Loss: 1.1047, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3422/10000, Loss: 1.1045, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3423/10000, Loss: 1.1043, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3424/10000, Loss: 1.1040, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3425/10000, Loss: 1.1038, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3426/10000, Loss: 1.1036, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3427/10000, Loss: 1.1033, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3428/10000, Loss: 1.1031, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3429/10000, Loss: 1.1029, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3430/10000, Loss: 1.1026, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3431/10000, Loss: 1.1024, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3432/10000, Loss: 1.1022, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3433/10000, Loss: 1.1019, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3434/10000, Loss: 1.1017, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3435/10000, Loss: 1.1015, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3436/10000, Loss: 1.1013, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3437/10000, Loss: 1.1010, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3438/10000, Loss: 1.1008, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3439/10000, Loss: 1.1006, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3440/10000, Loss: 1.1003, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3441/10000, Loss: 1.1001, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3442/10000, Loss: 1.0999, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3443/10000, Loss: 1.0996, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3444/10000, Loss: 1.0994, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3445/10000, Loss: 1.0992, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3446/10000, Loss: 1.0989, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3447/10000, Loss: 1.0987, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3448/10000, Loss: 1.0985, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3449/10000, Loss: 1.0982, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3450/10000, Loss: 1.0980, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3451/10000, Loss: 1.0978, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3452/10000, Loss: 1.0976, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 3453/10000, Loss: 1.0973, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3454/10000, Loss: 1.0971, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3455/10000, Loss: 1.0969, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3456/10000, Loss: 1.0966, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3457/10000, Loss: 1.0964, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3458/10000, Loss: 1.0962, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3459/10000, Loss: 1.0960, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3460/10000, Loss: 1.0957, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3461/10000, Loss: 1.0955, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3462/10000, Loss: 1.0953, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3463/10000, Loss: 1.0951, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3464/10000, Loss: 1.0948, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3465/10000, Loss: 1.0946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3466/10000, Loss: 1.0944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3467/10000, Loss: 1.0941, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3468/10000, Loss: 1.0939, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3469/10000, Loss: 1.0937, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3470/10000, Loss: 1.0935, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3471/10000, Loss: 1.0932, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3472/10000, Loss: 1.0930, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3473/10000, Loss: 1.0928, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3474/10000, Loss: 1.0926, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3475/10000, Loss: 1.0923, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3476/10000, Loss: 1.0921, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3477/10000, Loss: 1.0919, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3478/10000, Loss: 1.0917, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3479/10000, Loss: 1.0914, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3480/10000, Loss: 1.0912, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3481/10000, Loss: 1.0910, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3482/10000, Loss: 1.0908, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3483/10000, Loss: 1.0905, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3484/10000, Loss: 1.0903, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3485/10000, Loss: 1.0901, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3486/10000, Loss: 1.0899, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3487/10000, Loss: 1.0896, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3488/10000, Loss: 1.0894, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3489/10000, Loss: 1.0892, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3490/10000, Loss: 1.0890, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3491/10000, Loss: 1.0888, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3492/10000, Loss: 1.0885, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3493/10000, Loss: 1.0883, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3494/10000, Loss: 1.0881, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3495/10000, Loss: 1.0879, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3496/10000, Loss: 1.0876, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3497/10000, Loss: 1.0874, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3498/10000, Loss: 1.0872, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3499/10000, Loss: 1.0870, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3500/10000, Loss: 1.0868, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3501/10000, Loss: 1.0865, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3502/10000, Loss: 1.0863, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3503/10000, Loss: 1.0861, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3504/10000, Loss: 1.0859, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3505/10000, Loss: 1.0857, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3506/10000, Loss: 1.0854, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3507/10000, Loss: 1.0852, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3508/10000, Loss: 1.0850, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3509/10000, Loss: 1.0848, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3510/10000, Loss: 1.0846, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3511/10000, Loss: 1.0843, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3512/10000, Loss: 1.0841, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3513/10000, Loss: 1.0839, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3514/10000, Loss: 1.0837, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3515/10000, Loss: 1.0835, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3516/10000, Loss: 1.0832, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3517/10000, Loss: 1.0830, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3518/10000, Loss: 1.0828, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3519/10000, Loss: 1.0826, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3520/10000, Loss: 1.0824, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3521/10000, Loss: 1.0822, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3522/10000, Loss: 1.0819, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3523/10000, Loss: 1.0817, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3524/10000, Loss: 1.0815, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3525/10000, Loss: 1.0813, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3526/10000, Loss: 1.0811, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3527/10000, Loss: 1.0809, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3528/10000, Loss: 1.0806, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3529/10000, Loss: 1.0804, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3530/10000, Loss: 1.0802, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3531/10000, Loss: 1.0800, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3532/10000, Loss: 1.0798, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3533/10000, Loss: 1.0796, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3534/10000, Loss: 1.0793, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3535/10000, Loss: 1.0791, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3536/10000, Loss: 1.0789, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3537/10000, Loss: 1.0787, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3538/10000, Loss: 1.0785, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3539/10000, Loss: 1.0783, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3540/10000, Loss: 1.0780, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3541/10000, Loss: 1.0778, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3542/10000, Loss: 1.0776, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3543/10000, Loss: 1.0774, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3544/10000, Loss: 1.0772, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3545/10000, Loss: 1.0770, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3546/10000, Loss: 1.0768, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3547/10000, Loss: 1.0766, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3548/10000, Loss: 1.0763, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3549/10000, Loss: 1.0761, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3550/10000, Loss: 1.0759, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3551/10000, Loss: 1.0757, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3552/10000, Loss: 1.0755, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3553/10000, Loss: 1.0753, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3554/10000, Loss: 1.0751, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3555/10000, Loss: 1.0749, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3556/10000, Loss: 1.0746, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3557/10000, Loss: 1.0744, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3558/10000, Loss: 1.0742, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3559/10000, Loss: 1.0740, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3560/10000, Loss: 1.0738, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3561/10000, Loss: 1.0736, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3562/10000, Loss: 1.0734, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3563/10000, Loss: 1.0732, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3564/10000, Loss: 1.0729, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3565/10000, Loss: 1.0727, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3566/10000, Loss: 1.0725, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3567/10000, Loss: 1.0723, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3568/10000, Loss: 1.0721, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3569/10000, Loss: 1.0719, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3570/10000, Loss: 1.0717, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3571/10000, Loss: 1.0715, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3572/10000, Loss: 1.0713, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3573/10000, Loss: 1.0711, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3574/10000, Loss: 1.0708, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3575/10000, Loss: 1.0706, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3576/10000, Loss: 1.0704, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3577/10000, Loss: 1.0702, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3578/10000, Loss: 1.0700, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3579/10000, Loss: 1.0698, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3580/10000, Loss: 1.0696, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3581/10000, Loss: 1.0694, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3582/10000, Loss: 1.0692, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3583/10000, Loss: 1.0690, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3584/10000, Loss: 1.0688, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3585/10000, Loss: 1.0686, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3586/10000, Loss: 1.0684, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3587/10000, Loss: 1.0681, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3588/10000, Loss: 1.0679, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3589/10000, Loss: 1.0677, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3590/10000, Loss: 1.0675, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3591/10000, Loss: 1.0673, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3592/10000, Loss: 1.0671, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3593/10000, Loss: 1.0669, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3594/10000, Loss: 1.0667, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3595/10000, Loss: 1.0665, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3596/10000, Loss: 1.0663, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3597/10000, Loss: 1.0661, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3598/10000, Loss: 1.0659, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3599/10000, Loss: 1.0657, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3600/10000, Loss: 1.0655, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3601/10000, Loss: 1.0653, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3602/10000, Loss: 1.0651, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3603/10000, Loss: 1.0649, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3604/10000, Loss: 1.0646, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3605/10000, Loss: 1.0644, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3606/10000, Loss: 1.0642, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3607/10000, Loss: 1.0640, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3608/10000, Loss: 1.0638, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3609/10000, Loss: 1.0636, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3610/10000, Loss: 1.0634, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3611/10000, Loss: 1.0632, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3612/10000, Loss: 1.0630, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3613/10000, Loss: 1.0628, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3614/10000, Loss: 1.0626, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3615/10000, Loss: 1.0624, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3616/10000, Loss: 1.0622, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3617/10000, Loss: 1.0620, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3618/10000, Loss: 1.0618, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3619/10000, Loss: 1.0616, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3620/10000, Loss: 1.0614, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3621/10000, Loss: 1.0612, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3622/10000, Loss: 1.0610, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3623/10000, Loss: 1.0608, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3624/10000, Loss: 1.0606, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3625/10000, Loss: 1.0604, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3626/10000, Loss: 1.0602, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3627/10000, Loss: 1.0600, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3628/10000, Loss: 1.0598, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3629/10000, Loss: 1.0596, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3630/10000, Loss: 1.0594, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3631/10000, Loss: 1.0592, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3632/10000, Loss: 1.0590, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3633/10000, Loss: 1.0588, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3634/10000, Loss: 1.0586, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3635/10000, Loss: 1.0584, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3636/10000, Loss: 1.0582, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3637/10000, Loss: 1.0580, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3638/10000, Loss: 1.0578, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3639/10000, Loss: 1.0576, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3640/10000, Loss: 1.0574, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3641/10000, Loss: 1.0572, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3642/10000, Loss: 1.0570, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3643/10000, Loss: 1.0568, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3644/10000, Loss: 1.0566, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3645/10000, Loss: 1.0564, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3646/10000, Loss: 1.0562, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3647/10000, Loss: 1.0560, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3648/10000, Loss: 1.0558, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3649/10000, Loss: 1.0556, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3650/10000, Loss: 1.0554, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3651/10000, Loss: 1.0552, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3652/10000, Loss: 1.0550, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3653/10000, Loss: 1.0548, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3654/10000, Loss: 1.0546, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3655/10000, Loss: 1.0544, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3656/10000, Loss: 1.0542, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3657/10000, Loss: 1.0540, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3658/10000, Loss: 1.0538, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3659/10000, Loss: 1.0536, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3660/10000, Loss: 1.0534, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3661/10000, Loss: 1.0532, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3662/10000, Loss: 1.0530, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3663/10000, Loss: 1.0528, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3664/10000, Loss: 1.0527, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3665/10000, Loss: 1.0525, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3666/10000, Loss: 1.0523, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3667/10000, Loss: 1.0521, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3668/10000, Loss: 1.0519, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3669/10000, Loss: 1.0517, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3670/10000, Loss: 1.0515, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3671/10000, Loss: 1.0513, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3672/10000, Loss: 1.0511, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3673/10000, Loss: 1.0509, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3674/10000, Loss: 1.0507, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3675/10000, Loss: 1.0505, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3676/10000, Loss: 1.0503, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3677/10000, Loss: 1.0501, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3678/10000, Loss: 1.0499, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3679/10000, Loss: 1.0497, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3680/10000, Loss: 1.0495, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3681/10000, Loss: 1.0493, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3682/10000, Loss: 1.0492, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3683/10000, Loss: 1.0490, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3684/10000, Loss: 1.0488, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3685/10000, Loss: 1.0486, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3686/10000, Loss: 1.0484, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3687/10000, Loss: 1.0482, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3688/10000, Loss: 1.0480, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3689/10000, Loss: 1.0478, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3690/10000, Loss: 1.0476, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3691/10000, Loss: 1.0474, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3692/10000, Loss: 1.0472, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3693/10000, Loss: 1.0470, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3694/10000, Loss: 1.0468, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3695/10000, Loss: 1.0467, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3696/10000, Loss: 1.0465, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3697/10000, Loss: 1.0463, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3698/10000, Loss: 1.0461, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3699/10000, Loss: 1.0459, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3700/10000, Loss: 1.0457, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3701/10000, Loss: 1.0455, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3702/10000, Loss: 1.0453, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3703/10000, Loss: 1.0451, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3704/10000, Loss: 1.0449, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3705/10000, Loss: 1.0448, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3706/10000, Loss: 1.0446, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3707/10000, Loss: 1.0444, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3708/10000, Loss: 1.0442, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3709/10000, Loss: 1.0440, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3710/10000, Loss: 1.0438, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3711/10000, Loss: 1.0436, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3712/10000, Loss: 1.0434, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3713/10000, Loss: 1.0432, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3714/10000, Loss: 1.0431, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3715/10000, Loss: 1.0429, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3716/10000, Loss: 1.0427, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3717/10000, Loss: 1.0425, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3718/10000, Loss: 1.0423, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3719/10000, Loss: 1.0421, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3720/10000, Loss: 1.0419, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3721/10000, Loss: 1.0417, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3722/10000, Loss: 1.0416, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3723/10000, Loss: 1.0414, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3724/10000, Loss: 1.0412, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3725/10000, Loss: 1.0410, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3726/10000, Loss: 1.0408, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3727/10000, Loss: 1.0406, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3728/10000, Loss: 1.0404, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3729/10000, Loss: 1.0402, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3730/10000, Loss: 1.0401, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3731/10000, Loss: 1.0399, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3732/10000, Loss: 1.0397, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3733/10000, Loss: 1.0395, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3734/10000, Loss: 1.0393, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3735/10000, Loss: 1.0391, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3736/10000, Loss: 1.0389, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3737/10000, Loss: 1.0388, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3738/10000, Loss: 1.0386, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3739/10000, Loss: 1.0384, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3740/10000, Loss: 1.0382, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3741/10000, Loss: 1.0380, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3742/10000, Loss: 1.0378, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3743/10000, Loss: 1.0376, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3744/10000, Loss: 1.0375, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3745/10000, Loss: 1.0373, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3746/10000, Loss: 1.0371, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3747/10000, Loss: 1.0369, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3748/10000, Loss: 1.0367, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3749/10000, Loss: 1.0365, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3750/10000, Loss: 1.0364, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3751/10000, Loss: 1.0362, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3752/10000, Loss: 1.0360, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3753/10000, Loss: 1.0358, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3754/10000, Loss: 1.0356, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3755/10000, Loss: 1.0354, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3756/10000, Loss: 1.0353, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3757/10000, Loss: 1.0351, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3758/10000, Loss: 1.0349, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3759/10000, Loss: 1.0347, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3760/10000, Loss: 1.0345, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3761/10000, Loss: 1.0344, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3762/10000, Loss: 1.0342, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3763/10000, Loss: 1.0340, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3764/10000, Loss: 1.0338, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3765/10000, Loss: 1.0336, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3766/10000, Loss: 1.0334, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3767/10000, Loss: 1.0333, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3768/10000, Loss: 1.0331, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3769/10000, Loss: 1.0329, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3770/10000, Loss: 1.0327, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3771/10000, Loss: 1.0325, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3772/10000, Loss: 1.0324, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3773/10000, Loss: 1.0322, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3774/10000, Loss: 1.0320, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3775/10000, Loss: 1.0318, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3776/10000, Loss: 1.0316, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3777/10000, Loss: 1.0315, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3778/10000, Loss: 1.0313, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3779/10000, Loss: 1.0311, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3780/10000, Loss: 1.0309, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3781/10000, Loss: 1.0307, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3782/10000, Loss: 1.0306, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3783/10000, Loss: 1.0304, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3784/10000, Loss: 1.0302, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3785/10000, Loss: 1.0300, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3786/10000, Loss: 1.0298, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3787/10000, Loss: 1.0297, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3788/10000, Loss: 1.0295, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3789/10000, Loss: 1.0293, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3790/10000, Loss: 1.0291, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3791/10000, Loss: 1.0290, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3792/10000, Loss: 1.0288, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3793/10000, Loss: 1.0286, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3794/10000, Loss: 1.0284, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3795/10000, Loss: 1.0282, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3796/10000, Loss: 1.0281, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3797/10000, Loss: 1.0279, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3798/10000, Loss: 1.0277, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3799/10000, Loss: 1.0275, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3800/10000, Loss: 1.0274, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3801/10000, Loss: 1.0272, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3802/10000, Loss: 1.0270, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3803/10000, Loss: 1.0268, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3804/10000, Loss: 1.0266, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3805/10000, Loss: 1.0265, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3806/10000, Loss: 1.0263, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3807/10000, Loss: 1.0261, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3808/10000, Loss: 1.0259, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3809/10000, Loss: 1.0258, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3810/10000, Loss: 1.0256, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3811/10000, Loss: 1.0254, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3812/10000, Loss: 1.0252, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3813/10000, Loss: 1.0251, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3814/10000, Loss: 1.0249, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3815/10000, Loss: 1.0247, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3816/10000, Loss: 1.0245, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3817/10000, Loss: 1.0244, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3818/10000, Loss: 1.0242, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3819/10000, Loss: 1.0240, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3820/10000, Loss: 1.0238, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3821/10000, Loss: 1.0237, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3822/10000, Loss: 1.0235, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3823/10000, Loss: 1.0233, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3824/10000, Loss: 1.0231, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3825/10000, Loss: 1.0230, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3826/10000, Loss: 1.0228, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3827/10000, Loss: 1.0226, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3828/10000, Loss: 1.0225, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3829/10000, Loss: 1.0223, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3830/10000, Loss: 1.0221, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3831/10000, Loss: 1.0219, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3832/10000, Loss: 1.0218, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3833/10000, Loss: 1.0216, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3834/10000, Loss: 1.0214, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3835/10000, Loss: 1.0212, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3836/10000, Loss: 1.0211, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3837/10000, Loss: 1.0209, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3838/10000, Loss: 1.0207, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3839/10000, Loss: 1.0206, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3840/10000, Loss: 1.0204, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3841/10000, Loss: 1.0202, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3842/10000, Loss: 1.0200, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3843/10000, Loss: 1.0199, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3844/10000, Loss: 1.0197, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3845/10000, Loss: 1.0195, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3846/10000, Loss: 1.0194, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3847/10000, Loss: 1.0192, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3848/10000, Loss: 1.0190, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3849/10000, Loss: 1.0188, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3850/10000, Loss: 1.0187, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3851/10000, Loss: 1.0185, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3852/10000, Loss: 1.0183, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3853/10000, Loss: 1.0182, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3854/10000, Loss: 1.0180, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3855/10000, Loss: 1.0178, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3856/10000, Loss: 1.0177, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3857/10000, Loss: 1.0175, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3858/10000, Loss: 1.0173, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3859/10000, Loss: 1.0171, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3860/10000, Loss: 1.0170, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3861/10000, Loss: 1.0168, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3862/10000, Loss: 1.0166, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3863/10000, Loss: 1.0165, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3864/10000, Loss: 1.0163, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3865/10000, Loss: 1.0161, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3866/10000, Loss: 1.0160, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3867/10000, Loss: 1.0158, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3868/10000, Loss: 1.0156, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3869/10000, Loss: 1.0155, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3870/10000, Loss: 1.0153, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3871/10000, Loss: 1.0151, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3872/10000, Loss: 1.0150, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3873/10000, Loss: 1.0148, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3874/10000, Loss: 1.0146, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3875/10000, Loss: 1.0145, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3876/10000, Loss: 1.0143, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3877/10000, Loss: 1.0141, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3878/10000, Loss: 1.0139, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3879/10000, Loss: 1.0138, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3880/10000, Loss: 1.0136, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3881/10000, Loss: 1.0134, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3882/10000, Loss: 1.0133, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3883/10000, Loss: 1.0131, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3884/10000, Loss: 1.0129, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3885/10000, Loss: 1.0128, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3886/10000, Loss: 1.0126, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3887/10000, Loss: 1.0125, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3888/10000, Loss: 1.0123, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3889/10000, Loss: 1.0121, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3890/10000, Loss: 1.0120, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3891/10000, Loss: 1.0118, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3892/10000, Loss: 1.0116, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3893/10000, Loss: 1.0115, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3894/10000, Loss: 1.0113, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3895/10000, Loss: 1.0111, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3896/10000, Loss: 1.0110, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3897/10000, Loss: 1.0108, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3898/10000, Loss: 1.0106, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3899/10000, Loss: 1.0105, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3900/10000, Loss: 1.0103, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3901/10000, Loss: 1.0101, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3902/10000, Loss: 1.0100, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3903/10000, Loss: 1.0098, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3904/10000, Loss: 1.0096, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3905/10000, Loss: 1.0095, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3906/10000, Loss: 1.0093, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3907/10000, Loss: 1.0092, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3908/10000, Loss: 1.0090, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3909/10000, Loss: 1.0088, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3910/10000, Loss: 1.0087, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3911/10000, Loss: 1.0085, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3912/10000, Loss: 1.0083, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3913/10000, Loss: 1.0082, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3914/10000, Loss: 1.0080, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3915/10000, Loss: 1.0079, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3916/10000, Loss: 1.0077, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3917/10000, Loss: 1.0075, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3918/10000, Loss: 1.0074, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3919/10000, Loss: 1.0072, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3920/10000, Loss: 1.0070, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3921/10000, Loss: 1.0069, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3922/10000, Loss: 1.0067, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3923/10000, Loss: 1.0066, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3924/10000, Loss: 1.0064, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3925/10000, Loss: 1.0062, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3926/10000, Loss: 1.0061, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3927/10000, Loss: 1.0059, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3928/10000, Loss: 1.0057, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3929/10000, Loss: 1.0056, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3930/10000, Loss: 1.0054, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3931/10000, Loss: 1.0053, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3932/10000, Loss: 1.0051, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3933/10000, Loss: 1.0049, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3934/10000, Loss: 1.0048, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3935/10000, Loss: 1.0046, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3936/10000, Loss: 1.0045, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3937/10000, Loss: 1.0043, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3938/10000, Loss: 1.0041, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3939/10000, Loss: 1.0040, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3940/10000, Loss: 1.0038, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3941/10000, Loss: 1.0037, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3942/10000, Loss: 1.0035, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3943/10000, Loss: 1.0033, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3944/10000, Loss: 1.0032, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3945/10000, Loss: 1.0030, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3946/10000, Loss: 1.0029, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3947/10000, Loss: 1.0027, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3948/10000, Loss: 1.0025, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3949/10000, Loss: 1.0024, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3950/10000, Loss: 1.0022, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3951/10000, Loss: 1.0021, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3952/10000, Loss: 1.0019, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3953/10000, Loss: 1.0018, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3954/10000, Loss: 1.0016, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3955/10000, Loss: 1.0014, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3956/10000, Loss: 1.0013, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3957/10000, Loss: 1.0011, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3958/10000, Loss: 1.0010, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3959/10000, Loss: 1.0008, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3960/10000, Loss: 1.0006, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3961/10000, Loss: 1.0005, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3962/10000, Loss: 1.0003, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3963/10000, Loss: 1.0002, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3964/10000, Loss: 1.0000, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3965/10000, Loss: 0.9999, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3966/10000, Loss: 0.9997, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3967/10000, Loss: 0.9995, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3968/10000, Loss: 0.9994, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3969/10000, Loss: 0.9992, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3970/10000, Loss: 0.9991, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3971/10000, Loss: 0.9989, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3972/10000, Loss: 0.9988, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3973/10000, Loss: 0.9986, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3974/10000, Loss: 0.9985, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3975/10000, Loss: 0.9983, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3976/10000, Loss: 0.9981, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3977/10000, Loss: 0.9980, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3978/10000, Loss: 0.9978, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3979/10000, Loss: 0.9977, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3980/10000, Loss: 0.9975, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3981/10000, Loss: 0.9974, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3982/10000, Loss: 0.9972, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3983/10000, Loss: 0.9971, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3984/10000, Loss: 0.9969, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3985/10000, Loss: 0.9967, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3986/10000, Loss: 0.9966, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3987/10000, Loss: 0.9964, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3988/10000, Loss: 0.9963, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3989/10000, Loss: 0.9961, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3990/10000, Loss: 0.9960, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3991/10000, Loss: 0.9958, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3992/10000, Loss: 0.9957, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3993/10000, Loss: 0.9955, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3994/10000, Loss: 0.9954, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3995/10000, Loss: 0.9952, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3996/10000, Loss: 0.9951, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3997/10000, Loss: 0.9949, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 3998/10000, Loss: 0.9947, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 3999/10000, Loss: 0.9946, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4000/10000, Loss: 0.9944, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4001/10000, Loss: 0.9943, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4002/10000, Loss: 0.9941, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4003/10000, Loss: 0.9940, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4004/10000, Loss: 0.9938, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4005/10000, Loss: 0.9937, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4006/10000, Loss: 0.9935, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4007/10000, Loss: 0.9934, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4008/10000, Loss: 0.9932, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4009/10000, Loss: 0.9931, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4010/10000, Loss: 0.9929, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4011/10000, Loss: 0.9928, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4012/10000, Loss: 0.9926, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4013/10000, Loss: 0.9925, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4014/10000, Loss: 0.9923, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4015/10000, Loss: 0.9922, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4016/10000, Loss: 0.9920, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4017/10000, Loss: 0.9919, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4018/10000, Loss: 0.9917, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4019/10000, Loss: 0.9916, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4020/10000, Loss: 0.9914, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4021/10000, Loss: 0.9913, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4022/10000, Loss: 0.9911, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4023/10000, Loss: 0.9909, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4024/10000, Loss: 0.9908, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4025/10000, Loss: 0.9906, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4026/10000, Loss: 0.9905, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4027/10000, Loss: 0.9903, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4028/10000, Loss: 0.9902, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4029/10000, Loss: 0.9900, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4030/10000, Loss: 0.9899, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4031/10000, Loss: 0.9897, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4032/10000, Loss: 0.9896, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4033/10000, Loss: 0.9894, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4034/10000, Loss: 0.9893, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4035/10000, Loss: 0.9892, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4036/10000, Loss: 0.9890, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4037/10000, Loss: 0.9889, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4038/10000, Loss: 0.9887, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4039/10000, Loss: 0.9886, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4040/10000, Loss: 0.9884, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4041/10000, Loss: 0.9883, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4042/10000, Loss: 0.9881, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4043/10000, Loss: 0.9880, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4044/10000, Loss: 0.9878, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4045/10000, Loss: 0.9877, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4046/10000, Loss: 0.9875, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4047/10000, Loss: 0.9874, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4048/10000, Loss: 0.9872, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4049/10000, Loss: 0.9871, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4050/10000, Loss: 0.9869, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4051/10000, Loss: 0.9868, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4052/10000, Loss: 0.9866, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4053/10000, Loss: 0.9865, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4054/10000, Loss: 0.9863, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4055/10000, Loss: 0.9862, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4056/10000, Loss: 0.9860, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4057/10000, Loss: 0.9859, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4058/10000, Loss: 0.9857, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4059/10000, Loss: 0.9856, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4060/10000, Loss: 0.9855, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4061/10000, Loss: 0.9853, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4062/10000, Loss: 0.9852, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4063/10000, Loss: 0.9850, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4064/10000, Loss: 0.9849, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4065/10000, Loss: 0.9847, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4066/10000, Loss: 0.9846, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4067/10000, Loss: 0.9844, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4068/10000, Loss: 0.9843, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4069/10000, Loss: 0.9841, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4070/10000, Loss: 0.9840, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4071/10000, Loss: 0.9838, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4072/10000, Loss: 0.9837, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4073/10000, Loss: 0.9836, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4074/10000, Loss: 0.9834, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4075/10000, Loss: 0.9833, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4076/10000, Loss: 0.9831, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4077/10000, Loss: 0.9830, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4078/10000, Loss: 0.9828, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4079/10000, Loss: 0.9827, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4080/10000, Loss: 0.9825, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4081/10000, Loss: 0.9824, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4082/10000, Loss: 0.9823, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4083/10000, Loss: 0.9821, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4084/10000, Loss: 0.9820, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4085/10000, Loss: 0.9818, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4086/10000, Loss: 0.9817, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4087/10000, Loss: 0.9815, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4088/10000, Loss: 0.9814, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4089/10000, Loss: 0.9812, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4090/10000, Loss: 0.9811, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4091/10000, Loss: 0.9810, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4092/10000, Loss: 0.9808, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4093/10000, Loss: 0.9807, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4094/10000, Loss: 0.9805, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4095/10000, Loss: 0.9804, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4096/10000, Loss: 0.9802, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4097/10000, Loss: 0.9801, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4098/10000, Loss: 0.9800, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4099/10000, Loss: 0.9798, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4100/10000, Loss: 0.9797, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4101/10000, Loss: 0.9795, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4102/10000, Loss: 0.9794, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4103/10000, Loss: 0.9792, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4104/10000, Loss: 0.9791, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4105/10000, Loss: 0.9790, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4106/10000, Loss: 0.9788, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4107/10000, Loss: 0.9787, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4108/10000, Loss: 0.9785, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4109/10000, Loss: 0.9784, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4110/10000, Loss: 0.9782, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4111/10000, Loss: 0.9781, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4112/10000, Loss: 0.9780, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4113/10000, Loss: 0.9778, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4114/10000, Loss: 0.9777, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4115/10000, Loss: 0.9775, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4116/10000, Loss: 0.9774, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4117/10000, Loss: 0.9773, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4118/10000, Loss: 0.9771, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4119/10000, Loss: 0.9770, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4120/10000, Loss: 0.9768, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4121/10000, Loss: 0.9767, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4122/10000, Loss: 0.9766, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4123/10000, Loss: 0.9764, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4124/10000, Loss: 0.9763, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4125/10000, Loss: 0.9761, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4126/10000, Loss: 0.9760, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4127/10000, Loss: 0.9759, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4128/10000, Loss: 0.9757, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4129/10000, Loss: 0.9756, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4130/10000, Loss: 0.9754, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4131/10000, Loss: 0.9753, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4132/10000, Loss: 0.9752, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4133/10000, Loss: 0.9750, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4134/10000, Loss: 0.9749, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4135/10000, Loss: 0.9747, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4136/10000, Loss: 0.9746, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4137/10000, Loss: 0.9745, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4138/10000, Loss: 0.9743, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4139/10000, Loss: 0.9742, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4140/10000, Loss: 0.9740, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4141/10000, Loss: 0.9739, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4142/10000, Loss: 0.9738, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4143/10000, Loss: 0.9736, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4144/10000, Loss: 0.9735, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4145/10000, Loss: 0.9734, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4146/10000, Loss: 0.9732, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4147/10000, Loss: 0.9731, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4148/10000, Loss: 0.9729, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4149/10000, Loss: 0.9728, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4150/10000, Loss: 0.9727, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4151/10000, Loss: 0.9725, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4152/10000, Loss: 0.9724, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4153/10000, Loss: 0.9723, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4154/10000, Loss: 0.9721, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4155/10000, Loss: 0.9720, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4156/10000, Loss: 0.9718, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4157/10000, Loss: 0.9717, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4158/10000, Loss: 0.9716, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4159/10000, Loss: 0.9714, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4160/10000, Loss: 0.9713, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4161/10000, Loss: 0.9712, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4162/10000, Loss: 0.9710, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4163/10000, Loss: 0.9709, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4164/10000, Loss: 0.9707, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4165/10000, Loss: 0.9706, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4166/10000, Loss: 0.9705, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4167/10000, Loss: 0.9703, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4168/10000, Loss: 0.9702, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4169/10000, Loss: 0.9701, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4170/10000, Loss: 0.9699, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4171/10000, Loss: 0.9698, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4172/10000, Loss: 0.9697, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4173/10000, Loss: 0.9695, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4174/10000, Loss: 0.9694, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4175/10000, Loss: 0.9693, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4176/10000, Loss: 0.9691, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4177/10000, Loss: 0.9690, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4178/10000, Loss: 0.9688, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4179/10000, Loss: 0.9687, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4180/10000, Loss: 0.9686, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4181/10000, Loss: 0.9684, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4182/10000, Loss: 0.9683, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4183/10000, Loss: 0.9682, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4184/10000, Loss: 0.9680, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4185/10000, Loss: 0.9679, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4186/10000, Loss: 0.9678, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4187/10000, Loss: 0.9676, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4188/10000, Loss: 0.9675, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4189/10000, Loss: 0.9674, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4190/10000, Loss: 0.9672, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4191/10000, Loss: 0.9671, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4192/10000, Loss: 0.9670, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4193/10000, Loss: 0.9668, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4194/10000, Loss: 0.9667, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4195/10000, Loss: 0.9666, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4196/10000, Loss: 0.9664, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4197/10000, Loss: 0.9663, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4198/10000, Loss: 0.9662, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4199/10000, Loss: 0.9660, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4200/10000, Loss: 0.9659, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4201/10000, Loss: 0.9658, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4202/10000, Loss: 0.9656, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4203/10000, Loss: 0.9655, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4204/10000, Loss: 0.9654, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4205/10000, Loss: 0.9652, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4206/10000, Loss: 0.9651, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4207/10000, Loss: 0.9650, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4208/10000, Loss: 0.9648, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4209/10000, Loss: 0.9647, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4210/10000, Loss: 0.9646, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4211/10000, Loss: 0.9644, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4212/10000, Loss: 0.9643, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4213/10000, Loss: 0.9642, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4214/10000, Loss: 0.9640, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4215/10000, Loss: 0.9639, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4216/10000, Loss: 0.9638, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4217/10000, Loss: 0.9637, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4218/10000, Loss: 0.9635, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4219/10000, Loss: 0.9634, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4220/10000, Loss: 0.9633, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4221/10000, Loss: 0.9631, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4222/10000, Loss: 0.9630, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4223/10000, Loss: 0.9629, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4224/10000, Loss: 0.9627, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4225/10000, Loss: 0.9626, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4226/10000, Loss: 0.9625, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4227/10000, Loss: 0.9623, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4228/10000, Loss: 0.9622, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4229/10000, Loss: 0.9621, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4230/10000, Loss: 0.9619, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4231/10000, Loss: 0.9618, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4232/10000, Loss: 0.9617, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4233/10000, Loss: 0.9616, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4234/10000, Loss: 0.9614, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4235/10000, Loss: 0.9613, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4236/10000, Loss: 0.9612, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4237/10000, Loss: 0.9610, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4238/10000, Loss: 0.9609, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4239/10000, Loss: 0.9608, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4240/10000, Loss: 0.9607, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4241/10000, Loss: 0.9605, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4242/10000, Loss: 0.9604, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4243/10000, Loss: 0.9603, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4244/10000, Loss: 0.9601, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4245/10000, Loss: 0.9600, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4246/10000, Loss: 0.9599, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4247/10000, Loss: 0.9597, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4248/10000, Loss: 0.9596, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4249/10000, Loss: 0.9595, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4250/10000, Loss: 0.9594, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4251/10000, Loss: 0.9592, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4252/10000, Loss: 0.9591, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4253/10000, Loss: 0.9590, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4254/10000, Loss: 0.9588, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4255/10000, Loss: 0.9587, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4256/10000, Loss: 0.9586, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4257/10000, Loss: 0.9585, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4258/10000, Loss: 0.9583, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4259/10000, Loss: 0.9582, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4260/10000, Loss: 0.9581, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4261/10000, Loss: 0.9580, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4262/10000, Loss: 0.9578, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4263/10000, Loss: 0.9577, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4264/10000, Loss: 0.9576, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4265/10000, Loss: 0.9574, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4266/10000, Loss: 0.9573, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4267/10000, Loss: 0.9572, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4268/10000, Loss: 0.9571, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4269/10000, Loss: 0.9569, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4270/10000, Loss: 0.9568, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4271/10000, Loss: 0.9567, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4272/10000, Loss: 0.9566, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4273/10000, Loss: 0.9564, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4274/10000, Loss: 0.9563, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4275/10000, Loss: 0.9562, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4276/10000, Loss: 0.9561, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4277/10000, Loss: 0.9559, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4278/10000, Loss: 0.9558, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4279/10000, Loss: 0.9557, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4280/10000, Loss: 0.9555, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4281/10000, Loss: 0.9554, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4282/10000, Loss: 0.9553, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4283/10000, Loss: 0.9552, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4284/10000, Loss: 0.9550, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4285/10000, Loss: 0.9549, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4286/10000, Loss: 0.9548, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4287/10000, Loss: 0.9547, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4288/10000, Loss: 0.9545, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4289/10000, Loss: 0.9544, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4290/10000, Loss: 0.9543, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4291/10000, Loss: 0.9542, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4292/10000, Loss: 0.9540, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4293/10000, Loss: 0.9539, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4294/10000, Loss: 0.9538, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4295/10000, Loss: 0.9537, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4296/10000, Loss: 0.9535, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4297/10000, Loss: 0.9534, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4298/10000, Loss: 0.9533, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4299/10000, Loss: 0.9532, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4300/10000, Loss: 0.9530, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4301/10000, Loss: 0.9529, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4302/10000, Loss: 0.9528, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4303/10000, Loss: 0.9527, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4304/10000, Loss: 0.9525, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4305/10000, Loss: 0.9524, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4306/10000, Loss: 0.9523, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4307/10000, Loss: 0.9522, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4308/10000, Loss: 0.9521, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4309/10000, Loss: 0.9519, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4310/10000, Loss: 0.9518, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4311/10000, Loss: 0.9517, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4312/10000, Loss: 0.9516, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4313/10000, Loss: 0.9514, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4314/10000, Loss: 0.9513, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4315/10000, Loss: 0.9512, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4316/10000, Loss: 0.9511, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4317/10000, Loss: 0.9509, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4318/10000, Loss: 0.9508, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4319/10000, Loss: 0.9507, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4320/10000, Loss: 0.9506, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4321/10000, Loss: 0.9505, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4322/10000, Loss: 0.9503, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4323/10000, Loss: 0.9502, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4324/10000, Loss: 0.9501, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4325/10000, Loss: 0.9500, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4326/10000, Loss: 0.9498, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4327/10000, Loss: 0.9497, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4328/10000, Loss: 0.9496, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4329/10000, Loss: 0.9495, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 4330/10000, Loss: 0.9494, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4331/10000, Loss: 0.9492, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4332/10000, Loss: 0.9491, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4333/10000, Loss: 0.9490, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4334/10000, Loss: 0.9489, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4335/10000, Loss: 0.9487, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4336/10000, Loss: 0.9486, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4337/10000, Loss: 0.9485, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4338/10000, Loss: 0.9484, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4339/10000, Loss: 0.9483, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4340/10000, Loss: 0.9481, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4341/10000, Loss: 0.9480, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4342/10000, Loss: 0.9479, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4343/10000, Loss: 0.9478, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4344/10000, Loss: 0.9477, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4345/10000, Loss: 0.9475, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4346/10000, Loss: 0.9474, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4347/10000, Loss: 0.9473, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4348/10000, Loss: 0.9472, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4349/10000, Loss: 0.9471, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4350/10000, Loss: 0.9469, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4351/10000, Loss: 0.9468, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4352/10000, Loss: 0.9467, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4353/10000, Loss: 0.9466, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4354/10000, Loss: 0.9465, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4355/10000, Loss: 0.9463, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4356/10000, Loss: 0.9462, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4357/10000, Loss: 0.9461, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4358/10000, Loss: 0.9460, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4359/10000, Loss: 0.9459, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4360/10000, Loss: 0.9457, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4361/10000, Loss: 0.9456, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4362/10000, Loss: 0.9455, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4363/10000, Loss: 0.9454, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4364/10000, Loss: 0.9453, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4365/10000, Loss: 0.9451, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4366/10000, Loss: 0.9450, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4367/10000, Loss: 0.9449, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4368/10000, Loss: 0.9448, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4369/10000, Loss: 0.9447, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4370/10000, Loss: 0.9446, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4371/10000, Loss: 0.9444, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4372/10000, Loss: 0.9443, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4373/10000, Loss: 0.9442, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4374/10000, Loss: 0.9441, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4375/10000, Loss: 0.9440, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4376/10000, Loss: 0.9438, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4377/10000, Loss: 0.9437, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4378/10000, Loss: 0.9436, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4379/10000, Loss: 0.9435, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4380/10000, Loss: 0.9434, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4381/10000, Loss: 0.9433, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4382/10000, Loss: 0.9431, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4383/10000, Loss: 0.9430, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4384/10000, Loss: 0.9429, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4385/10000, Loss: 0.9428, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4386/10000, Loss: 0.9427, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4387/10000, Loss: 0.9425, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4388/10000, Loss: 0.9424, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4389/10000, Loss: 0.9423, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4390/10000, Loss: 0.9422, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4391/10000, Loss: 0.9421, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4392/10000, Loss: 0.9420, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4393/10000, Loss: 0.9418, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4394/10000, Loss: 0.9417, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4395/10000, Loss: 0.9416, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4396/10000, Loss: 0.9415, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4397/10000, Loss: 0.9414, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4398/10000, Loss: 0.9413, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4399/10000, Loss: 0.9411, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4400/10000, Loss: 0.9410, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4401/10000, Loss: 0.9409, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4402/10000, Loss: 0.9408, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4403/10000, Loss: 0.9407, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4404/10000, Loss: 0.9406, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4405/10000, Loss: 0.9405, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4406/10000, Loss: 0.9403, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4407/10000, Loss: 0.9402, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4408/10000, Loss: 0.9401, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4409/10000, Loss: 0.9400, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4410/10000, Loss: 0.9399, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4411/10000, Loss: 0.9398, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4412/10000, Loss: 0.9396, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4413/10000, Loss: 0.9395, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4414/10000, Loss: 0.9394, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4415/10000, Loss: 0.9393, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4416/10000, Loss: 0.9392, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4417/10000, Loss: 0.9391, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4418/10000, Loss: 0.9390, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4419/10000, Loss: 0.9388, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4420/10000, Loss: 0.9387, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4421/10000, Loss: 0.9386, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4422/10000, Loss: 0.9385, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4423/10000, Loss: 0.9384, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4424/10000, Loss: 0.9383, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4425/10000, Loss: 0.9382, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4426/10000, Loss: 0.9380, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4427/10000, Loss: 0.9379, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4428/10000, Loss: 0.9378, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4429/10000, Loss: 0.9377, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4430/10000, Loss: 0.9376, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4431/10000, Loss: 0.9375, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4432/10000, Loss: 0.9374, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4433/10000, Loss: 0.9372, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4434/10000, Loss: 0.9371, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4435/10000, Loss: 0.9370, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4436/10000, Loss: 0.9369, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4437/10000, Loss: 0.9368, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4438/10000, Loss: 0.9367, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4439/10000, Loss: 0.9366, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4440/10000, Loss: 0.9364, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4441/10000, Loss: 0.9363, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4442/10000, Loss: 0.9362, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4443/10000, Loss: 0.9361, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4444/10000, Loss: 0.9360, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4445/10000, Loss: 0.9359, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4446/10000, Loss: 0.9358, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4447/10000, Loss: 0.9357, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4448/10000, Loss: 0.9355, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4449/10000, Loss: 0.9354, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4450/10000, Loss: 0.9353, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4451/10000, Loss: 0.9352, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4452/10000, Loss: 0.9351, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4453/10000, Loss: 0.9350, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4454/10000, Loss: 0.9349, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4455/10000, Loss: 0.9348, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4456/10000, Loss: 0.9346, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4457/10000, Loss: 0.9345, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4458/10000, Loss: 0.9344, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4459/10000, Loss: 0.9343, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4460/10000, Loss: 0.9342, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4461/10000, Loss: 0.9341, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4462/10000, Loss: 0.9340, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4463/10000, Loss: 0.9339, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4464/10000, Loss: 0.9338, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4465/10000, Loss: 0.9336, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4466/10000, Loss: 0.9335, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4467/10000, Loss: 0.9334, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4468/10000, Loss: 0.9333, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4469/10000, Loss: 0.9332, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4470/10000, Loss: 0.9331, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4471/10000, Loss: 0.9330, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4472/10000, Loss: 0.9329, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4473/10000, Loss: 0.9328, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4474/10000, Loss: 0.9326, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4475/10000, Loss: 0.9325, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4476/10000, Loss: 0.9324, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4477/10000, Loss: 0.9323, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4478/10000, Loss: 0.9322, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4479/10000, Loss: 0.9321, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4480/10000, Loss: 0.9320, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4481/10000, Loss: 0.9319, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4482/10000, Loss: 0.9318, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4483/10000, Loss: 0.9317, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4484/10000, Loss: 0.9315, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4485/10000, Loss: 0.9314, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4486/10000, Loss: 0.9313, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4487/10000, Loss: 0.9312, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4488/10000, Loss: 0.9311, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4489/10000, Loss: 0.9310, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4490/10000, Loss: 0.9309, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4491/10000, Loss: 0.9308, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4492/10000, Loss: 0.9307, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4493/10000, Loss: 0.9306, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4494/10000, Loss: 0.9304, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4495/10000, Loss: 0.9303, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4496/10000, Loss: 0.9302, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4497/10000, Loss: 0.9301, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4498/10000, Loss: 0.9300, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4499/10000, Loss: 0.9299, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4500/10000, Loss: 0.9298, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4501/10000, Loss: 0.9297, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4502/10000, Loss: 0.9296, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4503/10000, Loss: 0.9295, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4504/10000, Loss: 0.9294, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4505/10000, Loss: 0.9292, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4506/10000, Loss: 0.9291, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4507/10000, Loss: 0.9290, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4508/10000, Loss: 0.9289, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4509/10000, Loss: 0.9288, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4510/10000, Loss: 0.9287, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4511/10000, Loss: 0.9286, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4512/10000, Loss: 0.9285, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4513/10000, Loss: 0.9284, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4514/10000, Loss: 0.9283, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4515/10000, Loss: 0.9282, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4516/10000, Loss: 0.9281, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4517/10000, Loss: 0.9280, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4518/10000, Loss: 0.9278, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4519/10000, Loss: 0.9277, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4520/10000, Loss: 0.9276, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4521/10000, Loss: 0.9275, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4522/10000, Loss: 0.9274, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4523/10000, Loss: 0.9273, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4524/10000, Loss: 0.9272, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4525/10000, Loss: 0.9271, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4526/10000, Loss: 0.9270, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4527/10000, Loss: 0.9269, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4528/10000, Loss: 0.9268, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4529/10000, Loss: 0.9267, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4530/10000, Loss: 0.9266, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4531/10000, Loss: 0.9265, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4532/10000, Loss: 0.9263, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4533/10000, Loss: 0.9262, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4534/10000, Loss: 0.9261, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4535/10000, Loss: 0.9260, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4536/10000, Loss: 0.9259, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4537/10000, Loss: 0.9258, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4538/10000, Loss: 0.9257, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4539/10000, Loss: 0.9256, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4540/10000, Loss: 0.9255, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4541/10000, Loss: 0.9254, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4542/10000, Loss: 0.9253, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4543/10000, Loss: 0.9252, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4544/10000, Loss: 0.9251, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4545/10000, Loss: 0.9250, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4546/10000, Loss: 0.9249, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4547/10000, Loss: 0.9248, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4548/10000, Loss: 0.9247, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4549/10000, Loss: 0.9245, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4550/10000, Loss: 0.9244, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4551/10000, Loss: 0.9243, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4552/10000, Loss: 0.9242, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4553/10000, Loss: 0.9241, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4554/10000, Loss: 0.9240, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4555/10000, Loss: 0.9239, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4556/10000, Loss: 0.9238, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4557/10000, Loss: 0.9237, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4558/10000, Loss: 0.9236, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4559/10000, Loss: 0.9235, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4560/10000, Loss: 0.9234, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4561/10000, Loss: 0.9233, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4562/10000, Loss: 0.9232, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4563/10000, Loss: 0.9231, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4564/10000, Loss: 0.9230, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4565/10000, Loss: 0.9229, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4566/10000, Loss: 0.9228, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4567/10000, Loss: 0.9227, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4568/10000, Loss: 0.9226, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4569/10000, Loss: 0.9225, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4570/10000, Loss: 0.9224, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4571/10000, Loss: 0.9222, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4572/10000, Loss: 0.9221, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4573/10000, Loss: 0.9220, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4574/10000, Loss: 0.9219, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4575/10000, Loss: 0.9218, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4576/10000, Loss: 0.9217, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4577/10000, Loss: 0.9216, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4578/10000, Loss: 0.9215, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4579/10000, Loss: 0.9214, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4580/10000, Loss: 0.9213, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4581/10000, Loss: 0.9212, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4582/10000, Loss: 0.9211, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4583/10000, Loss: 0.9210, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4584/10000, Loss: 0.9209, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4585/10000, Loss: 0.9208, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4586/10000, Loss: 0.9207, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4587/10000, Loss: 0.9206, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4588/10000, Loss: 0.9205, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4589/10000, Loss: 0.9204, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4590/10000, Loss: 0.9203, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4591/10000, Loss: 0.9202, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4592/10000, Loss: 0.9201, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4593/10000, Loss: 0.9200, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4594/10000, Loss: 0.9199, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4595/10000, Loss: 0.9198, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4596/10000, Loss: 0.9197, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4597/10000, Loss: 0.9196, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4598/10000, Loss: 0.9195, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4599/10000, Loss: 0.9194, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4600/10000, Loss: 0.9193, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4601/10000, Loss: 0.9192, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4602/10000, Loss: 0.9191, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4603/10000, Loss: 0.9190, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4604/10000, Loss: 0.9189, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4605/10000, Loss: 0.9188, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4606/10000, Loss: 0.9187, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4607/10000, Loss: 0.9186, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4608/10000, Loss: 0.9184, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4609/10000, Loss: 0.9183, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4610/10000, Loss: 0.9182, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4611/10000, Loss: 0.9181, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4612/10000, Loss: 0.9180, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4613/10000, Loss: 0.9179, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4614/10000, Loss: 0.9178, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4615/10000, Loss: 0.9177, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4616/10000, Loss: 0.9176, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4617/10000, Loss: 0.9175, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4618/10000, Loss: 0.9174, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4619/10000, Loss: 0.9173, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4620/10000, Loss: 0.9172, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4621/10000, Loss: 0.9171, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4622/10000, Loss: 0.9170, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4623/10000, Loss: 0.9169, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4624/10000, Loss: 0.9168, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4625/10000, Loss: 0.9167, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4626/10000, Loss: 0.9166, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4627/10000, Loss: 0.9165, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4628/10000, Loss: 0.9164, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4629/10000, Loss: 0.9163, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4630/10000, Loss: 0.9162, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4631/10000, Loss: 0.9161, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4632/10000, Loss: 0.9160, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4633/10000, Loss: 0.9159, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4634/10000, Loss: 0.9158, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4635/10000, Loss: 0.9157, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4636/10000, Loss: 0.9156, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4637/10000, Loss: 0.9155, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4638/10000, Loss: 0.9154, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4639/10000, Loss: 0.9153, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4640/10000, Loss: 0.9152, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4641/10000, Loss: 0.9151, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4642/10000, Loss: 0.9150, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4643/10000, Loss: 0.9149, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4644/10000, Loss: 0.9148, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4645/10000, Loss: 0.9147, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4646/10000, Loss: 0.9146, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4647/10000, Loss: 0.9145, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4648/10000, Loss: 0.9144, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4649/10000, Loss: 0.9143, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4650/10000, Loss: 0.9142, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4651/10000, Loss: 0.9141, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4652/10000, Loss: 0.9140, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4653/10000, Loss: 0.9139, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4654/10000, Loss: 0.9139, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4655/10000, Loss: 0.9138, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4656/10000, Loss: 0.9137, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4657/10000, Loss: 0.9136, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4658/10000, Loss: 0.9135, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4659/10000, Loss: 0.9134, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4660/10000, Loss: 0.9133, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4661/10000, Loss: 0.9132, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4662/10000, Loss: 0.9131, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4663/10000, Loss: 0.9130, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4664/10000, Loss: 0.9129, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4665/10000, Loss: 0.9128, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4666/10000, Loss: 0.9127, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4667/10000, Loss: 0.9126, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4668/10000, Loss: 0.9125, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4669/10000, Loss: 0.9124, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4670/10000, Loss: 0.9123, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4671/10000, Loss: 0.9122, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4672/10000, Loss: 0.9121, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4673/10000, Loss: 0.9120, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4674/10000, Loss: 0.9119, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4675/10000, Loss: 0.9118, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4676/10000, Loss: 0.9117, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4677/10000, Loss: 0.9116, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4678/10000, Loss: 0.9115, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4679/10000, Loss: 0.9114, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4680/10000, Loss: 0.9113, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4681/10000, Loss: 0.9112, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4682/10000, Loss: 0.9111, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4683/10000, Loss: 0.9110, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4684/10000, Loss: 0.9109, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4685/10000, Loss: 0.9108, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4686/10000, Loss: 0.9107, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4687/10000, Loss: 0.9106, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4688/10000, Loss: 0.9105, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4689/10000, Loss: 0.9104, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4690/10000, Loss: 0.9103, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4691/10000, Loss: 0.9102, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4692/10000, Loss: 0.9102, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4693/10000, Loss: 0.9101, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4694/10000, Loss: 0.9100, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4695/10000, Loss: 0.9099, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4696/10000, Loss: 0.9098, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4697/10000, Loss: 0.9097, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4698/10000, Loss: 0.9096, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4699/10000, Loss: 0.9095, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4700/10000, Loss: 0.9094, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4701/10000, Loss: 0.9093, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4702/10000, Loss: 0.9092, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4703/10000, Loss: 0.9091, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4704/10000, Loss: 0.9090, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4705/10000, Loss: 0.9089, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4706/10000, Loss: 0.9088, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4707/10000, Loss: 0.9087, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4708/10000, Loss: 0.9086, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4709/10000, Loss: 0.9085, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4710/10000, Loss: 0.9084, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4711/10000, Loss: 0.9083, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4712/10000, Loss: 0.9082, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4713/10000, Loss: 0.9081, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4714/10000, Loss: 0.9081, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4715/10000, Loss: 0.9080, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4716/10000, Loss: 0.9079, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4717/10000, Loss: 0.9078, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4718/10000, Loss: 0.9077, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4719/10000, Loss: 0.9076, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4720/10000, Loss: 0.9075, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4721/10000, Loss: 0.9074, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4722/10000, Loss: 0.9073, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4723/10000, Loss: 0.9072, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4724/10000, Loss: 0.9071, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4725/10000, Loss: 0.9070, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4726/10000, Loss: 0.9069, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4727/10000, Loss: 0.9068, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4728/10000, Loss: 0.9067, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4729/10000, Loss: 0.9066, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4730/10000, Loss: 0.9065, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4731/10000, Loss: 0.9064, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4732/10000, Loss: 0.9064, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4733/10000, Loss: 0.9063, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4734/10000, Loss: 0.9062, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4735/10000, Loss: 0.9061, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4736/10000, Loss: 0.9060, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4737/10000, Loss: 0.9059, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4738/10000, Loss: 0.9058, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4739/10000, Loss: 0.9057, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4740/10000, Loss: 0.9056, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4741/10000, Loss: 0.9055, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4742/10000, Loss: 0.9054, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4743/10000, Loss: 0.9053, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4744/10000, Loss: 0.9052, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4745/10000, Loss: 0.9051, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4746/10000, Loss: 0.9050, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4747/10000, Loss: 0.9050, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4748/10000, Loss: 0.9049, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4749/10000, Loss: 0.9048, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4750/10000, Loss: 0.9047, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4751/10000, Loss: 0.9046, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4752/10000, Loss: 0.9045, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4753/10000, Loss: 0.9044, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4754/10000, Loss: 0.9043, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4755/10000, Loss: 0.9042, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4756/10000, Loss: 0.9041, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4757/10000, Loss: 0.9040, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4758/10000, Loss: 0.9039, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4759/10000, Loss: 0.9038, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4760/10000, Loss: 0.9037, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4761/10000, Loss: 0.9037, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4762/10000, Loss: 0.9036, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4763/10000, Loss: 0.9035, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4764/10000, Loss: 0.9034, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4765/10000, Loss: 0.9033, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4766/10000, Loss: 0.9032, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4767/10000, Loss: 0.9031, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4768/10000, Loss: 0.9030, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4769/10000, Loss: 0.9029, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4770/10000, Loss: 0.9028, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4771/10000, Loss: 0.9027, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4772/10000, Loss: 0.9026, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4773/10000, Loss: 0.9026, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4774/10000, Loss: 0.9025, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4775/10000, Loss: 0.9024, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4776/10000, Loss: 0.9023, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4777/10000, Loss: 0.9022, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4778/10000, Loss: 0.9021, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4779/10000, Loss: 0.9020, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4780/10000, Loss: 0.9019, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4781/10000, Loss: 0.9018, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4782/10000, Loss: 0.9017, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4783/10000, Loss: 0.9016, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4784/10000, Loss: 0.9016, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4785/10000, Loss: 0.9015, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4786/10000, Loss: 0.9014, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4787/10000, Loss: 0.9013, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4788/10000, Loss: 0.9012, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4789/10000, Loss: 0.9011, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4790/10000, Loss: 0.9010, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4791/10000, Loss: 0.9009, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4792/10000, Loss: 0.9008, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4793/10000, Loss: 0.9007, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4794/10000, Loss: 0.9006, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4795/10000, Loss: 0.9006, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4796/10000, Loss: 0.9005, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4797/10000, Loss: 0.9004, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4798/10000, Loss: 0.9003, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4799/10000, Loss: 0.9002, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4800/10000, Loss: 0.9001, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4801/10000, Loss: 0.9000, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4802/10000, Loss: 0.8999, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4803/10000, Loss: 0.8998, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4804/10000, Loss: 0.8997, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4805/10000, Loss: 0.8997, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4806/10000, Loss: 0.8996, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4807/10000, Loss: 0.8995, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4808/10000, Loss: 0.8994, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4809/10000, Loss: 0.8993, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4810/10000, Loss: 0.8992, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4811/10000, Loss: 0.8991, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4812/10000, Loss: 0.8990, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4813/10000, Loss: 0.8989, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4814/10000, Loss: 0.8989, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4815/10000, Loss: 0.8988, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4816/10000, Loss: 0.8987, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4817/10000, Loss: 0.8986, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4818/10000, Loss: 0.8985, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4819/10000, Loss: 0.8984, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4820/10000, Loss: 0.8983, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4821/10000, Loss: 0.8982, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4822/10000, Loss: 0.8981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4823/10000, Loss: 0.8981, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4824/10000, Loss: 0.8980, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4825/10000, Loss: 0.8979, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4826/10000, Loss: 0.8978, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4827/10000, Loss: 0.8977, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4828/10000, Loss: 0.8976, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4829/10000, Loss: 0.8975, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4830/10000, Loss: 0.8974, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4831/10000, Loss: 0.8973, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4832/10000, Loss: 0.8973, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4833/10000, Loss: 0.8972, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4834/10000, Loss: 0.8971, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4835/10000, Loss: 0.8970, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4836/10000, Loss: 0.8969, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4837/10000, Loss: 0.8968, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4838/10000, Loss: 0.8967, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4839/10000, Loss: 0.8966, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4840/10000, Loss: 0.8966, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4841/10000, Loss: 0.8965, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4842/10000, Loss: 0.8964, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4843/10000, Loss: 0.8963, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4844/10000, Loss: 0.8962, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4845/10000, Loss: 0.8961, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4846/10000, Loss: 0.8960, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4847/10000, Loss: 0.8959, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4848/10000, Loss: 0.8959, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4849/10000, Loss: 0.8958, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4850/10000, Loss: 0.8957, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4851/10000, Loss: 0.8956, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4852/10000, Loss: 0.8955, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4853/10000, Loss: 0.8954, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4854/10000, Loss: 0.8953, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4855/10000, Loss: 0.8952, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4856/10000, Loss: 0.8952, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4857/10000, Loss: 0.8951, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4858/10000, Loss: 0.8950, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4859/10000, Loss: 0.8949, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4860/10000, Loss: 0.8948, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4861/10000, Loss: 0.8947, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4862/10000, Loss: 0.8946, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4863/10000, Loss: 0.8945, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4864/10000, Loss: 0.8945, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4865/10000, Loss: 0.8944, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4866/10000, Loss: 0.8943, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4867/10000, Loss: 0.8942, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4868/10000, Loss: 0.8941, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4869/10000, Loss: 0.8940, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4870/10000, Loss: 0.8939, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4871/10000, Loss: 0.8939, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4872/10000, Loss: 0.8938, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4873/10000, Loss: 0.8937, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4874/10000, Loss: 0.8936, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4875/10000, Loss: 0.8935, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4876/10000, Loss: 0.8934, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4877/10000, Loss: 0.8933, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4878/10000, Loss: 0.8933, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4879/10000, Loss: 0.8932, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4880/10000, Loss: 0.8931, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4881/10000, Loss: 0.8930, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4882/10000, Loss: 0.8929, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4883/10000, Loss: 0.8928, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4884/10000, Loss: 0.8927, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4885/10000, Loss: 0.8927, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4886/10000, Loss: 0.8926, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4887/10000, Loss: 0.8925, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4888/10000, Loss: 0.8924, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4889/10000, Loss: 0.8923, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4890/10000, Loss: 0.8922, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4891/10000, Loss: 0.8921, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4892/10000, Loss: 0.8921, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4893/10000, Loss: 0.8920, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4894/10000, Loss: 0.8919, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4895/10000, Loss: 0.8918, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4896/10000, Loss: 0.8917, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4897/10000, Loss: 0.8916, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4898/10000, Loss: 0.8915, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4899/10000, Loss: 0.8915, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4900/10000, Loss: 0.8914, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4901/10000, Loss: 0.8913, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4902/10000, Loss: 0.8912, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4903/10000, Loss: 0.8911, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4904/10000, Loss: 0.8910, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4905/10000, Loss: 0.8910, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4906/10000, Loss: 0.8909, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4907/10000, Loss: 0.8908, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4908/10000, Loss: 0.8907, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4909/10000, Loss: 0.8906, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4910/10000, Loss: 0.8905, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4911/10000, Loss: 0.8904, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4912/10000, Loss: 0.8904, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4913/10000, Loss: 0.8903, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4914/10000, Loss: 0.8902, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4915/10000, Loss: 0.8901, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4916/10000, Loss: 0.8900, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4917/10000, Loss: 0.8899, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4918/10000, Loss: 0.8899, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4919/10000, Loss: 0.8898, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4920/10000, Loss: 0.8897, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4921/10000, Loss: 0.8896, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4922/10000, Loss: 0.8895, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4923/10000, Loss: 0.8894, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4924/10000, Loss: 0.8894, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4925/10000, Loss: 0.8893, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4926/10000, Loss: 0.8892, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4927/10000, Loss: 0.8891, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4928/10000, Loss: 0.8890, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4929/10000, Loss: 0.8889, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4930/10000, Loss: 0.8889, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4931/10000, Loss: 0.8888, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4932/10000, Loss: 0.8887, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4933/10000, Loss: 0.8886, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4934/10000, Loss: 0.8885, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4935/10000, Loss: 0.8884, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4936/10000, Loss: 0.8884, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4937/10000, Loss: 0.8883, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4938/10000, Loss: 0.8882, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4939/10000, Loss: 0.8881, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4940/10000, Loss: 0.8880, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4941/10000, Loss: 0.8879, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4942/10000, Loss: 0.8879, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4943/10000, Loss: 0.8878, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4944/10000, Loss: 0.8877, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4945/10000, Loss: 0.8876, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4946/10000, Loss: 0.8875, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4947/10000, Loss: 0.8875, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4948/10000, Loss: 0.8874, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4949/10000, Loss: 0.8873, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4950/10000, Loss: 0.8872, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4951/10000, Loss: 0.8871, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4952/10000, Loss: 0.8870, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4953/10000, Loss: 0.8870, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4954/10000, Loss: 0.8869, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4955/10000, Loss: 0.8868, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4956/10000, Loss: 0.8867, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4957/10000, Loss: 0.8866, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4958/10000, Loss: 0.8866, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4959/10000, Loss: 0.8865, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4960/10000, Loss: 0.8864, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4961/10000, Loss: 0.8863, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4962/10000, Loss: 0.8862, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4963/10000, Loss: 0.8861, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4964/10000, Loss: 0.8861, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4965/10000, Loss: 0.8860, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4966/10000, Loss: 0.8859, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4967/10000, Loss: 0.8858, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4968/10000, Loss: 0.8857, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4969/10000, Loss: 0.8857, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4970/10000, Loss: 0.8856, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4971/10000, Loss: 0.8855, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4972/10000, Loss: 0.8854, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4973/10000, Loss: 0.8853, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 4974/10000, Loss: 0.8852, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4975/10000, Loss: 0.8852, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4976/10000, Loss: 0.8851, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4977/10000, Loss: 0.8850, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4978/10000, Loss: 0.8849, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4979/10000, Loss: 0.8848, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4980/10000, Loss: 0.8848, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4981/10000, Loss: 0.8847, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4982/10000, Loss: 0.8846, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4983/10000, Loss: 0.8845, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4984/10000, Loss: 0.8844, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4985/10000, Loss: 0.8844, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4986/10000, Loss: 0.8843, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4987/10000, Loss: 0.8842, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4988/10000, Loss: 0.8841, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4989/10000, Loss: 0.8840, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4990/10000, Loss: 0.8840, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4991/10000, Loss: 0.8839, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4992/10000, Loss: 0.8838, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4993/10000, Loss: 0.8837, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4994/10000, Loss: 0.8836, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4995/10000, Loss: 0.8836, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4996/10000, Loss: 0.8835, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4997/10000, Loss: 0.8834, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4998/10000, Loss: 0.8833, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 4999/10000, Loss: 0.8832, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5000/10000, Loss: 0.8832, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5001/10000, Loss: 0.8831, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5002/10000, Loss: 0.8830, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5003/10000, Loss: 0.8829, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5004/10000, Loss: 0.8828, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5005/10000, Loss: 0.8828, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5006/10000, Loss: 0.8827, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5007/10000, Loss: 0.8826, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5008/10000, Loss: 0.8825, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5009/10000, Loss: 0.8824, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5010/10000, Loss: 0.8824, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5011/10000, Loss: 0.8823, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5012/10000, Loss: 0.8822, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5013/10000, Loss: 0.8821, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5014/10000, Loss: 0.8820, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5015/10000, Loss: 0.8820, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5016/10000, Loss: 0.8819, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5017/10000, Loss: 0.8818, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5018/10000, Loss: 0.8817, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5019/10000, Loss: 0.8816, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5020/10000, Loss: 0.8816, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5021/10000, Loss: 0.8815, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5022/10000, Loss: 0.8814, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5023/10000, Loss: 0.8813, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5024/10000, Loss: 0.8813, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5025/10000, Loss: 0.8812, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5026/10000, Loss: 0.8811, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5027/10000, Loss: 0.8810, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5028/10000, Loss: 0.8809, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5029/10000, Loss: 0.8809, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5030/10000, Loss: 0.8808, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5031/10000, Loss: 0.8807, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5032/10000, Loss: 0.8806, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5033/10000, Loss: 0.8805, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5034/10000, Loss: 0.8805, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5035/10000, Loss: 0.8804, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5036/10000, Loss: 0.8803, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5037/10000, Loss: 0.8802, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5038/10000, Loss: 0.8802, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5039/10000, Loss: 0.8801, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5040/10000, Loss: 0.8800, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5041/10000, Loss: 0.8799, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5042/10000, Loss: 0.8798, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5043/10000, Loss: 0.8798, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5044/10000, Loss: 0.8797, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5045/10000, Loss: 0.8796, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5046/10000, Loss: 0.8795, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5047/10000, Loss: 0.8795, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5048/10000, Loss: 0.8794, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5049/10000, Loss: 0.8793, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5050/10000, Loss: 0.8792, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5051/10000, Loss: 0.8791, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5052/10000, Loss: 0.8791, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5053/10000, Loss: 0.8790, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5054/10000, Loss: 0.8789, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5055/10000, Loss: 0.8788, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5056/10000, Loss: 0.8788, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5057/10000, Loss: 0.8787, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5058/10000, Loss: 0.8786, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5059/10000, Loss: 0.8785, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5060/10000, Loss: 0.8784, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5061/10000, Loss: 0.8784, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5062/10000, Loss: 0.8783, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5063/10000, Loss: 0.8782, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5064/10000, Loss: 0.8781, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5065/10000, Loss: 0.8781, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5066/10000, Loss: 0.8780, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5067/10000, Loss: 0.8779, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5068/10000, Loss: 0.8778, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5069/10000, Loss: 0.8778, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5070/10000, Loss: 0.8777, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5071/10000, Loss: 0.8776, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5072/10000, Loss: 0.8775, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5073/10000, Loss: 0.8774, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5074/10000, Loss: 0.8774, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5075/10000, Loss: 0.8773, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5076/10000, Loss: 0.8772, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5077/10000, Loss: 0.8771, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5078/10000, Loss: 0.8771, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5079/10000, Loss: 0.8770, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5080/10000, Loss: 0.8769, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5081/10000, Loss: 0.8768, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5082/10000, Loss: 0.8768, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5083/10000, Loss: 0.8767, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5084/10000, Loss: 0.8766, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5085/10000, Loss: 0.8765, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5086/10000, Loss: 0.8765, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5087/10000, Loss: 0.8764, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5088/10000, Loss: 0.8763, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5089/10000, Loss: 0.8762, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5090/10000, Loss: 0.8761, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5091/10000, Loss: 0.8761, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5092/10000, Loss: 0.8760, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5093/10000, Loss: 0.8759, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5094/10000, Loss: 0.8758, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5095/10000, Loss: 0.8758, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5096/10000, Loss: 0.8757, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5097/10000, Loss: 0.8756, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5098/10000, Loss: 0.8755, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5099/10000, Loss: 0.8755, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5100/10000, Loss: 0.8754, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5101/10000, Loss: 0.8753, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5102/10000, Loss: 0.8752, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5103/10000, Loss: 0.8752, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5104/10000, Loss: 0.8751, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5105/10000, Loss: 0.8750, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5106/10000, Loss: 0.8749, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5107/10000, Loss: 0.8749, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5108/10000, Loss: 0.8748, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5109/10000, Loss: 0.8747, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5110/10000, Loss: 0.8746, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5111/10000, Loss: 0.8746, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5112/10000, Loss: 0.8745, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5113/10000, Loss: 0.8744, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5114/10000, Loss: 0.8743, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5115/10000, Loss: 0.8743, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5116/10000, Loss: 0.8742, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5117/10000, Loss: 0.8741, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5118/10000, Loss: 0.8740, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5119/10000, Loss: 0.8740, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5120/10000, Loss: 0.8739, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5121/10000, Loss: 0.8738, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5122/10000, Loss: 0.8737, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5123/10000, Loss: 0.8737, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5124/10000, Loss: 0.8736, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5125/10000, Loss: 0.8735, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5126/10000, Loss: 0.8734, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5127/10000, Loss: 0.8734, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5128/10000, Loss: 0.8733, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5129/10000, Loss: 0.8732, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5130/10000, Loss: 0.8731, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5131/10000, Loss: 0.8731, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5132/10000, Loss: 0.8730, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5133/10000, Loss: 0.8729, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5134/10000, Loss: 0.8729, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5135/10000, Loss: 0.8728, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5136/10000, Loss: 0.8727, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5137/10000, Loss: 0.8726, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5138/10000, Loss: 0.8726, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5139/10000, Loss: 0.8725, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5140/10000, Loss: 0.8724, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5141/10000, Loss: 0.8723, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5142/10000, Loss: 0.8723, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5143/10000, Loss: 0.8722, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5144/10000, Loss: 0.8721, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5145/10000, Loss: 0.8720, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5146/10000, Loss: 0.8720, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5147/10000, Loss: 0.8719, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5148/10000, Loss: 0.8718, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5149/10000, Loss: 0.8717, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5150/10000, Loss: 0.8717, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5151/10000, Loss: 0.8716, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5152/10000, Loss: 0.8715, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5153/10000, Loss: 0.8715, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5154/10000, Loss: 0.8714, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5155/10000, Loss: 0.8713, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5156/10000, Loss: 0.8712, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5157/10000, Loss: 0.8712, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5158/10000, Loss: 0.8711, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5159/10000, Loss: 0.8710, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5160/10000, Loss: 0.8709, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5161/10000, Loss: 0.8709, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5162/10000, Loss: 0.8708, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5163/10000, Loss: 0.8707, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5164/10000, Loss: 0.8706, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5165/10000, Loss: 0.8706, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5166/10000, Loss: 0.8705, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5167/10000, Loss: 0.8704, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5168/10000, Loss: 0.8704, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5169/10000, Loss: 0.8703, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5170/10000, Loss: 0.8702, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5171/10000, Loss: 0.8701, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5172/10000, Loss: 0.8701, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5173/10000, Loss: 0.8700, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5174/10000, Loss: 0.8699, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5175/10000, Loss: 0.8698, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5176/10000, Loss: 0.8698, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5177/10000, Loss: 0.8697, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5178/10000, Loss: 0.8696, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5179/10000, Loss: 0.8696, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5180/10000, Loss: 0.8695, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5181/10000, Loss: 0.8694, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5182/10000, Loss: 0.8693, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5183/10000, Loss: 0.8693, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5184/10000, Loss: 0.8692, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5185/10000, Loss: 0.8691, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5186/10000, Loss: 0.8691, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5187/10000, Loss: 0.8690, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5188/10000, Loss: 0.8689, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5189/10000, Loss: 0.8688, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5190/10000, Loss: 0.8688, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5191/10000, Loss: 0.8687, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5192/10000, Loss: 0.8686, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5193/10000, Loss: 0.8686, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5194/10000, Loss: 0.8685, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5195/10000, Loss: 0.8684, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5196/10000, Loss: 0.8683, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5197/10000, Loss: 0.8683, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5198/10000, Loss: 0.8682, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5199/10000, Loss: 0.8681, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5200/10000, Loss: 0.8681, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5201/10000, Loss: 0.8680, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5202/10000, Loss: 0.8679, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5203/10000, Loss: 0.8678, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5204/10000, Loss: 0.8678, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5205/10000, Loss: 0.8677, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5206/10000, Loss: 0.8676, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5207/10000, Loss: 0.8676, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5208/10000, Loss: 0.8675, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5209/10000, Loss: 0.8674, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5210/10000, Loss: 0.8673, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5211/10000, Loss: 0.8673, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5212/10000, Loss: 0.8672, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5213/10000, Loss: 0.8671, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5214/10000, Loss: 0.8671, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5215/10000, Loss: 0.8670, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5216/10000, Loss: 0.8669, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5217/10000, Loss: 0.8668, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5218/10000, Loss: 0.8668, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5219/10000, Loss: 0.8667, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5220/10000, Loss: 0.8666, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5221/10000, Loss: 0.8666, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5222/10000, Loss: 0.8665, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5223/10000, Loss: 0.8664, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5224/10000, Loss: 0.8663, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5225/10000, Loss: 0.8663, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5226/10000, Loss: 0.8662, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5227/10000, Loss: 0.8661, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5228/10000, Loss: 0.8661, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5229/10000, Loss: 0.8660, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5230/10000, Loss: 0.8659, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5231/10000, Loss: 0.8659, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5232/10000, Loss: 0.8658, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5233/10000, Loss: 0.8657, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5234/10000, Loss: 0.8656, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5235/10000, Loss: 0.8656, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5236/10000, Loss: 0.8655, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5237/10000, Loss: 0.8654, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5238/10000, Loss: 0.8654, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5239/10000, Loss: 0.8653, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5240/10000, Loss: 0.8652, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5241/10000, Loss: 0.8652, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5242/10000, Loss: 0.8651, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5243/10000, Loss: 0.8650, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5244/10000, Loss: 0.8649, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5245/10000, Loss: 0.8649, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5246/10000, Loss: 0.8648, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5247/10000, Loss: 0.8647, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5248/10000, Loss: 0.8647, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5249/10000, Loss: 0.8646, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5250/10000, Loss: 0.8645, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5251/10000, Loss: 0.8645, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5252/10000, Loss: 0.8644, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5253/10000, Loss: 0.8643, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5254/10000, Loss: 0.8642, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5255/10000, Loss: 0.8642, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5256/10000, Loss: 0.8641, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5257/10000, Loss: 0.8640, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5258/10000, Loss: 0.8640, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5259/10000, Loss: 0.8639, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5260/10000, Loss: 0.8638, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5261/10000, Loss: 0.8638, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5262/10000, Loss: 0.8637, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5263/10000, Loss: 0.8636, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5264/10000, Loss: 0.8636, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5265/10000, Loss: 0.8635, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5266/10000, Loss: 0.8634, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5267/10000, Loss: 0.8633, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5268/10000, Loss: 0.8633, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5269/10000, Loss: 0.8632, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5270/10000, Loss: 0.8631, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5271/10000, Loss: 0.8631, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5272/10000, Loss: 0.8630, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5273/10000, Loss: 0.8629, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5274/10000, Loss: 0.8629, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5275/10000, Loss: 0.8628, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5276/10000, Loss: 0.8627, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5277/10000, Loss: 0.8627, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5278/10000, Loss: 0.8626, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5279/10000, Loss: 0.8625, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5280/10000, Loss: 0.8625, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5281/10000, Loss: 0.8624, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5282/10000, Loss: 0.8623, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5283/10000, Loss: 0.8622, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5284/10000, Loss: 0.8622, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5285/10000, Loss: 0.8621, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5286/10000, Loss: 0.8620, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5287/10000, Loss: 0.8620, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5288/10000, Loss: 0.8619, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5289/10000, Loss: 0.8618, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5290/10000, Loss: 0.8618, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5291/10000, Loss: 0.8617, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5292/10000, Loss: 0.8616, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5293/10000, Loss: 0.8616, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5294/10000, Loss: 0.8615, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5295/10000, Loss: 0.8614, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5296/10000, Loss: 0.8614, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5297/10000, Loss: 0.8613, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5298/10000, Loss: 0.8612, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5299/10000, Loss: 0.8612, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5300/10000, Loss: 0.8611, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5301/10000, Loss: 0.8610, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5302/10000, Loss: 0.8610, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5303/10000, Loss: 0.8609, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5304/10000, Loss: 0.8608, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5305/10000, Loss: 0.8607, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5306/10000, Loss: 0.8607, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5307/10000, Loss: 0.8606, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5308/10000, Loss: 0.8605, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5309/10000, Loss: 0.8605, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5310/10000, Loss: 0.8604, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5311/10000, Loss: 0.8603, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5312/10000, Loss: 0.8603, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5313/10000, Loss: 0.8602, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5314/10000, Loss: 0.8601, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5315/10000, Loss: 0.8601, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5316/10000, Loss: 0.8600, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5317/10000, Loss: 0.8599, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5318/10000, Loss: 0.8599, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5319/10000, Loss: 0.8598, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5320/10000, Loss: 0.8597, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5321/10000, Loss: 0.8597, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5322/10000, Loss: 0.8596, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5323/10000, Loss: 0.8595, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5324/10000, Loss: 0.8595, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5325/10000, Loss: 0.8594, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5326/10000, Loss: 0.8593, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5327/10000, Loss: 0.8593, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5328/10000, Loss: 0.8592, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5329/10000, Loss: 0.8591, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5330/10000, Loss: 0.8591, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5331/10000, Loss: 0.8590, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5332/10000, Loss: 0.8589, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5333/10000, Loss: 0.8589, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5334/10000, Loss: 0.8588, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5335/10000, Loss: 0.8587, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5336/10000, Loss: 0.8587, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5337/10000, Loss: 0.8586, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5338/10000, Loss: 0.8585, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5339/10000, Loss: 0.8585, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5340/10000, Loss: 0.8584, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5341/10000, Loss: 0.8583, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5342/10000, Loss: 0.8583, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5343/10000, Loss: 0.8582, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5344/10000, Loss: 0.8581, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5345/10000, Loss: 0.8581, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5346/10000, Loss: 0.8580, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5347/10000, Loss: 0.8579, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5348/10000, Loss: 0.8579, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5349/10000, Loss: 0.8578, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5350/10000, Loss: 0.8577, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5351/10000, Loss: 0.8577, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5352/10000, Loss: 0.8576, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5353/10000, Loss: 0.8575, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5354/10000, Loss: 0.8575, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5355/10000, Loss: 0.8574, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5356/10000, Loss: 0.8573, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5357/10000, Loss: 0.8573, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5358/10000, Loss: 0.8572, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5359/10000, Loss: 0.8571, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5360/10000, Loss: 0.8571, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5361/10000, Loss: 0.8570, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5362/10000, Loss: 0.8569, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5363/10000, Loss: 0.8569, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5364/10000, Loss: 0.8568, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5365/10000, Loss: 0.8567, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5366/10000, Loss: 0.8567, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5367/10000, Loss: 0.8566, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5368/10000, Loss: 0.8565, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5369/10000, Loss: 0.8565, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5370/10000, Loss: 0.8564, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5371/10000, Loss: 0.8564, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5372/10000, Loss: 0.8563, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5373/10000, Loss: 0.8562, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5374/10000, Loss: 0.8562, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5375/10000, Loss: 0.8561, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5376/10000, Loss: 0.8560, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5377/10000, Loss: 0.8560, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5378/10000, Loss: 0.8559, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5379/10000, Loss: 0.8558, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5380/10000, Loss: 0.8558, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5381/10000, Loss: 0.8557, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5382/10000, Loss: 0.8556, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5383/10000, Loss: 0.8556, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5384/10000, Loss: 0.8555, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5385/10000, Loss: 0.8554, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5386/10000, Loss: 0.8554, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5387/10000, Loss: 0.8553, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5388/10000, Loss: 0.8552, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5389/10000, Loss: 0.8552, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5390/10000, Loss: 0.8551, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5391/10000, Loss: 0.8550, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5392/10000, Loss: 0.8550, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5393/10000, Loss: 0.8549, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5394/10000, Loss: 0.8549, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5395/10000, Loss: 0.8548, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5396/10000, Loss: 0.8547, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5397/10000, Loss: 0.8547, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5398/10000, Loss: 0.8546, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5399/10000, Loss: 0.8545, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5400/10000, Loss: 0.8545, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5401/10000, Loss: 0.8544, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5402/10000, Loss: 0.8543, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5403/10000, Loss: 0.8543, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5404/10000, Loss: 0.8542, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5405/10000, Loss: 0.8541, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5406/10000, Loss: 0.8541, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5407/10000, Loss: 0.8540, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5408/10000, Loss: 0.8540, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5409/10000, Loss: 0.8539, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5410/10000, Loss: 0.8538, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5411/10000, Loss: 0.8538, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5412/10000, Loss: 0.8537, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5413/10000, Loss: 0.8536, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5414/10000, Loss: 0.8536, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5415/10000, Loss: 0.8535, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5416/10000, Loss: 0.8534, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5417/10000, Loss: 0.8534, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5418/10000, Loss: 0.8533, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5419/10000, Loss: 0.8532, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5420/10000, Loss: 0.8532, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5421/10000, Loss: 0.8531, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5422/10000, Loss: 0.8531, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5423/10000, Loss: 0.8530, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5424/10000, Loss: 0.8529, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5425/10000, Loss: 0.8529, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5426/10000, Loss: 0.8528, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5427/10000, Loss: 0.8527, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5428/10000, Loss: 0.8527, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5429/10000, Loss: 0.8526, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5430/10000, Loss: 0.8525, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5431/10000, Loss: 0.8525, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5432/10000, Loss: 0.8524, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5433/10000, Loss: 0.8524, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5434/10000, Loss: 0.8523, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5435/10000, Loss: 0.8522, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5436/10000, Loss: 0.8522, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5437/10000, Loss: 0.8521, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5438/10000, Loss: 0.8520, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5439/10000, Loss: 0.8520, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5440/10000, Loss: 0.8519, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5441/10000, Loss: 0.8518, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5442/10000, Loss: 0.8518, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5443/10000, Loss: 0.8517, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5444/10000, Loss: 0.8517, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5445/10000, Loss: 0.8516, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5446/10000, Loss: 0.8515, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5447/10000, Loss: 0.8515, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5448/10000, Loss: 0.8514, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5449/10000, Loss: 0.8513, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5450/10000, Loss: 0.8513, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5451/10000, Loss: 0.8512, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5452/10000, Loss: 0.8511, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5453/10000, Loss: 0.8511, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5454/10000, Loss: 0.8510, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5455/10000, Loss: 0.8510, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5456/10000, Loss: 0.8509, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5457/10000, Loss: 0.8508, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5458/10000, Loss: 0.8508, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5459/10000, Loss: 0.8507, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5460/10000, Loss: 0.8506, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5461/10000, Loss: 0.8506, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5462/10000, Loss: 0.8505, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5463/10000, Loss: 0.8505, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5464/10000, Loss: 0.8504, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5465/10000, Loss: 0.8503, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5466/10000, Loss: 0.8503, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5467/10000, Loss: 0.8502, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5468/10000, Loss: 0.8501, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5469/10000, Loss: 0.8501, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5470/10000, Loss: 0.8500, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5471/10000, Loss: 0.8500, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5472/10000, Loss: 0.8499, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5473/10000, Loss: 0.8498, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5474/10000, Loss: 0.8498, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5475/10000, Loss: 0.8497, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5476/10000, Loss: 0.8496, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5477/10000, Loss: 0.8496, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5478/10000, Loss: 0.8495, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5479/10000, Loss: 0.8495, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5480/10000, Loss: 0.8494, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5481/10000, Loss: 0.8493, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5482/10000, Loss: 0.8493, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5483/10000, Loss: 0.8492, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5484/10000, Loss: 0.8491, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5485/10000, Loss: 0.8491, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5486/10000, Loss: 0.8490, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5487/10000, Loss: 0.8490, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5488/10000, Loss: 0.8489, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5489/10000, Loss: 0.8488, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5490/10000, Loss: 0.8488, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5491/10000, Loss: 0.8487, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5492/10000, Loss: 0.8486, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5493/10000, Loss: 0.8486, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5494/10000, Loss: 0.8485, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5495/10000, Loss: 0.8485, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5496/10000, Loss: 0.8484, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5497/10000, Loss: 0.8483, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5498/10000, Loss: 0.8483, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5499/10000, Loss: 0.8482, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5500/10000, Loss: 0.8482, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5501/10000, Loss: 0.8481, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5502/10000, Loss: 0.8480, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5503/10000, Loss: 0.8480, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5504/10000, Loss: 0.8479, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5505/10000, Loss: 0.8478, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5506/10000, Loss: 0.8478, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5507/10000, Loss: 0.8477, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5508/10000, Loss: 0.8477, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5509/10000, Loss: 0.8476, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5510/10000, Loss: 0.8475, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5511/10000, Loss: 0.8475, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5512/10000, Loss: 0.8474, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5513/10000, Loss: 0.8474, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5514/10000, Loss: 0.8473, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5515/10000, Loss: 0.8472, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5516/10000, Loss: 0.8472, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5517/10000, Loss: 0.8471, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5518/10000, Loss: 0.8470, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5519/10000, Loss: 0.8470, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5520/10000, Loss: 0.8469, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5521/10000, Loss: 0.8469, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5522/10000, Loss: 0.8468, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5523/10000, Loss: 0.8467, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5524/10000, Loss: 0.8467, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5525/10000, Loss: 0.8466, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5526/10000, Loss: 0.8466, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5527/10000, Loss: 0.8465, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5528/10000, Loss: 0.8464, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5529/10000, Loss: 0.8464, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5530/10000, Loss: 0.8463, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5531/10000, Loss: 0.8463, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5532/10000, Loss: 0.8462, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5533/10000, Loss: 0.8461, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5534/10000, Loss: 0.8461, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5535/10000, Loss: 0.8460, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5536/10000, Loss: 0.8459, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5537/10000, Loss: 0.8459, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5538/10000, Loss: 0.8458, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5539/10000, Loss: 0.8458, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5540/10000, Loss: 0.8457, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5541/10000, Loss: 0.8456, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5542/10000, Loss: 0.8456, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5543/10000, Loss: 0.8455, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5544/10000, Loss: 0.8455, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5545/10000, Loss: 0.8454, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5546/10000, Loss: 0.8453, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5547/10000, Loss: 0.8453, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5548/10000, Loss: 0.8452, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5549/10000, Loss: 0.8452, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5550/10000, Loss: 0.8451, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5551/10000, Loss: 0.8450, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5552/10000, Loss: 0.8450, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5553/10000, Loss: 0.8449, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5554/10000, Loss: 0.8449, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5555/10000, Loss: 0.8448, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5556/10000, Loss: 0.8447, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5557/10000, Loss: 0.8447, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5558/10000, Loss: 0.8446, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5559/10000, Loss: 0.8446, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5560/10000, Loss: 0.8445, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5561/10000, Loss: 0.8444, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5562/10000, Loss: 0.8444, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5563/10000, Loss: 0.8443, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5564/10000, Loss: 0.8443, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5565/10000, Loss: 0.8442, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5566/10000, Loss: 0.8441, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5567/10000, Loss: 0.8441, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5568/10000, Loss: 0.8440, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5569/10000, Loss: 0.8440, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5570/10000, Loss: 0.8439, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5571/10000, Loss: 0.8438, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5572/10000, Loss: 0.8438, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5573/10000, Loss: 0.8437, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5574/10000, Loss: 0.8437, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5575/10000, Loss: 0.8436, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5576/10000, Loss: 0.8435, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5577/10000, Loss: 0.8435, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5578/10000, Loss: 0.8434, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5579/10000, Loss: 0.8434, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5580/10000, Loss: 0.8433, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5581/10000, Loss: 0.8432, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5582/10000, Loss: 0.8432, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5583/10000, Loss: 0.8431, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5584/10000, Loss: 0.8431, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5585/10000, Loss: 0.8430, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5586/10000, Loss: 0.8429, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5587/10000, Loss: 0.8429, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5588/10000, Loss: 0.8428, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5589/10000, Loss: 0.8428, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5590/10000, Loss: 0.8427, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5591/10000, Loss: 0.8426, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5592/10000, Loss: 0.8426, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5593/10000, Loss: 0.8425, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5594/10000, Loss: 0.8425, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5595/10000, Loss: 0.8424, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5596/10000, Loss: 0.8424, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5597/10000, Loss: 0.8423, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5598/10000, Loss: 0.8422, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5599/10000, Loss: 0.8422, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5600/10000, Loss: 0.8421, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5601/10000, Loss: 0.8421, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5602/10000, Loss: 0.8420, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5603/10000, Loss: 0.8419, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5604/10000, Loss: 0.8419, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5605/10000, Loss: 0.8418, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5606/10000, Loss: 0.8418, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5607/10000, Loss: 0.8417, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5608/10000, Loss: 0.8416, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5609/10000, Loss: 0.8416, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5610/10000, Loss: 0.8415, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5611/10000, Loss: 0.8415, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5612/10000, Loss: 0.8414, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5613/10000, Loss: 0.8413, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5614/10000, Loss: 0.8413, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5615/10000, Loss: 0.8412, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5616/10000, Loss: 0.8412, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5617/10000, Loss: 0.8411, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5618/10000, Loss: 0.8411, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5619/10000, Loss: 0.8410, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5620/10000, Loss: 0.8409, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5621/10000, Loss: 0.8409, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5622/10000, Loss: 0.8408, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5623/10000, Loss: 0.8408, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5624/10000, Loss: 0.8407, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5625/10000, Loss: 0.8406, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5626/10000, Loss: 0.8406, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5627/10000, Loss: 0.8405, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5628/10000, Loss: 0.8405, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5629/10000, Loss: 0.8404, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5630/10000, Loss: 0.8404, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5631/10000, Loss: 0.8403, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5632/10000, Loss: 0.8402, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5633/10000, Loss: 0.8402, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5634/10000, Loss: 0.8401, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5635/10000, Loss: 0.8401, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5636/10000, Loss: 0.8400, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5637/10000, Loss: 0.8399, Accuracy: 0.6282, Learning Rate: 0.000100\n",
      "Epoch 5638/10000, Loss: 0.8399, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5639/10000, Loss: 0.8398, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5640/10000, Loss: 0.8398, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5641/10000, Loss: 0.8397, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5642/10000, Loss: 0.8397, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5643/10000, Loss: 0.8396, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5644/10000, Loss: 0.8395, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5645/10000, Loss: 0.8395, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5646/10000, Loss: 0.8394, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5647/10000, Loss: 0.8394, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5648/10000, Loss: 0.8393, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5649/10000, Loss: 0.8392, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5650/10000, Loss: 0.8392, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5651/10000, Loss: 0.8391, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5652/10000, Loss: 0.8391, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5653/10000, Loss: 0.8390, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5654/10000, Loss: 0.8390, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5655/10000, Loss: 0.8389, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5656/10000, Loss: 0.8388, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5657/10000, Loss: 0.8388, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5658/10000, Loss: 0.8387, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5659/10000, Loss: 0.8387, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5660/10000, Loss: 0.8386, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5661/10000, Loss: 0.8386, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5662/10000, Loss: 0.8385, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5663/10000, Loss: 0.8384, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5664/10000, Loss: 0.8384, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5665/10000, Loss: 0.8383, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5666/10000, Loss: 0.8383, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5667/10000, Loss: 0.8382, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5668/10000, Loss: 0.8382, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5669/10000, Loss: 0.8381, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5670/10000, Loss: 0.8380, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5671/10000, Loss: 0.8380, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5672/10000, Loss: 0.8379, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5673/10000, Loss: 0.8379, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5674/10000, Loss: 0.8378, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5675/10000, Loss: 0.8377, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5676/10000, Loss: 0.8377, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5677/10000, Loss: 0.8376, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5678/10000, Loss: 0.8376, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5679/10000, Loss: 0.8375, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5680/10000, Loss: 0.8375, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5681/10000, Loss: 0.8374, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5682/10000, Loss: 0.8373, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5683/10000, Loss: 0.8373, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5684/10000, Loss: 0.8372, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5685/10000, Loss: 0.8372, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5686/10000, Loss: 0.8371, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5687/10000, Loss: 0.8371, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5688/10000, Loss: 0.8370, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5689/10000, Loss: 0.8369, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5690/10000, Loss: 0.8369, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5691/10000, Loss: 0.8368, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5692/10000, Loss: 0.8368, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5693/10000, Loss: 0.8367, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5694/10000, Loss: 0.8367, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5695/10000, Loss: 0.8366, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5696/10000, Loss: 0.8365, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5697/10000, Loss: 0.8365, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5698/10000, Loss: 0.8364, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5699/10000, Loss: 0.8364, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5700/10000, Loss: 0.8363, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5701/10000, Loss: 0.8363, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5702/10000, Loss: 0.8362, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5703/10000, Loss: 0.8362, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5704/10000, Loss: 0.8361, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5705/10000, Loss: 0.8360, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5706/10000, Loss: 0.8360, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5707/10000, Loss: 0.8359, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5708/10000, Loss: 0.8359, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5709/10000, Loss: 0.8358, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5710/10000, Loss: 0.8358, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5711/10000, Loss: 0.8357, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5712/10000, Loss: 0.8356, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5713/10000, Loss: 0.8356, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5714/10000, Loss: 0.8355, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5715/10000, Loss: 0.8355, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5716/10000, Loss: 0.8354, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5717/10000, Loss: 0.8354, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5718/10000, Loss: 0.8353, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5719/10000, Loss: 0.8352, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5720/10000, Loss: 0.8352, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5721/10000, Loss: 0.8351, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5722/10000, Loss: 0.8351, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5723/10000, Loss: 0.8350, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5724/10000, Loss: 0.8350, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5725/10000, Loss: 0.8349, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5726/10000, Loss: 0.8349, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5727/10000, Loss: 0.8348, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5728/10000, Loss: 0.8347, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5729/10000, Loss: 0.8347, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5730/10000, Loss: 0.8346, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5731/10000, Loss: 0.8346, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5732/10000, Loss: 0.8345, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5733/10000, Loss: 0.8345, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5734/10000, Loss: 0.8344, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5735/10000, Loss: 0.8343, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5736/10000, Loss: 0.8343, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5737/10000, Loss: 0.8342, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5738/10000, Loss: 0.8342, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5739/10000, Loss: 0.8341, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5740/10000, Loss: 0.8341, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5741/10000, Loss: 0.8340, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5742/10000, Loss: 0.8340, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5743/10000, Loss: 0.8339, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5744/10000, Loss: 0.8338, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5745/10000, Loss: 0.8338, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5746/10000, Loss: 0.8337, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5747/10000, Loss: 0.8337, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5748/10000, Loss: 0.8336, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5749/10000, Loss: 0.8336, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5750/10000, Loss: 0.8335, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5751/10000, Loss: 0.8335, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5752/10000, Loss: 0.8334, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5753/10000, Loss: 0.8333, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5754/10000, Loss: 0.8333, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5755/10000, Loss: 0.8332, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5756/10000, Loss: 0.8332, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5757/10000, Loss: 0.8331, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5758/10000, Loss: 0.8331, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5759/10000, Loss: 0.8330, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5760/10000, Loss: 0.8330, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5761/10000, Loss: 0.8329, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5762/10000, Loss: 0.8328, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5763/10000, Loss: 0.8328, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5764/10000, Loss: 0.8327, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5765/10000, Loss: 0.8327, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5766/10000, Loss: 0.8326, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5767/10000, Loss: 0.8326, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5768/10000, Loss: 0.8325, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5769/10000, Loss: 0.8325, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5770/10000, Loss: 0.8324, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5771/10000, Loss: 0.8323, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5772/10000, Loss: 0.8323, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5773/10000, Loss: 0.8322, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5774/10000, Loss: 0.8322, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5775/10000, Loss: 0.8321, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5776/10000, Loss: 0.8321, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5777/10000, Loss: 0.8320, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5778/10000, Loss: 0.8320, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5779/10000, Loss: 0.8319, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5780/10000, Loss: 0.8318, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5781/10000, Loss: 0.8318, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5782/10000, Loss: 0.8317, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5783/10000, Loss: 0.8317, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5784/10000, Loss: 0.8316, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5785/10000, Loss: 0.8316, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5786/10000, Loss: 0.8315, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5787/10000, Loss: 0.8315, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5788/10000, Loss: 0.8314, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5789/10000, Loss: 0.8314, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5790/10000, Loss: 0.8313, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5791/10000, Loss: 0.8312, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5792/10000, Loss: 0.8312, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5793/10000, Loss: 0.8311, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5794/10000, Loss: 0.8311, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5795/10000, Loss: 0.8310, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5796/10000, Loss: 0.8310, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5797/10000, Loss: 0.8309, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5798/10000, Loss: 0.8309, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5799/10000, Loss: 0.8308, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5800/10000, Loss: 0.8307, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5801/10000, Loss: 0.8307, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5802/10000, Loss: 0.8306, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5803/10000, Loss: 0.8306, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5804/10000, Loss: 0.8305, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5805/10000, Loss: 0.8305, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5806/10000, Loss: 0.8304, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5807/10000, Loss: 0.8304, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5808/10000, Loss: 0.8303, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5809/10000, Loss: 0.8303, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5810/10000, Loss: 0.8302, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5811/10000, Loss: 0.8301, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5812/10000, Loss: 0.8301, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5813/10000, Loss: 0.8300, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5814/10000, Loss: 0.8300, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5815/10000, Loss: 0.8299, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5816/10000, Loss: 0.8299, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5817/10000, Loss: 0.8298, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5818/10000, Loss: 0.8298, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5819/10000, Loss: 0.8297, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5820/10000, Loss: 0.8297, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5821/10000, Loss: 0.8296, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5822/10000, Loss: 0.8296, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5823/10000, Loss: 0.8295, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5824/10000, Loss: 0.8294, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5825/10000, Loss: 0.8294, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5826/10000, Loss: 0.8293, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5827/10000, Loss: 0.8293, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5828/10000, Loss: 0.8292, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5829/10000, Loss: 0.8292, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5830/10000, Loss: 0.8291, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5831/10000, Loss: 0.8291, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5832/10000, Loss: 0.8290, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5833/10000, Loss: 0.8290, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5834/10000, Loss: 0.8289, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5835/10000, Loss: 0.8288, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5836/10000, Loss: 0.8288, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5837/10000, Loss: 0.8287, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5838/10000, Loss: 0.8287, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5839/10000, Loss: 0.8286, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5840/10000, Loss: 0.8286, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5841/10000, Loss: 0.8285, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5842/10000, Loss: 0.8285, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5843/10000, Loss: 0.8284, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5844/10000, Loss: 0.8284, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5845/10000, Loss: 0.8283, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5846/10000, Loss: 0.8283, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5847/10000, Loss: 0.8282, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5848/10000, Loss: 0.8281, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5849/10000, Loss: 0.8281, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5850/10000, Loss: 0.8280, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5851/10000, Loss: 0.8280, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5852/10000, Loss: 0.8279, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5853/10000, Loss: 0.8279, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5854/10000, Loss: 0.8278, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5855/10000, Loss: 0.8278, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5856/10000, Loss: 0.8277, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5857/10000, Loss: 0.8277, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5858/10000, Loss: 0.8276, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5859/10000, Loss: 0.8276, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5860/10000, Loss: 0.8275, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5861/10000, Loss: 0.8274, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5862/10000, Loss: 0.8274, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5863/10000, Loss: 0.8273, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5864/10000, Loss: 0.8273, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5865/10000, Loss: 0.8272, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5866/10000, Loss: 0.8272, Accuracy: 0.6410, Learning Rate: 0.000100\n",
      "Epoch 5867/10000, Loss: 0.8271, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5868/10000, Loss: 0.8271, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5869/10000, Loss: 0.8270, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5870/10000, Loss: 0.8270, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5871/10000, Loss: 0.8269, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5872/10000, Loss: 0.8269, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5873/10000, Loss: 0.8268, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5874/10000, Loss: 0.8268, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5875/10000, Loss: 0.8267, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5876/10000, Loss: 0.8266, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5877/10000, Loss: 0.8266, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5878/10000, Loss: 0.8265, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5879/10000, Loss: 0.8265, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5880/10000, Loss: 0.8264, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5881/10000, Loss: 0.8264, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5882/10000, Loss: 0.8263, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5883/10000, Loss: 0.8263, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5884/10000, Loss: 0.8262, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5885/10000, Loss: 0.8262, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5886/10000, Loss: 0.8261, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5887/10000, Loss: 0.8261, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5888/10000, Loss: 0.8260, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5889/10000, Loss: 0.8260, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5890/10000, Loss: 0.8259, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5891/10000, Loss: 0.8258, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5892/10000, Loss: 0.8258, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5893/10000, Loss: 0.8257, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5894/10000, Loss: 0.8257, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5895/10000, Loss: 0.8256, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5896/10000, Loss: 0.8256, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5897/10000, Loss: 0.8255, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5898/10000, Loss: 0.8255, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5899/10000, Loss: 0.8254, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5900/10000, Loss: 0.8254, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5901/10000, Loss: 0.8253, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5902/10000, Loss: 0.8253, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5903/10000, Loss: 0.8252, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5904/10000, Loss: 0.8252, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5905/10000, Loss: 0.8251, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5906/10000, Loss: 0.8251, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5907/10000, Loss: 0.8250, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5908/10000, Loss: 0.8250, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5909/10000, Loss: 0.8249, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5910/10000, Loss: 0.8248, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5911/10000, Loss: 0.8248, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5912/10000, Loss: 0.8247, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5913/10000, Loss: 0.8247, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5914/10000, Loss: 0.8246, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5915/10000, Loss: 0.8246, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5916/10000, Loss: 0.8245, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5917/10000, Loss: 0.8245, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5918/10000, Loss: 0.8244, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5919/10000, Loss: 0.8244, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5920/10000, Loss: 0.8243, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5921/10000, Loss: 0.8243, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5922/10000, Loss: 0.8242, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5923/10000, Loss: 0.8242, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5924/10000, Loss: 0.8241, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5925/10000, Loss: 0.8241, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5926/10000, Loss: 0.8240, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5927/10000, Loss: 0.8240, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5928/10000, Loss: 0.8239, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5929/10000, Loss: 0.8238, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5930/10000, Loss: 0.8238, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5931/10000, Loss: 0.8237, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5932/10000, Loss: 0.8237, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5933/10000, Loss: 0.8236, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5934/10000, Loss: 0.8236, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5935/10000, Loss: 0.8235, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5936/10000, Loss: 0.8235, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5937/10000, Loss: 0.8234, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5938/10000, Loss: 0.8234, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5939/10000, Loss: 0.8233, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5940/10000, Loss: 0.8233, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5941/10000, Loss: 0.8232, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5942/10000, Loss: 0.8232, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5943/10000, Loss: 0.8231, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5944/10000, Loss: 0.8231, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5945/10000, Loss: 0.8230, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5946/10000, Loss: 0.8230, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5947/10000, Loss: 0.8229, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5948/10000, Loss: 0.8229, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5949/10000, Loss: 0.8228, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5950/10000, Loss: 0.8228, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5951/10000, Loss: 0.8227, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5952/10000, Loss: 0.8226, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5953/10000, Loss: 0.8226, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5954/10000, Loss: 0.8225, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5955/10000, Loss: 0.8225, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5956/10000, Loss: 0.8224, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5957/10000, Loss: 0.8224, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5958/10000, Loss: 0.8223, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5959/10000, Loss: 0.8223, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5960/10000, Loss: 0.8222, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5961/10000, Loss: 0.8222, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5962/10000, Loss: 0.8221, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5963/10000, Loss: 0.8221, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5964/10000, Loss: 0.8220, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5965/10000, Loss: 0.8220, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5966/10000, Loss: 0.8219, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5967/10000, Loss: 0.8219, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5968/10000, Loss: 0.8218, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5969/10000, Loss: 0.8218, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5970/10000, Loss: 0.8217, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5971/10000, Loss: 0.8217, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5972/10000, Loss: 0.8216, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5973/10000, Loss: 0.8216, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5974/10000, Loss: 0.8215, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5975/10000, Loss: 0.8215, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5976/10000, Loss: 0.8214, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5977/10000, Loss: 0.8214, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5978/10000, Loss: 0.8213, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5979/10000, Loss: 0.8213, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5980/10000, Loss: 0.8212, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5981/10000, Loss: 0.8211, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5982/10000, Loss: 0.8211, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5983/10000, Loss: 0.8210, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5984/10000, Loss: 0.8210, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5985/10000, Loss: 0.8209, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5986/10000, Loss: 0.8209, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5987/10000, Loss: 0.8208, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5988/10000, Loss: 0.8208, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5989/10000, Loss: 0.8207, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5990/10000, Loss: 0.8207, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5991/10000, Loss: 0.8206, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5992/10000, Loss: 0.8206, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5993/10000, Loss: 0.8205, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5994/10000, Loss: 0.8205, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5995/10000, Loss: 0.8204, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5996/10000, Loss: 0.8204, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5997/10000, Loss: 0.8203, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5998/10000, Loss: 0.8203, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 5999/10000, Loss: 0.8202, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6000/10000, Loss: 0.8202, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6001/10000, Loss: 0.8201, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6002/10000, Loss: 0.8201, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6003/10000, Loss: 0.8200, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6004/10000, Loss: 0.8200, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6005/10000, Loss: 0.8199, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6006/10000, Loss: 0.8199, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6007/10000, Loss: 0.8198, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6008/10000, Loss: 0.8198, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6009/10000, Loss: 0.8197, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6010/10000, Loss: 0.8197, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6011/10000, Loss: 0.8196, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6012/10000, Loss: 0.8196, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6013/10000, Loss: 0.8195, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6014/10000, Loss: 0.8195, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6015/10000, Loss: 0.8194, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6016/10000, Loss: 0.8194, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6017/10000, Loss: 0.8193, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6018/10000, Loss: 0.8193, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6019/10000, Loss: 0.8192, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6020/10000, Loss: 0.8192, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6021/10000, Loss: 0.8191, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6022/10000, Loss: 0.8190, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6023/10000, Loss: 0.8190, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6024/10000, Loss: 0.8189, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6025/10000, Loss: 0.8189, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6026/10000, Loss: 0.8188, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6027/10000, Loss: 0.8188, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6028/10000, Loss: 0.8187, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6029/10000, Loss: 0.8187, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6030/10000, Loss: 0.8186, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6031/10000, Loss: 0.8186, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6032/10000, Loss: 0.8185, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6033/10000, Loss: 0.8185, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6034/10000, Loss: 0.8184, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6035/10000, Loss: 0.8184, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6036/10000, Loss: 0.8183, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6037/10000, Loss: 0.8183, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6038/10000, Loss: 0.8182, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6039/10000, Loss: 0.8182, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6040/10000, Loss: 0.8181, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6041/10000, Loss: 0.8181, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6042/10000, Loss: 0.8180, Accuracy: 0.6538, Learning Rate: 0.000100\n",
      "Epoch 6043/10000, Loss: 0.8180, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6044/10000, Loss: 0.8179, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6045/10000, Loss: 0.8179, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6046/10000, Loss: 0.8178, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6047/10000, Loss: 0.8178, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6048/10000, Loss: 0.8177, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6049/10000, Loss: 0.8177, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6050/10000, Loss: 0.8176, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6051/10000, Loss: 0.8176, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6052/10000, Loss: 0.8175, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6053/10000, Loss: 0.8175, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6054/10000, Loss: 0.8174, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6055/10000, Loss: 0.8174, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6056/10000, Loss: 0.8173, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6057/10000, Loss: 0.8173, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6058/10000, Loss: 0.8172, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6059/10000, Loss: 0.8172, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6060/10000, Loss: 0.8171, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6061/10000, Loss: 0.8171, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6062/10000, Loss: 0.8170, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6063/10000, Loss: 0.8170, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6064/10000, Loss: 0.8169, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6065/10000, Loss: 0.8169, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6066/10000, Loss: 0.8168, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6067/10000, Loss: 0.8168, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6068/10000, Loss: 0.8167, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6069/10000, Loss: 0.8167, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6070/10000, Loss: 0.8166, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6071/10000, Loss: 0.8166, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6072/10000, Loss: 0.8165, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6073/10000, Loss: 0.8165, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6074/10000, Loss: 0.8164, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6075/10000, Loss: 0.8164, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6076/10000, Loss: 0.8163, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6077/10000, Loss: 0.8163, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6078/10000, Loss: 0.8162, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6079/10000, Loss: 0.8162, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6080/10000, Loss: 0.8161, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6081/10000, Loss: 0.8161, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6082/10000, Loss: 0.8160, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6083/10000, Loss: 0.8160, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6084/10000, Loss: 0.8159, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6085/10000, Loss: 0.8159, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6086/10000, Loss: 0.8158, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6087/10000, Loss: 0.8158, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6088/10000, Loss: 0.8157, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6089/10000, Loss: 0.8157, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6090/10000, Loss: 0.8156, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6091/10000, Loss: 0.8156, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6092/10000, Loss: 0.8155, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6093/10000, Loss: 0.8155, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6094/10000, Loss: 0.8154, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6095/10000, Loss: 0.8154, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6096/10000, Loss: 0.8153, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6097/10000, Loss: 0.8153, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6098/10000, Loss: 0.8152, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6099/10000, Loss: 0.8152, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6100/10000, Loss: 0.8151, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6101/10000, Loss: 0.8151, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6102/10000, Loss: 0.8150, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6103/10000, Loss: 0.8150, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6104/10000, Loss: 0.8149, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6105/10000, Loss: 0.8149, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6106/10000, Loss: 0.8148, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6107/10000, Loss: 0.8148, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6108/10000, Loss: 0.8147, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6109/10000, Loss: 0.8147, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6110/10000, Loss: 0.8146, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6111/10000, Loss: 0.8146, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6112/10000, Loss: 0.8145, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6113/10000, Loss: 0.8145, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6114/10000, Loss: 0.8144, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6115/10000, Loss: 0.8144, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6116/10000, Loss: 0.8143, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6117/10000, Loss: 0.8143, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6118/10000, Loss: 0.8142, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6119/10000, Loss: 0.8142, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6120/10000, Loss: 0.8141, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6121/10000, Loss: 0.8141, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6122/10000, Loss: 0.8140, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6123/10000, Loss: 0.8140, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6124/10000, Loss: 0.8139, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6125/10000, Loss: 0.8139, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6126/10000, Loss: 0.8138, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6127/10000, Loss: 0.8138, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6128/10000, Loss: 0.8137, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6129/10000, Loss: 0.8137, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6130/10000, Loss: 0.8136, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6131/10000, Loss: 0.8136, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6132/10000, Loss: 0.8135, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6133/10000, Loss: 0.8135, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6134/10000, Loss: 0.8134, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6135/10000, Loss: 0.8134, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6136/10000, Loss: 0.8134, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6137/10000, Loss: 0.8133, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6138/10000, Loss: 0.8133, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6139/10000, Loss: 0.8132, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6140/10000, Loss: 0.8132, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6141/10000, Loss: 0.8131, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6142/10000, Loss: 0.8131, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6143/10000, Loss: 0.8130, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6144/10000, Loss: 0.8130, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6145/10000, Loss: 0.8129, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6146/10000, Loss: 0.8129, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6147/10000, Loss: 0.8128, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6148/10000, Loss: 0.8128, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6149/10000, Loss: 0.8127, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6150/10000, Loss: 0.8127, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6151/10000, Loss: 0.8126, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6152/10000, Loss: 0.8126, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6153/10000, Loss: 0.8125, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6154/10000, Loss: 0.8125, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6155/10000, Loss: 0.8124, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6156/10000, Loss: 0.8124, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6157/10000, Loss: 0.8123, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6158/10000, Loss: 0.8123, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6159/10000, Loss: 0.8122, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6160/10000, Loss: 0.8122, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6161/10000, Loss: 0.8121, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6162/10000, Loss: 0.8121, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6163/10000, Loss: 0.8120, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6164/10000, Loss: 0.8120, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6165/10000, Loss: 0.8119, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6166/10000, Loss: 0.8119, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6167/10000, Loss: 0.8118, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6168/10000, Loss: 0.8118, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6169/10000, Loss: 0.8117, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6170/10000, Loss: 0.8117, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6171/10000, Loss: 0.8116, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6172/10000, Loss: 0.8116, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6173/10000, Loss: 0.8115, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6174/10000, Loss: 0.8115, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6175/10000, Loss: 0.8114, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6176/10000, Loss: 0.8114, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6177/10000, Loss: 0.8113, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6178/10000, Loss: 0.8113, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6179/10000, Loss: 0.8112, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6180/10000, Loss: 0.8112, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6181/10000, Loss: 0.8112, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6182/10000, Loss: 0.8111, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6183/10000, Loss: 0.8111, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6184/10000, Loss: 0.8110, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6185/10000, Loss: 0.8110, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6186/10000, Loss: 0.8109, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6187/10000, Loss: 0.8109, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6188/10000, Loss: 0.8108, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6189/10000, Loss: 0.8108, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6190/10000, Loss: 0.8107, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6191/10000, Loss: 0.8107, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6192/10000, Loss: 0.8106, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6193/10000, Loss: 0.8106, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6194/10000, Loss: 0.8105, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6195/10000, Loss: 0.8105, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6196/10000, Loss: 0.8104, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6197/10000, Loss: 0.8104, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6198/10000, Loss: 0.8103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6199/10000, Loss: 0.8103, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6200/10000, Loss: 0.8102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6201/10000, Loss: 0.8102, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6202/10000, Loss: 0.8101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6203/10000, Loss: 0.8101, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6204/10000, Loss: 0.8100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6205/10000, Loss: 0.8100, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6206/10000, Loss: 0.8099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6207/10000, Loss: 0.8099, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6208/10000, Loss: 0.8098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6209/10000, Loss: 0.8098, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6210/10000, Loss: 0.8097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6211/10000, Loss: 0.8097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6212/10000, Loss: 0.8097, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6213/10000, Loss: 0.8096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6214/10000, Loss: 0.8096, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6215/10000, Loss: 0.8095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6216/10000, Loss: 0.8095, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6217/10000, Loss: 0.8094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6218/10000, Loss: 0.8094, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6219/10000, Loss: 0.8093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6220/10000, Loss: 0.8093, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6221/10000, Loss: 0.8092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6222/10000, Loss: 0.8092, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6223/10000, Loss: 0.8091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6224/10000, Loss: 0.8091, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6225/10000, Loss: 0.8090, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6226/10000, Loss: 0.8090, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6227/10000, Loss: 0.8089, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6228/10000, Loss: 0.8089, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6229/10000, Loss: 0.8088, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6230/10000, Loss: 0.8088, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6231/10000, Loss: 0.8087, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6232/10000, Loss: 0.8087, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6233/10000, Loss: 0.8086, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6234/10000, Loss: 0.8086, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6235/10000, Loss: 0.8085, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6236/10000, Loss: 0.8085, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6237/10000, Loss: 0.8085, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6238/10000, Loss: 0.8084, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6239/10000, Loss: 0.8084, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6240/10000, Loss: 0.8083, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6241/10000, Loss: 0.8083, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6242/10000, Loss: 0.8082, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6243/10000, Loss: 0.8082, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6244/10000, Loss: 0.8081, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6245/10000, Loss: 0.8081, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6246/10000, Loss: 0.8080, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6247/10000, Loss: 0.8080, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6248/10000, Loss: 0.8079, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6249/10000, Loss: 0.8079, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6250/10000, Loss: 0.8078, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6251/10000, Loss: 0.8078, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6252/10000, Loss: 0.8077, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6253/10000, Loss: 0.8077, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6254/10000, Loss: 0.8076, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6255/10000, Loss: 0.8076, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6256/10000, Loss: 0.8075, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6257/10000, Loss: 0.8075, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6258/10000, Loss: 0.8075, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6259/10000, Loss: 0.8074, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6260/10000, Loss: 0.8074, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6261/10000, Loss: 0.8073, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6262/10000, Loss: 0.8073, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6263/10000, Loss: 0.8072, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6264/10000, Loss: 0.8072, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6265/10000, Loss: 0.8071, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6266/10000, Loss: 0.8071, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6267/10000, Loss: 0.8070, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6268/10000, Loss: 0.8070, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6269/10000, Loss: 0.8069, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6270/10000, Loss: 0.8069, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6271/10000, Loss: 0.8068, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6272/10000, Loss: 0.8068, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6273/10000, Loss: 0.8067, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6274/10000, Loss: 0.8067, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6275/10000, Loss: 0.8066, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6276/10000, Loss: 0.8066, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6277/10000, Loss: 0.8065, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6278/10000, Loss: 0.8065, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6279/10000, Loss: 0.8065, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6280/10000, Loss: 0.8064, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6281/10000, Loss: 0.8064, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6282/10000, Loss: 0.8063, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6283/10000, Loss: 0.8063, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6284/10000, Loss: 0.8062, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6285/10000, Loss: 0.8062, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6286/10000, Loss: 0.8061, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6287/10000, Loss: 0.8061, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6288/10000, Loss: 0.8060, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6289/10000, Loss: 0.8060, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6290/10000, Loss: 0.8059, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6291/10000, Loss: 0.8059, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6292/10000, Loss: 0.8058, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6293/10000, Loss: 0.8058, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6294/10000, Loss: 0.8057, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6295/10000, Loss: 0.8057, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6296/10000, Loss: 0.8057, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6297/10000, Loss: 0.8056, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6298/10000, Loss: 0.8056, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6299/10000, Loss: 0.8055, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6300/10000, Loss: 0.8055, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6301/10000, Loss: 0.8054, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6302/10000, Loss: 0.8054, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6303/10000, Loss: 0.8053, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6304/10000, Loss: 0.8053, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6305/10000, Loss: 0.8052, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6306/10000, Loss: 0.8052, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6307/10000, Loss: 0.8051, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6308/10000, Loss: 0.8051, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6309/10000, Loss: 0.8050, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6310/10000, Loss: 0.8050, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6311/10000, Loss: 0.8049, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6312/10000, Loss: 0.8049, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6313/10000, Loss: 0.8049, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6314/10000, Loss: 0.8048, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6315/10000, Loss: 0.8048, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6316/10000, Loss: 0.8047, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6317/10000, Loss: 0.8047, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6318/10000, Loss: 0.8046, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6319/10000, Loss: 0.8046, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6320/10000, Loss: 0.8045, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6321/10000, Loss: 0.8045, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6322/10000, Loss: 0.8044, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6323/10000, Loss: 0.8044, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6324/10000, Loss: 0.8043, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6325/10000, Loss: 0.8043, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6326/10000, Loss: 0.8042, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6327/10000, Loss: 0.8042, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6328/10000, Loss: 0.8042, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6329/10000, Loss: 0.8041, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6330/10000, Loss: 0.8041, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6331/10000, Loss: 0.8040, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6332/10000, Loss: 0.8040, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6333/10000, Loss: 0.8039, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6334/10000, Loss: 0.8039, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6335/10000, Loss: 0.8038, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6336/10000, Loss: 0.8038, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6337/10000, Loss: 0.8037, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6338/10000, Loss: 0.8037, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6339/10000, Loss: 0.8036, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6340/10000, Loss: 0.8036, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6341/10000, Loss: 0.8035, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6342/10000, Loss: 0.8035, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6343/10000, Loss: 0.8035, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6344/10000, Loss: 0.8034, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6345/10000, Loss: 0.8034, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6346/10000, Loss: 0.8033, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6347/10000, Loss: 0.8033, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6348/10000, Loss: 0.8032, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6349/10000, Loss: 0.8032, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6350/10000, Loss: 0.8031, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6351/10000, Loss: 0.8031, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6352/10000, Loss: 0.8030, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6353/10000, Loss: 0.8030, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6354/10000, Loss: 0.8029, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6355/10000, Loss: 0.8029, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6356/10000, Loss: 0.8028, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6357/10000, Loss: 0.8028, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6358/10000, Loss: 0.8028, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6359/10000, Loss: 0.8027, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6360/10000, Loss: 0.8027, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6361/10000, Loss: 0.8026, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6362/10000, Loss: 0.8026, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6363/10000, Loss: 0.8025, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6364/10000, Loss: 0.8025, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6365/10000, Loss: 0.8024, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6366/10000, Loss: 0.8024, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6367/10000, Loss: 0.8023, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6368/10000, Loss: 0.8023, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6369/10000, Loss: 0.8022, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6370/10000, Loss: 0.8022, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6371/10000, Loss: 0.8022, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6372/10000, Loss: 0.8021, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6373/10000, Loss: 0.8021, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6374/10000, Loss: 0.8020, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6375/10000, Loss: 0.8020, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6376/10000, Loss: 0.8019, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6377/10000, Loss: 0.8019, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6378/10000, Loss: 0.8018, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6379/10000, Loss: 0.8018, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6380/10000, Loss: 0.8017, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6381/10000, Loss: 0.8017, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6382/10000, Loss: 0.8016, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6383/10000, Loss: 0.8016, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6384/10000, Loss: 0.8016, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6385/10000, Loss: 0.8015, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6386/10000, Loss: 0.8015, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6387/10000, Loss: 0.8014, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6388/10000, Loss: 0.8014, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6389/10000, Loss: 0.8013, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6390/10000, Loss: 0.8013, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6391/10000, Loss: 0.8012, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6392/10000, Loss: 0.8012, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6393/10000, Loss: 0.8011, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6394/10000, Loss: 0.8011, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6395/10000, Loss: 0.8010, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6396/10000, Loss: 0.8010, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6397/10000, Loss: 0.8010, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6398/10000, Loss: 0.8009, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6399/10000, Loss: 0.8009, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6400/10000, Loss: 0.8008, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6401/10000, Loss: 0.8008, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6402/10000, Loss: 0.8007, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6403/10000, Loss: 0.8007, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6404/10000, Loss: 0.8006, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6405/10000, Loss: 0.8006, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6406/10000, Loss: 0.8005, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6407/10000, Loss: 0.8005, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6408/10000, Loss: 0.8005, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6409/10000, Loss: 0.8004, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6410/10000, Loss: 0.8004, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6411/10000, Loss: 0.8003, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6412/10000, Loss: 0.8003, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6413/10000, Loss: 0.8002, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6414/10000, Loss: 0.8002, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6415/10000, Loss: 0.8001, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6416/10000, Loss: 0.8001, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6417/10000, Loss: 0.8000, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6418/10000, Loss: 0.8000, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6419/10000, Loss: 0.7999, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6420/10000, Loss: 0.7999, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6421/10000, Loss: 0.7999, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6422/10000, Loss: 0.7998, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6423/10000, Loss: 0.7998, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6424/10000, Loss: 0.7997, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6425/10000, Loss: 0.7997, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6426/10000, Loss: 0.7996, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6427/10000, Loss: 0.7996, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6428/10000, Loss: 0.7995, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6429/10000, Loss: 0.7995, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6430/10000, Loss: 0.7994, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6431/10000, Loss: 0.7994, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6432/10000, Loss: 0.7994, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6433/10000, Loss: 0.7993, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6434/10000, Loss: 0.7993, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6435/10000, Loss: 0.7992, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6436/10000, Loss: 0.7992, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6437/10000, Loss: 0.7991, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6438/10000, Loss: 0.7991, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6439/10000, Loss: 0.7990, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6440/10000, Loss: 0.7990, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6441/10000, Loss: 0.7989, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6442/10000, Loss: 0.7989, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6443/10000, Loss: 0.7989, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6444/10000, Loss: 0.7988, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6445/10000, Loss: 0.7988, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6446/10000, Loss: 0.7987, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6447/10000, Loss: 0.7987, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6448/10000, Loss: 0.7986, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6449/10000, Loss: 0.7986, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6450/10000, Loss: 0.7985, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6451/10000, Loss: 0.7985, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6452/10000, Loss: 0.7984, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6453/10000, Loss: 0.7984, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6454/10000, Loss: 0.7984, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6455/10000, Loss: 0.7983, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6456/10000, Loss: 0.7983, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6457/10000, Loss: 0.7982, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6458/10000, Loss: 0.7982, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6459/10000, Loss: 0.7981, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6460/10000, Loss: 0.7981, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6461/10000, Loss: 0.7980, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6462/10000, Loss: 0.7980, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6463/10000, Loss: 0.7979, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6464/10000, Loss: 0.7979, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6465/10000, Loss: 0.7979, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6466/10000, Loss: 0.7978, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6467/10000, Loss: 0.7978, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6468/10000, Loss: 0.7977, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6469/10000, Loss: 0.7977, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6470/10000, Loss: 0.7976, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6471/10000, Loss: 0.7976, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6472/10000, Loss: 0.7975, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6473/10000, Loss: 0.7975, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6474/10000, Loss: 0.7975, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6475/10000, Loss: 0.7974, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6476/10000, Loss: 0.7974, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6477/10000, Loss: 0.7973, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6478/10000, Loss: 0.7973, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6479/10000, Loss: 0.7972, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6480/10000, Loss: 0.7972, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6481/10000, Loss: 0.7971, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6482/10000, Loss: 0.7971, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6483/10000, Loss: 0.7970, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6484/10000, Loss: 0.7970, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6485/10000, Loss: 0.7970, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6486/10000, Loss: 0.7969, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6487/10000, Loss: 0.7969, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6488/10000, Loss: 0.7968, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6489/10000, Loss: 0.7968, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6490/10000, Loss: 0.7967, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6491/10000, Loss: 0.7967, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6492/10000, Loss: 0.7966, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6493/10000, Loss: 0.7966, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6494/10000, Loss: 0.7966, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6495/10000, Loss: 0.7965, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6496/10000, Loss: 0.7965, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6497/10000, Loss: 0.7964, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6498/10000, Loss: 0.7964, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6499/10000, Loss: 0.7963, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6500/10000, Loss: 0.7963, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6501/10000, Loss: 0.7962, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6502/10000, Loss: 0.7962, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6503/10000, Loss: 0.7961, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6504/10000, Loss: 0.7961, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6505/10000, Loss: 0.7961, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6506/10000, Loss: 0.7960, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6507/10000, Loss: 0.7960, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6508/10000, Loss: 0.7959, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6509/10000, Loss: 0.7959, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6510/10000, Loss: 0.7958, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6511/10000, Loss: 0.7958, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6512/10000, Loss: 0.7957, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6513/10000, Loss: 0.7957, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6514/10000, Loss: 0.7957, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6515/10000, Loss: 0.7956, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6516/10000, Loss: 0.7956, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6517/10000, Loss: 0.7955, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6518/10000, Loss: 0.7955, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6519/10000, Loss: 0.7954, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6520/10000, Loss: 0.7954, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6521/10000, Loss: 0.7953, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6522/10000, Loss: 0.7953, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6523/10000, Loss: 0.7953, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6524/10000, Loss: 0.7952, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6525/10000, Loss: 0.7952, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6526/10000, Loss: 0.7951, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6527/10000, Loss: 0.7951, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6528/10000, Loss: 0.7950, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6529/10000, Loss: 0.7950, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6530/10000, Loss: 0.7949, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6531/10000, Loss: 0.7949, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6532/10000, Loss: 0.7949, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6533/10000, Loss: 0.7948, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6534/10000, Loss: 0.7948, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6535/10000, Loss: 0.7947, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6536/10000, Loss: 0.7947, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6537/10000, Loss: 0.7946, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6538/10000, Loss: 0.7946, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6539/10000, Loss: 0.7945, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6540/10000, Loss: 0.7945, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6541/10000, Loss: 0.7945, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6542/10000, Loss: 0.7944, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6543/10000, Loss: 0.7944, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6544/10000, Loss: 0.7943, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6545/10000, Loss: 0.7943, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6546/10000, Loss: 0.7942, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6547/10000, Loss: 0.7942, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6548/10000, Loss: 0.7941, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6549/10000, Loss: 0.7941, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6550/10000, Loss: 0.7941, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6551/10000, Loss: 0.7940, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6552/10000, Loss: 0.7940, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6553/10000, Loss: 0.7939, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6554/10000, Loss: 0.7939, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6555/10000, Loss: 0.7938, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6556/10000, Loss: 0.7938, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6557/10000, Loss: 0.7937, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6558/10000, Loss: 0.7937, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6559/10000, Loss: 0.7937, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6560/10000, Loss: 0.7936, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6561/10000, Loss: 0.7936, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6562/10000, Loss: 0.7935, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6563/10000, Loss: 0.7935, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6564/10000, Loss: 0.7934, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6565/10000, Loss: 0.7934, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6566/10000, Loss: 0.7933, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6567/10000, Loss: 0.7933, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6568/10000, Loss: 0.7933, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6569/10000, Loss: 0.7932, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6570/10000, Loss: 0.7932, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6571/10000, Loss: 0.7931, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6572/10000, Loss: 0.7931, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6573/10000, Loss: 0.7930, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6574/10000, Loss: 0.7930, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6575/10000, Loss: 0.7929, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6576/10000, Loss: 0.7929, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6577/10000, Loss: 0.7929, Accuracy: 0.6667, Learning Rate: 0.000100\n",
      "Epoch 6578/10000, Loss: 0.7928, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6579/10000, Loss: 0.7928, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6580/10000, Loss: 0.7927, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6581/10000, Loss: 0.7927, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6582/10000, Loss: 0.7926, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6583/10000, Loss: 0.7926, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6584/10000, Loss: 0.7926, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6585/10000, Loss: 0.7925, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6586/10000, Loss: 0.7925, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6587/10000, Loss: 0.7924, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6588/10000, Loss: 0.7924, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6589/10000, Loss: 0.7923, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6590/10000, Loss: 0.7923, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6591/10000, Loss: 0.7922, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6592/10000, Loss: 0.7922, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6593/10000, Loss: 0.7922, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6594/10000, Loss: 0.7921, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6595/10000, Loss: 0.7921, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6596/10000, Loss: 0.7920, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6597/10000, Loss: 0.7920, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6598/10000, Loss: 0.7919, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6599/10000, Loss: 0.7919, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6600/10000, Loss: 0.7918, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6601/10000, Loss: 0.7918, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6602/10000, Loss: 0.7918, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6603/10000, Loss: 0.7917, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6604/10000, Loss: 0.7917, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6605/10000, Loss: 0.7916, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6606/10000, Loss: 0.7916, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6607/10000, Loss: 0.7915, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6608/10000, Loss: 0.7915, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6609/10000, Loss: 0.7915, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6610/10000, Loss: 0.7914, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6611/10000, Loss: 0.7914, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6612/10000, Loss: 0.7913, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6613/10000, Loss: 0.7913, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6614/10000, Loss: 0.7912, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6615/10000, Loss: 0.7912, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6616/10000, Loss: 0.7911, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6617/10000, Loss: 0.7911, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6618/10000, Loss: 0.7911, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6619/10000, Loss: 0.7910, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6620/10000, Loss: 0.7910, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6621/10000, Loss: 0.7909, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6622/10000, Loss: 0.7909, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6623/10000, Loss: 0.7908, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6624/10000, Loss: 0.7908, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6625/10000, Loss: 0.7908, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6626/10000, Loss: 0.7907, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6627/10000, Loss: 0.7907, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6628/10000, Loss: 0.7906, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6629/10000, Loss: 0.7906, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6630/10000, Loss: 0.7905, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6631/10000, Loss: 0.7905, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6632/10000, Loss: 0.7905, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6633/10000, Loss: 0.7904, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6634/10000, Loss: 0.7904, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6635/10000, Loss: 0.7903, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6636/10000, Loss: 0.7903, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6637/10000, Loss: 0.7902, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6638/10000, Loss: 0.7902, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6639/10000, Loss: 0.7901, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6640/10000, Loss: 0.7901, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6641/10000, Loss: 0.7901, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6642/10000, Loss: 0.7900, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6643/10000, Loss: 0.7900, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6644/10000, Loss: 0.7899, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6645/10000, Loss: 0.7899, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6646/10000, Loss: 0.7898, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6647/10000, Loss: 0.7898, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6648/10000, Loss: 0.7898, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6649/10000, Loss: 0.7897, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6650/10000, Loss: 0.7897, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6651/10000, Loss: 0.7896, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6652/10000, Loss: 0.7896, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6653/10000, Loss: 0.7895, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6654/10000, Loss: 0.7895, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6655/10000, Loss: 0.7895, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6656/10000, Loss: 0.7894, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6657/10000, Loss: 0.7894, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6658/10000, Loss: 0.7893, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6659/10000, Loss: 0.7893, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6660/10000, Loss: 0.7892, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6661/10000, Loss: 0.7892, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6662/10000, Loss: 0.7891, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6663/10000, Loss: 0.7891, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6664/10000, Loss: 0.7891, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6665/10000, Loss: 0.7890, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6666/10000, Loss: 0.7890, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6667/10000, Loss: 0.7889, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6668/10000, Loss: 0.7889, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6669/10000, Loss: 0.7888, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6670/10000, Loss: 0.7888, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6671/10000, Loss: 0.7888, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6672/10000, Loss: 0.7887, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6673/10000, Loss: 0.7887, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6674/10000, Loss: 0.7886, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6675/10000, Loss: 0.7886, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6676/10000, Loss: 0.7885, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6677/10000, Loss: 0.7885, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6678/10000, Loss: 0.7885, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6679/10000, Loss: 0.7884, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6680/10000, Loss: 0.7884, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6681/10000, Loss: 0.7883, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6682/10000, Loss: 0.7883, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6683/10000, Loss: 0.7882, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6684/10000, Loss: 0.7882, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6685/10000, Loss: 0.7882, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6686/10000, Loss: 0.7881, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6687/10000, Loss: 0.7881, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6688/10000, Loss: 0.7880, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6689/10000, Loss: 0.7880, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6690/10000, Loss: 0.7879, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6691/10000, Loss: 0.7879, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6692/10000, Loss: 0.7879, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6693/10000, Loss: 0.7878, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6694/10000, Loss: 0.7878, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6695/10000, Loss: 0.7877, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6696/10000, Loss: 0.7877, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6697/10000, Loss: 0.7876, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6698/10000, Loss: 0.7876, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6699/10000, Loss: 0.7876, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6700/10000, Loss: 0.7875, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6701/10000, Loss: 0.7875, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6702/10000, Loss: 0.7874, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6703/10000, Loss: 0.7874, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6704/10000, Loss: 0.7873, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6705/10000, Loss: 0.7873, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6706/10000, Loss: 0.7873, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6707/10000, Loss: 0.7872, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6708/10000, Loss: 0.7872, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6709/10000, Loss: 0.7871, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6710/10000, Loss: 0.7871, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6711/10000, Loss: 0.7870, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6712/10000, Loss: 0.7870, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6713/10000, Loss: 0.7870, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6714/10000, Loss: 0.7869, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6715/10000, Loss: 0.7869, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6716/10000, Loss: 0.7868, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6717/10000, Loss: 0.7868, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6718/10000, Loss: 0.7867, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6719/10000, Loss: 0.7867, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6720/10000, Loss: 0.7867, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6721/10000, Loss: 0.7866, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6722/10000, Loss: 0.7866, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6723/10000, Loss: 0.7865, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6724/10000, Loss: 0.7865, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6725/10000, Loss: 0.7864, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6726/10000, Loss: 0.7864, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6727/10000, Loss: 0.7864, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6728/10000, Loss: 0.7863, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6729/10000, Loss: 0.7863, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6730/10000, Loss: 0.7862, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6731/10000, Loss: 0.7862, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6732/10000, Loss: 0.7861, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6733/10000, Loss: 0.7861, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6734/10000, Loss: 0.7861, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6735/10000, Loss: 0.7860, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6736/10000, Loss: 0.7860, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6737/10000, Loss: 0.7859, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6738/10000, Loss: 0.7859, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6739/10000, Loss: 0.7858, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6740/10000, Loss: 0.7858, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6741/10000, Loss: 0.7858, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6742/10000, Loss: 0.7857, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6743/10000, Loss: 0.7857, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6744/10000, Loss: 0.7856, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6745/10000, Loss: 0.7856, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6746/10000, Loss: 0.7855, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6747/10000, Loss: 0.7855, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6748/10000, Loss: 0.7855, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6749/10000, Loss: 0.7854, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6750/10000, Loss: 0.7854, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6751/10000, Loss: 0.7853, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6752/10000, Loss: 0.7853, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6753/10000, Loss: 0.7853, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6754/10000, Loss: 0.7852, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6755/10000, Loss: 0.7852, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6756/10000, Loss: 0.7851, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6757/10000, Loss: 0.7851, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6758/10000, Loss: 0.7850, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6759/10000, Loss: 0.7850, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6760/10000, Loss: 0.7850, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6761/10000, Loss: 0.7849, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6762/10000, Loss: 0.7849, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6763/10000, Loss: 0.7848, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6764/10000, Loss: 0.7848, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6765/10000, Loss: 0.7847, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6766/10000, Loss: 0.7847, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6767/10000, Loss: 0.7847, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6768/10000, Loss: 0.7846, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6769/10000, Loss: 0.7846, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6770/10000, Loss: 0.7845, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6771/10000, Loss: 0.7845, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6772/10000, Loss: 0.7844, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6773/10000, Loss: 0.7844, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6774/10000, Loss: 0.7844, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6775/10000, Loss: 0.7843, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6776/10000, Loss: 0.7843, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6777/10000, Loss: 0.7842, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6778/10000, Loss: 0.7842, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6779/10000, Loss: 0.7842, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6780/10000, Loss: 0.7841, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6781/10000, Loss: 0.7841, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6782/10000, Loss: 0.7840, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6783/10000, Loss: 0.7840, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6784/10000, Loss: 0.7839, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6785/10000, Loss: 0.7839, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6786/10000, Loss: 0.7839, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6787/10000, Loss: 0.7838, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6788/10000, Loss: 0.7838, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6789/10000, Loss: 0.7837, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6790/10000, Loss: 0.7837, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6791/10000, Loss: 0.7836, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6792/10000, Loss: 0.7836, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6793/10000, Loss: 0.7836, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6794/10000, Loss: 0.7835, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6795/10000, Loss: 0.7835, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6796/10000, Loss: 0.7834, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6797/10000, Loss: 0.7834, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6798/10000, Loss: 0.7834, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6799/10000, Loss: 0.7833, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6800/10000, Loss: 0.7833, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6801/10000, Loss: 0.7832, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6802/10000, Loss: 0.7832, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6803/10000, Loss: 0.7831, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6804/10000, Loss: 0.7831, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6805/10000, Loss: 0.7831, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6806/10000, Loss: 0.7830, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6807/10000, Loss: 0.7830, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6808/10000, Loss: 0.7829, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6809/10000, Loss: 0.7829, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6810/10000, Loss: 0.7828, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6811/10000, Loss: 0.7828, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6812/10000, Loss: 0.7828, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6813/10000, Loss: 0.7827, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6814/10000, Loss: 0.7827, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6815/10000, Loss: 0.7826, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6816/10000, Loss: 0.7826, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6817/10000, Loss: 0.7826, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6818/10000, Loss: 0.7825, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6819/10000, Loss: 0.7825, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6820/10000, Loss: 0.7824, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6821/10000, Loss: 0.7824, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6822/10000, Loss: 0.7823, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6823/10000, Loss: 0.7823, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6824/10000, Loss: 0.7823, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6825/10000, Loss: 0.7822, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6826/10000, Loss: 0.7822, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6827/10000, Loss: 0.7821, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6828/10000, Loss: 0.7821, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6829/10000, Loss: 0.7821, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6830/10000, Loss: 0.7820, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6831/10000, Loss: 0.7820, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6832/10000, Loss: 0.7819, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6833/10000, Loss: 0.7819, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6834/10000, Loss: 0.7818, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6835/10000, Loss: 0.7818, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6836/10000, Loss: 0.7818, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6837/10000, Loss: 0.7817, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6838/10000, Loss: 0.7817, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6839/10000, Loss: 0.7816, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6840/10000, Loss: 0.7816, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6841/10000, Loss: 0.7816, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6842/10000, Loss: 0.7815, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6843/10000, Loss: 0.7815, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6844/10000, Loss: 0.7814, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6845/10000, Loss: 0.7814, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6846/10000, Loss: 0.7813, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6847/10000, Loss: 0.7813, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6848/10000, Loss: 0.7813, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6849/10000, Loss: 0.7812, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6850/10000, Loss: 0.7812, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6851/10000, Loss: 0.7811, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6852/10000, Loss: 0.7811, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6853/10000, Loss: 0.7811, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6854/10000, Loss: 0.7810, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6855/10000, Loss: 0.7810, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6856/10000, Loss: 0.7809, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6857/10000, Loss: 0.7809, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6858/10000, Loss: 0.7808, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6859/10000, Loss: 0.7808, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6860/10000, Loss: 0.7808, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6861/10000, Loss: 0.7807, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6862/10000, Loss: 0.7807, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6863/10000, Loss: 0.7806, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6864/10000, Loss: 0.7806, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6865/10000, Loss: 0.7806, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6866/10000, Loss: 0.7805, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6867/10000, Loss: 0.7805, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6868/10000, Loss: 0.7804, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6869/10000, Loss: 0.7804, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6870/10000, Loss: 0.7803, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6871/10000, Loss: 0.7803, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6872/10000, Loss: 0.7803, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6873/10000, Loss: 0.7802, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6874/10000, Loss: 0.7802, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6875/10000, Loss: 0.7801, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6876/10000, Loss: 0.7801, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6877/10000, Loss: 0.7801, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6878/10000, Loss: 0.7800, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6879/10000, Loss: 0.7800, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6880/10000, Loss: 0.7799, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6881/10000, Loss: 0.7799, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6882/10000, Loss: 0.7799, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6883/10000, Loss: 0.7798, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6884/10000, Loss: 0.7798, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6885/10000, Loss: 0.7797, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6886/10000, Loss: 0.7797, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6887/10000, Loss: 0.7796, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6888/10000, Loss: 0.7796, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6889/10000, Loss: 0.7796, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6890/10000, Loss: 0.7795, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6891/10000, Loss: 0.7795, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6892/10000, Loss: 0.7794, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6893/10000, Loss: 0.7794, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6894/10000, Loss: 0.7794, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6895/10000, Loss: 0.7793, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6896/10000, Loss: 0.7793, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6897/10000, Loss: 0.7792, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6898/10000, Loss: 0.7792, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6899/10000, Loss: 0.7791, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6900/10000, Loss: 0.7791, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6901/10000, Loss: 0.7791, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6902/10000, Loss: 0.7790, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6903/10000, Loss: 0.7790, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6904/10000, Loss: 0.7789, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6905/10000, Loss: 0.7789, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6906/10000, Loss: 0.7789, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6907/10000, Loss: 0.7788, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6908/10000, Loss: 0.7788, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6909/10000, Loss: 0.7787, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6910/10000, Loss: 0.7787, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6911/10000, Loss: 0.7787, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6912/10000, Loss: 0.7786, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6913/10000, Loss: 0.7786, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6914/10000, Loss: 0.7785, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6915/10000, Loss: 0.7785, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6916/10000, Loss: 0.7785, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6917/10000, Loss: 0.7784, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6918/10000, Loss: 0.7784, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6919/10000, Loss: 0.7783, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6920/10000, Loss: 0.7783, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6921/10000, Loss: 0.7782, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6922/10000, Loss: 0.7782, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6923/10000, Loss: 0.7782, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6924/10000, Loss: 0.7781, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6925/10000, Loss: 0.7781, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6926/10000, Loss: 0.7780, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6927/10000, Loss: 0.7780, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6928/10000, Loss: 0.7780, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6929/10000, Loss: 0.7779, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6930/10000, Loss: 0.7779, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6931/10000, Loss: 0.7778, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6932/10000, Loss: 0.7778, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6933/10000, Loss: 0.7778, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6934/10000, Loss: 0.7777, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6935/10000, Loss: 0.7777, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6936/10000, Loss: 0.7776, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6937/10000, Loss: 0.7776, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6938/10000, Loss: 0.7775, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6939/10000, Loss: 0.7775, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6940/10000, Loss: 0.7775, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6941/10000, Loss: 0.7774, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6942/10000, Loss: 0.7774, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6943/10000, Loss: 0.7773, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6944/10000, Loss: 0.7773, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6945/10000, Loss: 0.7773, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6946/10000, Loss: 0.7772, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6947/10000, Loss: 0.7772, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6948/10000, Loss: 0.7771, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6949/10000, Loss: 0.7771, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6950/10000, Loss: 0.7771, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6951/10000, Loss: 0.7770, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6952/10000, Loss: 0.7770, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6953/10000, Loss: 0.7769, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6954/10000, Loss: 0.7769, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6955/10000, Loss: 0.7769, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6956/10000, Loss: 0.7768, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6957/10000, Loss: 0.7768, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6958/10000, Loss: 0.7767, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6959/10000, Loss: 0.7767, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6960/10000, Loss: 0.7767, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6961/10000, Loss: 0.7766, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6962/10000, Loss: 0.7766, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6963/10000, Loss: 0.7765, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6964/10000, Loss: 0.7765, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6965/10000, Loss: 0.7764, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6966/10000, Loss: 0.7764, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6967/10000, Loss: 0.7764, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6968/10000, Loss: 0.7763, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6969/10000, Loss: 0.7763, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6970/10000, Loss: 0.7762, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6971/10000, Loss: 0.7762, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6972/10000, Loss: 0.7762, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6973/10000, Loss: 0.7761, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6974/10000, Loss: 0.7761, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6975/10000, Loss: 0.7760, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6976/10000, Loss: 0.7760, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6977/10000, Loss: 0.7760, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6978/10000, Loss: 0.7759, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6979/10000, Loss: 0.7759, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6980/10000, Loss: 0.7758, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6981/10000, Loss: 0.7758, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6982/10000, Loss: 0.7758, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6983/10000, Loss: 0.7757, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6984/10000, Loss: 0.7757, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6985/10000, Loss: 0.7756, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6986/10000, Loss: 0.7756, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6987/10000, Loss: 0.7756, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6988/10000, Loss: 0.7755, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6989/10000, Loss: 0.7755, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6990/10000, Loss: 0.7754, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6991/10000, Loss: 0.7754, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6992/10000, Loss: 0.7754, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6993/10000, Loss: 0.7753, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6994/10000, Loss: 0.7753, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6995/10000, Loss: 0.7752, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6996/10000, Loss: 0.7752, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6997/10000, Loss: 0.7752, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6998/10000, Loss: 0.7751, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 6999/10000, Loss: 0.7751, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7000/10000, Loss: 0.7750, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7001/10000, Loss: 0.7750, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7002/10000, Loss: 0.7749, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7003/10000, Loss: 0.7749, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7004/10000, Loss: 0.7749, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7005/10000, Loss: 0.7748, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7006/10000, Loss: 0.7748, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7007/10000, Loss: 0.7747, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7008/10000, Loss: 0.7747, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7009/10000, Loss: 0.7747, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7010/10000, Loss: 0.7746, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7011/10000, Loss: 0.7746, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7012/10000, Loss: 0.7745, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7013/10000, Loss: 0.7745, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7014/10000, Loss: 0.7745, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7015/10000, Loss: 0.7744, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7016/10000, Loss: 0.7744, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7017/10000, Loss: 0.7743, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7018/10000, Loss: 0.7743, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7019/10000, Loss: 0.7743, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7020/10000, Loss: 0.7742, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7021/10000, Loss: 0.7742, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7022/10000, Loss: 0.7741, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7023/10000, Loss: 0.7741, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7024/10000, Loss: 0.7741, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7025/10000, Loss: 0.7740, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7026/10000, Loss: 0.7740, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7027/10000, Loss: 0.7739, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7028/10000, Loss: 0.7739, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7029/10000, Loss: 0.7739, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7030/10000, Loss: 0.7738, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7031/10000, Loss: 0.7738, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7032/10000, Loss: 0.7737, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7033/10000, Loss: 0.7737, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7034/10000, Loss: 0.7737, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7035/10000, Loss: 0.7736, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7036/10000, Loss: 0.7736, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7037/10000, Loss: 0.7735, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7038/10000, Loss: 0.7735, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7039/10000, Loss: 0.7735, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7040/10000, Loss: 0.7734, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7041/10000, Loss: 0.7734, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7042/10000, Loss: 0.7733, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7043/10000, Loss: 0.7733, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7044/10000, Loss: 0.7733, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7045/10000, Loss: 0.7732, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7046/10000, Loss: 0.7732, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7047/10000, Loss: 0.7731, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7048/10000, Loss: 0.7731, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7049/10000, Loss: 0.7731, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7050/10000, Loss: 0.7730, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7051/10000, Loss: 0.7730, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7052/10000, Loss: 0.7729, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7053/10000, Loss: 0.7729, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7054/10000, Loss: 0.7729, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7055/10000, Loss: 0.7728, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7056/10000, Loss: 0.7728, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7057/10000, Loss: 0.7727, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7058/10000, Loss: 0.7727, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7059/10000, Loss: 0.7727, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7060/10000, Loss: 0.7726, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7061/10000, Loss: 0.7726, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7062/10000, Loss: 0.7725, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7063/10000, Loss: 0.7725, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7064/10000, Loss: 0.7725, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7065/10000, Loss: 0.7724, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7066/10000, Loss: 0.7724, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7067/10000, Loss: 0.7723, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7068/10000, Loss: 0.7723, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7069/10000, Loss: 0.7723, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7070/10000, Loss: 0.7722, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7071/10000, Loss: 0.7722, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7072/10000, Loss: 0.7721, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7073/10000, Loss: 0.7721, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7074/10000, Loss: 0.7721, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7075/10000, Loss: 0.7720, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7076/10000, Loss: 0.7720, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7077/10000, Loss: 0.7719, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7078/10000, Loss: 0.7719, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7079/10000, Loss: 0.7719, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7080/10000, Loss: 0.7718, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7081/10000, Loss: 0.7718, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7082/10000, Loss: 0.7717, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7083/10000, Loss: 0.7717, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7084/10000, Loss: 0.7717, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7085/10000, Loss: 0.7716, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7086/10000, Loss: 0.7716, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7087/10000, Loss: 0.7715, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7088/10000, Loss: 0.7715, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7089/10000, Loss: 0.7715, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7090/10000, Loss: 0.7714, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7091/10000, Loss: 0.7714, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7092/10000, Loss: 0.7713, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7093/10000, Loss: 0.7713, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7094/10000, Loss: 0.7713, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7095/10000, Loss: 0.7712, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7096/10000, Loss: 0.7712, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7097/10000, Loss: 0.7712, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7098/10000, Loss: 0.7711, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7099/10000, Loss: 0.7711, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7100/10000, Loss: 0.7710, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7101/10000, Loss: 0.7710, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7102/10000, Loss: 0.7710, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7103/10000, Loss: 0.7709, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7104/10000, Loss: 0.7709, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7105/10000, Loss: 0.7708, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7106/10000, Loss: 0.7708, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7107/10000, Loss: 0.7708, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7108/10000, Loss: 0.7707, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7109/10000, Loss: 0.7707, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7110/10000, Loss: 0.7706, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7111/10000, Loss: 0.7706, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7112/10000, Loss: 0.7706, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7113/10000, Loss: 0.7705, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7114/10000, Loss: 0.7705, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7115/10000, Loss: 0.7704, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7116/10000, Loss: 0.7704, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7117/10000, Loss: 0.7704, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7118/10000, Loss: 0.7703, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7119/10000, Loss: 0.7703, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7120/10000, Loss: 0.7702, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7121/10000, Loss: 0.7702, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7122/10000, Loss: 0.7702, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7123/10000, Loss: 0.7701, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7124/10000, Loss: 0.7701, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7125/10000, Loss: 0.7700, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7126/10000, Loss: 0.7700, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7127/10000, Loss: 0.7700, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7128/10000, Loss: 0.7699, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7129/10000, Loss: 0.7699, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7130/10000, Loss: 0.7698, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7131/10000, Loss: 0.7698, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7132/10000, Loss: 0.7698, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7133/10000, Loss: 0.7697, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7134/10000, Loss: 0.7697, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7135/10000, Loss: 0.7697, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7136/10000, Loss: 0.7696, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7137/10000, Loss: 0.7696, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7138/10000, Loss: 0.7695, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7139/10000, Loss: 0.7695, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7140/10000, Loss: 0.7695, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7141/10000, Loss: 0.7694, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7142/10000, Loss: 0.7694, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7143/10000, Loss: 0.7693, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7144/10000, Loss: 0.7693, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7145/10000, Loss: 0.7693, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7146/10000, Loss: 0.7692, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7147/10000, Loss: 0.7692, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7148/10000, Loss: 0.7691, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7149/10000, Loss: 0.7691, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7150/10000, Loss: 0.7691, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7151/10000, Loss: 0.7690, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7152/10000, Loss: 0.7690, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7153/10000, Loss: 0.7689, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7154/10000, Loss: 0.7689, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7155/10000, Loss: 0.7689, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7156/10000, Loss: 0.7688, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7157/10000, Loss: 0.7688, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7158/10000, Loss: 0.7687, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7159/10000, Loss: 0.7687, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7160/10000, Loss: 0.7687, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7161/10000, Loss: 0.7686, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7162/10000, Loss: 0.7686, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7163/10000, Loss: 0.7686, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7164/10000, Loss: 0.7685, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7165/10000, Loss: 0.7685, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7166/10000, Loss: 0.7684, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7167/10000, Loss: 0.7684, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7168/10000, Loss: 0.7684, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7169/10000, Loss: 0.7683, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7170/10000, Loss: 0.7683, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7171/10000, Loss: 0.7682, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7172/10000, Loss: 0.7682, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7173/10000, Loss: 0.7682, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7174/10000, Loss: 0.7681, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7175/10000, Loss: 0.7681, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7176/10000, Loss: 0.7680, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7177/10000, Loss: 0.7680, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7178/10000, Loss: 0.7680, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7179/10000, Loss: 0.7679, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7180/10000, Loss: 0.7679, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7181/10000, Loss: 0.7678, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7182/10000, Loss: 0.7678, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7183/10000, Loss: 0.7678, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7184/10000, Loss: 0.7677, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7185/10000, Loss: 0.7677, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7186/10000, Loss: 0.7677, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7187/10000, Loss: 0.7676, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7188/10000, Loss: 0.7676, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7189/10000, Loss: 0.7675, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7190/10000, Loss: 0.7675, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7191/10000, Loss: 0.7675, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7192/10000, Loss: 0.7674, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7193/10000, Loss: 0.7674, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7194/10000, Loss: 0.7673, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7195/10000, Loss: 0.7673, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7196/10000, Loss: 0.7673, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7197/10000, Loss: 0.7672, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7198/10000, Loss: 0.7672, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7199/10000, Loss: 0.7671, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7200/10000, Loss: 0.7671, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7201/10000, Loss: 0.7671, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7202/10000, Loss: 0.7670, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7203/10000, Loss: 0.7670, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7204/10000, Loss: 0.7670, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7205/10000, Loss: 0.7669, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7206/10000, Loss: 0.7669, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7207/10000, Loss: 0.7668, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7208/10000, Loss: 0.7668, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7209/10000, Loss: 0.7668, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7210/10000, Loss: 0.7667, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7211/10000, Loss: 0.7667, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7212/10000, Loss: 0.7666, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7213/10000, Loss: 0.7666, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7214/10000, Loss: 0.7666, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7215/10000, Loss: 0.7665, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7216/10000, Loss: 0.7665, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7217/10000, Loss: 0.7664, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7218/10000, Loss: 0.7664, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7219/10000, Loss: 0.7664, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7220/10000, Loss: 0.7663, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7221/10000, Loss: 0.7663, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7222/10000, Loss: 0.7663, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7223/10000, Loss: 0.7662, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7224/10000, Loss: 0.7662, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7225/10000, Loss: 0.7661, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7226/10000, Loss: 0.7661, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7227/10000, Loss: 0.7661, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7228/10000, Loss: 0.7660, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7229/10000, Loss: 0.7660, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7230/10000, Loss: 0.7659, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7231/10000, Loss: 0.7659, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7232/10000, Loss: 0.7659, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7233/10000, Loss: 0.7658, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7234/10000, Loss: 0.7658, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7235/10000, Loss: 0.7658, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7236/10000, Loss: 0.7657, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7237/10000, Loss: 0.7657, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7238/10000, Loss: 0.7656, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7239/10000, Loss: 0.7656, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7240/10000, Loss: 0.7656, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7241/10000, Loss: 0.7655, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7242/10000, Loss: 0.7655, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7243/10000, Loss: 0.7654, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7244/10000, Loss: 0.7654, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7245/10000, Loss: 0.7654, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7246/10000, Loss: 0.7653, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7247/10000, Loss: 0.7653, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7248/10000, Loss: 0.7653, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7249/10000, Loss: 0.7652, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7250/10000, Loss: 0.7652, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7251/10000, Loss: 0.7651, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7252/10000, Loss: 0.7651, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7253/10000, Loss: 0.7651, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7254/10000, Loss: 0.7650, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7255/10000, Loss: 0.7650, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7256/10000, Loss: 0.7649, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7257/10000, Loss: 0.7649, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7258/10000, Loss: 0.7649, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7259/10000, Loss: 0.7648, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7260/10000, Loss: 0.7648, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7261/10000, Loss: 0.7648, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7262/10000, Loss: 0.7647, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7263/10000, Loss: 0.7647, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7264/10000, Loss: 0.7646, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7265/10000, Loss: 0.7646, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7266/10000, Loss: 0.7646, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7267/10000, Loss: 0.7645, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7268/10000, Loss: 0.7645, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7269/10000, Loss: 0.7644, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7270/10000, Loss: 0.7644, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7271/10000, Loss: 0.7644, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7272/10000, Loss: 0.7643, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7273/10000, Loss: 0.7643, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7274/10000, Loss: 0.7643, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7275/10000, Loss: 0.7642, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7276/10000, Loss: 0.7642, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7277/10000, Loss: 0.7641, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7278/10000, Loss: 0.7641, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7279/10000, Loss: 0.7641, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7280/10000, Loss: 0.7640, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7281/10000, Loss: 0.7640, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7282/10000, Loss: 0.7639, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7283/10000, Loss: 0.7639, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7284/10000, Loss: 0.7639, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7285/10000, Loss: 0.7638, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7286/10000, Loss: 0.7638, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7287/10000, Loss: 0.7638, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7288/10000, Loss: 0.7637, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7289/10000, Loss: 0.7637, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7290/10000, Loss: 0.7636, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7291/10000, Loss: 0.7636, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7292/10000, Loss: 0.7636, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7293/10000, Loss: 0.7635, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7294/10000, Loss: 0.7635, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7295/10000, Loss: 0.7634, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7296/10000, Loss: 0.7634, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7297/10000, Loss: 0.7634, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7298/10000, Loss: 0.7633, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7299/10000, Loss: 0.7633, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7300/10000, Loss: 0.7633, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7301/10000, Loss: 0.7632, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7302/10000, Loss: 0.7632, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7303/10000, Loss: 0.7631, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7304/10000, Loss: 0.7631, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7305/10000, Loss: 0.7631, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7306/10000, Loss: 0.7630, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7307/10000, Loss: 0.7630, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7308/10000, Loss: 0.7630, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7309/10000, Loss: 0.7629, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7310/10000, Loss: 0.7629, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7311/10000, Loss: 0.7628, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7312/10000, Loss: 0.7628, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7313/10000, Loss: 0.7628, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7314/10000, Loss: 0.7627, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7315/10000, Loss: 0.7627, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7316/10000, Loss: 0.7626, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7317/10000, Loss: 0.7626, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7318/10000, Loss: 0.7626, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7319/10000, Loss: 0.7625, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7320/10000, Loss: 0.7625, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7321/10000, Loss: 0.7625, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7322/10000, Loss: 0.7624, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7323/10000, Loss: 0.7624, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7324/10000, Loss: 0.7623, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7325/10000, Loss: 0.7623, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7326/10000, Loss: 0.7623, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7327/10000, Loss: 0.7622, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7328/10000, Loss: 0.7622, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7329/10000, Loss: 0.7622, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7330/10000, Loss: 0.7621, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7331/10000, Loss: 0.7621, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7332/10000, Loss: 0.7620, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7333/10000, Loss: 0.7620, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7334/10000, Loss: 0.7620, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7335/10000, Loss: 0.7619, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7336/10000, Loss: 0.7619, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7337/10000, Loss: 0.7619, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7338/10000, Loss: 0.7618, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7339/10000, Loss: 0.7618, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7340/10000, Loss: 0.7617, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7341/10000, Loss: 0.7617, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7342/10000, Loss: 0.7617, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7343/10000, Loss: 0.7616, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7344/10000, Loss: 0.7616, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7345/10000, Loss: 0.7615, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7346/10000, Loss: 0.7615, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7347/10000, Loss: 0.7615, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7348/10000, Loss: 0.7614, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7349/10000, Loss: 0.7614, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7350/10000, Loss: 0.7614, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7351/10000, Loss: 0.7613, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7352/10000, Loss: 0.7613, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7353/10000, Loss: 0.7612, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7354/10000, Loss: 0.7612, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7355/10000, Loss: 0.7612, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7356/10000, Loss: 0.7611, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7357/10000, Loss: 0.7611, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7358/10000, Loss: 0.7611, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7359/10000, Loss: 0.7610, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7360/10000, Loss: 0.7610, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7361/10000, Loss: 0.7609, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7362/10000, Loss: 0.7609, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7363/10000, Loss: 0.7609, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7364/10000, Loss: 0.7608, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7365/10000, Loss: 0.7608, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7366/10000, Loss: 0.7608, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7367/10000, Loss: 0.7607, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7368/10000, Loss: 0.7607, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7369/10000, Loss: 0.7606, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7370/10000, Loss: 0.7606, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7371/10000, Loss: 0.7606, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7372/10000, Loss: 0.7605, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7373/10000, Loss: 0.7605, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7374/10000, Loss: 0.7605, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7375/10000, Loss: 0.7604, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7376/10000, Loss: 0.7604, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7377/10000, Loss: 0.7603, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7378/10000, Loss: 0.7603, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7379/10000, Loss: 0.7603, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7380/10000, Loss: 0.7602, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7381/10000, Loss: 0.7602, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7382/10000, Loss: 0.7602, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7383/10000, Loss: 0.7601, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7384/10000, Loss: 0.7601, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7385/10000, Loss: 0.7600, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7386/10000, Loss: 0.7600, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7387/10000, Loss: 0.7600, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7388/10000, Loss: 0.7599, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7389/10000, Loss: 0.7599, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7390/10000, Loss: 0.7599, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7391/10000, Loss: 0.7598, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7392/10000, Loss: 0.7598, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7393/10000, Loss: 0.7597, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7394/10000, Loss: 0.7597, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7395/10000, Loss: 0.7597, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7396/10000, Loss: 0.7596, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7397/10000, Loss: 0.7596, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7398/10000, Loss: 0.7596, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7399/10000, Loss: 0.7595, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7400/10000, Loss: 0.7595, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7401/10000, Loss: 0.7594, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7402/10000, Loss: 0.7594, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7403/10000, Loss: 0.7594, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7404/10000, Loss: 0.7593, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7405/10000, Loss: 0.7593, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7406/10000, Loss: 0.7593, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7407/10000, Loss: 0.7592, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7408/10000, Loss: 0.7592, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7409/10000, Loss: 0.7591, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7410/10000, Loss: 0.7591, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7411/10000, Loss: 0.7591, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7412/10000, Loss: 0.7590, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7413/10000, Loss: 0.7590, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7414/10000, Loss: 0.7590, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7415/10000, Loss: 0.7589, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7416/10000, Loss: 0.7589, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7417/10000, Loss: 0.7588, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7418/10000, Loss: 0.7588, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7419/10000, Loss: 0.7588, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7420/10000, Loss: 0.7587, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7421/10000, Loss: 0.7587, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7422/10000, Loss: 0.7587, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7423/10000, Loss: 0.7586, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7424/10000, Loss: 0.7586, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7425/10000, Loss: 0.7585, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7426/10000, Loss: 0.7585, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7427/10000, Loss: 0.7585, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7428/10000, Loss: 0.7584, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7429/10000, Loss: 0.7584, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7430/10000, Loss: 0.7584, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7431/10000, Loss: 0.7583, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7432/10000, Loss: 0.7583, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7433/10000, Loss: 0.7582, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7434/10000, Loss: 0.7582, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7435/10000, Loss: 0.7582, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7436/10000, Loss: 0.7581, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7437/10000, Loss: 0.7581, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7438/10000, Loss: 0.7581, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7439/10000, Loss: 0.7580, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7440/10000, Loss: 0.7580, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7441/10000, Loss: 0.7579, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7442/10000, Loss: 0.7579, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7443/10000, Loss: 0.7579, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7444/10000, Loss: 0.7578, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7445/10000, Loss: 0.7578, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7446/10000, Loss: 0.7578, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7447/10000, Loss: 0.7577, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7448/10000, Loss: 0.7577, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7449/10000, Loss: 0.7576, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7450/10000, Loss: 0.7576, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7451/10000, Loss: 0.7576, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7452/10000, Loss: 0.7575, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7453/10000, Loss: 0.7575, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7454/10000, Loss: 0.7575, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7455/10000, Loss: 0.7574, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7456/10000, Loss: 0.7574, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7457/10000, Loss: 0.7574, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7458/10000, Loss: 0.7573, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7459/10000, Loss: 0.7573, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7460/10000, Loss: 0.7572, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7461/10000, Loss: 0.7572, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7462/10000, Loss: 0.7572, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7463/10000, Loss: 0.7571, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7464/10000, Loss: 0.7571, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7465/10000, Loss: 0.7571, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7466/10000, Loss: 0.7570, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7467/10000, Loss: 0.7570, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7468/10000, Loss: 0.7569, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7469/10000, Loss: 0.7569, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7470/10000, Loss: 0.7569, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7471/10000, Loss: 0.7568, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7472/10000, Loss: 0.7568, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7473/10000, Loss: 0.7568, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7474/10000, Loss: 0.7567, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7475/10000, Loss: 0.7567, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7476/10000, Loss: 0.7566, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7477/10000, Loss: 0.7566, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7478/10000, Loss: 0.7566, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7479/10000, Loss: 0.7565, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7480/10000, Loss: 0.7565, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7481/10000, Loss: 0.7565, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7482/10000, Loss: 0.7564, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7483/10000, Loss: 0.7564, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7484/10000, Loss: 0.7564, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7485/10000, Loss: 0.7563, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7486/10000, Loss: 0.7563, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7487/10000, Loss: 0.7562, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7488/10000, Loss: 0.7562, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7489/10000, Loss: 0.7562, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7490/10000, Loss: 0.7561, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7491/10000, Loss: 0.7561, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7492/10000, Loss: 0.7561, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7493/10000, Loss: 0.7560, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7494/10000, Loss: 0.7560, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7495/10000, Loss: 0.7559, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7496/10000, Loss: 0.7559, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7497/10000, Loss: 0.7559, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7498/10000, Loss: 0.7558, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7499/10000, Loss: 0.7558, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7500/10000, Loss: 0.7558, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7501/10000, Loss: 0.7557, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7502/10000, Loss: 0.7557, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7503/10000, Loss: 0.7557, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7504/10000, Loss: 0.7556, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7505/10000, Loss: 0.7556, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7506/10000, Loss: 0.7555, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7507/10000, Loss: 0.7555, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7508/10000, Loss: 0.7555, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7509/10000, Loss: 0.7554, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7510/10000, Loss: 0.7554, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7511/10000, Loss: 0.7554, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7512/10000, Loss: 0.7553, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7513/10000, Loss: 0.7553, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7514/10000, Loss: 0.7552, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7515/10000, Loss: 0.7552, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7516/10000, Loss: 0.7552, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7517/10000, Loss: 0.7551, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7518/10000, Loss: 0.7551, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7519/10000, Loss: 0.7551, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7520/10000, Loss: 0.7550, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7521/10000, Loss: 0.7550, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7522/10000, Loss: 0.7550, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7523/10000, Loss: 0.7549, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7524/10000, Loss: 0.7549, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7525/10000, Loss: 0.7548, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7526/10000, Loss: 0.7548, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7527/10000, Loss: 0.7548, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7528/10000, Loss: 0.7547, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7529/10000, Loss: 0.7547, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7530/10000, Loss: 0.7547, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7531/10000, Loss: 0.7546, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7532/10000, Loss: 0.7546, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7533/10000, Loss: 0.7546, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7534/10000, Loss: 0.7545, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7535/10000, Loss: 0.7545, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7536/10000, Loss: 0.7544, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7537/10000, Loss: 0.7544, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7538/10000, Loss: 0.7544, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7539/10000, Loss: 0.7543, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7540/10000, Loss: 0.7543, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7541/10000, Loss: 0.7543, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7542/10000, Loss: 0.7542, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7543/10000, Loss: 0.7542, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7544/10000, Loss: 0.7542, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7545/10000, Loss: 0.7541, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7546/10000, Loss: 0.7541, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7547/10000, Loss: 0.7540, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7548/10000, Loss: 0.7540, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7549/10000, Loss: 0.7540, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7550/10000, Loss: 0.7539, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7551/10000, Loss: 0.7539, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7552/10000, Loss: 0.7539, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7553/10000, Loss: 0.7538, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7554/10000, Loss: 0.7538, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7555/10000, Loss: 0.7538, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7556/10000, Loss: 0.7537, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7557/10000, Loss: 0.7537, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7558/10000, Loss: 0.7536, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7559/10000, Loss: 0.7536, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7560/10000, Loss: 0.7536, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7561/10000, Loss: 0.7535, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7562/10000, Loss: 0.7535, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7563/10000, Loss: 0.7535, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7564/10000, Loss: 0.7534, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7565/10000, Loss: 0.7534, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7566/10000, Loss: 0.7533, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7567/10000, Loss: 0.7533, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7568/10000, Loss: 0.7533, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7569/10000, Loss: 0.7532, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7570/10000, Loss: 0.7532, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7571/10000, Loss: 0.7532, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7572/10000, Loss: 0.7531, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7573/10000, Loss: 0.7531, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7574/10000, Loss: 0.7531, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7575/10000, Loss: 0.7530, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7576/10000, Loss: 0.7530, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7577/10000, Loss: 0.7530, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7578/10000, Loss: 0.7529, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7579/10000, Loss: 0.7529, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7580/10000, Loss: 0.7528, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7581/10000, Loss: 0.7528, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7582/10000, Loss: 0.7528, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7583/10000, Loss: 0.7527, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7584/10000, Loss: 0.7527, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7585/10000, Loss: 0.7527, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7586/10000, Loss: 0.7526, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7587/10000, Loss: 0.7526, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7588/10000, Loss: 0.7526, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7589/10000, Loss: 0.7525, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7590/10000, Loss: 0.7525, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7591/10000, Loss: 0.7524, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7592/10000, Loss: 0.7524, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7593/10000, Loss: 0.7524, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7594/10000, Loss: 0.7523, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7595/10000, Loss: 0.7523, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7596/10000, Loss: 0.7523, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7597/10000, Loss: 0.7522, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7598/10000, Loss: 0.7522, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7599/10000, Loss: 0.7522, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7600/10000, Loss: 0.7521, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7601/10000, Loss: 0.7521, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7602/10000, Loss: 0.7520, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7603/10000, Loss: 0.7520, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7604/10000, Loss: 0.7520, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7605/10000, Loss: 0.7519, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7606/10000, Loss: 0.7519, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7607/10000, Loss: 0.7519, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7608/10000, Loss: 0.7518, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7609/10000, Loss: 0.7518, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7610/10000, Loss: 0.7518, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7611/10000, Loss: 0.7517, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7612/10000, Loss: 0.7517, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7613/10000, Loss: 0.7516, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7614/10000, Loss: 0.7516, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7615/10000, Loss: 0.7516, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7616/10000, Loss: 0.7515, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7617/10000, Loss: 0.7515, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7618/10000, Loss: 0.7515, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7619/10000, Loss: 0.7514, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7620/10000, Loss: 0.7514, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7621/10000, Loss: 0.7514, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7622/10000, Loss: 0.7513, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7623/10000, Loss: 0.7513, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7624/10000, Loss: 0.7513, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7625/10000, Loss: 0.7512, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7626/10000, Loss: 0.7512, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7627/10000, Loss: 0.7511, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7628/10000, Loss: 0.7511, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7629/10000, Loss: 0.7511, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7630/10000, Loss: 0.7510, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7631/10000, Loss: 0.7510, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7632/10000, Loss: 0.7510, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7633/10000, Loss: 0.7509, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7634/10000, Loss: 0.7509, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7635/10000, Loss: 0.7509, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7636/10000, Loss: 0.7508, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7637/10000, Loss: 0.7508, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7638/10000, Loss: 0.7507, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7639/10000, Loss: 0.7507, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7640/10000, Loss: 0.7507, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7641/10000, Loss: 0.7506, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7642/10000, Loss: 0.7506, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7643/10000, Loss: 0.7506, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7644/10000, Loss: 0.7505, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7645/10000, Loss: 0.7505, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7646/10000, Loss: 0.7505, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7647/10000, Loss: 0.7504, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7648/10000, Loss: 0.7504, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7649/10000, Loss: 0.7504, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7650/10000, Loss: 0.7503, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7651/10000, Loss: 0.7503, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7652/10000, Loss: 0.7502, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7653/10000, Loss: 0.7502, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7654/10000, Loss: 0.7502, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7655/10000, Loss: 0.7501, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7656/10000, Loss: 0.7501, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7657/10000, Loss: 0.7501, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7658/10000, Loss: 0.7500, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7659/10000, Loss: 0.7500, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7660/10000, Loss: 0.7500, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7661/10000, Loss: 0.7499, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7662/10000, Loss: 0.7499, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7663/10000, Loss: 0.7499, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7664/10000, Loss: 0.7498, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7665/10000, Loss: 0.7498, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7666/10000, Loss: 0.7497, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7667/10000, Loss: 0.7497, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7668/10000, Loss: 0.7497, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7669/10000, Loss: 0.7496, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7670/10000, Loss: 0.7496, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7671/10000, Loss: 0.7496, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7672/10000, Loss: 0.7495, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7673/10000, Loss: 0.7495, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7674/10000, Loss: 0.7495, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7675/10000, Loss: 0.7494, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7676/10000, Loss: 0.7494, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7677/10000, Loss: 0.7494, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7678/10000, Loss: 0.7493, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7679/10000, Loss: 0.7493, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7680/10000, Loss: 0.7492, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7681/10000, Loss: 0.7492, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7682/10000, Loss: 0.7492, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7683/10000, Loss: 0.7491, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7684/10000, Loss: 0.7491, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7685/10000, Loss: 0.7491, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7686/10000, Loss: 0.7490, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7687/10000, Loss: 0.7490, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7688/10000, Loss: 0.7490, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7689/10000, Loss: 0.7489, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7690/10000, Loss: 0.7489, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7691/10000, Loss: 0.7489, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7692/10000, Loss: 0.7488, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7693/10000, Loss: 0.7488, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7694/10000, Loss: 0.7487, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7695/10000, Loss: 0.7487, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7696/10000, Loss: 0.7487, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7697/10000, Loss: 0.7486, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7698/10000, Loss: 0.7486, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7699/10000, Loss: 0.7486, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7700/10000, Loss: 0.7485, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7701/10000, Loss: 0.7485, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7702/10000, Loss: 0.7485, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7703/10000, Loss: 0.7484, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7704/10000, Loss: 0.7484, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7705/10000, Loss: 0.7484, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7706/10000, Loss: 0.7483, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7707/10000, Loss: 0.7483, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7708/10000, Loss: 0.7483, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7709/10000, Loss: 0.7482, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7710/10000, Loss: 0.7482, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7711/10000, Loss: 0.7481, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7712/10000, Loss: 0.7481, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7713/10000, Loss: 0.7481, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7714/10000, Loss: 0.7480, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7715/10000, Loss: 0.7480, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7716/10000, Loss: 0.7480, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7717/10000, Loss: 0.7479, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7718/10000, Loss: 0.7479, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7719/10000, Loss: 0.7479, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7720/10000, Loss: 0.7478, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7721/10000, Loss: 0.7478, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7722/10000, Loss: 0.7478, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7723/10000, Loss: 0.7477, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7724/10000, Loss: 0.7477, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7725/10000, Loss: 0.7477, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7726/10000, Loss: 0.7476, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7727/10000, Loss: 0.7476, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7728/10000, Loss: 0.7475, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7729/10000, Loss: 0.7475, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7730/10000, Loss: 0.7475, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7731/10000, Loss: 0.7474, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7732/10000, Loss: 0.7474, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7733/10000, Loss: 0.7474, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7734/10000, Loss: 0.7473, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7735/10000, Loss: 0.7473, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7736/10000, Loss: 0.7473, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7737/10000, Loss: 0.7472, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7738/10000, Loss: 0.7472, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7739/10000, Loss: 0.7472, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7740/10000, Loss: 0.7471, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7741/10000, Loss: 0.7471, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7742/10000, Loss: 0.7471, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7743/10000, Loss: 0.7470, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7744/10000, Loss: 0.7470, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7745/10000, Loss: 0.7469, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7746/10000, Loss: 0.7469, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7747/10000, Loss: 0.7469, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7748/10000, Loss: 0.7468, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7749/10000, Loss: 0.7468, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7750/10000, Loss: 0.7468, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7751/10000, Loss: 0.7467, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7752/10000, Loss: 0.7467, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7753/10000, Loss: 0.7467, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7754/10000, Loss: 0.7466, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7755/10000, Loss: 0.7466, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7756/10000, Loss: 0.7466, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7757/10000, Loss: 0.7465, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7758/10000, Loss: 0.7465, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7759/10000, Loss: 0.7465, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7760/10000, Loss: 0.7464, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7761/10000, Loss: 0.7464, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7762/10000, Loss: 0.7463, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7763/10000, Loss: 0.7463, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7764/10000, Loss: 0.7463, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7765/10000, Loss: 0.7462, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7766/10000, Loss: 0.7462, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7767/10000, Loss: 0.7462, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7768/10000, Loss: 0.7461, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7769/10000, Loss: 0.7461, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7770/10000, Loss: 0.7461, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7771/10000, Loss: 0.7460, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7772/10000, Loss: 0.7460, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7773/10000, Loss: 0.7460, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7774/10000, Loss: 0.7459, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7775/10000, Loss: 0.7459, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7776/10000, Loss: 0.7459, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7777/10000, Loss: 0.7458, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7778/10000, Loss: 0.7458, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7779/10000, Loss: 0.7458, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7780/10000, Loss: 0.7457, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7781/10000, Loss: 0.7457, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7782/10000, Loss: 0.7456, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7783/10000, Loss: 0.7456, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7784/10000, Loss: 0.7456, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7785/10000, Loss: 0.7455, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7786/10000, Loss: 0.7455, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7787/10000, Loss: 0.7455, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7788/10000, Loss: 0.7454, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7789/10000, Loss: 0.7454, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7790/10000, Loss: 0.7454, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7791/10000, Loss: 0.7453, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7792/10000, Loss: 0.7453, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7793/10000, Loss: 0.7453, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7794/10000, Loss: 0.7452, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7795/10000, Loss: 0.7452, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7796/10000, Loss: 0.7452, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7797/10000, Loss: 0.7451, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7798/10000, Loss: 0.7451, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7799/10000, Loss: 0.7451, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7800/10000, Loss: 0.7450, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7801/10000, Loss: 0.7450, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7802/10000, Loss: 0.7449, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7803/10000, Loss: 0.7449, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7804/10000, Loss: 0.7449, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7805/10000, Loss: 0.7448, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7806/10000, Loss: 0.7448, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7807/10000, Loss: 0.7448, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7808/10000, Loss: 0.7447, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7809/10000, Loss: 0.7447, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7810/10000, Loss: 0.7447, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7811/10000, Loss: 0.7446, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7812/10000, Loss: 0.7446, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7813/10000, Loss: 0.7446, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7814/10000, Loss: 0.7445, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7815/10000, Loss: 0.7445, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7816/10000, Loss: 0.7445, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7817/10000, Loss: 0.7444, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7818/10000, Loss: 0.7444, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7819/10000, Loss: 0.7444, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7820/10000, Loss: 0.7443, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7821/10000, Loss: 0.7443, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7822/10000, Loss: 0.7443, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7823/10000, Loss: 0.7442, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7824/10000, Loss: 0.7442, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7825/10000, Loss: 0.7441, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7826/10000, Loss: 0.7441, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7827/10000, Loss: 0.7441, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7828/10000, Loss: 0.7440, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7829/10000, Loss: 0.7440, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7830/10000, Loss: 0.7440, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7831/10000, Loss: 0.7439, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7832/10000, Loss: 0.7439, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7833/10000, Loss: 0.7439, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7834/10000, Loss: 0.7438, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7835/10000, Loss: 0.7438, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7836/10000, Loss: 0.7438, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7837/10000, Loss: 0.7437, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7838/10000, Loss: 0.7437, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7839/10000, Loss: 0.7437, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7840/10000, Loss: 0.7436, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7841/10000, Loss: 0.7436, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7842/10000, Loss: 0.7436, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7843/10000, Loss: 0.7435, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7844/10000, Loss: 0.7435, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7845/10000, Loss: 0.7435, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7846/10000, Loss: 0.7434, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7847/10000, Loss: 0.7434, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7848/10000, Loss: 0.7434, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7849/10000, Loss: 0.7433, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7850/10000, Loss: 0.7433, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7851/10000, Loss: 0.7432, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7852/10000, Loss: 0.7432, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7853/10000, Loss: 0.7432, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7854/10000, Loss: 0.7431, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7855/10000, Loss: 0.7431, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7856/10000, Loss: 0.7431, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7857/10000, Loss: 0.7430, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7858/10000, Loss: 0.7430, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7859/10000, Loss: 0.7430, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7860/10000, Loss: 0.7429, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7861/10000, Loss: 0.7429, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7862/10000, Loss: 0.7429, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7863/10000, Loss: 0.7428, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7864/10000, Loss: 0.7428, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7865/10000, Loss: 0.7428, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7866/10000, Loss: 0.7427, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7867/10000, Loss: 0.7427, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7868/10000, Loss: 0.7427, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7869/10000, Loss: 0.7426, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7870/10000, Loss: 0.7426, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7871/10000, Loss: 0.7426, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7872/10000, Loss: 0.7425, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7873/10000, Loss: 0.7425, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7874/10000, Loss: 0.7425, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7875/10000, Loss: 0.7424, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7876/10000, Loss: 0.7424, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7877/10000, Loss: 0.7424, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7878/10000, Loss: 0.7423, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7879/10000, Loss: 0.7423, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7880/10000, Loss: 0.7422, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7881/10000, Loss: 0.7422, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7882/10000, Loss: 0.7422, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7883/10000, Loss: 0.7421, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7884/10000, Loss: 0.7421, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7885/10000, Loss: 0.7421, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7886/10000, Loss: 0.7420, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7887/10000, Loss: 0.7420, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7888/10000, Loss: 0.7420, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7889/10000, Loss: 0.7419, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7890/10000, Loss: 0.7419, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7891/10000, Loss: 0.7419, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7892/10000, Loss: 0.7418, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7893/10000, Loss: 0.7418, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7894/10000, Loss: 0.7418, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7895/10000, Loss: 0.7417, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7896/10000, Loss: 0.7417, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7897/10000, Loss: 0.7417, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7898/10000, Loss: 0.7416, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7899/10000, Loss: 0.7416, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7900/10000, Loss: 0.7416, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7901/10000, Loss: 0.7415, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7902/10000, Loss: 0.7415, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7903/10000, Loss: 0.7415, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7904/10000, Loss: 0.7414, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7905/10000, Loss: 0.7414, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7906/10000, Loss: 0.7414, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7907/10000, Loss: 0.7413, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7908/10000, Loss: 0.7413, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7909/10000, Loss: 0.7413, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7910/10000, Loss: 0.7412, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7911/10000, Loss: 0.7412, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7912/10000, Loss: 0.7412, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7913/10000, Loss: 0.7411, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7914/10000, Loss: 0.7411, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7915/10000, Loss: 0.7410, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7916/10000, Loss: 0.7410, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7917/10000, Loss: 0.7410, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7918/10000, Loss: 0.7409, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7919/10000, Loss: 0.7409, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7920/10000, Loss: 0.7409, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7921/10000, Loss: 0.7408, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7922/10000, Loss: 0.7408, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7923/10000, Loss: 0.7408, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7924/10000, Loss: 0.7407, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7925/10000, Loss: 0.7407, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7926/10000, Loss: 0.7407, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7927/10000, Loss: 0.7406, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7928/10000, Loss: 0.7406, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7929/10000, Loss: 0.7406, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7930/10000, Loss: 0.7405, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7931/10000, Loss: 0.7405, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7932/10000, Loss: 0.7405, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7933/10000, Loss: 0.7404, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7934/10000, Loss: 0.7404, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7935/10000, Loss: 0.7404, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7936/10000, Loss: 0.7403, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7937/10000, Loss: 0.7403, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7938/10000, Loss: 0.7403, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7939/10000, Loss: 0.7402, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7940/10000, Loss: 0.7402, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7941/10000, Loss: 0.7402, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7942/10000, Loss: 0.7401, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7943/10000, Loss: 0.7401, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7944/10000, Loss: 0.7401, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7945/10000, Loss: 0.7400, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7946/10000, Loss: 0.7400, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7947/10000, Loss: 0.7400, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7948/10000, Loss: 0.7399, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7949/10000, Loss: 0.7399, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7950/10000, Loss: 0.7399, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7951/10000, Loss: 0.7398, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7952/10000, Loss: 0.7398, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7953/10000, Loss: 0.7398, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7954/10000, Loss: 0.7397, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7955/10000, Loss: 0.7397, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7956/10000, Loss: 0.7397, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7957/10000, Loss: 0.7396, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7958/10000, Loss: 0.7396, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7959/10000, Loss: 0.7396, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7960/10000, Loss: 0.7395, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7961/10000, Loss: 0.7395, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7962/10000, Loss: 0.7394, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7963/10000, Loss: 0.7394, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7964/10000, Loss: 0.7394, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 7965/10000, Loss: 0.7393, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7966/10000, Loss: 0.7393, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7967/10000, Loss: 0.7393, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7968/10000, Loss: 0.7392, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7969/10000, Loss: 0.7392, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7970/10000, Loss: 0.7392, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7971/10000, Loss: 0.7391, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7972/10000, Loss: 0.7391, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7973/10000, Loss: 0.7391, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7974/10000, Loss: 0.7390, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7975/10000, Loss: 0.7390, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7976/10000, Loss: 0.7390, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7977/10000, Loss: 0.7389, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7978/10000, Loss: 0.7389, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7979/10000, Loss: 0.7389, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7980/10000, Loss: 0.7388, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7981/10000, Loss: 0.7388, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7982/10000, Loss: 0.7388, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7983/10000, Loss: 0.7387, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7984/10000, Loss: 0.7387, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7985/10000, Loss: 0.7387, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7986/10000, Loss: 0.7386, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7987/10000, Loss: 0.7386, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7988/10000, Loss: 0.7386, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7989/10000, Loss: 0.7385, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7990/10000, Loss: 0.7385, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7991/10000, Loss: 0.7385, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7992/10000, Loss: 0.7384, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7993/10000, Loss: 0.7384, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7994/10000, Loss: 0.7384, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7995/10000, Loss: 0.7383, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7996/10000, Loss: 0.7383, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7997/10000, Loss: 0.7383, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7998/10000, Loss: 0.7382, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 7999/10000, Loss: 0.7382, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8000/10000, Loss: 0.7382, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8001/10000, Loss: 0.7381, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8002/10000, Loss: 0.7381, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8003/10000, Loss: 0.7381, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8004/10000, Loss: 0.7380, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8005/10000, Loss: 0.7380, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8006/10000, Loss: 0.7380, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8007/10000, Loss: 0.7379, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8008/10000, Loss: 0.7379, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8009/10000, Loss: 0.7379, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8010/10000, Loss: 0.7378, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8011/10000, Loss: 0.7378, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8012/10000, Loss: 0.7378, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8013/10000, Loss: 0.7377, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8014/10000, Loss: 0.7377, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8015/10000, Loss: 0.7377, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8016/10000, Loss: 0.7376, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8017/10000, Loss: 0.7376, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8018/10000, Loss: 0.7376, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8019/10000, Loss: 0.7375, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8020/10000, Loss: 0.7375, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8021/10000, Loss: 0.7375, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8022/10000, Loss: 0.7374, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8023/10000, Loss: 0.7374, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8024/10000, Loss: 0.7374, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8025/10000, Loss: 0.7373, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8026/10000, Loss: 0.7373, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8027/10000, Loss: 0.7373, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8028/10000, Loss: 0.7372, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8029/10000, Loss: 0.7372, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8030/10000, Loss: 0.7372, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8031/10000, Loss: 0.7371, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8032/10000, Loss: 0.7371, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8033/10000, Loss: 0.7371, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8034/10000, Loss: 0.7370, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8035/10000, Loss: 0.7370, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8036/10000, Loss: 0.7370, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8037/10000, Loss: 0.7369, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8038/10000, Loss: 0.7369, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8039/10000, Loss: 0.7369, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8040/10000, Loss: 0.7368, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8041/10000, Loss: 0.7368, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8042/10000, Loss: 0.7368, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8043/10000, Loss: 0.7367, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8044/10000, Loss: 0.7367, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8045/10000, Loss: 0.7367, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8046/10000, Loss: 0.7366, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8047/10000, Loss: 0.7366, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8048/10000, Loss: 0.7366, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8049/10000, Loss: 0.7365, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8050/10000, Loss: 0.7365, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8051/10000, Loss: 0.7365, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8052/10000, Loss: 0.7364, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8053/10000, Loss: 0.7364, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8054/10000, Loss: 0.7364, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8055/10000, Loss: 0.7363, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8056/10000, Loss: 0.7363, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8057/10000, Loss: 0.7363, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8058/10000, Loss: 0.7362, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8059/10000, Loss: 0.7362, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8060/10000, Loss: 0.7362, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8061/10000, Loss: 0.7361, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8062/10000, Loss: 0.7361, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8063/10000, Loss: 0.7361, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8064/10000, Loss: 0.7360, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8065/10000, Loss: 0.7360, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8066/10000, Loss: 0.7360, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8067/10000, Loss: 0.7359, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8068/10000, Loss: 0.7359, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8069/10000, Loss: 0.7359, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8070/10000, Loss: 0.7358, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8071/10000, Loss: 0.7358, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8072/10000, Loss: 0.7358, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8073/10000, Loss: 0.7357, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8074/10000, Loss: 0.7357, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8075/10000, Loss: 0.7357, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8076/10000, Loss: 0.7356, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8077/10000, Loss: 0.7356, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8078/10000, Loss: 0.7356, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8079/10000, Loss: 0.7355, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8080/10000, Loss: 0.7355, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8081/10000, Loss: 0.7355, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8082/10000, Loss: 0.7354, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8083/10000, Loss: 0.7354, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8084/10000, Loss: 0.7354, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8085/10000, Loss: 0.7353, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8086/10000, Loss: 0.7353, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8087/10000, Loss: 0.7353, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8088/10000, Loss: 0.7352, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8089/10000, Loss: 0.7352, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8090/10000, Loss: 0.7352, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8091/10000, Loss: 0.7351, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8092/10000, Loss: 0.7351, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8093/10000, Loss: 0.7351, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8094/10000, Loss: 0.7350, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8095/10000, Loss: 0.7350, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8096/10000, Loss: 0.7350, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8097/10000, Loss: 0.7349, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8098/10000, Loss: 0.7349, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8099/10000, Loss: 0.7349, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8100/10000, Loss: 0.7348, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8101/10000, Loss: 0.7348, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8102/10000, Loss: 0.7348, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8103/10000, Loss: 0.7347, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8104/10000, Loss: 0.7347, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8105/10000, Loss: 0.7347, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8106/10000, Loss: 0.7346, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8107/10000, Loss: 0.7346, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8108/10000, Loss: 0.7346, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8109/10000, Loss: 0.7345, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8110/10000, Loss: 0.7345, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8111/10000, Loss: 0.7345, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8112/10000, Loss: 0.7344, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8113/10000, Loss: 0.7344, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8114/10000, Loss: 0.7344, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8115/10000, Loss: 0.7343, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8116/10000, Loss: 0.7343, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8117/10000, Loss: 0.7343, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8118/10000, Loss: 0.7342, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8119/10000, Loss: 0.7342, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8120/10000, Loss: 0.7342, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8121/10000, Loss: 0.7341, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8122/10000, Loss: 0.7341, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8123/10000, Loss: 0.7341, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8124/10000, Loss: 0.7340, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8125/10000, Loss: 0.7340, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8126/10000, Loss: 0.7340, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8127/10000, Loss: 0.7339, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8128/10000, Loss: 0.7339, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8129/10000, Loss: 0.7339, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8130/10000, Loss: 0.7338, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8131/10000, Loss: 0.7338, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8132/10000, Loss: 0.7338, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8133/10000, Loss: 0.7337, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8134/10000, Loss: 0.7337, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8135/10000, Loss: 0.7337, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8136/10000, Loss: 0.7336, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8137/10000, Loss: 0.7336, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8138/10000, Loss: 0.7336, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8139/10000, Loss: 0.7335, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8140/10000, Loss: 0.7335, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8141/10000, Loss: 0.7335, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8142/10000, Loss: 0.7334, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8143/10000, Loss: 0.7334, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8144/10000, Loss: 0.7334, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8145/10000, Loss: 0.7333, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8146/10000, Loss: 0.7333, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8147/10000, Loss: 0.7333, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8148/10000, Loss: 0.7333, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8149/10000, Loss: 0.7332, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8150/10000, Loss: 0.7332, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8151/10000, Loss: 0.7332, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8152/10000, Loss: 0.7331, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8153/10000, Loss: 0.7331, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8154/10000, Loss: 0.7331, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8155/10000, Loss: 0.7330, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8156/10000, Loss: 0.7330, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8157/10000, Loss: 0.7330, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8158/10000, Loss: 0.7329, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8159/10000, Loss: 0.7329, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8160/10000, Loss: 0.7329, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8161/10000, Loss: 0.7328, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8162/10000, Loss: 0.7328, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8163/10000, Loss: 0.7328, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8164/10000, Loss: 0.7327, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8165/10000, Loss: 0.7327, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8166/10000, Loss: 0.7327, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8167/10000, Loss: 0.7326, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8168/10000, Loss: 0.7326, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8169/10000, Loss: 0.7326, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8170/10000, Loss: 0.7325, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8171/10000, Loss: 0.7325, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8172/10000, Loss: 0.7325, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8173/10000, Loss: 0.7324, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8174/10000, Loss: 0.7324, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8175/10000, Loss: 0.7324, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8176/10000, Loss: 0.7323, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8177/10000, Loss: 0.7323, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8178/10000, Loss: 0.7323, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8179/10000, Loss: 0.7322, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8180/10000, Loss: 0.7322, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8181/10000, Loss: 0.7322, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8182/10000, Loss: 0.7321, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8183/10000, Loss: 0.7321, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8184/10000, Loss: 0.7321, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8185/10000, Loss: 0.7320, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8186/10000, Loss: 0.7320, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8187/10000, Loss: 0.7320, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8188/10000, Loss: 0.7319, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8189/10000, Loss: 0.7319, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8190/10000, Loss: 0.7319, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8191/10000, Loss: 0.7318, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8192/10000, Loss: 0.7318, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8193/10000, Loss: 0.7318, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8194/10000, Loss: 0.7317, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8195/10000, Loss: 0.7317, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8196/10000, Loss: 0.7317, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8197/10000, Loss: 0.7317, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8198/10000, Loss: 0.7316, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8199/10000, Loss: 0.7316, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8200/10000, Loss: 0.7316, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8201/10000, Loss: 0.7315, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8202/10000, Loss: 0.7315, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8203/10000, Loss: 0.7315, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8204/10000, Loss: 0.7314, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8205/10000, Loss: 0.7314, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8206/10000, Loss: 0.7314, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8207/10000, Loss: 0.7313, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8208/10000, Loss: 0.7313, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8209/10000, Loss: 0.7313, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8210/10000, Loss: 0.7312, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8211/10000, Loss: 0.7312, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8212/10000, Loss: 0.7312, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8213/10000, Loss: 0.7311, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8214/10000, Loss: 0.7311, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8215/10000, Loss: 0.7311, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8216/10000, Loss: 0.7310, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8217/10000, Loss: 0.7310, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8218/10000, Loss: 0.7310, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8219/10000, Loss: 0.7309, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8220/10000, Loss: 0.7309, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8221/10000, Loss: 0.7309, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8222/10000, Loss: 0.7308, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8223/10000, Loss: 0.7308, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8224/10000, Loss: 0.7308, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8225/10000, Loss: 0.7307, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8226/10000, Loss: 0.7307, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8227/10000, Loss: 0.7307, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8228/10000, Loss: 0.7306, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8229/10000, Loss: 0.7306, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8230/10000, Loss: 0.7306, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8231/10000, Loss: 0.7306, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8232/10000, Loss: 0.7305, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8233/10000, Loss: 0.7305, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8234/10000, Loss: 0.7305, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8235/10000, Loss: 0.7304, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8236/10000, Loss: 0.7304, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8237/10000, Loss: 0.7304, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8238/10000, Loss: 0.7303, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8239/10000, Loss: 0.7303, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8240/10000, Loss: 0.7303, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8241/10000, Loss: 0.7302, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8242/10000, Loss: 0.7302, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8243/10000, Loss: 0.7302, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8244/10000, Loss: 0.7301, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8245/10000, Loss: 0.7301, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8246/10000, Loss: 0.7301, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8247/10000, Loss: 0.7300, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8248/10000, Loss: 0.7300, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8249/10000, Loss: 0.7300, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8250/10000, Loss: 0.7299, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8251/10000, Loss: 0.7299, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8252/10000, Loss: 0.7299, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8253/10000, Loss: 0.7298, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8254/10000, Loss: 0.7298, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8255/10000, Loss: 0.7298, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8256/10000, Loss: 0.7297, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8257/10000, Loss: 0.7297, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8258/10000, Loss: 0.7297, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8259/10000, Loss: 0.7296, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8260/10000, Loss: 0.7296, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8261/10000, Loss: 0.7296, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8262/10000, Loss: 0.7296, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8263/10000, Loss: 0.7295, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8264/10000, Loss: 0.7295, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8265/10000, Loss: 0.7295, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8266/10000, Loss: 0.7294, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8267/10000, Loss: 0.7294, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8268/10000, Loss: 0.7294, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8269/10000, Loss: 0.7293, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8270/10000, Loss: 0.7293, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8271/10000, Loss: 0.7293, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8272/10000, Loss: 0.7292, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8273/10000, Loss: 0.7292, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8274/10000, Loss: 0.7292, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8275/10000, Loss: 0.7291, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8276/10000, Loss: 0.7291, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8277/10000, Loss: 0.7291, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8278/10000, Loss: 0.7290, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8279/10000, Loss: 0.7290, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8280/10000, Loss: 0.7290, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8281/10000, Loss: 0.7289, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8282/10000, Loss: 0.7289, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8283/10000, Loss: 0.7289, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8284/10000, Loss: 0.7288, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8285/10000, Loss: 0.7288, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8286/10000, Loss: 0.7288, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8287/10000, Loss: 0.7288, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8288/10000, Loss: 0.7287, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8289/10000, Loss: 0.7287, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8290/10000, Loss: 0.7287, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8291/10000, Loss: 0.7286, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8292/10000, Loss: 0.7286, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8293/10000, Loss: 0.7286, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8294/10000, Loss: 0.7285, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8295/10000, Loss: 0.7285, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8296/10000, Loss: 0.7285, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8297/10000, Loss: 0.7284, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8298/10000, Loss: 0.7284, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8299/10000, Loss: 0.7284, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8300/10000, Loss: 0.7283, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8301/10000, Loss: 0.7283, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8302/10000, Loss: 0.7283, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8303/10000, Loss: 0.7282, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8304/10000, Loss: 0.7282, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8305/10000, Loss: 0.7282, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8306/10000, Loss: 0.7281, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8307/10000, Loss: 0.7281, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8308/10000, Loss: 0.7281, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8309/10000, Loss: 0.7280, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8310/10000, Loss: 0.7280, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8311/10000, Loss: 0.7280, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8312/10000, Loss: 0.7280, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8313/10000, Loss: 0.7279, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8314/10000, Loss: 0.7279, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8315/10000, Loss: 0.7279, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8316/10000, Loss: 0.7278, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8317/10000, Loss: 0.7278, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8318/10000, Loss: 0.7278, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8319/10000, Loss: 0.7277, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8320/10000, Loss: 0.7277, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8321/10000, Loss: 0.7277, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8322/10000, Loss: 0.7276, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8323/10000, Loss: 0.7276, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8324/10000, Loss: 0.7276, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8325/10000, Loss: 0.7275, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8326/10000, Loss: 0.7275, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8327/10000, Loss: 0.7275, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8328/10000, Loss: 0.7274, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8329/10000, Loss: 0.7274, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8330/10000, Loss: 0.7274, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8331/10000, Loss: 0.7274, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8332/10000, Loss: 0.7273, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8333/10000, Loss: 0.7273, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8334/10000, Loss: 0.7273, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8335/10000, Loss: 0.7272, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8336/10000, Loss: 0.7272, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8337/10000, Loss: 0.7272, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8338/10000, Loss: 0.7271, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8339/10000, Loss: 0.7271, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8340/10000, Loss: 0.7271, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8341/10000, Loss: 0.7270, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8342/10000, Loss: 0.7270, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8343/10000, Loss: 0.7270, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8344/10000, Loss: 0.7269, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8345/10000, Loss: 0.7269, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8346/10000, Loss: 0.7269, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8347/10000, Loss: 0.7268, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8348/10000, Loss: 0.7268, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8349/10000, Loss: 0.7268, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8350/10000, Loss: 0.7267, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8351/10000, Loss: 0.7267, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8352/10000, Loss: 0.7267, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8353/10000, Loss: 0.7267, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8354/10000, Loss: 0.7266, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8355/10000, Loss: 0.7266, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8356/10000, Loss: 0.7266, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8357/10000, Loss: 0.7265, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8358/10000, Loss: 0.7265, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8359/10000, Loss: 0.7265, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8360/10000, Loss: 0.7264, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8361/10000, Loss: 0.7264, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8362/10000, Loss: 0.7264, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8363/10000, Loss: 0.7263, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8364/10000, Loss: 0.7263, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8365/10000, Loss: 0.7263, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8366/10000, Loss: 0.7262, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8367/10000, Loss: 0.7262, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8368/10000, Loss: 0.7262, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8369/10000, Loss: 0.7261, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8370/10000, Loss: 0.7261, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8371/10000, Loss: 0.7261, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8372/10000, Loss: 0.7261, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8373/10000, Loss: 0.7260, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8374/10000, Loss: 0.7260, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8375/10000, Loss: 0.7260, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8376/10000, Loss: 0.7259, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8377/10000, Loss: 0.7259, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8378/10000, Loss: 0.7259, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8379/10000, Loss: 0.7258, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8380/10000, Loss: 0.7258, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8381/10000, Loss: 0.7258, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8382/10000, Loss: 0.7257, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8383/10000, Loss: 0.7257, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8384/10000, Loss: 0.7257, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8385/10000, Loss: 0.7256, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8386/10000, Loss: 0.7256, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8387/10000, Loss: 0.7256, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8388/10000, Loss: 0.7256, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8389/10000, Loss: 0.7255, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8390/10000, Loss: 0.7255, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8391/10000, Loss: 0.7255, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8392/10000, Loss: 0.7254, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8393/10000, Loss: 0.7254, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8394/10000, Loss: 0.7254, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8395/10000, Loss: 0.7253, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8396/10000, Loss: 0.7253, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8397/10000, Loss: 0.7253, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8398/10000, Loss: 0.7252, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8399/10000, Loss: 0.7252, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8400/10000, Loss: 0.7252, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8401/10000, Loss: 0.7251, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8402/10000, Loss: 0.7251, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8403/10000, Loss: 0.7251, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8404/10000, Loss: 0.7251, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8405/10000, Loss: 0.7250, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8406/10000, Loss: 0.7250, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8407/10000, Loss: 0.7250, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8408/10000, Loss: 0.7249, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8409/10000, Loss: 0.7249, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8410/10000, Loss: 0.7249, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8411/10000, Loss: 0.7248, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8412/10000, Loss: 0.7248, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8413/10000, Loss: 0.7248, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8414/10000, Loss: 0.7247, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8415/10000, Loss: 0.7247, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8416/10000, Loss: 0.7247, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8417/10000, Loss: 0.7246, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8418/10000, Loss: 0.7246, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8419/10000, Loss: 0.7246, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8420/10000, Loss: 0.7246, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8421/10000, Loss: 0.7245, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8422/10000, Loss: 0.7245, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8423/10000, Loss: 0.7245, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8424/10000, Loss: 0.7244, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8425/10000, Loss: 0.7244, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8426/10000, Loss: 0.7244, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8427/10000, Loss: 0.7243, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8428/10000, Loss: 0.7243, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8429/10000, Loss: 0.7243, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8430/10000, Loss: 0.7242, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8431/10000, Loss: 0.7242, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8432/10000, Loss: 0.7242, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8433/10000, Loss: 0.7241, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8434/10000, Loss: 0.7241, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8435/10000, Loss: 0.7241, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8436/10000, Loss: 0.7241, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8437/10000, Loss: 0.7240, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8438/10000, Loss: 0.7240, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8439/10000, Loss: 0.7240, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8440/10000, Loss: 0.7239, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8441/10000, Loss: 0.7239, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8442/10000, Loss: 0.7239, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8443/10000, Loss: 0.7238, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8444/10000, Loss: 0.7238, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8445/10000, Loss: 0.7238, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8446/10000, Loss: 0.7237, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8447/10000, Loss: 0.7237, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8448/10000, Loss: 0.7237, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8449/10000, Loss: 0.7236, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8450/10000, Loss: 0.7236, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8451/10000, Loss: 0.7236, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8452/10000, Loss: 0.7236, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8453/10000, Loss: 0.7235, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8454/10000, Loss: 0.7235, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8455/10000, Loss: 0.7235, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8456/10000, Loss: 0.7234, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8457/10000, Loss: 0.7234, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8458/10000, Loss: 0.7234, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8459/10000, Loss: 0.7233, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8460/10000, Loss: 0.7233, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8461/10000, Loss: 0.7233, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8462/10000, Loss: 0.7232, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8463/10000, Loss: 0.7232, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8464/10000, Loss: 0.7232, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8465/10000, Loss: 0.7232, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8466/10000, Loss: 0.7231, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8467/10000, Loss: 0.7231, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8468/10000, Loss: 0.7231, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8469/10000, Loss: 0.7230, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8470/10000, Loss: 0.7230, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8471/10000, Loss: 0.7230, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8472/10000, Loss: 0.7229, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8473/10000, Loss: 0.7229, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8474/10000, Loss: 0.7229, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8475/10000, Loss: 0.7228, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8476/10000, Loss: 0.7228, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8477/10000, Loss: 0.7228, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8478/10000, Loss: 0.7227, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8479/10000, Loss: 0.7227, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8480/10000, Loss: 0.7227, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8481/10000, Loss: 0.7227, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8482/10000, Loss: 0.7226, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8483/10000, Loss: 0.7226, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8484/10000, Loss: 0.7226, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8485/10000, Loss: 0.7225, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8486/10000, Loss: 0.7225, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8487/10000, Loss: 0.7225, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8488/10000, Loss: 0.7224, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8489/10000, Loss: 0.7224, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8490/10000, Loss: 0.7224, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8491/10000, Loss: 0.7223, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8492/10000, Loss: 0.7223, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8493/10000, Loss: 0.7223, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8494/10000, Loss: 0.7223, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8495/10000, Loss: 0.7222, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8496/10000, Loss: 0.7222, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8497/10000, Loss: 0.7222, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8498/10000, Loss: 0.7221, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8499/10000, Loss: 0.7221, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8500/10000, Loss: 0.7221, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8501/10000, Loss: 0.7220, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8502/10000, Loss: 0.7220, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8503/10000, Loss: 0.7220, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8504/10000, Loss: 0.7219, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8505/10000, Loss: 0.7219, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8506/10000, Loss: 0.7219, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8507/10000, Loss: 0.7219, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8508/10000, Loss: 0.7218, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8509/10000, Loss: 0.7218, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8510/10000, Loss: 0.7218, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8511/10000, Loss: 0.7217, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8512/10000, Loss: 0.7217, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8513/10000, Loss: 0.7217, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8514/10000, Loss: 0.7216, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8515/10000, Loss: 0.7216, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8516/10000, Loss: 0.7216, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8517/10000, Loss: 0.7215, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8518/10000, Loss: 0.7215, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8519/10000, Loss: 0.7215, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8520/10000, Loss: 0.7215, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8521/10000, Loss: 0.7214, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8522/10000, Loss: 0.7214, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8523/10000, Loss: 0.7214, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8524/10000, Loss: 0.7213, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8525/10000, Loss: 0.7213, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8526/10000, Loss: 0.7213, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8527/10000, Loss: 0.7212, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8528/10000, Loss: 0.7212, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8529/10000, Loss: 0.7212, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8530/10000, Loss: 0.7212, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8531/10000, Loss: 0.7211, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8532/10000, Loss: 0.7211, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8533/10000, Loss: 0.7211, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8534/10000, Loss: 0.7210, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8535/10000, Loss: 0.7210, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8536/10000, Loss: 0.7210, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8537/10000, Loss: 0.7209, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8538/10000, Loss: 0.7209, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8539/10000, Loss: 0.7209, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8540/10000, Loss: 0.7208, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8541/10000, Loss: 0.7208, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8542/10000, Loss: 0.7208, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8543/10000, Loss: 0.7208, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8544/10000, Loss: 0.7207, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8545/10000, Loss: 0.7207, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8546/10000, Loss: 0.7207, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8547/10000, Loss: 0.7206, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8548/10000, Loss: 0.7206, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8549/10000, Loss: 0.7206, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8550/10000, Loss: 0.7205, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8551/10000, Loss: 0.7205, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8552/10000, Loss: 0.7205, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8553/10000, Loss: 0.7204, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8554/10000, Loss: 0.7204, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8555/10000, Loss: 0.7204, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8556/10000, Loss: 0.7204, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8557/10000, Loss: 0.7203, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8558/10000, Loss: 0.7203, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8559/10000, Loss: 0.7203, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8560/10000, Loss: 0.7202, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8561/10000, Loss: 0.7202, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8562/10000, Loss: 0.7202, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8563/10000, Loss: 0.7201, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8564/10000, Loss: 0.7201, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8565/10000, Loss: 0.7201, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8566/10000, Loss: 0.7201, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8567/10000, Loss: 0.7200, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8568/10000, Loss: 0.7200, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8569/10000, Loss: 0.7200, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8570/10000, Loss: 0.7199, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8571/10000, Loss: 0.7199, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8572/10000, Loss: 0.7199, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8573/10000, Loss: 0.7198, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8574/10000, Loss: 0.7198, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8575/10000, Loss: 0.7198, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8576/10000, Loss: 0.7197, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8577/10000, Loss: 0.7197, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8578/10000, Loss: 0.7197, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8579/10000, Loss: 0.7197, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8580/10000, Loss: 0.7196, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8581/10000, Loss: 0.7196, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8582/10000, Loss: 0.7196, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8583/10000, Loss: 0.7195, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8584/10000, Loss: 0.7195, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8585/10000, Loss: 0.7195, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8586/10000, Loss: 0.7194, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8587/10000, Loss: 0.7194, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8588/10000, Loss: 0.7194, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8589/10000, Loss: 0.7194, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8590/10000, Loss: 0.7193, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8591/10000, Loss: 0.7193, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8592/10000, Loss: 0.7193, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8593/10000, Loss: 0.7192, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8594/10000, Loss: 0.7192, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8595/10000, Loss: 0.7192, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8596/10000, Loss: 0.7191, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8597/10000, Loss: 0.7191, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8598/10000, Loss: 0.7191, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8599/10000, Loss: 0.7191, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8600/10000, Loss: 0.7190, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8601/10000, Loss: 0.7190, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8602/10000, Loss: 0.7190, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8603/10000, Loss: 0.7189, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8604/10000, Loss: 0.7189, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8605/10000, Loss: 0.7189, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8606/10000, Loss: 0.7188, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8607/10000, Loss: 0.7188, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8608/10000, Loss: 0.7188, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8609/10000, Loss: 0.7188, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8610/10000, Loss: 0.7187, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8611/10000, Loss: 0.7187, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8612/10000, Loss: 0.7187, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8613/10000, Loss: 0.7186, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8614/10000, Loss: 0.7186, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8615/10000, Loss: 0.7186, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8616/10000, Loss: 0.7185, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8617/10000, Loss: 0.7185, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8618/10000, Loss: 0.7185, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8619/10000, Loss: 0.7185, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8620/10000, Loss: 0.7184, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8621/10000, Loss: 0.7184, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8622/10000, Loss: 0.7184, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8623/10000, Loss: 0.7183, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8624/10000, Loss: 0.7183, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8625/10000, Loss: 0.7183, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8626/10000, Loss: 0.7182, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8627/10000, Loss: 0.7182, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8628/10000, Loss: 0.7182, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8629/10000, Loss: 0.7182, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8630/10000, Loss: 0.7181, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8631/10000, Loss: 0.7181, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8632/10000, Loss: 0.7181, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8633/10000, Loss: 0.7180, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8634/10000, Loss: 0.7180, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8635/10000, Loss: 0.7180, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8636/10000, Loss: 0.7179, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8637/10000, Loss: 0.7179, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8638/10000, Loss: 0.7179, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8639/10000, Loss: 0.7179, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8640/10000, Loss: 0.7178, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8641/10000, Loss: 0.7178, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8642/10000, Loss: 0.7178, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8643/10000, Loss: 0.7177, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8644/10000, Loss: 0.7177, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8645/10000, Loss: 0.7177, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8646/10000, Loss: 0.7176, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8647/10000, Loss: 0.7176, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8648/10000, Loss: 0.7176, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8649/10000, Loss: 0.7176, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8650/10000, Loss: 0.7175, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8651/10000, Loss: 0.7175, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8652/10000, Loss: 0.7175, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8653/10000, Loss: 0.7174, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8654/10000, Loss: 0.7174, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8655/10000, Loss: 0.7174, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8656/10000, Loss: 0.7173, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8657/10000, Loss: 0.7173, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8658/10000, Loss: 0.7173, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8659/10000, Loss: 0.7173, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8660/10000, Loss: 0.7172, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8661/10000, Loss: 0.7172, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8662/10000, Loss: 0.7172, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8663/10000, Loss: 0.7171, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8664/10000, Loss: 0.7171, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8665/10000, Loss: 0.7171, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8666/10000, Loss: 0.7170, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8667/10000, Loss: 0.7170, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8668/10000, Loss: 0.7170, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8669/10000, Loss: 0.7170, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8670/10000, Loss: 0.7169, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8671/10000, Loss: 0.7169, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8672/10000, Loss: 0.7169, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8673/10000, Loss: 0.7168, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8674/10000, Loss: 0.7168, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8675/10000, Loss: 0.7168, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8676/10000, Loss: 0.7167, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8677/10000, Loss: 0.7167, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8678/10000, Loss: 0.7167, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8679/10000, Loss: 0.7167, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8680/10000, Loss: 0.7166, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8681/10000, Loss: 0.7166, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8682/10000, Loss: 0.7166, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8683/10000, Loss: 0.7165, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8684/10000, Loss: 0.7165, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8685/10000, Loss: 0.7165, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8686/10000, Loss: 0.7164, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8687/10000, Loss: 0.7164, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8688/10000, Loss: 0.7164, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8689/10000, Loss: 0.7164, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8690/10000, Loss: 0.7163, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8691/10000, Loss: 0.7163, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8692/10000, Loss: 0.7163, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8693/10000, Loss: 0.7162, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8694/10000, Loss: 0.7162, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8695/10000, Loss: 0.7162, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8696/10000, Loss: 0.7161, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8697/10000, Loss: 0.7161, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8698/10000, Loss: 0.7161, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8699/10000, Loss: 0.7161, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8700/10000, Loss: 0.7160, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8701/10000, Loss: 0.7160, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8702/10000, Loss: 0.7160, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8703/10000, Loss: 0.7159, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8704/10000, Loss: 0.7159, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8705/10000, Loss: 0.7159, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8706/10000, Loss: 0.7159, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8707/10000, Loss: 0.7158, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8708/10000, Loss: 0.7158, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8709/10000, Loss: 0.7158, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8710/10000, Loss: 0.7157, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8711/10000, Loss: 0.7157, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8712/10000, Loss: 0.7157, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8713/10000, Loss: 0.7156, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8714/10000, Loss: 0.7156, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8715/10000, Loss: 0.7156, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8716/10000, Loss: 0.7156, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8717/10000, Loss: 0.7155, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8718/10000, Loss: 0.7155, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8719/10000, Loss: 0.7155, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8720/10000, Loss: 0.7154, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8721/10000, Loss: 0.7154, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8722/10000, Loss: 0.7154, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8723/10000, Loss: 0.7154, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8724/10000, Loss: 0.7153, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8725/10000, Loss: 0.7153, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8726/10000, Loss: 0.7153, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8727/10000, Loss: 0.7152, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8728/10000, Loss: 0.7152, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8729/10000, Loss: 0.7152, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8730/10000, Loss: 0.7151, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8731/10000, Loss: 0.7151, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8732/10000, Loss: 0.7151, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8733/10000, Loss: 0.7151, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8734/10000, Loss: 0.7150, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8735/10000, Loss: 0.7150, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8736/10000, Loss: 0.7150, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8737/10000, Loss: 0.7149, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8738/10000, Loss: 0.7149, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8739/10000, Loss: 0.7149, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8740/10000, Loss: 0.7148, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8741/10000, Loss: 0.7148, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8742/10000, Loss: 0.7148, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8743/10000, Loss: 0.7148, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8744/10000, Loss: 0.7147, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8745/10000, Loss: 0.7147, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8746/10000, Loss: 0.7147, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8747/10000, Loss: 0.7146, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8748/10000, Loss: 0.7146, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8749/10000, Loss: 0.7146, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8750/10000, Loss: 0.7146, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8751/10000, Loss: 0.7145, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8752/10000, Loss: 0.7145, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8753/10000, Loss: 0.7145, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8754/10000, Loss: 0.7144, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8755/10000, Loss: 0.7144, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8756/10000, Loss: 0.7144, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8757/10000, Loss: 0.7144, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8758/10000, Loss: 0.7143, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8759/10000, Loss: 0.7143, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8760/10000, Loss: 0.7143, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8761/10000, Loss: 0.7142, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8762/10000, Loss: 0.7142, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8763/10000, Loss: 0.7142, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8764/10000, Loss: 0.7141, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8765/10000, Loss: 0.7141, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8766/10000, Loss: 0.7141, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8767/10000, Loss: 0.7141, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8768/10000, Loss: 0.7140, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8769/10000, Loss: 0.7140, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8770/10000, Loss: 0.7140, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8771/10000, Loss: 0.7139, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8772/10000, Loss: 0.7139, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8773/10000, Loss: 0.7139, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8774/10000, Loss: 0.7139, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8775/10000, Loss: 0.7138, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8776/10000, Loss: 0.7138, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8777/10000, Loss: 0.7138, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8778/10000, Loss: 0.7137, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8779/10000, Loss: 0.7137, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8780/10000, Loss: 0.7137, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8781/10000, Loss: 0.7136, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8782/10000, Loss: 0.7136, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8783/10000, Loss: 0.7136, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8784/10000, Loss: 0.7136, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8785/10000, Loss: 0.7135, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8786/10000, Loss: 0.7135, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8787/10000, Loss: 0.7135, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8788/10000, Loss: 0.7134, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8789/10000, Loss: 0.7134, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8790/10000, Loss: 0.7134, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8791/10000, Loss: 0.7134, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8792/10000, Loss: 0.7133, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8793/10000, Loss: 0.7133, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8794/10000, Loss: 0.7133, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8795/10000, Loss: 0.7132, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8796/10000, Loss: 0.7132, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8797/10000, Loss: 0.7132, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8798/10000, Loss: 0.7132, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8799/10000, Loss: 0.7131, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8800/10000, Loss: 0.7131, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8801/10000, Loss: 0.7131, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8802/10000, Loss: 0.7130, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8803/10000, Loss: 0.7130, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8804/10000, Loss: 0.7130, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8805/10000, Loss: 0.7129, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8806/10000, Loss: 0.7129, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8807/10000, Loss: 0.7129, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8808/10000, Loss: 0.7129, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8809/10000, Loss: 0.7128, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8810/10000, Loss: 0.7128, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8811/10000, Loss: 0.7128, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8812/10000, Loss: 0.7127, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8813/10000, Loss: 0.7127, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8814/10000, Loss: 0.7127, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8815/10000, Loss: 0.7127, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8816/10000, Loss: 0.7126, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8817/10000, Loss: 0.7126, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8818/10000, Loss: 0.7126, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8819/10000, Loss: 0.7125, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8820/10000, Loss: 0.7125, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8821/10000, Loss: 0.7125, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8822/10000, Loss: 0.7125, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8823/10000, Loss: 0.7124, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8824/10000, Loss: 0.7124, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8825/10000, Loss: 0.7124, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8826/10000, Loss: 0.7123, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8827/10000, Loss: 0.7123, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8828/10000, Loss: 0.7123, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8829/10000, Loss: 0.7123, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8830/10000, Loss: 0.7122, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8831/10000, Loss: 0.7122, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8832/10000, Loss: 0.7122, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8833/10000, Loss: 0.7121, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8834/10000, Loss: 0.7121, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8835/10000, Loss: 0.7121, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8836/10000, Loss: 0.7120, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8837/10000, Loss: 0.7120, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8838/10000, Loss: 0.7120, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8839/10000, Loss: 0.7120, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8840/10000, Loss: 0.7119, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8841/10000, Loss: 0.7119, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8842/10000, Loss: 0.7119, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8843/10000, Loss: 0.7118, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8844/10000, Loss: 0.7118, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8845/10000, Loss: 0.7118, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8846/10000, Loss: 0.7118, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8847/10000, Loss: 0.7117, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8848/10000, Loss: 0.7117, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8849/10000, Loss: 0.7117, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8850/10000, Loss: 0.7116, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8851/10000, Loss: 0.7116, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8852/10000, Loss: 0.7116, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8853/10000, Loss: 0.7116, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8854/10000, Loss: 0.7115, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8855/10000, Loss: 0.7115, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8856/10000, Loss: 0.7115, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8857/10000, Loss: 0.7114, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8858/10000, Loss: 0.7114, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8859/10000, Loss: 0.7114, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8860/10000, Loss: 0.7114, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8861/10000, Loss: 0.7113, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8862/10000, Loss: 0.7113, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8863/10000, Loss: 0.7113, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8864/10000, Loss: 0.7112, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8865/10000, Loss: 0.7112, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8866/10000, Loss: 0.7112, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8867/10000, Loss: 0.7112, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8868/10000, Loss: 0.7111, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8869/10000, Loss: 0.7111, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8870/10000, Loss: 0.7111, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8871/10000, Loss: 0.7110, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8872/10000, Loss: 0.7110, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8873/10000, Loss: 0.7110, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8874/10000, Loss: 0.7110, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8875/10000, Loss: 0.7109, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8876/10000, Loss: 0.7109, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8877/10000, Loss: 0.7109, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8878/10000, Loss: 0.7108, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8879/10000, Loss: 0.7108, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8880/10000, Loss: 0.7108, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8881/10000, Loss: 0.7108, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8882/10000, Loss: 0.7107, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8883/10000, Loss: 0.7107, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8884/10000, Loss: 0.7107, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8885/10000, Loss: 0.7106, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8886/10000, Loss: 0.7106, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8887/10000, Loss: 0.7106, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8888/10000, Loss: 0.7106, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8889/10000, Loss: 0.7105, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8890/10000, Loss: 0.7105, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8891/10000, Loss: 0.7105, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8892/10000, Loss: 0.7104, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8893/10000, Loss: 0.7104, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8894/10000, Loss: 0.7104, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8895/10000, Loss: 0.7104, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8896/10000, Loss: 0.7103, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8897/10000, Loss: 0.7103, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8898/10000, Loss: 0.7103, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8899/10000, Loss: 0.7102, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8900/10000, Loss: 0.7102, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8901/10000, Loss: 0.7102, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8902/10000, Loss: 0.7102, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8903/10000, Loss: 0.7101, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8904/10000, Loss: 0.7101, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8905/10000, Loss: 0.7101, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8906/10000, Loss: 0.7100, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8907/10000, Loss: 0.7100, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8908/10000, Loss: 0.7100, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8909/10000, Loss: 0.7100, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8910/10000, Loss: 0.7099, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8911/10000, Loss: 0.7099, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8912/10000, Loss: 0.7099, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8913/10000, Loss: 0.7098, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8914/10000, Loss: 0.7098, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8915/10000, Loss: 0.7098, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8916/10000, Loss: 0.7098, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8917/10000, Loss: 0.7097, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8918/10000, Loss: 0.7097, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8919/10000, Loss: 0.7097, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8920/10000, Loss: 0.7096, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8921/10000, Loss: 0.7096, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8922/10000, Loss: 0.7096, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8923/10000, Loss: 0.7096, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8924/10000, Loss: 0.7095, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8925/10000, Loss: 0.7095, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8926/10000, Loss: 0.7095, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8927/10000, Loss: 0.7094, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8928/10000, Loss: 0.7094, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8929/10000, Loss: 0.7094, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8930/10000, Loss: 0.7094, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8931/10000, Loss: 0.7093, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8932/10000, Loss: 0.7093, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8933/10000, Loss: 0.7093, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8934/10000, Loss: 0.7092, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8935/10000, Loss: 0.7092, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8936/10000, Loss: 0.7092, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8937/10000, Loss: 0.7092, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8938/10000, Loss: 0.7091, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8939/10000, Loss: 0.7091, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8940/10000, Loss: 0.7091, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8941/10000, Loss: 0.7090, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8942/10000, Loss: 0.7090, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8943/10000, Loss: 0.7090, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8944/10000, Loss: 0.7090, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8945/10000, Loss: 0.7089, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8946/10000, Loss: 0.7089, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8947/10000, Loss: 0.7089, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8948/10000, Loss: 0.7088, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8949/10000, Loss: 0.7088, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8950/10000, Loss: 0.7088, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8951/10000, Loss: 0.7088, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8952/10000, Loss: 0.7087, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8953/10000, Loss: 0.7087, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8954/10000, Loss: 0.7087, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8955/10000, Loss: 0.7086, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8956/10000, Loss: 0.7086, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8957/10000, Loss: 0.7086, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8958/10000, Loss: 0.7086, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8959/10000, Loss: 0.7085, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8960/10000, Loss: 0.7085, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8961/10000, Loss: 0.7085, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8962/10000, Loss: 0.7085, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8963/10000, Loss: 0.7084, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8964/10000, Loss: 0.7084, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8965/10000, Loss: 0.7084, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8966/10000, Loss: 0.7083, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8967/10000, Loss: 0.7083, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8968/10000, Loss: 0.7083, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8969/10000, Loss: 0.7083, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8970/10000, Loss: 0.7082, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8971/10000, Loss: 0.7082, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8972/10000, Loss: 0.7082, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8973/10000, Loss: 0.7081, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8974/10000, Loss: 0.7081, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8975/10000, Loss: 0.7081, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8976/10000, Loss: 0.7081, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8977/10000, Loss: 0.7080, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8978/10000, Loss: 0.7080, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8979/10000, Loss: 0.7080, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8980/10000, Loss: 0.7079, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8981/10000, Loss: 0.7079, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8982/10000, Loss: 0.7079, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8983/10000, Loss: 0.7079, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8984/10000, Loss: 0.7078, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8985/10000, Loss: 0.7078, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8986/10000, Loss: 0.7078, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8987/10000, Loss: 0.7077, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8988/10000, Loss: 0.7077, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8989/10000, Loss: 0.7077, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8990/10000, Loss: 0.7077, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8991/10000, Loss: 0.7076, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8992/10000, Loss: 0.7076, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8993/10000, Loss: 0.7076, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8994/10000, Loss: 0.7076, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8995/10000, Loss: 0.7075, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8996/10000, Loss: 0.7075, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8997/10000, Loss: 0.7075, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8998/10000, Loss: 0.7074, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 8999/10000, Loss: 0.7074, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9000/10000, Loss: 0.7074, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9001/10000, Loss: 0.7074, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9002/10000, Loss: 0.7073, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9003/10000, Loss: 0.7073, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9004/10000, Loss: 0.7073, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9005/10000, Loss: 0.7072, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9006/10000, Loss: 0.7072, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9007/10000, Loss: 0.7072, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9008/10000, Loss: 0.7072, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9009/10000, Loss: 0.7071, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9010/10000, Loss: 0.7071, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9011/10000, Loss: 0.7071, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9012/10000, Loss: 0.7070, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9013/10000, Loss: 0.7070, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9014/10000, Loss: 0.7070, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9015/10000, Loss: 0.7070, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9016/10000, Loss: 0.7069, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9017/10000, Loss: 0.7069, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9018/10000, Loss: 0.7069, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9019/10000, Loss: 0.7069, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9020/10000, Loss: 0.7068, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9021/10000, Loss: 0.7068, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9022/10000, Loss: 0.7068, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9023/10000, Loss: 0.7067, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9024/10000, Loss: 0.7067, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9025/10000, Loss: 0.7067, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9026/10000, Loss: 0.7067, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9027/10000, Loss: 0.7066, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9028/10000, Loss: 0.7066, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9029/10000, Loss: 0.7066, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9030/10000, Loss: 0.7065, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9031/10000, Loss: 0.7065, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9032/10000, Loss: 0.7065, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9033/10000, Loss: 0.7065, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9034/10000, Loss: 0.7064, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9035/10000, Loss: 0.7064, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9036/10000, Loss: 0.7064, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9037/10000, Loss: 0.7063, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9038/10000, Loss: 0.7063, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9039/10000, Loss: 0.7063, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9040/10000, Loss: 0.7063, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9041/10000, Loss: 0.7062, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9042/10000, Loss: 0.7062, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9043/10000, Loss: 0.7062, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9044/10000, Loss: 0.7062, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9045/10000, Loss: 0.7061, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9046/10000, Loss: 0.7061, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9047/10000, Loss: 0.7061, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9048/10000, Loss: 0.7060, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9049/10000, Loss: 0.7060, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9050/10000, Loss: 0.7060, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9051/10000, Loss: 0.7060, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9052/10000, Loss: 0.7059, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9053/10000, Loss: 0.7059, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9054/10000, Loss: 0.7059, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9055/10000, Loss: 0.7058, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9056/10000, Loss: 0.7058, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9057/10000, Loss: 0.7058, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9058/10000, Loss: 0.7058, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9059/10000, Loss: 0.7057, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9060/10000, Loss: 0.7057, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9061/10000, Loss: 0.7057, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9062/10000, Loss: 0.7057, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9063/10000, Loss: 0.7056, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9064/10000, Loss: 0.7056, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9065/10000, Loss: 0.7056, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9066/10000, Loss: 0.7055, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9067/10000, Loss: 0.7055, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9068/10000, Loss: 0.7055, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9069/10000, Loss: 0.7055, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9070/10000, Loss: 0.7054, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9071/10000, Loss: 0.7054, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9072/10000, Loss: 0.7054, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9073/10000, Loss: 0.7054, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9074/10000, Loss: 0.7053, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9075/10000, Loss: 0.7053, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9076/10000, Loss: 0.7053, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9077/10000, Loss: 0.7052, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9078/10000, Loss: 0.7052, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9079/10000, Loss: 0.7052, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9080/10000, Loss: 0.7052, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9081/10000, Loss: 0.7051, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9082/10000, Loss: 0.7051, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9083/10000, Loss: 0.7051, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9084/10000, Loss: 0.7050, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9085/10000, Loss: 0.7050, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9086/10000, Loss: 0.7050, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9087/10000, Loss: 0.7050, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9088/10000, Loss: 0.7049, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9089/10000, Loss: 0.7049, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9090/10000, Loss: 0.7049, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9091/10000, Loss: 0.7049, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9092/10000, Loss: 0.7048, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9093/10000, Loss: 0.7048, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9094/10000, Loss: 0.7048, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9095/10000, Loss: 0.7047, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9096/10000, Loss: 0.7047, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9097/10000, Loss: 0.7047, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9098/10000, Loss: 0.7047, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9099/10000, Loss: 0.7046, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9100/10000, Loss: 0.7046, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9101/10000, Loss: 0.7046, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9102/10000, Loss: 0.7046, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9103/10000, Loss: 0.7045, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9104/10000, Loss: 0.7045, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9105/10000, Loss: 0.7045, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9106/10000, Loss: 0.7044, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9107/10000, Loss: 0.7044, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9108/10000, Loss: 0.7044, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9109/10000, Loss: 0.7044, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9110/10000, Loss: 0.7043, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9111/10000, Loss: 0.7043, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9112/10000, Loss: 0.7043, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9113/10000, Loss: 0.7042, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9114/10000, Loss: 0.7042, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9115/10000, Loss: 0.7042, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9116/10000, Loss: 0.7042, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9117/10000, Loss: 0.7041, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9118/10000, Loss: 0.7041, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9119/10000, Loss: 0.7041, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9120/10000, Loss: 0.7041, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9121/10000, Loss: 0.7040, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9122/10000, Loss: 0.7040, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9123/10000, Loss: 0.7040, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9124/10000, Loss: 0.7039, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9125/10000, Loss: 0.7039, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9126/10000, Loss: 0.7039, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9127/10000, Loss: 0.7039, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9128/10000, Loss: 0.7038, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9129/10000, Loss: 0.7038, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9130/10000, Loss: 0.7038, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9131/10000, Loss: 0.7038, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9132/10000, Loss: 0.7037, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9133/10000, Loss: 0.7037, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9134/10000, Loss: 0.7037, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9135/10000, Loss: 0.7036, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9136/10000, Loss: 0.7036, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9137/10000, Loss: 0.7036, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9138/10000, Loss: 0.7036, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9139/10000, Loss: 0.7035, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9140/10000, Loss: 0.7035, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9141/10000, Loss: 0.7035, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9142/10000, Loss: 0.7035, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9143/10000, Loss: 0.7034, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9144/10000, Loss: 0.7034, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9145/10000, Loss: 0.7034, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9146/10000, Loss: 0.7033, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9147/10000, Loss: 0.7033, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9148/10000, Loss: 0.7033, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9149/10000, Loss: 0.7033, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9150/10000, Loss: 0.7032, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9151/10000, Loss: 0.7032, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9152/10000, Loss: 0.7032, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9153/10000, Loss: 0.7032, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9154/10000, Loss: 0.7031, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9155/10000, Loss: 0.7031, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9156/10000, Loss: 0.7031, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9157/10000, Loss: 0.7030, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9158/10000, Loss: 0.7030, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9159/10000, Loss: 0.7030, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9160/10000, Loss: 0.7030, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9161/10000, Loss: 0.7029, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9162/10000, Loss: 0.7029, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9163/10000, Loss: 0.7029, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9164/10000, Loss: 0.7029, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9165/10000, Loss: 0.7028, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9166/10000, Loss: 0.7028, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9167/10000, Loss: 0.7028, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9168/10000, Loss: 0.7027, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9169/10000, Loss: 0.7027, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9170/10000, Loss: 0.7027, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9171/10000, Loss: 0.7027, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9172/10000, Loss: 0.7026, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9173/10000, Loss: 0.7026, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9174/10000, Loss: 0.7026, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9175/10000, Loss: 0.7026, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9176/10000, Loss: 0.7025, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9177/10000, Loss: 0.7025, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9178/10000, Loss: 0.7025, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9179/10000, Loss: 0.7025, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9180/10000, Loss: 0.7024, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9181/10000, Loss: 0.7024, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9182/10000, Loss: 0.7024, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9183/10000, Loss: 0.7023, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9184/10000, Loss: 0.7023, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9185/10000, Loss: 0.7023, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9186/10000, Loss: 0.7023, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9187/10000, Loss: 0.7022, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9188/10000, Loss: 0.7022, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9189/10000, Loss: 0.7022, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9190/10000, Loss: 0.7022, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9191/10000, Loss: 0.7021, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9192/10000, Loss: 0.7021, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9193/10000, Loss: 0.7021, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9194/10000, Loss: 0.7020, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9195/10000, Loss: 0.7020, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9196/10000, Loss: 0.7020, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9197/10000, Loss: 0.7020, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9198/10000, Loss: 0.7019, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9199/10000, Loss: 0.7019, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9200/10000, Loss: 0.7019, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9201/10000, Loss: 0.7019, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9202/10000, Loss: 0.7018, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9203/10000, Loss: 0.7018, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9204/10000, Loss: 0.7018, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9205/10000, Loss: 0.7017, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9206/10000, Loss: 0.7017, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9207/10000, Loss: 0.7017, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9208/10000, Loss: 0.7017, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9209/10000, Loss: 0.7016, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9210/10000, Loss: 0.7016, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9211/10000, Loss: 0.7016, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9212/10000, Loss: 0.7016, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9213/10000, Loss: 0.7015, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9214/10000, Loss: 0.7015, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9215/10000, Loss: 0.7015, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9216/10000, Loss: 0.7015, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9217/10000, Loss: 0.7014, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9218/10000, Loss: 0.7014, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9219/10000, Loss: 0.7014, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9220/10000, Loss: 0.7013, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9221/10000, Loss: 0.7013, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9222/10000, Loss: 0.7013, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9223/10000, Loss: 0.7013, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9224/10000, Loss: 0.7012, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9225/10000, Loss: 0.7012, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9226/10000, Loss: 0.7012, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9227/10000, Loss: 0.7012, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9228/10000, Loss: 0.7011, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9229/10000, Loss: 0.7011, Accuracy: 0.6923, Learning Rate: 0.000100\n",
      "Epoch 9230/10000, Loss: 0.7011, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9231/10000, Loss: 0.7010, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9232/10000, Loss: 0.7010, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9233/10000, Loss: 0.7010, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9234/10000, Loss: 0.7010, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9235/10000, Loss: 0.7009, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9236/10000, Loss: 0.7009, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9237/10000, Loss: 0.7009, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9238/10000, Loss: 0.7009, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9239/10000, Loss: 0.7008, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9240/10000, Loss: 0.7008, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9241/10000, Loss: 0.7008, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9242/10000, Loss: 0.7008, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9243/10000, Loss: 0.7007, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9244/10000, Loss: 0.7007, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9245/10000, Loss: 0.7007, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9246/10000, Loss: 0.7006, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9247/10000, Loss: 0.7006, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9248/10000, Loss: 0.7006, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9249/10000, Loss: 0.7006, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9250/10000, Loss: 0.7005, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9251/10000, Loss: 0.7005, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9252/10000, Loss: 0.7005, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9253/10000, Loss: 0.7005, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9254/10000, Loss: 0.7004, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9255/10000, Loss: 0.7004, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9256/10000, Loss: 0.7004, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9257/10000, Loss: 0.7004, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9258/10000, Loss: 0.7003, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9259/10000, Loss: 0.7003, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9260/10000, Loss: 0.7003, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9261/10000, Loss: 0.7002, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9262/10000, Loss: 0.7002, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9263/10000, Loss: 0.7002, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9264/10000, Loss: 0.7002, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9265/10000, Loss: 0.7001, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9266/10000, Loss: 0.7001, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9267/10000, Loss: 0.7001, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9268/10000, Loss: 0.7001, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9269/10000, Loss: 0.7000, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9270/10000, Loss: 0.7000, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9271/10000, Loss: 0.7000, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9272/10000, Loss: 0.7000, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9273/10000, Loss: 0.6999, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9274/10000, Loss: 0.6999, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9275/10000, Loss: 0.6999, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9276/10000, Loss: 0.6998, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9277/10000, Loss: 0.6998, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9278/10000, Loss: 0.6998, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9279/10000, Loss: 0.6998, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9280/10000, Loss: 0.6997, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9281/10000, Loss: 0.6997, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9282/10000, Loss: 0.6997, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9283/10000, Loss: 0.6997, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9284/10000, Loss: 0.6996, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9285/10000, Loss: 0.6996, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9286/10000, Loss: 0.6996, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9287/10000, Loss: 0.6996, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9288/10000, Loss: 0.6995, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9289/10000, Loss: 0.6995, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9290/10000, Loss: 0.6995, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9291/10000, Loss: 0.6995, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9292/10000, Loss: 0.6994, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9293/10000, Loss: 0.6994, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9294/10000, Loss: 0.6994, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9295/10000, Loss: 0.6993, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9296/10000, Loss: 0.6993, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9297/10000, Loss: 0.6993, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9298/10000, Loss: 0.6993, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9299/10000, Loss: 0.6992, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9300/10000, Loss: 0.6992, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9301/10000, Loss: 0.6992, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9302/10000, Loss: 0.6992, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9303/10000, Loss: 0.6991, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9304/10000, Loss: 0.6991, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9305/10000, Loss: 0.6991, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9306/10000, Loss: 0.6991, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9307/10000, Loss: 0.6990, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9308/10000, Loss: 0.6990, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9309/10000, Loss: 0.6990, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9310/10000, Loss: 0.6989, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9311/10000, Loss: 0.6989, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9312/10000, Loss: 0.6989, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9313/10000, Loss: 0.6989, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9314/10000, Loss: 0.6988, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9315/10000, Loss: 0.6988, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9316/10000, Loss: 0.6988, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9317/10000, Loss: 0.6988, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9318/10000, Loss: 0.6987, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9319/10000, Loss: 0.6987, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9320/10000, Loss: 0.6987, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9321/10000, Loss: 0.6987, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9322/10000, Loss: 0.6986, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9323/10000, Loss: 0.6986, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9324/10000, Loss: 0.6986, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9325/10000, Loss: 0.6986, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9326/10000, Loss: 0.6985, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9327/10000, Loss: 0.6985, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9328/10000, Loss: 0.6985, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9329/10000, Loss: 0.6984, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9330/10000, Loss: 0.6984, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9331/10000, Loss: 0.6984, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9332/10000, Loss: 0.6984, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9333/10000, Loss: 0.6983, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9334/10000, Loss: 0.6983, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9335/10000, Loss: 0.6983, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9336/10000, Loss: 0.6983, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9337/10000, Loss: 0.6982, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9338/10000, Loss: 0.6982, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9339/10000, Loss: 0.6982, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9340/10000, Loss: 0.6982, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9341/10000, Loss: 0.6981, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9342/10000, Loss: 0.6981, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9343/10000, Loss: 0.6981, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9344/10000, Loss: 0.6981, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9345/10000, Loss: 0.6980, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9346/10000, Loss: 0.6980, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9347/10000, Loss: 0.6980, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9348/10000, Loss: 0.6979, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9349/10000, Loss: 0.6979, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9350/10000, Loss: 0.6979, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9351/10000, Loss: 0.6979, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9352/10000, Loss: 0.6978, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9353/10000, Loss: 0.6978, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9354/10000, Loss: 0.6978, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9355/10000, Loss: 0.6978, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9356/10000, Loss: 0.6977, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9357/10000, Loss: 0.6977, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9358/10000, Loss: 0.6977, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9359/10000, Loss: 0.6977, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9360/10000, Loss: 0.6976, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9361/10000, Loss: 0.6976, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9362/10000, Loss: 0.6976, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9363/10000, Loss: 0.6976, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9364/10000, Loss: 0.6975, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9365/10000, Loss: 0.6975, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9366/10000, Loss: 0.6975, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9367/10000, Loss: 0.6975, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9368/10000, Loss: 0.6974, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9369/10000, Loss: 0.6974, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9370/10000, Loss: 0.6974, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9371/10000, Loss: 0.6973, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9372/10000, Loss: 0.6973, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9373/10000, Loss: 0.6973, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9374/10000, Loss: 0.6973, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9375/10000, Loss: 0.6972, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9376/10000, Loss: 0.6972, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9377/10000, Loss: 0.6972, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9378/10000, Loss: 0.6972, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9379/10000, Loss: 0.6971, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9380/10000, Loss: 0.6971, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9381/10000, Loss: 0.6971, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9382/10000, Loss: 0.6971, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9383/10000, Loss: 0.6970, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9384/10000, Loss: 0.6970, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9385/10000, Loss: 0.6970, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9386/10000, Loss: 0.6970, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9387/10000, Loss: 0.6969, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9388/10000, Loss: 0.6969, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9389/10000, Loss: 0.6969, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9390/10000, Loss: 0.6969, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9391/10000, Loss: 0.6968, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9392/10000, Loss: 0.6968, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9393/10000, Loss: 0.6968, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9394/10000, Loss: 0.6968, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9395/10000, Loss: 0.6967, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9396/10000, Loss: 0.6967, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9397/10000, Loss: 0.6967, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9398/10000, Loss: 0.6966, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9399/10000, Loss: 0.6966, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9400/10000, Loss: 0.6966, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9401/10000, Loss: 0.6966, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9402/10000, Loss: 0.6965, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9403/10000, Loss: 0.6965, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9404/10000, Loss: 0.6965, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9405/10000, Loss: 0.6965, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9406/10000, Loss: 0.6964, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9407/10000, Loss: 0.6964, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9408/10000, Loss: 0.6964, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9409/10000, Loss: 0.6964, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9410/10000, Loss: 0.6963, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9411/10000, Loss: 0.6963, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9412/10000, Loss: 0.6963, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9413/10000, Loss: 0.6963, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9414/10000, Loss: 0.6962, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9415/10000, Loss: 0.6962, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9416/10000, Loss: 0.6962, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9417/10000, Loss: 0.6962, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9418/10000, Loss: 0.6961, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9419/10000, Loss: 0.6961, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9420/10000, Loss: 0.6961, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9421/10000, Loss: 0.6961, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9422/10000, Loss: 0.6960, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9423/10000, Loss: 0.6960, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9424/10000, Loss: 0.6960, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9425/10000, Loss: 0.6959, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9426/10000, Loss: 0.6959, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9427/10000, Loss: 0.6959, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9428/10000, Loss: 0.6959, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9429/10000, Loss: 0.6958, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9430/10000, Loss: 0.6958, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9431/10000, Loss: 0.6958, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9432/10000, Loss: 0.6958, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9433/10000, Loss: 0.6957, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9434/10000, Loss: 0.6957, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9435/10000, Loss: 0.6957, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9436/10000, Loss: 0.6957, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9437/10000, Loss: 0.6956, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9438/10000, Loss: 0.6956, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9439/10000, Loss: 0.6956, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9440/10000, Loss: 0.6956, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9441/10000, Loss: 0.6955, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9442/10000, Loss: 0.6955, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9443/10000, Loss: 0.6955, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9444/10000, Loss: 0.6955, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9445/10000, Loss: 0.6954, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9446/10000, Loss: 0.6954, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9447/10000, Loss: 0.6954, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9448/10000, Loss: 0.6954, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9449/10000, Loss: 0.6953, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9450/10000, Loss: 0.6953, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9451/10000, Loss: 0.6953, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9452/10000, Loss: 0.6953, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9453/10000, Loss: 0.6952, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9454/10000, Loss: 0.6952, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9455/10000, Loss: 0.6952, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9456/10000, Loss: 0.6952, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9457/10000, Loss: 0.6951, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9458/10000, Loss: 0.6951, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9459/10000, Loss: 0.6951, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9460/10000, Loss: 0.6950, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9461/10000, Loss: 0.6950, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9462/10000, Loss: 0.6950, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9463/10000, Loss: 0.6950, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9464/10000, Loss: 0.6949, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9465/10000, Loss: 0.6949, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9466/10000, Loss: 0.6949, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9467/10000, Loss: 0.6949, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9468/10000, Loss: 0.6948, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9469/10000, Loss: 0.6948, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9470/10000, Loss: 0.6948, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9471/10000, Loss: 0.6948, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9472/10000, Loss: 0.6947, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9473/10000, Loss: 0.6947, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9474/10000, Loss: 0.6947, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9475/10000, Loss: 0.6947, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9476/10000, Loss: 0.6946, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9477/10000, Loss: 0.6946, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9478/10000, Loss: 0.6946, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9479/10000, Loss: 0.6946, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9480/10000, Loss: 0.6945, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9481/10000, Loss: 0.6945, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9482/10000, Loss: 0.6945, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9483/10000, Loss: 0.6945, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9484/10000, Loss: 0.6944, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9485/10000, Loss: 0.6944, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9486/10000, Loss: 0.6944, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9487/10000, Loss: 0.6944, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9488/10000, Loss: 0.6943, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9489/10000, Loss: 0.6943, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9490/10000, Loss: 0.6943, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9491/10000, Loss: 0.6943, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9492/10000, Loss: 0.6942, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9493/10000, Loss: 0.6942, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9494/10000, Loss: 0.6942, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9495/10000, Loss: 0.6942, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9496/10000, Loss: 0.6941, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9497/10000, Loss: 0.6941, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9498/10000, Loss: 0.6941, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9499/10000, Loss: 0.6941, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9500/10000, Loss: 0.6940, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9501/10000, Loss: 0.6940, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9502/10000, Loss: 0.6940, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9503/10000, Loss: 0.6940, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9504/10000, Loss: 0.6939, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9505/10000, Loss: 0.6939, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9506/10000, Loss: 0.6939, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9507/10000, Loss: 0.6938, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9508/10000, Loss: 0.6938, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9509/10000, Loss: 0.6938, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9510/10000, Loss: 0.6938, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9511/10000, Loss: 0.6937, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9512/10000, Loss: 0.6937, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9513/10000, Loss: 0.6937, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9514/10000, Loss: 0.6937, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9515/10000, Loss: 0.6936, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9516/10000, Loss: 0.6936, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9517/10000, Loss: 0.6936, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9518/10000, Loss: 0.6936, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9519/10000, Loss: 0.6935, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9520/10000, Loss: 0.6935, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9521/10000, Loss: 0.6935, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9522/10000, Loss: 0.6935, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9523/10000, Loss: 0.6934, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9524/10000, Loss: 0.6934, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9525/10000, Loss: 0.6934, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9526/10000, Loss: 0.6934, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9527/10000, Loss: 0.6933, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9528/10000, Loss: 0.6933, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9529/10000, Loss: 0.6933, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9530/10000, Loss: 0.6933, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9531/10000, Loss: 0.6932, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9532/10000, Loss: 0.6932, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9533/10000, Loss: 0.6932, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9534/10000, Loss: 0.6932, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9535/10000, Loss: 0.6931, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9536/10000, Loss: 0.6931, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9537/10000, Loss: 0.6931, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9538/10000, Loss: 0.6931, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9539/10000, Loss: 0.6930, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9540/10000, Loss: 0.6930, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9541/10000, Loss: 0.6930, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9542/10000, Loss: 0.6930, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9543/10000, Loss: 0.6929, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9544/10000, Loss: 0.6929, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9545/10000, Loss: 0.6929, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9546/10000, Loss: 0.6929, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9547/10000, Loss: 0.6928, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9548/10000, Loss: 0.6928, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9549/10000, Loss: 0.6928, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9550/10000, Loss: 0.6928, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9551/10000, Loss: 0.6927, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9552/10000, Loss: 0.6927, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9553/10000, Loss: 0.6927, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9554/10000, Loss: 0.6927, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9555/10000, Loss: 0.6926, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9556/10000, Loss: 0.6926, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9557/10000, Loss: 0.6926, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9558/10000, Loss: 0.6926, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9559/10000, Loss: 0.6925, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9560/10000, Loss: 0.6925, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9561/10000, Loss: 0.6925, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9562/10000, Loss: 0.6925, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9563/10000, Loss: 0.6924, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9564/10000, Loss: 0.6924, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9565/10000, Loss: 0.6924, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9566/10000, Loss: 0.6924, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9567/10000, Loss: 0.6923, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9568/10000, Loss: 0.6923, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9569/10000, Loss: 0.6923, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9570/10000, Loss: 0.6923, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9571/10000, Loss: 0.6922, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9572/10000, Loss: 0.6922, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9573/10000, Loss: 0.6922, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9574/10000, Loss: 0.6922, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9575/10000, Loss: 0.6921, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9576/10000, Loss: 0.6921, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9577/10000, Loss: 0.6921, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9578/10000, Loss: 0.6921, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9579/10000, Loss: 0.6920, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9580/10000, Loss: 0.6920, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9581/10000, Loss: 0.6920, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9582/10000, Loss: 0.6920, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9583/10000, Loss: 0.6919, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9584/10000, Loss: 0.6919, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9585/10000, Loss: 0.6919, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9586/10000, Loss: 0.6919, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9587/10000, Loss: 0.6918, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9588/10000, Loss: 0.6918, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9589/10000, Loss: 0.6918, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9590/10000, Loss: 0.6918, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9591/10000, Loss: 0.6917, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9592/10000, Loss: 0.6917, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9593/10000, Loss: 0.6917, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9594/10000, Loss: 0.6917, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9595/10000, Loss: 0.6916, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9596/10000, Loss: 0.6916, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9597/10000, Loss: 0.6916, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9598/10000, Loss: 0.6916, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9599/10000, Loss: 0.6915, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9600/10000, Loss: 0.6915, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9601/10000, Loss: 0.6915, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9602/10000, Loss: 0.6915, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9603/10000, Loss: 0.6914, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9604/10000, Loss: 0.6914, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9605/10000, Loss: 0.6914, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9606/10000, Loss: 0.6914, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9607/10000, Loss: 0.6913, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9608/10000, Loss: 0.6913, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9609/10000, Loss: 0.6913, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9610/10000, Loss: 0.6913, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9611/10000, Loss: 0.6912, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9612/10000, Loss: 0.6912, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9613/10000, Loss: 0.6912, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9614/10000, Loss: 0.6912, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9615/10000, Loss: 0.6911, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9616/10000, Loss: 0.6911, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9617/10000, Loss: 0.6911, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9618/10000, Loss: 0.6911, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9619/10000, Loss: 0.6910, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9620/10000, Loss: 0.6910, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9621/10000, Loss: 0.6910, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9622/10000, Loss: 0.6910, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9623/10000, Loss: 0.6909, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9624/10000, Loss: 0.6909, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9625/10000, Loss: 0.6909, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9626/10000, Loss: 0.6909, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9627/10000, Loss: 0.6908, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9628/10000, Loss: 0.6908, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9629/10000, Loss: 0.6908, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9630/10000, Loss: 0.6908, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9631/10000, Loss: 0.6907, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9632/10000, Loss: 0.6907, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9633/10000, Loss: 0.6907, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9634/10000, Loss: 0.6907, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9635/10000, Loss: 0.6906, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9636/10000, Loss: 0.6906, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9637/10000, Loss: 0.6906, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9638/10000, Loss: 0.6906, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9639/10000, Loss: 0.6905, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9640/10000, Loss: 0.6905, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9641/10000, Loss: 0.6905, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9642/10000, Loss: 0.6905, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9643/10000, Loss: 0.6904, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9644/10000, Loss: 0.6904, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9645/10000, Loss: 0.6904, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9646/10000, Loss: 0.6904, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9647/10000, Loss: 0.6903, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9648/10000, Loss: 0.6903, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9649/10000, Loss: 0.6903, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9650/10000, Loss: 0.6903, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9651/10000, Loss: 0.6902, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9652/10000, Loss: 0.6902, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9653/10000, Loss: 0.6902, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9654/10000, Loss: 0.6902, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9655/10000, Loss: 0.6901, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9656/10000, Loss: 0.6901, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9657/10000, Loss: 0.6901, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9658/10000, Loss: 0.6901, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9659/10000, Loss: 0.6901, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9660/10000, Loss: 0.6900, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9661/10000, Loss: 0.6900, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9662/10000, Loss: 0.6900, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9663/10000, Loss: 0.6900, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9664/10000, Loss: 0.6899, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9665/10000, Loss: 0.6899, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9666/10000, Loss: 0.6899, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9667/10000, Loss: 0.6899, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9668/10000, Loss: 0.6898, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9669/10000, Loss: 0.6898, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9670/10000, Loss: 0.6898, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9671/10000, Loss: 0.6898, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9672/10000, Loss: 0.6897, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9673/10000, Loss: 0.6897, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9674/10000, Loss: 0.6897, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9675/10000, Loss: 0.6897, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9676/10000, Loss: 0.6896, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9677/10000, Loss: 0.6896, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9678/10000, Loss: 0.6896, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9679/10000, Loss: 0.6896, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9680/10000, Loss: 0.6895, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9681/10000, Loss: 0.6895, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9682/10000, Loss: 0.6895, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9683/10000, Loss: 0.6895, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9684/10000, Loss: 0.6894, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9685/10000, Loss: 0.6894, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9686/10000, Loss: 0.6894, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9687/10000, Loss: 0.6894, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9688/10000, Loss: 0.6893, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9689/10000, Loss: 0.6893, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9690/10000, Loss: 0.6893, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9691/10000, Loss: 0.6893, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9692/10000, Loss: 0.6892, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9693/10000, Loss: 0.6892, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9694/10000, Loss: 0.6892, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9695/10000, Loss: 0.6892, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9696/10000, Loss: 0.6891, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9697/10000, Loss: 0.6891, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9698/10000, Loss: 0.6891, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9699/10000, Loss: 0.6891, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9700/10000, Loss: 0.6890, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9701/10000, Loss: 0.6890, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9702/10000, Loss: 0.6890, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9703/10000, Loss: 0.6890, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9704/10000, Loss: 0.6889, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9705/10000, Loss: 0.6889, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9706/10000, Loss: 0.6889, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9707/10000, Loss: 0.6889, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9708/10000, Loss: 0.6889, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9709/10000, Loss: 0.6888, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9710/10000, Loss: 0.6888, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9711/10000, Loss: 0.6888, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9712/10000, Loss: 0.6888, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9713/10000, Loss: 0.6887, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9714/10000, Loss: 0.6887, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9715/10000, Loss: 0.6887, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9716/10000, Loss: 0.6887, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9717/10000, Loss: 0.6886, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9718/10000, Loss: 0.6886, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9719/10000, Loss: 0.6886, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9720/10000, Loss: 0.6886, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9721/10000, Loss: 0.6885, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9722/10000, Loss: 0.6885, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9723/10000, Loss: 0.6885, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9724/10000, Loss: 0.6885, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9725/10000, Loss: 0.6884, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9726/10000, Loss: 0.6884, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9727/10000, Loss: 0.6884, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9728/10000, Loss: 0.6884, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9729/10000, Loss: 0.6883, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9730/10000, Loss: 0.6883, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9731/10000, Loss: 0.6883, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9732/10000, Loss: 0.6883, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9733/10000, Loss: 0.6882, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9734/10000, Loss: 0.6882, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9735/10000, Loss: 0.6882, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9736/10000, Loss: 0.6882, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9737/10000, Loss: 0.6881, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9738/10000, Loss: 0.6881, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9739/10000, Loss: 0.6881, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9740/10000, Loss: 0.6881, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9741/10000, Loss: 0.6880, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9742/10000, Loss: 0.6880, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9743/10000, Loss: 0.6880, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9744/10000, Loss: 0.6880, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9745/10000, Loss: 0.6880, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9746/10000, Loss: 0.6879, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9747/10000, Loss: 0.6879, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9748/10000, Loss: 0.6879, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9749/10000, Loss: 0.6879, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9750/10000, Loss: 0.6878, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9751/10000, Loss: 0.6878, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9752/10000, Loss: 0.6878, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9753/10000, Loss: 0.6878, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9754/10000, Loss: 0.6877, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9755/10000, Loss: 0.6877, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9756/10000, Loss: 0.6877, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9757/10000, Loss: 0.6877, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9758/10000, Loss: 0.6876, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9759/10000, Loss: 0.6876, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9760/10000, Loss: 0.6876, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9761/10000, Loss: 0.6876, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9762/10000, Loss: 0.6875, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9763/10000, Loss: 0.6875, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9764/10000, Loss: 0.6875, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9765/10000, Loss: 0.6875, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9766/10000, Loss: 0.6874, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9767/10000, Loss: 0.6874, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9768/10000, Loss: 0.6874, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9769/10000, Loss: 0.6874, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9770/10000, Loss: 0.6873, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9771/10000, Loss: 0.6873, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9772/10000, Loss: 0.6873, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9773/10000, Loss: 0.6873, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9774/10000, Loss: 0.6873, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9775/10000, Loss: 0.6872, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9776/10000, Loss: 0.6872, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9777/10000, Loss: 0.6872, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9778/10000, Loss: 0.6872, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9779/10000, Loss: 0.6871, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9780/10000, Loss: 0.6871, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9781/10000, Loss: 0.6871, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9782/10000, Loss: 0.6871, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9783/10000, Loss: 0.6870, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9784/10000, Loss: 0.6870, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9785/10000, Loss: 0.6870, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9786/10000, Loss: 0.6870, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9787/10000, Loss: 0.6869, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9788/10000, Loss: 0.6869, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9789/10000, Loss: 0.6869, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9790/10000, Loss: 0.6869, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9791/10000, Loss: 0.6868, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9792/10000, Loss: 0.6868, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9793/10000, Loss: 0.6868, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9794/10000, Loss: 0.6868, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9795/10000, Loss: 0.6867, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9796/10000, Loss: 0.6867, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9797/10000, Loss: 0.6867, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9798/10000, Loss: 0.6867, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9799/10000, Loss: 0.6867, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9800/10000, Loss: 0.6866, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9801/10000, Loss: 0.6866, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9802/10000, Loss: 0.6866, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9803/10000, Loss: 0.6866, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9804/10000, Loss: 0.6865, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9805/10000, Loss: 0.6865, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9806/10000, Loss: 0.6865, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9807/10000, Loss: 0.6865, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9808/10000, Loss: 0.6864, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9809/10000, Loss: 0.6864, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9810/10000, Loss: 0.6864, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9811/10000, Loss: 0.6864, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9812/10000, Loss: 0.6863, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9813/10000, Loss: 0.6863, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9814/10000, Loss: 0.6863, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9815/10000, Loss: 0.6863, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9816/10000, Loss: 0.6862, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9817/10000, Loss: 0.6862, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9818/10000, Loss: 0.6862, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9819/10000, Loss: 0.6862, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9820/10000, Loss: 0.6862, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9821/10000, Loss: 0.6861, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9822/10000, Loss: 0.6861, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9823/10000, Loss: 0.6861, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9824/10000, Loss: 0.6861, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9825/10000, Loss: 0.6860, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9826/10000, Loss: 0.6860, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9827/10000, Loss: 0.6860, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9828/10000, Loss: 0.6860, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9829/10000, Loss: 0.6859, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9830/10000, Loss: 0.6859, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9831/10000, Loss: 0.6859, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9832/10000, Loss: 0.6859, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9833/10000, Loss: 0.6858, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9834/10000, Loss: 0.6858, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9835/10000, Loss: 0.6858, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9836/10000, Loss: 0.6858, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9837/10000, Loss: 0.6857, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9838/10000, Loss: 0.6857, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9839/10000, Loss: 0.6857, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9840/10000, Loss: 0.6857, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9841/10000, Loss: 0.6857, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9842/10000, Loss: 0.6856, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9843/10000, Loss: 0.6856, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9844/10000, Loss: 0.6856, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9845/10000, Loss: 0.6856, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9846/10000, Loss: 0.6855, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9847/10000, Loss: 0.6855, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9848/10000, Loss: 0.6855, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9849/10000, Loss: 0.6855, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9850/10000, Loss: 0.6854, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9851/10000, Loss: 0.6854, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9852/10000, Loss: 0.6854, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9853/10000, Loss: 0.6854, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9854/10000, Loss: 0.6853, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9855/10000, Loss: 0.6853, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9856/10000, Loss: 0.6853, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9857/10000, Loss: 0.6853, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9858/10000, Loss: 0.6853, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9859/10000, Loss: 0.6852, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9860/10000, Loss: 0.6852, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9861/10000, Loss: 0.6852, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9862/10000, Loss: 0.6852, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9863/10000, Loss: 0.6851, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9864/10000, Loss: 0.6851, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9865/10000, Loss: 0.6851, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9866/10000, Loss: 0.6851, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9867/10000, Loss: 0.6850, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9868/10000, Loss: 0.6850, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9869/10000, Loss: 0.6850, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9870/10000, Loss: 0.6850, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9871/10000, Loss: 0.6849, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9872/10000, Loss: 0.6849, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9873/10000, Loss: 0.6849, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9874/10000, Loss: 0.6849, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9875/10000, Loss: 0.6849, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9876/10000, Loss: 0.6848, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9877/10000, Loss: 0.6848, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9878/10000, Loss: 0.6848, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9879/10000, Loss: 0.6848, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9880/10000, Loss: 0.6847, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9881/10000, Loss: 0.6847, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9882/10000, Loss: 0.6847, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9883/10000, Loss: 0.6847, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9884/10000, Loss: 0.6846, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9885/10000, Loss: 0.6846, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9886/10000, Loss: 0.6846, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9887/10000, Loss: 0.6846, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9888/10000, Loss: 0.6845, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9889/10000, Loss: 0.6845, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9890/10000, Loss: 0.6845, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9891/10000, Loss: 0.6845, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9892/10000, Loss: 0.6845, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9893/10000, Loss: 0.6844, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9894/10000, Loss: 0.6844, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9895/10000, Loss: 0.6844, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9896/10000, Loss: 0.6844, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9897/10000, Loss: 0.6843, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9898/10000, Loss: 0.6843, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9899/10000, Loss: 0.6843, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9900/10000, Loss: 0.6843, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9901/10000, Loss: 0.6842, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9902/10000, Loss: 0.6842, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9903/10000, Loss: 0.6842, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9904/10000, Loss: 0.6842, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9905/10000, Loss: 0.6841, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9906/10000, Loss: 0.6841, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9907/10000, Loss: 0.6841, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9908/10000, Loss: 0.6841, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9909/10000, Loss: 0.6841, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9910/10000, Loss: 0.6840, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9911/10000, Loss: 0.6840, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9912/10000, Loss: 0.6840, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9913/10000, Loss: 0.6840, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9914/10000, Loss: 0.6839, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9915/10000, Loss: 0.6839, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9916/10000, Loss: 0.6839, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9917/10000, Loss: 0.6839, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9918/10000, Loss: 0.6838, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9919/10000, Loss: 0.6838, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9920/10000, Loss: 0.6838, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9921/10000, Loss: 0.6838, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9922/10000, Loss: 0.6838, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9923/10000, Loss: 0.6837, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9924/10000, Loss: 0.6837, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9925/10000, Loss: 0.6837, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9926/10000, Loss: 0.6837, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9927/10000, Loss: 0.6836, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9928/10000, Loss: 0.6836, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9929/10000, Loss: 0.6836, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9930/10000, Loss: 0.6836, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9931/10000, Loss: 0.6835, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9932/10000, Loss: 0.6835, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9933/10000, Loss: 0.6835, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9934/10000, Loss: 0.6835, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9935/10000, Loss: 0.6834, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9936/10000, Loss: 0.6834, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9937/10000, Loss: 0.6834, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9938/10000, Loss: 0.6834, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9939/10000, Loss: 0.6834, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9940/10000, Loss: 0.6833, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9941/10000, Loss: 0.6833, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9942/10000, Loss: 0.6833, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9943/10000, Loss: 0.6833, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9944/10000, Loss: 0.6832, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9945/10000, Loss: 0.6832, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9946/10000, Loss: 0.6832, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9947/10000, Loss: 0.6832, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9948/10000, Loss: 0.6831, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9949/10000, Loss: 0.6831, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9950/10000, Loss: 0.6831, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9951/10000, Loss: 0.6831, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9952/10000, Loss: 0.6831, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9953/10000, Loss: 0.6830, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9954/10000, Loss: 0.6830, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9955/10000, Loss: 0.6830, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9956/10000, Loss: 0.6830, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9957/10000, Loss: 0.6829, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9958/10000, Loss: 0.6829, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9959/10000, Loss: 0.6829, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9960/10000, Loss: 0.6829, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9961/10000, Loss: 0.6828, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9962/10000, Loss: 0.6828, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9963/10000, Loss: 0.6828, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9964/10000, Loss: 0.6828, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9965/10000, Loss: 0.6828, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9966/10000, Loss: 0.6827, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9967/10000, Loss: 0.6827, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9968/10000, Loss: 0.6827, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9969/10000, Loss: 0.6827, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9970/10000, Loss: 0.6826, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9971/10000, Loss: 0.6826, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9972/10000, Loss: 0.6826, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9973/10000, Loss: 0.6826, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9974/10000, Loss: 0.6825, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9975/10000, Loss: 0.6825, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9976/10000, Loss: 0.6825, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9977/10000, Loss: 0.6825, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9978/10000, Loss: 0.6825, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9979/10000, Loss: 0.6824, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9980/10000, Loss: 0.6824, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9981/10000, Loss: 0.6824, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9982/10000, Loss: 0.6824, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9983/10000, Loss: 0.6823, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9984/10000, Loss: 0.6823, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9985/10000, Loss: 0.6823, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9986/10000, Loss: 0.6823, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9987/10000, Loss: 0.6822, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9988/10000, Loss: 0.6822, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9989/10000, Loss: 0.6822, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9990/10000, Loss: 0.6822, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9991/10000, Loss: 0.6822, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9992/10000, Loss: 0.6821, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9993/10000, Loss: 0.6821, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9994/10000, Loss: 0.6821, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9995/10000, Loss: 0.6821, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9996/10000, Loss: 0.6820, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9997/10000, Loss: 0.6820, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9998/10000, Loss: 0.6820, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 9999/10000, Loss: 0.6820, Accuracy: 0.6795, Learning Rate: 0.000100\n",
      "Epoch 10000/10000, Loss: 0.6819, Accuracy: 0.6795, Learning Rate: 0.000100\n"
     ]
    }
   ],
   "source": [
    "# training on validation dataset\n",
    "lr.fit(val_x,val_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "ebee4146-929f-4f6c-b3d4-b45b2a1f8243",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#validation loss vs validation accuracy\n",
    "\n",
    "lr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8b4c36-e793-4f03-b389-55cb15f38cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3389a4-6de5-4827-9c57-70336282f213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66da3956-2b67-451a-8da0-a83fdd4e79b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
